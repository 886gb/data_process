开始统计文件行数...
0it [00:00, ?it/s]1it [00:10, 10.78s/it]388it [00:10, 50.66it/s]1453it [00:11, 244.15it/s]2518it [00:11, 507.08it/s]3946it [00:11, 988.32it/s]5106it [00:11, 1491.45it/s]6494it [00:11, 2278.34it/s]7679it [00:11, 2907.83it/s]9059it [00:11, 4008.14it/s]10463it [00:11, 5273.47it/s]11792it [00:11, 6491.39it/s]13158it [00:11, 7772.46it/s]14577it [00:12, 9073.08it/s]15903it [00:12, 8807.96it/s]17286it [00:12, 9915.11it/s]18659it [00:12, 10826.19it/s]20071it [00:12, 11665.27it/s]21465it [00:12, 12265.95it/s]22805it [00:12, 10773.03it/s]24177it [00:12, 11510.15it/s]25574it [00:13, 12160.26it/s]27054it [00:13, 12880.81it/s]28494it [00:13, 13307.05it/s]30033it [00:13, 13898.96it/s]31456it [00:13, 13987.27it/s]32894it [00:13, 14099.20it/s]34321it [00:13, 13992.91it/s]35732it [00:13, 13303.74it/s]37185it [00:13, 13643.48it/s]38814it [00:13, 14408.57it/s]40267it [00:14, 14216.45it/s]41697it [00:14, 14195.47it/s]43123it [00:14, 14135.72it/s]44541it [00:14, 13799.20it/s]46035it [00:14, 14130.26it/s]47596it [00:14, 14556.55it/s]49081it [00:14, 14639.70it/s]50548it [00:14, 14303.61it/s]51982it [00:14, 14198.94it/s]53405it [00:14, 14030.94it/s]54810it [00:15, 13844.61it/s]56196it [00:15, 13733.16it/s]57591it [00:15, 13786.10it/s]58993it [00:15, 13845.84it/s]60379it [00:15, 13755.09it/s]61755it [00:15, 13694.12it/s]63161it [00:15, 13791.91it/s]64618it [00:15, 14022.68it/s]66021it [00:15, 13863.84it/s]67432it [00:15, 13935.09it/s]68862it [00:16, 14042.67it/s]70271it [00:16, 14043.90it/s]71747it [00:16, 14257.12it/s]73231it [00:16, 14424.78it/s]74674it [00:16, 14417.91it/s]76116it [00:16, 14207.84it/s]77538it [00:16, 14098.63it/s]78949it [00:16, 13791.93it/s]80419it [00:16, 14056.08it/s]81923it [00:17, 14345.76it/s]83479it [00:17, 14691.38it/s]85021it [00:17, 14900.27it/s]86513it [00:17, 14894.44it/s]88024it [00:17, 14957.61it/s]89521it [00:17, 14870.61it/s]91100it [00:17, 15142.45it/s]92615it [00:17, 15050.84it/s]94138it [00:17, 15090.20it/s]95672it [00:17, 15163.98it/s]97272it [00:18, 15412.32it/s]98837it [00:18, 15482.88it/s]100489it [00:18, 15781.00it/s]102155it [00:18, 16035.13it/s]103798it [00:18, 16149.71it/s]105414it [00:18, 15964.00it/s]107011it [00:18, 15961.17it/s]108608it [00:18, 15820.30it/s]110241it [00:18, 15960.20it/s]111838it [00:18, 15899.33it/s]113429it [00:19, 15774.36it/s]115007it [00:19, 15605.33it/s]116614it [00:19, 15734.35it/s]118225it [00:19, 15845.35it/s]119815it [00:19, 15844.83it/s]121494it [00:19, 16112.49it/s]124169it [00:19, 19287.02it/s]126966it [00:19, 21881.15it/s]129734it [00:19, 23615.89it/s]132670it [00:19, 25334.65it/s]135353it [00:20, 25778.53it/s]138288it [00:20, 26848.40it/s]141114it [00:20, 27271.06it/s]143911it [00:20, 27459.93it/s]146665it [00:20, 27482.68it/s]149605it [00:20, 28046.64it/s]152557it [00:20, 28488.15it/s]155406it [00:20, 28455.68it/s]158255it [00:20, 28463.69it/s]161102it [00:20, 28162.76it/s]163973it [00:21, 28316.13it/s]166912it [00:21, 28634.40it/s]169777it [00:22, 4628.21it/s] 171829it [00:23, 5195.26it/s]173526it [00:23, 5679.21it/s]174971it [00:23, 6085.00it/s]176233it [00:23, 6484.41it/s]177658it [00:23, 7506.24it/s]179236it [00:23, 8811.60it/s]180684it [00:24, 9856.29it/s]182199it [00:24, 10959.55it/s]183610it [00:24, 11568.07it/s]185004it [00:24, 5015.33it/s] 186041it [00:26, 2244.89it/s]186791it [00:26, 2047.76it/s]187361it [00:27, 1761.96it/s]187792it [00:27, 1621.53it/s]188128it [00:27, 1585.14it/s]188405it [00:28, 1583.90it/s]188647it [00:28, 1469.01it/s]188848it [00:28, 1125.39it/s]189004it [00:28, 991.42it/s] 191102it [00:29, 3362.28it/s]192229it [00:29, 4507.95it/s]193932it [00:29, 6652.73it/s]196218it [00:29, 9840.52it/s]198281it [00:29, 12204.97it/s]200514it [00:29, 14613.63it/s]202904it [00:29, 16968.12it/s]205133it [00:29, 18372.60it/s]207460it [00:29, 19720.38it/s]209809it [00:29, 20769.81it/s]212127it [00:30, 21462.00it/s]214481it [00:30, 22065.98it/s]216783it [00:30, 22344.28it/s]219156it [00:30, 22741.03it/s]221584it [00:30, 23187.48it/s]223926it [00:30, 23193.31it/s]226299it [00:30, 23347.69it/s]228646it [00:30, 23221.32it/s]230977it [00:30, 22938.05it/s]233278it [00:30, 22763.98it/s]235559it [00:31, 22555.12it/s]237818it [00:31, 22247.07it/s]240046it [00:31, 21491.82it/s]242202it [00:31, 21350.15it/s]244341it [00:31, 20909.14it/s]246436it [00:31, 20579.77it/s]248497it [00:31, 20312.56it/s]250636it [00:31, 20622.32it/s]252701it [00:31, 20392.39it/s]254828it [00:32, 20624.50it/s]256893it [00:32, 19912.22it/s]259006it [00:32, 20260.80it/s]261038it [00:32, 19978.37it/s]263121it [00:32, 20214.22it/s]265183it [00:32, 20318.63it/s]267218it [00:32, 20303.75it/s]269251it [00:32, 19866.57it/s]271374it [00:32, 20263.32it/s]273454it [00:32, 20420.35it/s]275509it [00:33, 20446.09it/s]277593it [00:33, 20552.79it/s]279650it [00:33, 20435.46it/s]281695it [00:33, 20422.10it/s]283827it [00:33, 20688.90it/s]285897it [00:33, 20534.00it/s]287952it [00:33, 20230.54it/s]289977it [00:33, 20082.53it/s]291987it [00:33, 20057.21it/s]293994it [00:33, 19798.89it/s]296010it [00:34, 19903.71it/s]298136it [00:34, 20304.46it/s]300168it [00:34, 20282.23it/s]302271it [00:34, 20495.98it/s]304322it [00:34, 20127.10it/s]306337it [00:34, 19292.96it/s]308274it [00:34, 18657.90it/s]310383it [00:34, 19348.11it/s]312417it [00:34, 19632.57it/s]314505it [00:34, 19993.27it/s]316511it [00:35, 19905.31it/s]318525it [00:35, 19968.69it/s]320573it [00:35, 20111.62it/s]322587it [00:35, 19338.64it/s]324897it [00:35, 20427.88it/s]327413it [00:35, 21795.11it/s]329829it [00:35, 22491.65it/s]332316it [00:35, 23195.09it/s]334811it [00:35, 23709.87it/s]337187it [00:36, 20730.57it/s]339331it [00:36, 18703.03it/s]341279it [00:36, 16097.48it/s]342991it [00:36, 12265.72it/s]344404it [00:36, 10685.69it/s]345616it [00:36, 9898.85it/s] 346700it [00:37, 9194.68it/s]347678it [00:37, 8763.28it/s]348588it [00:37, 8405.46it/s]349447it [00:37, 8143.08it/s]350270it [00:37, 7949.13it/s]351282it [00:37, 8487.90it/s]352306it [00:37, 8937.40it/s]353330it [00:37, 9292.40it/s]354420it [00:37, 9741.61it/s]355477it [00:38, 9972.86it/s]356578it [00:38, 10262.15it/s]357613it [00:38, 9836.21it/s] 359526it [00:38, 12478.51it/s]361871it [00:38, 15651.83it/s]363952it [00:38, 17159.85it/s]366015it [00:38, 18164.32it/s]368142it [00:38, 19071.78it/s]370208it [00:38, 19543.48it/s]372209it [00:38, 19664.99it/s]374182it [00:39, 5659.51it/s] 375627it [00:40, 5957.79it/s]377932it [00:40, 8061.27it/s]380218it [00:40, 10273.52it/s]382567it [00:40, 12595.96it/s]384943it [00:40, 14834.76it/s]387356it [00:40, 16906.00it/s]389818it [00:40, 18768.80it/s]392180it [00:40, 19997.71it/s]394469it [00:40, 20512.30it/s]396727it [00:41, 20262.57it/s]399015it [00:41, 20961.53it/s]401421it [00:41, 21829.44it/s]403686it [00:41, 17542.86it/s]405629it [00:41, 17848.65it/s]407910it [00:41, 18768.83it/s]409893it [00:41, 15095.42it/s]412178it [00:41, 16887.27it/s]414347it [00:42, 18079.03it/s]416655it [00:42, 19385.65it/s]418718it [00:42, 16066.46it/s]420906it [00:42, 17464.16it/s]422903it [00:42, 18096.33it/s]425013it [00:42, 18894.69it/s]427131it [00:42, 19523.25it/s]429155it [00:42, 18283.44it/s]431288it [00:42, 19113.22it/s]433392it [00:43, 19652.89it/s]435491it [00:43, 20018.48it/s]437523it [00:43, 16886.24it/s]439458it [00:43, 16778.60it/s]441207it [00:43, 16647.99it/s]442920it [00:43, 14366.13it/s]444436it [00:43, 11007.61it/s]446383it [00:44, 12786.98it/s]448426it [00:44, 14552.34it/s]450464it [00:44, 15998.32it/s]452495it [00:44, 17126.54it/s]454536it [00:44, 18019.05it/s]456572it [00:44, 18673.77it/s]458725it [00:44, 19489.21it/s]460917it [00:44, 20180.06it/s]463155it [00:44, 20822.92it/s]465398it [00:44, 21295.54it/s]467550it [00:45, 21353.15it/s]469749it [00:45, 21535.35it/s]471914it [00:45, 20160.90it/s]473956it [00:45, 18367.87it/s]475837it [00:45, 18153.44it/s]477815it [00:45, 18599.12it/s]479989it [00:45, 19483.56it/s]482249it [00:45, 20365.64it/s]484624it [00:45, 21347.82it/s]487013it [00:46, 22091.04it/s]489351it [00:46, 22469.12it/s]491609it [00:46, 22130.27it/s]494111it [00:46, 22962.47it/s]496432it [00:46, 23025.80it/s]498816it [00:46, 23265.71it/s]501170it [00:46, 23343.43it/s]503508it [00:46, 23099.90it/s]505821it [00:46, 21792.61it/s]508017it [00:46, 21357.52it/s]510165it [00:47, 18654.09it/s]512094it [00:47, 17413.98it/s]513891it [00:47, 17555.33it/s]515685it [00:47, 16621.03it/s]517457it [00:47, 16904.14it/s]519239it [00:47, 17149.14it/s]520975it [00:47, 17208.27it/s]522879it [00:47, 17730.50it/s]524665it [00:47, 17673.51it/s]526441it [00:48, 17494.81it/s]528197it [00:48, 17298.57it/s]529932it [00:48, 17155.03it/s]531651it [00:48, 17103.34it/s]533370it [00:48, 17127.92it/s]535085it [00:48, 17059.42it/s]536792it [00:48, 16624.97it/s]538458it [00:48, 16475.14it/s]540222it [00:48, 16806.28it/s]542069it [00:48, 17295.23it/s]543819it [00:49, 17338.39it/s]545555it [00:49, 17156.66it/s]547434it [00:49, 17630.64it/s]549432it [00:49, 18326.74it/s]551372it [00:49, 18646.09it/s]553375it [00:49, 19054.04it/s]555493it [00:49, 19688.27it/s]557569it [00:49, 20007.87it/s]559571it [00:49, 19960.91it/s]561613it [00:49, 20086.25it/s]563670it [00:50, 20223.14it/s]565693it [00:50, 20130.93it/s]567836it [00:50, 20518.05it/s]569999it [00:50, 20837.27it/s]572084it [00:50, 19286.17it/s]574036it [00:50, 14572.37it/s]575674it [00:50, 13282.66it/s]577137it [00:51, 12303.70it/s]578463it [00:51, 11835.90it/s]580483it [00:51, 13801.80it/s]582519it [00:51, 15448.22it/s]584632it [00:51, 16945.42it/s]586638it [00:51, 17798.86it/s]588489it [00:51, 14521.53it/s]590085it [00:51, 11976.04it/s]591443it [00:52, 10696.76it/s]592634it [00:52, 9688.97it/s] 593690it [00:52, 8961.06it/s]594643it [00:52, 8515.04it/s]595529it [00:52, 8370.04it/s]596387it [00:52, 8160.90it/s]597215it [00:52, 8037.89it/s]598025it [00:52, 8025.22it/s]598835it [00:53, 8044.82it/s]599643it [00:53, 7928.19it/s]600438it [00:53, 6161.88it/s]601112it [00:53, 6261.92it/s]602175it [00:53, 7362.07it/s]603185it [00:53, 8086.79it/s]604138it [00:53, 8475.81it/s]605067it [00:53, 8704.34it/s]605973it [00:53, 8804.40it/s]606953it [00:54, 9092.03it/s]607895it [00:54, 9182.11it/s]608824it [00:54, 9209.95it/s]609753it [00:54, 7799.57it/s]610575it [00:54, 4990.51it/s]612080it [00:54, 6919.88it/s]613746it [00:54, 9013.79it/s]615370it [00:55, 10712.24it/s]616907it [00:55, 11881.06it/s]618531it [00:55, 13029.25it/s]620038it [00:55, 13587.47it/s]621656it [00:55, 14312.88it/s]623478it [00:55, 15426.87it/s]625144it [00:55, 15784.04it/s]626778it [00:55, 15946.28it/s]628402it [00:55, 15914.97it/s]630014it [00:55, 15861.51it/s]631654it [00:56, 16010.34it/s]633266it [00:56, 15950.07it/s]634886it [00:56, 16009.52it/s]636582it [00:56, 16291.60it/s]638215it [00:56, 16182.29it/s]639837it [00:56, 15756.92it/s]641417it [00:56, 15702.80it/s]643040it [00:56, 15840.59it/s]644627it [00:56, 15770.39it/s]646245it [00:57, 15886.41it/s]647836it [00:57, 15878.10it/s]649425it [00:57, 15855.46it/s]651012it [00:57, 15755.46it/s]652597it [00:57, 15772.75it/s]654240it [00:57, 15967.81it/s]655842it [00:57, 15982.57it/s]657515it [00:57, 16188.53it/s]659165it [00:57, 16265.08it/s]660792it [00:57, 16019.07it/s]662395it [00:58, 15831.88it/s]664011it [00:58, 15915.05it/s]665704it [00:58, 16214.10it/s]667327it [00:58, 16015.31it/s]668930it [00:58, 15788.09it/s]670579it [00:58, 15975.96it/s]672224it [00:58, 16111.61it/s]673837it [00:58, 15688.11it/s]675522it [00:58, 16026.37it/s]677128it [00:58, 15731.59it/s]678718it [00:59, 15778.54it/s]680336it [00:59, 15896.02it/s]681928it [00:59, 15862.75it/s]683609it [00:59, 16140.25it/s]685265it [00:59, 16238.75it/s]686890it [00:59, 16134.79it/s]688505it [00:59, 16115.91it/s]690174it [00:59, 16277.59it/s]691836it [00:59, 16378.30it/s]693475it [00:59, 16116.00it/s]695088it [01:00, 16004.03it/s]696719it [01:00, 16093.78it/s]698389it [01:00, 16265.18it/s]700091it [01:00, 16488.65it/s]701810it [01:00, 16697.12it/s]703699it [01:00, 17344.24it/s]705434it [01:00, 16783.63it/s]707117it [01:00, 16675.34it/s]708788it [01:00, 16671.00it/s]710544it [01:00, 16930.57it/s]712239it [01:01, 16582.52it/s]713900it [01:01, 16052.91it/s]715510it [01:01, 15632.40it/s]717078it [01:01, 15470.18it/s]718628it [01:01, 15362.19it/s]720166it [01:01, 15354.18it/s]721740it [01:01, 15465.69it/s]723353it [01:01, 15648.75it/s]724919it [01:01, 15610.32it/s]726545it [01:02, 15801.01it/s]728135it [01:02, 15828.19it/s]729765it [01:02, 15964.95it/s]731430it [01:02, 16163.05it/s]733047it [01:02, 15876.55it/s]734660it [01:02, 15938.97it/s]736318it [01:02, 16128.24it/s]737932it [01:02, 15974.68it/s]739564it [01:02, 16062.80it/s]741171it [01:02, 16007.44it/s]742841it [01:03, 16206.00it/s]744463it [01:03, 15995.18it/s]746064it [01:03, 15927.37it/s]747658it [01:03, 14977.61it/s]749167it [01:03, 12036.82it/s]750466it [01:03, 10507.54it/s]751607it [01:03, 8487.91it/s] 752566it [01:04, 8415.32it/s]753483it [01:04, 8380.54it/s]754373it [01:04, 8346.89it/s]755244it [01:04, 8174.36it/s]756085it [01:04, 8099.17it/s]756911it [01:04, 8136.57it/s]757909it [01:04, 8636.49it/s]758786it [01:04, 7583.22it/s]759635it [01:04, 7814.10it/s]760451it [01:05, 7906.53it/s]761270it [01:05, 7985.19it/s]762082it [01:05, 7185.89it/s]762823it [01:05, 6976.46it/s]763671it [01:05, 7374.97it/s]764478it [01:05, 7566.96it/s]765335it [01:05, 7846.48it/s]766164it [01:05, 7962.68it/s]767010it [01:05, 8105.93it/s]767855it [01:05, 8206.62it/s]768758it [01:06, 8447.67it/s]769607it [01:06, 8339.51it/s]770444it [01:06, 7572.04it/s]771216it [01:06, 6821.25it/s]772043it [01:06, 7199.26it/s]772894it [01:06, 7547.00it/s]773720it [01:06, 7745.16it/s]774546it [01:06, 7891.11it/s]775417it [01:06, 8118.80it/s]776257it [01:07, 8200.11it/s]777113it [01:07, 8302.68it/s]779000it [01:07, 11431.51it/s]781123it [01:07, 14335.40it/s]783125it [01:07, 16028.75it/s]785189it [01:07, 17404.97it/s]787120it [01:07, 17969.91it/s]789236it [01:07, 18924.26it/s]791345it [01:07, 19571.66it/s]793385it [01:07, 19798.66it/s]795422it [01:08, 19954.81it/s]797551it [01:08, 20352.92it/s]799602it [01:08, 20399.09it/s]801751it [01:08, 20724.74it/s]803824it [01:08, 20513.32it/s]805927it [01:08, 20651.25it/s]807993it [01:08, 20424.35it/s]810037it [01:08, 20060.89it/s]812045it [01:08, 19984.08it/s]814045it [01:08, 19933.31it/s]816135it [01:09, 20215.20it/s]818158it [01:09, 19887.35it/s]820149it [01:09, 19753.04it/s]822196it [01:09, 19949.32it/s]824270it [01:09, 20182.37it/s]826296it [01:09, 20205.02it/s]828417it [01:09, 20499.09it/s]830468it [01:09, 20419.36it/s]832572it [01:09, 20604.07it/s]834633it [01:09, 20209.05it/s]836656it [01:10, 20215.00it/s]838679it [01:10, 20107.54it/s]841029it [01:10, 21106.27it/s]843389it [01:10, 21845.86it/s]845584it [01:10, 21875.42it/s]847912it [01:10, 22292.45it/s]850280it [01:10, 22707.20it/s]852563it [01:10, 22732.01it/s]854878it [01:10, 22856.46it/s]857263it [01:10, 23153.52it/s]859579it [01:11, 23092.77it/s]861890it [01:11, 23076.07it/s]864198it [01:11, 22810.23it/s]866480it [01:11, 21613.82it/s]868655it [01:11, 20679.39it/s]870738it [01:11, 19292.74it/s]872691it [01:11, 18694.41it/s]874576it [01:11, 18541.89it/s]876440it [01:12, 17601.73it/s]878212it [01:12, 17089.77it/s]879929it [01:12, 16577.63it/s]881592it [01:12, 16383.74it/s]883233it [01:12, 16390.06it/s]884998it [01:12, 16746.80it/s]886723it [01:12, 16885.05it/s]888415it [01:12, 16472.62it/s]890066it [01:12, 16330.14it/s]891702it [01:12, 15678.81it/s]893276it [01:13, 14925.82it/s]894778it [01:13, 14649.51it/s]896249it [01:13, 14474.63it/s]897700it [01:13, 14348.37it/s]899137it [01:13, 14140.73it/s]900553it [01:13, 13990.58it/s]901953it [01:13, 13796.56it/s]903345it [01:13, 13814.22it/s]904727it [01:13, 13716.32it/s]906171it [01:14, 13923.82it/s]907594it [01:14, 14006.52it/s]909070it [01:14, 14210.73it/s]910492it [01:14, 14095.09it/s]911953it [01:14, 14247.36it/s]913379it [01:14, 12608.88it/s]914675it [01:15, 3360.88it/s] 915617it [01:16, 2296.86it/s]916309it [01:16, 2137.89it/s]916843it [01:17, 2097.69it/s]917275it [01:17, 2078.29it/s]917637it [01:17, 2042.01it/s]917947it [01:18, 1640.20it/s]918189it [01:18, 985.71it/s] 918368it [01:18, 1038.71it/s]918581it [01:19, 1124.85it/s]918830it [01:19, 1114.51it/s]918983it [01:19, 838.88it/s] 919428it [01:19, 1277.49it/s]919793it [01:19, 1626.45it/s]920051it [01:20, 1205.74it/s]920252it [01:20, 926.07it/s] 920408it [01:20, 958.80it/s]920611it [01:20, 964.05it/s]920885it [01:21, 1180.99it/s]921243it [01:21, 1595.38it/s]922370it [01:21, 3510.37it/s]923848it [01:21, 5994.57it/s]925148it [01:21, 7671.95it/s]926500it [01:21, 9157.18it/s]927661it [01:21, 9808.13it/s]929634it [01:21, 12529.97it/s]931736it [01:21, 14923.54it/s]933745it [01:21, 16402.74it/s]935451it [01:22, 16450.77it/s]937244it [01:22, 16882.19it/s]938966it [01:22, 16890.49it/s]940695it [01:22, 16997.20it/s]942444it [01:22, 17142.42it/s]944239it [01:22, 17371.52it/s]945985it [01:22, 17289.96it/s]947821it [01:22, 17606.96it/s]949608it [01:22, 17678.99it/s]951380it [01:23, 17382.31it/s]953122it [01:23, 17099.42it/s]954956it [01:23, 17462.68it/s]956835it [01:23, 17854.28it/s]958681it [01:23, 18033.67it/s]960487it [01:23, 18024.10it/s]962291it [01:23, 17520.02it/s]964047it [01:23, 17513.94it/s]965802it [01:23, 17460.49it/s]967567it [01:23, 17507.10it/s]969458it [01:24, 17922.57it/s]971252it [01:24, 17908.19it/s]973044it [01:24, 17790.31it/s]974921it [01:24, 18076.24it/s]977043it [01:24, 19008.17it/s]979298it [01:24, 20063.21it/s]981306it [01:24, 18711.67it/s]983197it [01:24, 16404.69it/s]984897it [01:24, 16260.49it/s]986575it [01:25, 16390.55it/s]988244it [01:25, 16402.31it/s]989956it [01:25, 16597.24it/s]991632it [01:25, 16347.58it/s]993297it [01:25, 16421.50it/s]994977it [01:25, 16514.61it/s]996635it [01:25, 16418.49it/s]998281it [01:25, 16345.62it/s]999919it [01:25, 16238.05it/s]1001596it [01:25, 16391.84it/s]1003257it [01:26, 16447.74it/s]1004923it [01:26, 16504.55it/s]1006575it [01:26, 16490.32it/s]1008225it [01:26, 16384.81it/s]1009865it [01:26, 16297.18it/s]1011499it [01:26, 16308.86it/s]1013181it [01:26, 16454.91it/s]1014827it [01:26, 16304.11it/s]1016458it [01:26, 14060.29it/s]1017918it [01:27, 12809.77it/s]1019252it [01:27, 11732.56it/s]1020471it [01:27, 9872.08it/s] 1021527it [01:27, 9554.82it/s]1022527it [01:27, 9447.16it/s]1023501it [01:27, 9182.43it/s]1024438it [01:27, 8985.72it/s]1025348it [01:27, 8951.63it/s]1026251it [01:28, 8851.10it/s]1027141it [01:28, 8787.04it/s]1028058it [01:28, 8894.03it/s]1028950it [01:28, 8636.67it/s]1029830it [01:28, 8682.10it/s]1030701it [01:28, 8612.73it/s]1031564it [01:28, 8502.12it/s]1032417it [01:28, 8508.83it/s]1033293it [01:28, 8573.50it/s]1034254it [01:28, 8879.06it/s]1035143it [01:29, 8725.44it/s]1036028it [01:29, 8758.30it/s]1036905it [01:29, 8691.49it/s]1037787it [01:29, 8723.09it/s]1038678it [01:29, 8771.94it/s]1039559it [01:29, 8782.89it/s]1040442it [01:29, 8794.86it/s]1041376it [01:29, 8957.07it/s]1042272it [01:29, 8608.79it/s]1043136it [01:29, 8384.72it/s]1043978it [01:30, 8348.41it/s]1044815it [01:30, 8293.56it/s]1045646it [01:30, 8065.44it/s]1046455it [01:30, 7995.16it/s]1047256it [01:30, 7973.65it/s]1048055it [01:30, 7930.64it/s]1048850it [01:30, 7935.76it/s]1049644it [01:30, 7803.20it/s]1050425it [01:30, 7513.06it/s]1051179it [01:31, 7401.96it/s]1051921it [01:31, 7379.64it/s]1052660it [01:31, 7204.10it/s]1053382it [01:31, 6981.62it/s]1054082it [01:31, 6943.56it/s]1054824it [01:31, 7080.66it/s]1055534it [01:31, 7014.18it/s]1056257it [01:31, 7068.86it/s]1056965it [01:31, 6995.71it/s]1057757it [01:31, 7266.52it/s]1058646it [01:32, 7736.43it/s]1059477it [01:32, 7905.83it/s]1060316it [01:32, 8048.79it/s]1061239it [01:32, 8400.80it/s]1062080it [01:32, 8360.80it/s]1062917it [01:32, 8269.41it/s]1063745it [01:32, 8122.19it/s]1064559it [01:32, 8058.49it/s]1065394it [01:32, 8137.89it/s]1066236it [01:32, 8217.32it/s]1067067it [01:33, 8242.28it/s]1067892it [01:33, 8194.87it/s]1068712it [01:33, 8176.98it/s]1069530it [01:33, 7748.13it/s]1070310it [01:33, 7076.04it/s]1071031it [01:33, 6100.68it/s]1071670it [01:33, 4335.23it/s]1072438it [01:34, 5005.41it/s]1073165it [01:34, 5504.86it/s]1073905it [01:34, 5957.17it/s]1074796it [01:34, 6711.96it/s]1075670it [01:34, 7250.83it/s]1076512it [01:34, 7573.15it/s]1077382it [01:34, 7889.26it/s]1078258it [01:34, 8139.85it/s]1079157it [01:34, 8379.62it/s]1080010it [01:34, 8397.38it/s]1080861it [01:35, 8038.30it/s]1081676it [01:35, 8046.69it/s]1082488it [01:35, 6659.95it/s]1083483it [01:35, 7497.83it/s]1084485it [01:35, 8170.49it/s]1085499it [01:35, 8711.90it/s]1086462it [01:35, 8969.71it/s]1087385it [01:35, 9043.21it/s]1088351it [01:35, 9217.35it/s]1089286it [01:36, 9242.76it/s]1090275it [01:36, 9425.15it/s]1091225it [01:36, 9320.35it/s]1092162it [01:36, 9033.63it/s]1093071it [01:36, 8761.99it/s]1093952it [01:36, 8657.11it/s]1094821it [01:36, 8550.59it/s]1095679it [01:36, 8305.46it/s]1096512it [01:36, 8250.55it/s]1097339it [01:37, 4094.28it/s]1097973it [01:37, 4217.31it/s]1098783it [01:37, 4936.99it/s]1099550it [01:37, 5508.37it/s]1100351it [01:37, 6080.87it/s]1101153it [01:37, 6554.50it/s]1101959it [01:37, 6946.97it/s]1102721it [01:38, 6946.20it/s]1104182it [01:38, 9037.48it/s]1105690it [01:38, 10737.05it/s]1107261it [01:38, 12159.15it/s]1108900it [01:38, 13387.07it/s]1110271it [01:38, 12211.83it/s]1111535it [01:38, 8800.02it/s] 1112574it [01:39, 7545.00it/s]1113460it [01:39, 6841.90it/s]1114237it [01:39, 6626.88it/s]1114961it [01:39, 6623.22it/s]1116497it [01:39, 8645.78it/s]1117982it [01:39, 10182.16it/s]1119409it [01:39, 11249.19it/s]1120810it [01:39, 12000.10it/s]1122484it [01:39, 13315.40it/s]1123974it [01:40, 13766.79it/s]1125628it [01:40, 14557.45it/s]1127153it [01:40, 14755.15it/s]1128762it [01:40, 15143.27it/s]1130372it [01:40, 15423.16it/s]1131926it [01:40, 15300.04it/s]1133465it [01:40, 14904.67it/s]1134964it [01:40, 14848.14it/s]1136455it [01:40, 14767.08it/s]1137962it [01:40, 14853.18it/s]1139451it [01:41, 14753.08it/s]1140968it [01:41, 14870.43it/s]1142457it [01:41, 13544.94it/s]1143835it [01:41, 11412.17it/s]1145044it [01:41, 10248.30it/s]1146129it [01:41, 9659.18it/s] 1147136it [01:41, 9246.13it/s]1148200it [01:42, 9589.50it/s]1149337it [01:42, 10052.59it/s]1150452it [01:42, 10337.35it/s]1151507it [01:42, 10395.59it/s]1152613it [01:42, 10584.50it/s]1153683it [01:42, 10507.30it/s]1154913it [01:42, 11027.01it/s]1156376it [01:42, 12071.90it/s]1157903it [01:42, 13003.55it/s]1159331it [01:42, 13363.26it/s]1160883it [01:43, 14003.68it/s]1162288it [01:43, 13616.48it/s]1163655it [01:43, 13348.49it/s]1164994it [01:43, 13359.44it/s]1166460it [01:43, 13740.00it/s]1167837it [01:43, 13603.53it/s]1169200it [01:43, 13609.08it/s]1170599it [01:43, 13719.46it/s]1171973it [01:43, 13686.83it/s]1173343it [01:43, 13605.52it/s]1174774it [01:44, 13805.26it/s]1176225it [01:44, 14004.75it/s]1177666it [01:44, 14118.89it/s]1179079it [01:44, 13807.07it/s]1180462it [01:44, 13476.04it/s]1181866it [01:44, 13632.10it/s]1183232it [01:44, 13458.36it/s]1184580it [01:44, 13308.35it/s]1185913it [01:44, 12944.73it/s]1187210it [01:44, 12496.97it/s]1188464it [01:45, 12408.23it/s]1189737it [01:45, 12500.50it/s]1191033it [01:45, 12633.51it/s]1192299it [01:45, 12588.69it/s]1193565it [01:45, 12602.31it/s]1194872it [01:45, 12740.61it/s]1197096it [01:45, 15562.18it/s]1199786it [01:45, 18941.37it/s]1202128it [01:45, 20273.26it/s]1204159it [01:46, 15872.24it/s]1205897it [01:46, 13709.87it/s]1207413it [01:46, 12503.96it/s]1208771it [01:46, 11331.26it/s]1209985it [01:46, 10650.01it/s]1211103it [01:46, 10098.09it/s]1212145it [01:46, 10017.32it/s]1213168it [01:47, 9840.38it/s] 1214165it [01:47, 9686.03it/s]1215634it [01:47, 11011.35it/s]1217169it [01:47, 12191.63it/s]1218774it [01:47, 13276.74it/s]1220473it [01:47, 14337.78it/s]1221930it [01:47, 14001.44it/s]1223348it [01:47, 13329.90it/s]1224698it [01:47, 12664.22it/s]1225981it [01:48, 12202.59it/s]1227213it [01:48, 12038.41it/s]1228425it [01:48, 11746.05it/s]1229643it [01:48, 11858.64it/s]1230834it [01:48, 11827.77it/s]1232020it [01:48, 11628.18it/s]1233185it [01:48, 11540.33it/s]1234341it [01:48, 11274.95it/s]1235470it [01:48, 11034.62it/s]1236617it [01:48, 11154.93it/s]1237734it [01:49, 11075.37it/s]1238843it [01:49, 10899.75it/s]1239939it [01:49, 10916.43it/s]1241032it [01:49, 10828.71it/s]1242116it [01:49, 10819.54it/s]1243252it [01:49, 10978.45it/s]1244351it [01:49, 10967.23it/s]1245473it [01:49, 11041.42it/s]1246578it [01:49, 10768.81it/s]1247657it [01:49, 10753.81it/s]1248734it [01:50, 10704.18it/s]1249806it [01:50, 10553.08it/s]1250863it [01:50, 9050.25it/s] 1251805it [01:50, 7962.17it/s]1252645it [01:50, 7292.07it/s]1253410it [01:50, 6792.30it/s]1254114it [01:50, 6613.11it/s]1254791it [01:51, 6317.69it/s]1255433it [01:51, 6206.83it/s]1256078it [01:51, 6270.18it/s]1256710it [01:51, 6265.31it/s]1257783it [01:51, 7511.36it/s]1258963it [01:51, 8730.66it/s]1260082it [01:51, 9440.88it/s]1261039it [01:51, 9461.34it/s]1261995it [01:51, 9301.70it/s]1262932it [01:51, 9059.82it/s]1263844it [01:52, 9010.67it/s]1264749it [01:52, 8535.95it/s]1266074it [01:52, 9863.18it/s]1267518it [01:52, 11175.29it/s]1269095it [01:52, 12509.59it/s]1270640it [01:52, 13367.12it/s]1272239it [01:52, 14140.67it/s]1274089it [01:52, 15432.67it/s]1275979it [01:52, 16455.48it/s]1277783it [01:52, 16923.32it/s]1279617it [01:53, 17332.21it/s]1281354it [01:53, 17257.75it/s]1283083it [01:53, 16354.86it/s]1284730it [01:53, 15118.63it/s]1286266it [01:53, 14356.83it/s]1287722it [01:53, 14280.23it/s]1289548it [01:53, 15377.65it/s]1291527it [01:53, 16627.89it/s]1293509it [01:53, 17538.18it/s]1295320it [01:54, 17704.61it/s]1297104it [01:54, 16559.37it/s]1298783it [01:54, 15655.90it/s]1300372it [01:54, 15203.54it/s]1301908it [01:54, 14777.76it/s]1303462it [01:54, 14986.88it/s]1305064it [01:54, 15274.77it/s]1306715it [01:54, 15624.25it/s]1308480it [01:54, 16213.56it/s]1310171it [01:55, 16417.09it/s]1311818it [01:55, 16428.67it/s]1313476it [01:55, 16472.77it/s]1315163it [01:55, 16576.19it/s]1316904it [01:55, 16821.29it/s]1318588it [01:55, 16815.02it/s]1320364it [01:55, 17084.45it/s]1322074it [01:55, 16975.26it/s]1323785it [01:55, 17012.22it/s]1325487it [01:55, 16623.86it/s]1327152it [01:56, 16618.28it/s]1328816it [01:56, 16048.35it/s]1330426it [01:56, 13966.42it/s]1331871it [01:56, 12912.80it/s]1333205it [01:56, 12120.38it/s]1334449it [01:56, 11646.02it/s]1335634it [01:56, 11315.26it/s]1336778it [01:56, 10861.37it/s]1337872it [01:57, 10538.29it/s]1338930it [01:57, 10140.99it/s]1339947it [01:57, 9903.31it/s] 1340950it [01:57, 9934.72it/s]1341993it [01:57, 10067.72it/s]1343045it [01:57, 10191.99it/s]1344083it [01:57, 10242.66it/s]1345109it [01:57, 10122.91it/s]1346123it [01:57, 10028.32it/s]1347147it [01:57, 10078.38it/s]1348156it [01:58, 9976.30it/s] 1349207it [01:58, 10132.59it/s]1350283it [01:58, 10317.61it/s]1351316it [01:58, 10067.59it/s]1352325it [01:58, 9882.03it/s] 1353349it [01:58, 9978.60it/s]1354483it [01:58, 10371.93it/s]1355535it [01:58, 10413.89it/s]1356578it [01:58, 10320.60it/s]1357612it [01:58, 10322.43it/s]1358645it [01:59, 10302.09it/s]1359697it [01:59, 10361.40it/s]1360767it [01:59, 10456.27it/s]1361813it [01:59, 10438.63it/s]1363433it [01:59, 12149.19it/s]1365039it [01:59, 13313.50it/s]1366677it [01:59, 14225.40it/s]1368387it [01:59, 15084.59it/s]1370029it [01:59, 15481.31it/s]1371777it [01:59, 16078.30it/s]1373393it [02:00, 16102.41it/s]1375004it [02:00, 15841.05it/s]1376611it [02:00, 15908.07it/s]1378203it [02:00, 15388.90it/s]1379746it [02:00, 14063.18it/s]1381175it [02:00, 12193.00it/s]1382448it [02:00, 10871.42it/s]1383589it [02:00, 10082.46it/s]1384636it [02:01, 9616.55it/s] 1385622it [02:01, 9286.99it/s]1386565it [02:01, 8872.09it/s]1387461it [02:01, 8473.12it/s]1388313it [02:01, 8295.97it/s]1389144it [02:01, 8207.06it/s]1389965it [02:01, 8156.09it/s]1390799it [02:01, 8205.26it/s]1391620it [02:01, 8147.50it/s]1392464it [02:02, 8223.33it/s]1393287it [02:02, 8062.06it/s]1394138it [02:02, 8188.22it/s]1394958it [02:02, 7964.80it/s]1395756it [02:02, 7868.35it/s]1396544it [02:02, 7653.55it/s]1397374it [02:02, 7833.84it/s]1398160it [02:02, 7839.03it/s]1398946it [02:02, 7843.53it/s]1399852it [02:02, 8199.12it/s]1401155it [02:03, 9620.65it/s]1402273it [02:03, 10078.92it/s]1403375it [02:03, 10342.57it/s]1404411it [02:03, 10070.77it/s]1405446it [02:03, 10145.79it/s]1406469it [02:03, 10167.53it/s]1407488it [02:03, 10084.36it/s]1408498it [02:03, 9692.96it/s] 1409471it [02:03, 9525.97it/s]1410427it [02:04, 9362.02it/s]1411366it [02:04, 9215.00it/s]1412289it [02:04, 9125.45it/s]1413203it [02:04, 9010.28it/s]1414105it [02:04, 8881.79it/s]1414994it [02:04, 8883.03it/s]1415885it [02:04, 8890.09it/s]1416781it [02:04, 8902.19it/s]1417681it [02:04, 8930.68it/s]1418575it [02:04, 8636.55it/s]1419441it [02:05, 8117.30it/s]1420260it [02:05, 8016.93it/s]1421078it [02:05, 8059.24it/s]1421900it [02:05, 8094.23it/s]1422753it [02:05, 8216.11it/s]1423579it [02:05, 8228.29it/s]1424404it [02:05, 8205.25it/s]1425226it [02:05, 8184.70it/s]1426066it [02:05, 8248.08it/s]1426892it [02:06, 8233.42it/s]1427719it [02:06, 8242.76it/s]1428544it [02:06, 8136.95it/s]1429359it [02:06, 8103.23it/s]1430170it [02:06, 8046.77it/s]1431030it [02:06, 8210.34it/s]1431852it [02:06, 8186.93it/s]1432674it [02:06, 8189.21it/s]1433505it [02:06, 8223.49it/s]1434328it [02:06, 8065.89it/s]1435136it [02:07, 7981.34it/s]1435957it [02:07, 8044.02it/s]1436763it [02:07, 8041.41it/s]1437568it [02:07, 7592.88it/s]1438333it [02:08, 2115.24it/s]1438891it [02:08, 1993.78it/s]1439752it [02:08, 2689.56it/s]1440571it [02:08, 3408.23it/s]1441378it [02:08, 4138.47it/s]1442250it [02:09, 4976.60it/s]1443076it [02:09, 5657.82it/s]1443900it [02:09, 6245.45it/s]1444685it [02:09, 5266.32it/s]1445625it [02:09, 6167.25it/s]1446482it [02:09, 6280.25it/s]1447202it [02:09, 5649.99it/s]1447927it [02:09, 6016.89it/s]1448590it [02:10, 6038.93it/s]1449237it [02:10, 6106.55it/s]1449879it [02:10, 6008.89it/s]1450502it [02:10, 5365.63it/s]1451557it [02:10, 6684.05it/s]1452577it [02:10, 7620.98it/s]1453380it [02:10, 6587.21it/s]1454090it [02:10, 6230.24it/s]1454750it [02:11, 5945.69it/s]1455370it [02:11, 5950.30it/s]1455983it [02:11, 5386.56it/s]1456541it [02:11, 4757.33it/s]1457448it [02:11, 5789.77it/s]1458276it [02:11, 6423.05it/s]1458959it [02:11, 5155.75it/s]1459778it [02:11, 5853.76it/s]1460429it [02:12, 5898.90it/s]1461066it [02:12, 5440.28it/s]1462091it [02:12, 6635.68it/s]1463127it [02:12, 7608.70it/s]1463936it [02:12, 7403.25it/s]1464711it [02:12, 6909.97it/s]1465703it [02:12, 7701.48it/s]1466504it [02:12, 6435.47it/s]1467507it [02:13, 7309.50it/s]1468295it [02:13, 6319.07it/s]1468986it [02:13, 6075.31it/s]1469832it [02:13, 6400.38it/s]1470504it [02:13, 4466.94it/s]1471046it [02:13, 4216.22it/s]1471687it [02:14, 4662.07it/s]1472220it [02:14, 4618.86it/s]1472728it [02:14, 4368.65it/s]1473800it [02:14, 5876.44it/s]1474568it [02:14, 6315.08it/s]1475251it [02:14, 5646.54it/s]1475872it [02:14, 5666.19it/s]1476628it [02:14, 6119.21it/s]1477384it [02:14, 6505.75it/s]1478060it [02:15, 4585.68it/s]1478612it [02:15, 4424.95it/s]1479119it [02:15, 4546.52it/s]1479623it [02:15, 4233.91it/s]1481690it [02:15, 8135.16it/s]1483928it [02:15, 11728.78it/s]1486204it [02:15, 14648.96it/s]1487815it [02:15, 14981.67it/s]1490695it [02:16, 18837.63it/s]1493183it [02:16, 20565.93it/s]1495992it [02:16, 22748.21it/s]1498999it [02:16, 24886.99it/s]1501991it [02:16, 26370.52it/s]1504868it [02:16, 27081.20it/s]1507856it [02:16, 27913.17it/s]1510835it [02:16, 28472.52it/s]1514062it [02:16, 29606.90it/s]1517401it [02:16, 30707.43it/s]1520738it [02:17, 31503.12it/s]1524081it [02:17, 32066.01it/s]1527363it [02:17, 32290.25it/s]1530595it [02:17, 31310.12it/s]1533735it [02:17, 30879.10it/s]1536830it [02:17, 29792.02it/s]1539820it [02:17, 29179.98it/s]1542829it [02:17, 29439.22it/s]1545780it [02:17, 28596.40it/s]1548648it [02:18, 26753.37it/s]1551348it [02:18, 25841.80it/s]1553950it [02:18, 24706.67it/s]1556437it [02:18, 24235.76it/s]1559353it [02:18, 25579.13it/s]1562477it [02:18, 27152.81it/s]1565214it [02:18, 26803.70it/s]1567910it [02:18, 26500.98it/s]1570981it [02:18, 27716.65it/s]1573765it [02:19, 26049.80it/s]1576396it [02:19, 26095.57it/s]1579752it [02:19, 28233.91it/s]1583805it [02:19, 31783.93it/s]1587011it [02:19, 29573.74it/s]1590016it [02:19, 26413.42it/s]1593078it [02:19, 27509.51it/s]1596689it [02:19, 29841.34it/s]1599847it [02:19, 30324.98it/s]1602968it [02:19, 30553.57it/s]1607234it [02:20, 34060.39it/s]1610681it [02:20, 33481.90it/s]1614547it [02:20, 34969.88it/s]1619327it [02:20, 38698.32it/s]1624019it [02:20, 41122.84it/s]1629108it [02:20, 44005.13it/s]1633528it [02:20, 42240.55it/s]1637780it [02:20, 38464.53it/s]1641704it [02:21, 31656.69it/s]1645101it [02:21, 28046.19it/s]1648110it [02:21, 25704.41it/s]1650829it [02:21, 24550.80it/s]1653377it [02:21, 23605.18it/s]1656283it [02:21, 24921.10it/s]1660635it [02:21, 29709.90it/s]1665342it [02:21, 34381.23it/s]1669974it [02:21, 37695.87it/s]1673870it [02:22, 29387.19it/s]1677171it [02:22, 25403.56it/s]1680032it [02:22, 23201.04it/s]1682583it [02:22, 22032.16it/s]1684938it [02:22, 20695.62it/s]1687106it [02:22, 19831.57it/s]1689149it [02:23, 19097.23it/s]1691093it [02:23, 18433.12it/s]1692954it [02:23, 18184.17it/s]1694782it [02:23, 18196.64it/s]1696608it [02:23, 17894.26it/s]1698470it [02:23, 18088.13it/s]1700283it [02:23, 17987.39it/s]1703918it [02:23, 23233.41it/s]1709518it [02:23, 32716.65it/s]1712899it [02:23, 33034.27it/s]1716237it [02:24, 32159.56it/s]1719482it [02:24, 29595.26it/s]1722498it [02:24, 28418.92it/s]1725382it [02:24, 27925.85it/s]1728203it [02:24, 27603.11it/s]1730982it [02:24, 27391.33it/s]1733770it [02:24, 27516.30it/s]1736780it [02:24, 28255.90it/s]1739923it [02:24, 29175.19it/s]1742850it [02:25, 28266.23it/s]1745688it [02:25, 28156.85it/s]1748712it [02:25, 28744.84it/s]1751594it [02:25, 28579.45it/s]1754465it [02:25, 28600.99it/s]1757329it [02:25, 28203.97it/s]1760153it [02:25, 28173.71it/s]1762973it [02:25, 27384.03it/s]1765717it [02:25, 26563.68it/s]1768446it [02:25, 26760.12it/s]1771244it [02:26, 27110.80it/s]1773989it [02:26, 27192.47it/s]1776805it [02:26, 27458.94it/s]1779554it [02:26, 27106.85it/s]1782708it [02:26, 28401.09it/s]1785553it [02:26, 27493.20it/s]1788311it [02:26, 26602.57it/s]1790982it [02:26, 25852.60it/s]1793644it [02:26, 26069.45it/s]1796422it [02:27, 26554.42it/s]1799188it [02:27, 26842.60it/s]1802088it [02:27, 27476.33it/s]1804841it [02:27, 27229.96it/s]1807614it [02:27, 27370.04it/s]1810354it [02:27, 27358.20it/s]1813209it [02:27, 27711.36it/s]1816061it [02:27, 27942.94it/s]1818857it [02:27, 27619.96it/s]1821651it [02:27, 27698.70it/s]1824499it [02:28, 27930.31it/s]1827697it [02:28, 29131.10it/s]1830631it [02:28, 29175.10it/s]1833677it [02:28, 29530.17it/s]1836748it [02:28, 29882.13it/s]1840412it [02:28, 31896.41it/s]1843603it [02:28, 31020.10it/s]1846711it [02:28, 29113.19it/s]1849648it [02:28, 29028.40it/s]1852569it [02:28, 28641.44it/s]1855445it [02:29, 28027.17it/s]1858257it [02:29, 27900.94it/s]1861129it [02:29, 28135.43it/s]1863954it [02:29, 28167.69it/s]1866916it [02:29, 28573.15it/s]1870031it [02:29, 29330.90it/s]1873218it [02:29, 30082.31it/s]1876362it [02:29, 30484.24it/s]1879516it [02:29, 30795.28it/s]1882598it [02:29, 30310.77it/s]1885632it [02:30, 29410.83it/s]1888580it [02:30, 29283.37it/s]1891624it [02:30, 29582.60it/s]1894736it [02:30, 30028.73it/s]1897906it [02:30, 30514.62it/s]1901243it [02:30, 31361.91it/s]1904705it [02:30, 32313.64it/s]1908159it [02:30, 32977.74it/s]1911459it [02:30, 25088.65it/s]1914252it [02:32, 5082.46it/s] 1916255it [02:33, 4234.53it/s]1917736it [02:34, 3697.80it/s]1918844it [02:34, 3424.38it/s]1919694it [02:35, 3108.63it/s]1920351it [02:35, 2919.68it/s]1920875it [02:35, 2910.07it/s]1921328it [02:35, 2741.11it/s]1921707it [02:35, 2824.39it/s]1922075it [02:36, 2593.36it/s]1922414it [02:36, 2711.03it/s]1922735it [02:36, 2576.56it/s]1923024it [02:36, 2449.84it/s]1923288it [02:36, 2298.44it/s]1923529it [02:36, 2250.89it/s]1923761it [02:36, 2185.47it/s]1923983it [02:36, 2174.31it/s]1924335it [02:36, 2510.52it/s]1924610it [02:37, 2571.76it/s]1924874it [02:37, 2539.31it/s]1925133it [02:37, 2447.56it/s]1925438it [02:37, 2610.19it/s]1925721it [02:37, 2670.42it/s]1926028it [02:37, 2783.90it/s]1926344it [02:37, 2892.42it/s]1926636it [02:37, 2548.65it/s]1926921it [02:37, 2628.44it/s]1927266it [02:38, 2854.33it/s]1927634it [02:38, 3085.99it/s]1927976it [02:38, 3178.19it/s]1928339it [02:38, 3308.98it/s]1928725it [02:38, 3468.73it/s]1929075it [02:38, 3443.37it/s]1929426it [02:38, 3462.43it/s]1929774it [02:38, 3403.34it/s]1930116it [02:38, 3390.35it/s]1930456it [02:38, 3314.30it/s]1930789it [02:39, 3210.58it/s]1931112it [02:39, 3007.58it/s]1931416it [02:39, 2909.67it/s]1931709it [02:39, 2853.39it/s]1932017it [02:39, 2915.14it/s]1932323it [02:39, 2955.82it/s]1932620it [02:39, 2697.18it/s]1932897it [02:39, 2715.75it/s]1933173it [02:40, 2263.46it/s]1933461it [02:40, 2416.44it/s]1933716it [02:40, 2083.53it/s]1934002it [02:40, 2249.51it/s]1934263it [02:40, 2340.92it/s]1934603it [02:40, 2623.24it/s]1934920it [02:40, 2773.91it/s]1935211it [02:40, 2811.94it/s]1935522it [02:41, 2284.17it/s]1935772it [02:41, 1170.40it/s]1936015it [02:41, 1342.96it/s]1936292it [02:41, 1590.90it/s]1936546it [02:41, 1778.48it/s]1936836it [02:41, 2025.58it/s]1937140it [02:42, 2267.96it/s]1937406it [02:42, 2350.14it/s]1937670it [02:42, 2334.28it/s]1937932it [02:42, 2322.83it/s]1938179it [02:42, 1508.93it/s]1938462it [02:42, 1722.95it/s]1938675it [02:42, 1759.53it/s]1938931it [02:42, 1943.12it/s]1939152it [02:43, 2001.11it/s]1939372it [02:43, 2037.72it/s]1939595it [02:43, 2087.48it/s]1939834it [02:43, 2168.72it/s]1940059it [02:43, 1698.61it/s]1940250it [02:43, 1377.49it/s]1940516it [02:43, 1648.21it/s]1940738it [02:44, 1779.33it/s]1941064it [02:44, 2147.65it/s]1941358it [02:44, 2355.18it/s]1941613it [02:44, 1819.15it/s]1941827it [02:44, 1391.00it/s]1942133it [02:44, 1711.79it/s]1942356it [02:44, 1800.36it/s]1942569it [02:45, 1791.78it/s]1942816it [02:45, 1952.52it/s]1943084it [02:45, 2137.72it/s]1943383it [02:45, 2364.91it/s]1943653it [02:45, 2443.23it/s]1943912it [02:45, 2482.75it/s]1944191it [02:45, 2568.30it/s]1944454it [02:45, 2555.72it/s]1944743it [02:45, 2652.81it/s]1945012it [02:46, 2167.57it/s]1945318it [02:46, 2393.10it/s]1945588it [02:46, 2473.87it/s]1945900it [02:46, 2650.49it/s]1946175it [02:47, 532.97it/s] 1946373it [02:48, 517.03it/s]1946570it [02:48, 631.62it/s]1946736it [02:48, 710.65it/s]1946938it [02:48, 871.20it/s]1947106it [02:48, 920.02it/s]1947324it [02:48, 1126.92it/s]1947553it [02:48, 1347.75it/s]1947741it [02:49, 1396.99it/s]1948064it [02:49, 1809.39it/s]1948354it [02:49, 2073.40it/s]1948621it [02:49, 2227.25it/s]1948904it [02:49, 2385.90it/s]1949163it [02:49, 1546.98it/s]1949370it [02:49, 1545.41it/s]1949561it [02:50, 1455.30it/s]1949840it [02:50, 1739.66it/s]1950108it [02:50, 1936.22it/s]1950327it [02:50, 1756.07it/s]1950523it [02:50, 1415.87it/s]1950687it [02:50, 1279.69it/s]1950903it [02:50, 1462.07it/s]1951113it [02:51, 1434.37it/s]1951271it [02:51, 1239.58it/s]1951592it [02:51, 1660.38it/s]1951784it [02:51, 1496.83it/s]1951953it [02:51, 1486.23it/s]1952115it [02:51, 1260.63it/s]1952340it [02:51, 1475.19it/s]1952505it [02:52, 926.15it/s] 1952634it [02:52, 947.37it/s]1952869it [02:52, 1214.49it/s]1953140it [02:52, 1532.37it/s]1953330it [02:52, 1334.77it/s]1953493it [02:53, 1006.91it/s]1953625it [02:53, 715.26it/s] 1953873it [02:53, 916.44it/s]1953997it [02:53, 884.74it/s]1954272it [02:53, 1215.97it/s]1954432it [02:54, 746.94it/s] 1954651it [02:54, 952.65it/s]1954802it [02:54, 998.86it/s]1955087it [02:54, 1346.26it/s]1955337it [02:54, 1590.22it/s]1955542it [02:54, 1695.89it/s]1955746it [02:55, 1183.48it/s]1955909it [02:55, 835.12it/s] 1956129it [02:55, 1042.62it/s]1956284it [02:55, 992.20it/s] 1956491it [02:55, 1188.77it/s]1956724it [02:55, 1424.75it/s]1956915it [02:56, 1487.49it/s]1957132it [02:56, 1649.45it/s]1957320it [02:56, 1561.57it/s]1957493it [02:56, 1530.25it/s]1957696it [02:56, 1657.03it/s]1957890it [02:56, 1732.18it/s]1958092it [02:56, 1802.07it/s]1958292it [02:56, 1857.14it/s]1958519it [02:56, 1975.47it/s]1958721it [02:57, 1425.00it/s]1958952it [02:57, 1609.35it/s]1959135it [02:57, 1617.80it/s]1959313it [02:57, 1478.73it/s]1959474it [02:57, 1480.73it/s]1959658it [02:57, 1571.47it/s]1959850it [02:57, 1642.57it/s]1960069it [02:57, 1791.02it/s]1960288it [02:58, 1902.63it/s]1960483it [02:58, 1818.98it/s]1960669it [02:58, 1732.81it/s]1960846it [02:58, 1717.56it/s]1961051it [02:58, 1794.01it/s]1961233it [02:58, 1380.17it/s]1961471it [02:58, 1615.32it/s]1961650it [02:58, 1599.09it/s]1961848it [02:59, 1696.26it/s]1962059it [02:59, 1804.44it/s]1962248it [02:59, 1740.66it/s]1962428it [02:59, 1684.95it/s]1962632it [02:59, 1781.80it/s]1962833it [02:59, 1840.37it/s]1963035it [02:59, 1891.43it/s]1963227it [02:59, 1831.25it/s]1963413it [02:59, 1763.55it/s]1963616it [03:00, 1786.61it/s]1963796it [03:00, 1648.63it/s]1963964it [03:00, 1639.22it/s]1964176it [03:00, 1766.84it/s]1964355it [03:00, 1760.62it/s]1964587it [03:00, 1918.07it/s]1964781it [03:00, 1898.38it/s]1964973it [03:00, 1823.34it/s]1965210it [03:00, 1977.95it/s]1965426it [03:00, 2028.33it/s]1965631it [03:01, 1928.75it/s]1965826it [03:01, 1405.99it/s]1966058it [03:01, 1612.46it/s]1966241it [03:01, 1478.16it/s]1966445it [03:01, 1573.04it/s]1966616it [03:01, 1458.93it/s]1966776it [03:01, 1434.57it/s]1966928it [03:02, 1452.88it/s]1967099it [03:02, 1518.19it/s]1967299it [03:02, 1648.71it/s]1967475it [03:02, 1677.81it/s]1967692it [03:02, 1816.18it/s]1967879it [03:02, 1831.23it/s]1968099it [03:02, 1935.42it/s]1968295it [03:02, 1505.26it/s]1968462it [03:02, 1451.66it/s]1968629it [03:03, 1505.14it/s]1968852it [03:03, 1693.36it/s]1969031it [03:03, 1673.40it/s]1969223it [03:03, 1740.49it/s]1969402it [03:03, 1727.31it/s]1969579it [03:03, 1699.20it/s]1969752it [03:03, 1676.75it/s]1969922it [03:03, 1639.62it/s]1970111it [03:03, 1709.78it/s]1970284it [03:04, 1400.89it/s]1970434it [03:04, 1378.34it/s]1970642it [03:04, 1534.98it/s]1970807it [03:04, 1564.15it/s]1970969it [03:04, 1562.41it/s]1971171it [03:04, 1690.00it/s]1971344it [03:04, 1519.71it/s]1971542it [03:04, 1642.50it/s]1971721it [03:04, 1681.98it/s]1971894it [03:05, 1659.53it/s]1972092it [03:05, 1749.41it/s]1972299it [03:05, 1841.38it/s]1972486it [03:05, 1828.14it/s]1972679it [03:05, 1857.33it/s]1972899it [03:05, 1957.50it/s]1973096it [03:05, 1887.74it/s]1973289it [03:05, 1899.78it/s]1973480it [03:05, 1758.51it/s]1973659it [03:06, 1727.01it/s]1973890it [03:06, 1888.09it/s]1974082it [03:06, 1543.43it/s]1974248it [03:06, 1542.33it/s]1974411it [03:06, 1547.11it/s]1974572it [03:06, 1547.54it/s]1974795it [03:06, 1734.71it/s]1975056it [03:06, 1977.66it/s]1975259it [03:06, 1909.98it/s]1975454it [03:07, 1859.08it/s]1975670it [03:07, 1942.27it/s]1975867it [03:07, 1925.06it/s]1976140it [03:07, 2153.02it/s]1976389it [03:07, 2248.69it/s]1976616it [03:07, 2224.96it/s]1976840it [03:07, 2113.09it/s]1977058it [03:07, 2129.26it/s]1977273it [03:07, 2098.50it/s]1977484it [03:08, 1971.07it/s]1977684it [03:08, 1877.01it/s]1977883it [03:08, 1905.30it/s]1978076it [03:08, 1536.15it/s]1978242it [03:08, 1410.57it/s]1978409it [03:08, 1471.94it/s]1978565it [03:08, 1489.60it/s]1978733it [03:08, 1538.43it/s]1978948it [03:08, 1706.38it/s]1979283it [03:09, 2169.07it/s]1979568it [03:09, 2363.17it/s]1979813it [03:09, 2387.52it/s]1980058it [03:09, 2405.61it/s]1980302it [03:09, 2193.47it/s]1980541it [03:09, 2246.75it/s]1980770it [03:09, 2061.03it/s]1981001it [03:09, 2126.53it/s]1981219it [03:09, 2050.75it/s]1981428it [03:10, 1986.69it/s]1981630it [03:10, 1982.07it/s]1981830it [03:10, 1916.68it/s]1982023it [03:10, 1797.86it/s]1982205it [03:10, 1751.83it/s]1982401it [03:10, 1807.71it/s]1982588it [03:10, 1822.58it/s]1982772it [03:10, 1486.11it/s]1982941it [03:11, 1536.85it/s]1983103it [03:11, 1040.67it/s]1983234it [03:11, 630.14it/s] 1983354it [03:11, 710.58it/s]1983520it [03:11, 869.25it/s]1983644it [03:12, 878.37it/s]1983767it [03:12, 950.04it/s]1983945it [03:12, 1137.04it/s]1984168it [03:12, 1403.82it/s]1984371it [03:12, 1558.55it/s]1984612it [03:12, 1756.95it/s]1984814it [03:12, 1828.85it/s]1985027it [03:12, 1910.68it/s]1985278it [03:12, 2080.65it/s]1985511it [03:13, 2151.65it/s]1985731it [03:13, 1637.66it/s]1986006it [03:13, 1903.92it/s]1986218it [03:13, 1837.58it/s]1986478it [03:13, 2030.90it/s]1986696it [03:13, 1954.45it/s]1986902it [03:13, 1818.40it/s]1987092it [03:13, 1705.78it/s]1987269it [03:14, 1720.41it/s]1987449it [03:14, 1722.98it/s]1987625it [03:14, 1215.26it/s]1987784it [03:14, 1294.99it/s]1987947it [03:14, 1360.38it/s]1988098it [03:14, 1293.23it/s]1988305it [03:14, 1476.90it/s]1988464it [03:14, 1473.04it/s]1988628it [03:15, 1516.68it/s]1988786it [03:15, 1258.91it/s]1988978it [03:15, 1420.29it/s]1989179it [03:15, 1572.18it/s]1989381it [03:15, 1692.66it/s]1989559it [03:15, 1713.87it/s]1989737it [03:15, 1718.44it/s]1989921it [03:15, 1753.13it/s]1990129it [03:15, 1847.90it/s]1990317it [03:16, 1724.93it/s]1990493it [03:16, 1617.44it/s]1990659it [03:16, 1312.91it/s]1990801it [03:16, 1328.66it/s]1991025it [03:16, 1558.59it/s]1991223it [03:16, 1669.26it/s]1991420it [03:16, 1751.10it/s]1991632it [03:16, 1854.74it/s]1991823it [03:16, 1816.96it/s]1992009it [03:17, 1822.32it/s]1992194it [03:17, 1700.74it/s]1992381it [03:17, 1746.86it/s]1992559it [03:17, 1579.45it/s]1992751it [03:17, 1668.36it/s]1992980it [03:17, 1789.45it/s]1993218it [03:17, 1949.13it/s]1993417it [03:17, 1589.46it/s]1993611it [03:18, 1674.88it/s]1993857it [03:18, 1847.91it/s]1994051it [03:18, 1815.77it/s]1994314it [03:18, 2035.88it/s]1994594it [03:18, 2246.75it/s]1994851it [03:18, 2334.76it/s]1995131it [03:18, 2468.28it/s]1995382it [03:18, 2442.32it/s]1995629it [03:18, 2389.06it/s]1995872it [03:18, 2398.50it/s]1996114it [03:19, 1402.60it/s]1996308it [03:19, 1506.29it/s]1996542it [03:19, 1687.50it/s]1996811it [03:19, 1924.05it/s]1997067it [03:19, 2083.87it/s]1997300it [03:19, 1930.07it/s]1997519it [03:19, 1994.05it/s]1997733it [03:20, 1916.16it/s]1997935it [03:20, 1744.64it/s]1998134it [03:20, 1805.31it/s]1998392it [03:20, 2010.50it/s]1998602it [03:20, 1867.89it/s]1998796it [03:20, 1317.47it/s]1999026it [03:20, 1521.21it/s]1999238it [03:21, 1657.66it/s]1999477it [03:21, 1837.31it/s]1999718it [03:21, 1984.56it/s]2000009it [03:21, 2234.89it/s]2000247it [03:21, 2056.76it/s]2000495it [03:21, 2167.78it/s]2000750it [03:21, 2232.95it/s]2000981it [03:21, 2210.52it/s]2001265it [03:21, 2383.16it/s]2001508it [03:21, 2261.77it/s]2001763it [03:22, 2264.50it/s]2001993it [03:22, 1643.63it/s]2002262it [03:22, 1825.46it/s]2002467it [03:22, 1592.67it/s]2002655it [03:22, 1654.90it/s]2002844it [03:22, 1710.98it/s]2003151it [03:22, 2058.55it/s]2003372it [03:23, 2051.32it/s]2003588it [03:23, 834.82it/s] 2003765it [03:23, 952.92it/s]2003981it [03:23, 1146.27it/s]2004161it [03:24, 1268.04it/s]2004340it [03:24, 1371.80it/s]2004538it [03:24, 1482.41it/s]2004718it [03:24, 1475.45it/s]2004950it [03:24, 1684.01it/s]2005232it [03:24, 1978.29it/s]2005497it [03:24, 2156.17it/s]2005727it [03:24, 2110.00it/s]2006000it [03:24, 2280.67it/s]2006242it [03:24, 2318.94it/s]2006481it [03:25, 2137.01it/s]2006702it [03:25, 2001.59it/s]2006909it [03:25, 1875.18it/s]2007138it [03:25, 1947.24it/s]2007337it [03:25, 1836.39it/s]2007524it [03:25, 1560.26it/s]2007716it [03:25, 1646.61it/s]2007942it [03:25, 1800.05it/s]2008130it [03:26, 1817.60it/s]2008354it [03:26, 1932.31it/s]2008645it [03:26, 2207.96it/s]2008878it [03:26, 2242.23it/s]2009106it [03:26, 1632.20it/s]2009369it [03:26, 1862.62it/s]2009581it [03:26, 1741.36it/s]2009812it [03:26, 1877.34it/s]2010016it [03:27, 1676.71it/s]2010294it [03:27, 1942.17it/s]2010505it [03:27, 1822.93it/s]2010706it [03:27, 1868.94it/s]2010986it [03:27, 2114.84it/s]2011208it [03:27, 2024.25it/s]2011421it [03:27, 2049.86it/s]2011632it [03:27, 2004.14it/s]2011837it [03:27, 1922.24it/s]2012033it [03:28, 1914.59it/s]2012227it [03:28, 1873.94it/s]2012471it [03:28, 2030.51it/s]2012677it [03:28, 2024.09it/s]2012884it [03:28, 2006.30it/s]2013101it [03:28, 2053.08it/s]2013367it [03:28, 2229.06it/s]2013591it [03:28, 2221.10it/s]2013849it [03:28, 2325.12it/s]2014083it [03:29, 1943.99it/s]2014319it [03:29, 2049.88it/s]2014534it [03:29, 1994.96it/s]2014774it [03:29, 2103.48it/s]2014990it [03:29, 1862.29it/s]2015199it [03:29, 1881.38it/s]2015411it [03:29, 1944.66it/s]2015611it [03:29, 1760.27it/s]2015837it [03:29, 1890.41it/s]2016056it [03:30, 1971.65it/s]2016294it [03:30, 2084.00it/s]2016580it [03:30, 2303.04it/s]2016825it [03:30, 2344.63it/s]2017073it [03:30, 2384.00it/s]2017331it [03:30, 2438.08it/s]2017577it [03:30, 2432.60it/s]2017822it [03:30, 1842.77it/s]2018029it [03:31, 1107.15it/s]2018220it [03:31, 1241.75it/s]2018390it [03:31, 1183.30it/s]2018540it [03:31, 814.79it/s] 2018657it [03:32, 743.98it/s]2018807it [03:32, 845.80it/s]2018946it [03:32, 940.80it/s]2019177it [03:32, 1221.36it/s]2019328it [03:32, 992.59it/s] 2019477it [03:32, 1037.72it/s]2019600it [03:32, 1010.24it/s]2019715it [03:33, 979.16it/s] 2019822it [03:33, 762.88it/s]2019973it [03:33, 911.13it/s]2020080it [03:33, 894.20it/s]2020249it [03:33, 1013.14it/s]2020359it [03:33, 746.18it/s] 2020449it [03:34, 734.21it/s]2020533it [03:34, 593.38it/s]2020607it [03:34, 607.72it/s]2020720it [03:34, 716.54it/s]2020949it [03:34, 1079.00it/s]2021241it [03:34, 1533.64it/s]2021417it [03:34, 1565.08it/s]2021590it [03:34, 1599.35it/s]2021762it [03:35, 1497.42it/s]2021953it [03:35, 1605.55it/s]2022130it [03:35, 1649.91it/s]2022343it [03:35, 1784.61it/s]2022571it [03:35, 1926.71it/s]2022768it [03:35, 1824.90it/s]2022955it [03:35, 1580.30it/s]2023138it [03:35, 1643.20it/s]2023408it [03:35, 1925.06it/s]2023635it [03:35, 2018.18it/s]2023844it [03:36, 1818.59it/s]2024095it [03:36, 2000.36it/s]2024340it [03:36, 2122.37it/s]2024572it [03:36, 2038.59it/s]2024782it [03:36, 1374.08it/s]2025005it [03:36, 1550.88it/s]2025190it [03:37, 1387.28it/s]2025373it [03:37, 1483.77it/s]2025617it [03:37, 1668.41it/s]2025801it [03:37, 1598.30it/s]2026045it [03:37, 1805.23it/s]2026238it [03:37, 1736.46it/s]2026437it [03:37, 1801.37it/s]2026625it [03:37, 1749.74it/s]2026817it [03:37, 1792.94it/s]2027001it [03:38, 1617.25it/s]2027212it [03:38, 1703.94it/s]2027387it [03:38, 1507.98it/s]2027584it [03:38, 1622.40it/s]2027763it [03:38, 1630.81it/s]2027931it [03:38, 1639.99it/s]2028215it [03:38, 1971.93it/s]2028447it [03:38, 2069.43it/s]2028704it [03:38, 2212.28it/s]2028942it [03:39, 2258.82it/s]2029177it [03:39, 1872.83it/s]2029378it [03:39, 1079.31it/s]2029543it [03:39, 1176.94it/s]2029738it [03:39, 1316.55it/s]2029905it [03:39, 1346.51it/s]2030065it [03:40, 1340.82it/s]2030217it [03:40, 1164.04it/s]2030362it [03:40, 1227.73it/s]2030588it [03:40, 1476.08it/s]2030798it [03:40, 1624.54it/s]2031006it [03:40, 1744.79it/s]2031223it [03:40, 1861.60it/s]2031418it [03:40, 1566.26it/s]2031661it [03:40, 1780.02it/s]2031886it [03:41, 1902.50it/s]2032126it [03:41, 2036.14it/s]2032357it [03:41, 2098.36it/s]2032574it [03:41, 1909.13it/s]2032818it [03:41, 2051.12it/s]2033055it [03:41, 2137.09it/s]2033343it [03:41, 2345.67it/s]2033583it [03:41, 2334.63it/s]2033855it [03:41, 2443.01it/s]2034103it [03:42, 2359.98it/s]2034342it [03:42, 2167.94it/s]2034564it [03:42, 2149.72it/s]2034782it [03:42, 1744.78it/s]2034979it [03:42, 1791.19it/s]2035169it [03:42, 1802.45it/s]2035357it [03:42, 1667.28it/s]2035562it [03:42, 1764.13it/s]2035849it [03:43, 2058.30it/s]2036063it [03:43, 1794.76it/s]2036275it [03:43, 1875.36it/s]2036472it [03:43, 1880.11it/s]2036746it [03:43, 2115.15it/s]2036965it [03:43, 2130.55it/s]2037207it [03:43, 2213.09it/s]2037433it [03:43, 2080.20it/s]2037681it [03:43, 2188.21it/s]2037904it [03:44, 2176.98it/s]2038188it [03:44, 2366.00it/s]2038428it [03:44, 1692.01it/s]2038626it [03:44, 1715.47it/s]2038818it [03:44, 1757.66it/s]2039090it [03:44, 2002.23it/s]2039306it [03:45, 988.23it/s] 2039470it [03:45, 863.65it/s]2039603it [03:45, 627.25it/s]2039706it [03:46, 431.10it/s]2039784it [03:46, 441.77it/s]2039862it [03:46, 480.29it/s]2039933it [03:46, 483.11it/s]2039998it [03:48, 169.28it/s]2040219it [03:48, 317.30it/s]2040406it [03:48, 463.04it/s]2040606it [03:48, 644.57it/s]2040797it [03:48, 805.38it/s]2040949it [03:48, 804.47it/s]2041084it [03:48, 888.11it/s]2041213it [03:49, 719.82it/s]2041367it [03:49, 859.92it/s]2041486it [03:49, 855.11it/s]2041690it [03:49, 1098.32it/s]2041903it [03:49, 1331.38it/s]2042284it [03:49, 1937.91it/s]2042609it [03:49, 2276.71it/s]2043427it [03:49, 3871.35it/s]2044464it [03:49, 5680.48it/s]2045401it [03:50, 6727.44it/s]2046280it [03:50, 7321.49it/s]2047118it [03:50, 7629.83it/s]2047954it [03:50, 7844.71it/s]2048862it [03:50, 8210.22it/s]2049794it [03:50, 8539.27it/s]2050671it [03:50, 8602.82it/s]2051538it [03:50, 8616.85it/s]2052433it [03:50, 8715.68it/s]2053308it [03:50, 8486.04it/s]2054160it [03:51, 8393.38it/s]2055004it [03:51, 8406.74it/s]2055862it [03:51, 8457.11it/s]2056709it [03:51, 8453.10it/s]2057578it [03:51, 8515.25it/s]2058431it [03:51, 8494.75it/s]2059281it [03:51, 8487.54it/s]2060131it [03:51, 8402.29it/s]2061004it [03:51, 8494.91it/s]2061855it [03:51, 8499.13it/s]2062706it [03:52, 7153.70it/s]2064179it [03:52, 9152.88it/s]2065665it [03:52, 10712.28it/s]2067068it [03:52, 11644.73it/s]2068543it [03:52, 12528.60it/s]2069955it [03:52, 12980.50it/s]2071350it [03:52, 13263.98it/s]2072695it [03:52, 13217.63it/s]2074207it [03:52, 13778.18it/s]2075688it [03:53, 14082.95it/s]2077243it [03:53, 14515.97it/s]2080103it [03:53, 18714.97it/s]2090370it [03:53, 43752.54it/s]2100937it [03:53, 62246.35it/s]2111127it [03:53, 74084.50it/s]2121881it [03:53, 84098.83it/s]2132520it [03:53, 90723.31it/s]2143040it [03:53, 95040.78it/s]2153276it [03:53, 97214.64it/s]2164287it [03:54, 101045.21it/s]2175000it [03:54, 102862.77it/s]2185928it [03:54, 104785.02it/s]2196471it [03:54, 104953.16it/s]2206968it [03:54, 104859.52it/s]2217594it [03:54, 105151.31it/s]2228110it [03:54, 103957.20it/s]2238509it [03:54, 101667.75it/s]2248871it [03:54, 102239.12it/s]2259304it [03:54, 102855.93it/s]2269774it [03:55, 103347.68it/s]2280547it [03:55, 104632.73it/s]2291016it [03:55, 102276.61it/s]2301258it [03:55, 98041.94it/s] 2311103it [03:55, 97531.21it/s]2321035it [03:55, 98047.76it/s]2330975it [03:55, 98442.11it/s]2341135it [03:55, 99337.38it/s]2351082it [03:55, 99020.54it/s]2361302it [03:55, 99938.75it/s]2371303it [03:56, 99216.98it/s]2381231it [03:56, 97661.22it/s]2391005it [03:56, 97048.22it/s]2400961it [03:56, 97787.44it/s]2410745it [03:56, 97739.53it/s]2420850it [03:56, 98664.23it/s]2430758it [03:56, 98787.22it/s]2440640it [03:56, 98262.05it/s]2450689it [03:56, 98922.78it/s]2460584it [03:57, 97269.16it/s]2470318it [03:57, 97168.71it/s]2480424it [03:57, 98320.43it/s]2490572it [03:57, 99258.23it/s]2500502it [03:57, 98206.61it/s]2510405it [03:57, 98446.76it/s]2520254it [03:57, 96680.42it/s]2530120it [03:57, 97195.16it/s]2539847it [03:57, 96620.89it/s]2549625it [03:57, 96961.21it/s]2559325it [03:58, 95871.40it/s]2568991it [03:58, 96033.60it/s]2578647it [03:58, 96187.92it/s]2588289it [03:58, 96211.97it/s]2598510it [03:58, 97860.44it/s]2608298it [03:58, 97427.75it/s]2618295it [03:58, 98074.87it/s]2628326it [03:58, 98737.65it/s]2638310it [03:58, 99065.56it/s]2648218it [03:58, 98818.68it/s]2658101it [03:59, 98820.19it/s]2668001it [03:59, 98860.48it/s]2677888it [03:59, 98402.18it/s]2687729it [03:59, 97983.47it/s]2697529it [03:59, 96593.20it/s]2707330it [03:59, 97004.72it/s]2717034it [03:59, 96373.69it/s]2726675it [03:59, 95951.23it/s]2736273it [03:59, 94984.35it/s]2746301it [03:59, 96524.81it/s]2755958it [04:00, 96159.42it/s]2765577it [04:00, 94546.02it/s]2775039it [04:00, 94159.87it/s]2784460it [04:00, 92764.34it/s]2793844it [04:00, 93005.73it/s]2803277it [04:00, 93394.95it/s]2812989it [04:00, 94464.98it/s]2822871it [04:00, 95658.73it/s]2832836it [04:00, 96820.22it/s]2842521it [04:00, 96411.59it/s]2852320it [04:01, 96848.82it/s]2862007it [04:01, 96810.17it/s]2871690it [04:01, 96120.89it/s]2881304it [04:01, 95570.59it/s]2891056it [04:01, 96091.42it/s]2900667it [04:01, 94531.57it/s]2910191it [04:01, 94704.47it/s]2919885it [04:01, 95322.20it/s]2929421it [04:01, 93767.39it/s]2938805it [04:02, 53958.09it/s]2946177it [04:03, 16149.82it/s]2951493it [04:05, 8002.68it/s] 2955295it [04:12, 2519.11it/s]2957974it [04:16, 1691.52it/s]2959867it [04:18, 1492.88it/s]2961218it [04:19, 1629.27it/s]2962321it [04:19, 1770.23it/s]2963239it [04:19, 1925.34it/s]2964031it [04:19, 2100.17it/s]2964739it [04:19, 2287.68it/s]2965379it [04:20, 2500.86it/s]2965976it [04:20, 2773.17it/s]2966566it [04:20, 3081.81it/s]2967148it [04:20, 3421.25it/s]2967726it [04:20, 3714.23it/s]2968285it [04:20, 3308.96it/s]2968751it [04:20, 3175.77it/s]2969161it [04:21, 3028.34it/s]2969708it [04:21, 3489.23it/s]2970275it [04:21, 3950.80it/s]2970806it [04:21, 4267.26it/s]2971309it [04:21, 4454.96it/s]2971862it [04:21, 4735.33it/s]2972427it [04:21, 4982.59it/s]2972952it [04:21, 4367.63it/s]2973520it [04:21, 4702.94it/s]2974018it [04:22, 4071.22it/s]2974551it [04:22, 4378.73it/s]2975061it [04:22, 4563.67it/s]2975541it [04:22, 3544.17it/s]2976159it [04:22, 4146.03it/s]2976767it [04:22, 4621.76it/s]2977453it [04:22, 5201.25it/s]2978100it [04:22, 5540.66it/s]2978716it [04:22, 5707.69it/s]2979312it [04:23, 5579.05it/s]2979888it [04:23, 5346.12it/s]2980437it [04:23, 4754.18it/s]2980962it [04:23, 4879.93it/s]2981476it [04:23, 4947.75it/s]2981983it [04:23, 4945.37it/s]2982512it [04:23, 5042.36it/s]2983034it [04:23, 5090.86it/s]2983548it [04:23, 5090.79it/s]2984061it [04:24, 5025.99it/s]2984573it [04:24, 5050.73it/s]2985090it [04:24, 5085.27it/s]2985619it [04:24, 5144.78it/s]2986135it [04:24, 5141.04it/s]2986667it [04:24, 5190.04it/s]2987191it [04:24, 5200.59it/s]2987712it [04:24, 5123.09it/s]2988246it [04:24, 5186.60it/s]2988801it [04:24, 5292.37it/s]2989338it [04:25, 5309.62it/s]2989870it [04:25, 5141.54it/s]2990386it [04:25, 5139.24it/s]2990914it [04:25, 5179.84it/s]2991435it [04:25, 5184.31it/s]2991962it [04:25, 5209.54it/s]2992563it [04:25, 5443.81it/s]2993108it [04:25, 5290.31it/s]2993658it [04:25, 5346.42it/s]2994194it [04:25, 5181.43it/s]2994781it [04:26, 5377.63it/s]2995333it [04:26, 5417.34it/s]2995877it [04:26, 5387.94it/s]2996482it [04:26, 5577.09it/s]2997041it [04:26, 5564.28it/s]2997599it [04:26, 5535.14it/s]2998153it [04:26, 5463.86it/s]2998700it [04:26, 5437.23it/s]2999245it [04:26, 5430.55it/s]2999789it [04:26, 5329.75it/s]3000323it [04:27, 3597.40it/s]3000848it [04:27, 3961.27it/s]3001362it [04:27, 4243.33it/s]3001884it [04:27, 4491.50it/s]3002461it [04:27, 4829.69it/s]3002977it [04:27, 4878.46it/s]3003525it [04:27, 5043.70it/s]3004098it [04:27, 5232.51it/s]3004698it [04:28, 5450.15it/s]3005308it [04:28, 5639.95it/s]3005880it [04:28, 5567.17it/s]3006449it [04:28, 5602.56it/s]3007014it [04:28, 5481.88it/s]3007591it [04:28, 5561.60it/s]3008150it [04:28, 5562.40it/s]3008708it [04:28, 5562.81it/s]3009266it [04:28, 5472.70it/s]3009815it [04:28, 5430.37it/s]3010359it [04:29, 5361.12it/s]3010896it [04:29, 5347.67it/s]3011432it [04:29, 5220.76it/s]3011963it [04:29, 5246.65it/s]3012519it [04:29, 5334.19it/s]3013094it [04:29, 5456.17it/s]3013756it [04:29, 5801.36it/s]3014339it [04:29, 5808.98it/s]3014958it [04:29, 5922.00it/s]3015551it [04:30, 5772.92it/s]3016130it [04:30, 5602.65it/s]3016692it [04:30, 5550.11it/s]3017249it [04:30, 5488.63it/s]3017799it [04:30, 5412.98it/s]3018341it [04:31, 1811.56it/s]3018741it [04:31, 1532.92it/s]3019281it [04:31, 1972.86it/s]3019822it [04:31, 2450.95it/s]3020249it [04:31, 2604.16it/s]3020707it [04:32, 2948.23it/s]3021178it [04:32, 3143.81it/s]3021690it [04:32, 3576.31it/s]3022245it [04:32, 4045.40it/s]3022817it [04:32, 4470.30it/s]3023348it [04:32, 4689.41it/s]3023918it [04:32, 4966.92it/s]3024526it [04:32, 5278.73it/s]3025391it [04:32, 6244.89it/s]3026102it [04:32, 6496.22it/s]3026960it [04:33, 7103.64it/s]3027834it [04:33, 7582.20it/s]3028700it [04:33, 7895.36it/s]3029569it [04:33, 8124.64it/s]3030387it [04:33, 8140.30it/s]3031235it [04:33, 8233.57it/s]3032165it [04:33, 8531.45it/s]3033020it [04:33, 8531.52it/s]3033875it [04:33, 8482.75it/s]3034725it [04:33, 8464.41it/s]3035573it [04:34, 8350.66it/s]3036454it [04:34, 8486.07it/s]3037304it [04:34, 8329.62it/s]3038199it [04:34, 8511.17it/s]3039081it [04:34, 8588.43it/s]3039941it [04:34, 5396.59it/s]3040629it [04:34, 5055.61it/s]3041478it [04:35, 5774.16it/s]3042366it [04:35, 6489.01it/s]3043182it [04:35, 6625.82it/s]3043912it [04:35, 6021.94it/s]3044806it [04:35, 6725.19it/s]3045586it [04:35, 7001.80it/s]3046329it [04:35, 6546.49it/s]3047155it [04:35, 6993.65it/s]3047890it [04:35, 7088.80it/s]3048742it [04:36, 7486.73it/s]3049624it [04:36, 7864.74it/s]3050426it [04:36, 7099.81it/s]3051296it [04:36, 7524.27it/s]3052158it [04:36, 7828.93it/s]3053067it [04:36, 8184.38it/s]3054046it [04:36, 8646.71it/s]3054978it [04:36, 8841.81it/s]3055871it [04:36, 8852.30it/s]3056763it [04:37, 8706.79it/s]3057639it [04:37, 8674.60it/s]3058647it [04:37, 9068.04it/s]3059557it [04:37, 9010.13it/s]3060460it [04:37, 8976.45it/s]3061360it [04:37, 8812.01it/s]3062243it [04:38, 3342.04it/s]3062902it [04:38, 2050.62it/s]3063391it [04:39, 1708.05it/s]3064292it [04:39, 2374.73it/s]3064988it [04:39, 2903.90it/s]3065568it [04:39, 3011.70it/s]3066237it [04:39, 3581.99it/s]3066793it [04:40, 3588.88it/s]3067291it [04:40, 3421.03it/s]3067729it [04:40, 3280.10it/s]3068641it [04:40, 4457.60it/s]3069305it [04:40, 4799.05it/s]3069864it [04:40, 3628.62it/s]3070435it [04:40, 4039.47it/s]3071313it [04:40, 5079.17it/s]3071919it [04:41, 4508.13it/s]3072448it [04:41, 3488.31it/s]3073358it [04:41, 4568.74it/s]3074209it [04:41, 5419.47it/s]3075038it [04:41, 6096.04it/s]3075836it [04:41, 6570.53it/s]3076572it [04:41, 5723.96it/s]3077220it [04:42, 5906.51it/s]3077866it [04:42, 5048.89it/s]3078615it [04:42, 5621.10it/s]3079233it [04:42, 4631.58it/s]3079760it [04:42, 3463.09it/s]3080563it [04:42, 4320.67it/s]3081402it [04:43, 5182.27it/s]3082271it [04:43, 5543.47it/s]3082905it [04:43, 5350.97it/s]3083822it [04:43, 6261.44it/s]3084714it [04:43, 6929.92it/s]3085598it [04:43, 7430.05it/s]3086449it [04:43, 7722.04it/s]3087352it [04:43, 8089.28it/s]3088360it [04:43, 8660.87it/s]3089247it [04:44, 5311.89it/s]3089951it [04:44, 4659.00it/s]3090826it [04:44, 5443.46it/s]3091748it [04:44, 6255.78it/s]3092585it [04:44, 6747.84it/s]3093454it [04:44, 7229.83it/s]3094387it [04:44, 7781.33it/s]3095286it [04:45, 8111.83it/s]3096205it [04:45, 8414.55it/s]3097082it [04:45, 8452.43it/s]3097977it [04:45, 8586.59it/s]3098859it [04:45, 8654.30it/s]3099758it [04:45, 8748.39it/s]3100642it [04:45, 8493.64it/s]3101510it [04:45, 8545.49it/s]3102371it [04:45, 8053.41it/s]3103219it [04:45, 8169.28it/s]3104082it [04:46, 8285.42it/s]3104932it [04:46, 8342.14it/s]3105830it [04:46, 8524.43it/s]3106686it [04:46, 8521.74it/s]3107541it [04:46, 8440.65it/s]3108419it [04:46, 8533.68it/s]3109274it [04:46, 8335.70it/s]3110110it [04:46, 8196.02it/s]3110952it [04:46, 8260.64it/s]3111805it [04:46, 8337.75it/s]3112641it [04:47, 8333.02it/s]3113476it [04:47, 8275.77it/s]3114336it [04:47, 8368.47it/s]3115174it [04:47, 8263.02it/s]3116001it [04:47, 8181.77it/s]3116851it [04:47, 8274.07it/s]3117680it [04:47, 8269.52it/s]3118544it [04:47, 8379.09it/s]3119419it [04:47, 8486.15it/s]3120361it [04:47, 8755.16it/s]3121312it [04:48, 8980.52it/s]3122211it [04:48, 8845.49it/s]3123097it [04:48, 8351.95it/s]3123938it [04:48, 8303.51it/s]3124773it [04:48, 8078.68it/s]3125585it [04:48, 7891.63it/s]3126377it [04:48, 7841.46it/s]3127163it [04:49, 4998.58it/s]3127793it [04:49, 3350.43it/s]3128686it [04:49, 4233.25it/s]3129480it [04:49, 4914.49it/s]3130304it [04:49, 5431.52it/s]3131191it [04:49, 6198.61it/s]3132137it [04:49, 6987.93it/s]3133002it [04:50, 7414.66it/s]3133870it [04:50, 7746.19it/s]3134816it [04:50, 8220.61it/s]3135684it [04:50, 8342.81it/s]3136620it [04:50, 8629.14it/s]3137582it [04:50, 8913.88it/s]3138529it [04:50, 9076.44it/s]3139450it [04:50, 6343.12it/s]3140206it [04:51, 5722.11it/s]3140870it [04:51, 5842.26it/s]3141684it [04:51, 6383.65it/s]3142533it [04:51, 6907.09it/s]3143407it [04:51, 7391.35it/s]3144239it [04:51, 7645.51it/s]3145092it [04:51, 7889.43it/s]3145997it [04:51, 8218.52it/s]3146973it [04:51, 8665.55it/s]3147901it [04:51, 8839.57it/s]3148796it [04:52, 5699.25it/s]3149516it [04:52, 4044.94it/s]3150086it [04:53, 2534.46it/s]3150518it [04:53, 2585.44it/s]3151422it [04:53, 3507.77it/s]3152178it [04:53, 4193.25it/s]3152784it [04:53, 3064.05it/s]3153660it [04:53, 3961.14it/s]3154580it [04:53, 4921.32it/s]3155350it [04:54, 5497.03it/s]3156232it [04:54, 6253.46it/s]3157125it [04:54, 6910.93it/s]3157928it [04:54, 6827.19it/s]3158808it [04:54, 7338.89it/s]3159664it [04:54, 7659.35it/s]3160477it [04:54, 7767.65it/s]3161460it [04:54, 8345.11it/s]3162323it [04:54, 8419.53it/s]3163233it [04:55, 8617.13it/s]3164157it [04:55, 8792.22it/s]3165047it [04:55, 8330.31it/s]3165892it [04:55, 8024.48it/s]3166712it [04:55, 8071.46it/s]3167636it [04:55, 8404.32it/s]3168510it [04:55, 8501.55it/s]3169424it [04:55, 8688.55it/s]3170297it [04:55, 8584.22it/s]3171169it [04:55, 8619.88it/s]3172037it [04:56, 8637.53it/s]3172938it [04:56, 8746.86it/s]3173815it [04:56, 8749.47it/s]3174696it [04:56, 8763.00it/s]3175605it [04:56, 8857.72it/s]3176516it [04:56, 8920.45it/s]3177518it [04:56, 9247.34it/s]3178444it [04:56, 9006.88it/s]3179347it [04:56, 8583.37it/s]3180210it [04:57, 8236.11it/s]3181056it [04:57, 8298.38it/s]3182083it [04:57, 8859.76it/s]3183035it [04:57, 9047.32it/s]3183945it [04:57, 8955.92it/s]3184844it [04:57, 8892.39it/s]3185736it [04:57, 8796.37it/s]3186655it [04:57, 8906.90it/s]3187548it [04:57, 8898.76it/s]3188505it [04:57, 9079.81it/s]3189414it [04:58, 8775.71it/s]3190295it [04:58, 8751.68it/s]3191172it [04:58, 5450.54it/s]3191872it [04:58, 5397.21it/s]3192736it [04:58, 6095.56it/s]3193593it [04:58, 6677.26it/s]3194488it [04:58, 7245.45it/s]3195366it [04:58, 7650.95it/s]3196285it [04:59, 8066.20it/s]3197135it [04:59, 8161.15it/s]3197987it [04:59, 8250.68it/s]3198834it [04:59, 8297.81it/s]3199740it [04:59, 8517.80it/s]3200654it [04:59, 8699.23it/s]3201533it [04:59, 8540.31it/s]3202451it [04:59, 8727.18it/s]3203351it [04:59, 8807.15it/s]3204236it [04:59, 8701.00it/s]3205109it [05:00, 8469.09it/s]3205959it [05:00, 6141.73it/s]3206837it [05:00, 6751.17it/s]3207595it [05:00, 6269.50it/s]3208548it [05:00, 7055.11it/s]3209400it [05:00, 7428.23it/s]3210226it [05:00, 7645.45it/s]3211104it [05:00, 7958.14it/s]3211967it [05:01, 8148.44it/s]3212862it [05:01, 8373.93it/s]3213764it [05:01, 8560.89it/s]3214666it [05:01, 8695.76it/s]3215544it [05:01, 8698.79it/s]3216449it [05:01, 8801.98it/s]3217334it [05:01, 8658.65it/s]3218204it [05:01, 8231.87it/s]3219110it [05:01, 8466.46it/s]3219963it [05:02, 5422.45it/s]3220850it [05:02, 6141.60it/s]3221771it [05:02, 6847.17it/s]3222715it [05:02, 6782.78it/s]3223473it [05:02, 6962.26it/s]3224359it [05:02, 7446.30it/s]3225258it [05:02, 7858.65it/s]3226084it [05:03, 4654.25it/s]3226732it [05:03, 4531.90it/s]3227461it [05:03, 5070.85it/s]3228315it [05:03, 5826.06it/s]3229241it [05:03, 6639.34it/s]3230120it [05:03, 7183.46it/s]3231055it [05:03, 7758.59it/s]3232003it [05:03, 8227.34it/s]3232919it [05:04, 8489.95it/s]3233871it [05:04, 8785.36it/s]3234776it [05:04, 8784.32it/s]3235673it [05:04, 8608.84it/s]3236555it [05:04, 8669.06it/s]3237432it [05:04, 8391.69it/s]3238280it [05:04, 8273.14it/s]3239113it [05:04, 8288.47it/s]3240023it [05:04, 8523.60it/s]3240879it [05:04, 8532.30it/s]3241765it [05:05, 8623.19it/s]3242686it [05:05, 8788.95it/s]3243575it [05:05, 8810.44it/s]3244499it [05:05, 8925.51it/s]3245393it [05:05, 8814.99it/s]3246276it [05:05, 8814.31it/s]3247192it [05:05, 8916.02it/s]3248098it [05:05, 8954.44it/s]3249014it [05:05, 9009.27it/s]3249916it [05:05, 8936.13it/s]3250810it [05:06, 4264.19it/s]3251493it [05:06, 4630.75it/s]3252161it [05:06, 4666.43it/s]3252853it [05:06, 4707.99it/s]3253716it [05:06, 5528.19it/s]3254621it [05:07, 6339.68it/s]3255501it [05:07, 6947.87it/s]3256312it [05:07, 7247.77it/s]3257217it [05:07, 7729.89it/s]3258191it [05:07, 8289.66it/s]3259088it [05:07, 8477.32it/s]3259963it [05:07, 7329.81it/s]3260799it [05:07, 7599.14it/s]3261634it [05:07, 7801.20it/s]3262469it [05:08, 7953.79it/s]3263311it [05:08, 8078.51it/s]3264193it [05:08, 8281.92it/s]3265049it [05:08, 8350.97it/s]3265892it [05:08, 8163.19it/s]3266715it [05:08, 7985.51it/s]3267519it [05:08, 7911.35it/s]3268314it [05:08, 7708.54it/s]3269088it [05:08, 7345.46it/s]3269974it [05:08, 7768.63it/s]3270788it [05:09, 7867.68it/s]3271580it [05:09, 6944.79it/s]3272465it [05:09, 7452.44it/s]3273361it [05:09, 7865.81it/s]3274305it [05:09, 8310.75it/s]3275188it [05:09, 8454.39it/s]3276122it [05:09, 8711.99it/s]3277027it [05:09, 8808.87it/s]3277915it [05:09, 8754.86it/s]3278795it [05:10, 8764.97it/s]3279675it [05:10, 8649.97it/s]3280560it [05:10, 8698.20it/s]3281438it [05:10, 8721.33it/s]3282342it [05:10, 8808.01it/s]3283224it [05:10, 8733.60it/s]3284099it [05:10, 8684.71it/s]3284969it [05:10, 8644.44it/s]3285844it [05:10, 8674.48it/s]3286777it [05:10, 8862.75it/s]3287664it [05:11, 8772.92it/s]3288542it [05:11, 8737.46it/s]3289496it [05:11, 8968.98it/s]3290394it [05:11, 8899.85it/s]3291285it [05:11, 7972.11it/s]3292101it [05:11, 7653.53it/s]3292880it [05:11, 7637.49it/s]3293653it [05:11, 7648.01it/s]3294513it [05:11, 7913.28it/s]3295351it [05:11, 8042.33it/s]3296245it [05:12, 8298.90it/s]3297116it [05:12, 8416.10it/s]3298001it [05:12, 8537.50it/s]3298916it [05:12, 8716.39it/s]3299790it [05:12, 8674.45it/s]3300779it [05:12, 9028.62it/s]3301683it [05:12, 8322.96it/s]3302527it [05:13, 5385.48it/s]3303374it [05:13, 6019.75it/s]3304295it [05:13, 6742.17it/s]3305142it [05:13, 7165.11it/s]3306051it [05:13, 7661.74it/s]3306912it [05:13, 7916.50it/s]3307755it [05:13, 8046.28it/s]3308627it [05:13, 8234.66it/s]3309478it [05:13, 8298.14it/s]3310400it [05:13, 8566.54it/s]3311277it [05:14, 8619.01it/s]3312149it [05:14, 8331.99it/s]3312992it [05:14, 8063.14it/s]3313806it [05:14, 8004.50it/s]3314612it [05:14, 7804.40it/s]3315523it [05:14, 8175.87it/s]3316389it [05:14, 8312.48it/s]3317224it [05:14, 8302.05it/s]3318080it [05:14, 8376.58it/s]3319038it [05:14, 8731.47it/s]3319940it [05:15, 8816.47it/s]3320824it [05:15, 8787.28it/s]3321742it [05:15, 8902.34it/s]3322633it [05:15, 8698.32it/s]3323505it [05:15, 8432.69it/s]3324351it [05:15, 8189.08it/s]3325173it [05:15, 7977.92it/s]3325973it [05:15, 7802.70it/s]3326755it [05:15, 7749.47it/s]3327638it [05:16, 8050.94it/s]3328445it [05:16, 7926.08it/s]3329383it [05:16, 8346.30it/s]3330258it [05:16, 8456.48it/s]3331258it [05:16, 8906.29it/s]3332154it [05:16, 8921.18it/s]3333050it [05:16, 8925.71it/s]3333944it [05:16, 8859.62it/s]3334872it [05:16, 8978.40it/s]3335771it [05:16, 8948.34it/s]3336667it [05:17, 8844.61it/s]3337561it [05:17, 8872.64it/s]3338452it [05:17, 8877.33it/s]3339394it [05:17, 9038.02it/s]3340354it [05:17, 9200.60it/s]3341275it [05:17, 9133.32it/s]3342189it [05:17, 9017.03it/s]3343092it [05:17, 8519.29it/s]3343950it [05:17, 8253.30it/s]3344780it [05:17, 7903.36it/s]3345595it [05:18, 7965.10it/s]3346609it [05:18, 8582.88it/s]3347674it [05:18, 9179.39it/s]3348599it [05:18, 9186.67it/s]3349523it [05:18, 8947.47it/s]3350422it [05:18, 8891.16it/s]3351332it [05:18, 8945.54it/s]3352247it [05:18, 9005.29it/s]3353150it [05:18, 8579.32it/s]3354013it [05:19, 8193.76it/s]3354839it [05:19, 7949.68it/s]3355733it [05:19, 8223.40it/s]3356608it [05:19, 8372.64it/s]3357501it [05:19, 8528.55it/s]3358358it [05:19, 8299.35it/s]3359192it [05:19, 8064.79it/s]3360046it [05:19, 8195.76it/s]3360869it [05:19, 8049.35it/s]3361677it [05:19, 7901.84it/s]3362469it [05:20, 7852.74it/s]3363256it [05:20, 7640.56it/s]3364022it [05:20, 7638.04it/s]3364787it [05:20, 7605.65it/s]3365577it [05:20, 7688.61it/s]3366469it [05:20, 8050.30it/s]3367481it [05:20, 8662.36it/s]3368349it [05:20, 8522.17it/s]3369204it [05:20, 8518.86it/s]3370071it [05:20, 8563.15it/s]3370996it [05:21, 8757.16it/s]3371873it [05:21, 8501.57it/s]3372726it [05:21, 8248.26it/s]3373554it [05:21, 7978.43it/s]3374355it [05:21, 7908.86it/s]3375148it [05:21, 7606.58it/s]3375912it [05:21, 7566.42it/s]3376671it [05:21, 7448.20it/s]3377417it [05:21, 7407.55it/s]3378230it [05:22, 7612.15it/s]3378993it [05:22, 7536.95it/s]3379920it [05:22, 8038.08it/s]3380883it [05:22, 8506.86it/s]3381736it [05:22, 8432.75it/s]3382585it [05:22, 8446.75it/s]3383484it [05:22, 8600.38it/s]3384345it [05:22, 8559.62it/s]3385202it [05:22, 8303.08it/s]3386035it [05:22, 7859.20it/s]3386845it [05:23, 7923.48it/s]3387642it [05:23, 7619.64it/s]3388409it [05:23, 7459.33it/s]3389205it [05:23, 7595.81it/s]3389968it [05:23, 7568.81it/s]3390727it [05:23, 7486.97it/s]3391545it [05:23, 7682.39it/s]3392315it [05:23, 7641.38it/s]3393207it [05:23, 8009.01it/s]3394072it [05:24, 8193.51it/s]3394893it [05:24, 8151.98it/s]3395714it [05:24, 8168.25it/s]3396570it [05:24, 8275.01it/s]3397398it [05:24, 8223.46it/s]3398221it [05:24, 8122.91it/s]3399034it [05:24, 7711.72it/s]3399810it [05:24, 7591.78it/s]3400622it [05:24, 7739.69it/s]3401416it [05:24, 7797.16it/s]3402198it [05:25, 7604.97it/s]3403074it [05:25, 7936.45it/s]3404006it [05:25, 8340.83it/s]3404877it [05:25, 8449.22it/s]3405725it [05:25, 8293.40it/s]3406557it [05:25, 8096.97it/s]3407373it [05:25, 8105.64it/s]3408186it [05:25, 7837.74it/s]3408973it [05:25, 7815.73it/s]3409757it [05:26, 7695.53it/s]3410528it [05:26, 7546.39it/s]3411402it [05:26, 7888.86it/s]3412286it [05:26, 8166.43it/s]3413278it [05:26, 8674.44it/s]3414148it [05:26, 8513.27it/s]3415002it [05:26, 7993.86it/s]3415809it [05:26, 7895.20it/s]3416604it [05:26, 7799.49it/s]3417510it [05:26, 8159.48it/s]3418407it [05:27, 8390.53it/s]3419297it [05:27, 8522.68it/s]3420153it [05:27, 8023.88it/s]3420963it [05:27, 7735.99it/s]3421743it [05:27, 7472.65it/s]3422496it [05:27, 7462.09it/s]3423246it [05:27, 7402.95it/s]3423989it [05:27, 7334.79it/s]3424850it [05:27, 7695.36it/s]3425685it [05:28, 7883.30it/s]3426581it [05:28, 8193.90it/s]3427403it [05:28, 8145.76it/s]3428220it [05:28, 7739.17it/s]3428999it [05:28, 7657.26it/s]3429768it [05:28, 7452.51it/s]3430517it [05:28, 7317.18it/s]3431253it [05:28, 7325.96it/s]3432003it [05:28, 7363.53it/s]3432749it [05:28, 7388.71it/s]3433493it [05:29, 7399.13it/s]3435087it [05:29, 9920.24it/s]3439041it [05:29, 18715.66it/s]3442666it [05:29, 23918.18it/s]3445893it [05:29, 26409.47it/s]3449468it [05:29, 29199.70it/s]3453053it [05:29, 31188.26it/s]3456216it [05:29, 31320.17it/s]3459355it [05:29, 31306.49it/s]3462489it [05:29, 31187.09it/s]3465610it [05:30, 30764.95it/s]3469057it [05:30, 31861.69it/s]3473020it [05:30, 34170.85it/s]3476442it [05:30, 33967.32it/s]3479842it [05:30, 33910.34it/s]3483427it [05:30, 34486.87it/s]3486878it [05:30, 33831.32it/s]3490266it [05:30, 33817.56it/s]3493713it [05:30, 33985.76it/s]3497220it [05:30, 34305.11it/s]3500653it [05:31, 34110.22it/s]3504066it [05:31, 34003.85it/s]3507468it [05:31, 33792.78it/s]3511040it [05:31, 34352.91it/s]3514477it [05:31, 33387.31it/s]3517822it [05:31, 32419.14it/s]3521073it [05:31, 31904.40it/s]3524270it [05:31, 31217.52it/s]3527397it [05:31, 30892.02it/s]3531008it [05:32, 32396.16it/s]3534761it [05:32, 33892.70it/s]3538211it [05:32, 34070.37it/s]3541626it [05:32, 33300.67it/s]3544965it [05:32, 32358.13it/s]3548211it [05:32, 31606.68it/s]3551380it [05:32, 30909.25it/s]3554585it [05:32, 31229.37it/s]3557923it [05:32, 31852.66it/s]3561115it [05:32, 31835.73it/s]3564303it [05:33, 31169.20it/s]3567682it [05:33, 31924.71it/s]3571373it [05:33, 33385.29it/s]3574993it [05:33, 34208.24it/s]3578420it [05:33, 34080.96it/s]3582224it [05:33, 35243.47it/s]3585799it [05:33, 35362.40it/s]3589339it [05:33, 33607.61it/s]3592720it [05:33, 32535.15it/s]3595992it [05:34, 31647.44it/s]3599171it [05:34, 30937.77it/s]3602275it [05:34, 30639.46it/s]3605345it [05:34, 30353.03it/s]3608384it [05:34, 29995.91it/s]3611421it [05:34, 30103.55it/s]3614434it [05:34, 30101.77it/s]3617446it [05:34, 29698.93it/s]3620550it [05:34, 30073.79it/s]3623833it [05:34, 30883.82it/s]3626924it [05:35, 30438.15it/s]3629971it [05:35, 29899.67it/s]3633458it [05:35, 31312.26it/s]3636595it [05:35, 30980.06it/s]3639698it [05:35, 30870.13it/s]3642830it [05:35, 30981.84it/s]3645931it [05:35, 30440.65it/s]3648979it [05:35, 30355.65it/s]3652021it [05:35, 30326.18it/s]3655064it [05:35, 30314.30it/s]3658260it [05:36, 30760.18it/s]3661540it [05:36, 31366.13it/s]3665063it [05:36, 32499.75it/s]3668315it [05:36, 32368.88it/s]3671904it [05:36, 33372.54it/s]3675397it [05:36, 33808.74it/s]3678779it [05:36, 32827.10it/s]3682069it [05:36, 32629.68it/s]3685337it [05:36, 32332.62it/s]3688574it [05:36, 31909.93it/s]3691768it [05:37, 31700.92it/s]3695023it [05:37, 31944.14it/s]3698298it [05:37, 32146.68it/s]3701731it [05:37, 32775.38it/s]3705011it [05:37, 32230.31it/s]3708237it [05:37, 32069.08it/s]3711446it [05:37, 31537.80it/s]3714603it [05:37, 31408.88it/s]3717746it [05:37, 30656.47it/s]3720816it [05:38, 30391.34it/s]3723858it [05:38, 30055.48it/s]3726866it [05:38, 29900.77it/s]3729858it [05:38, 29563.49it/s]3732816it [05:38, 29314.93it/s]3735814it [05:38, 29509.13it/s]3738766it [05:38, 28962.71it/s]3741758it [05:38, 29242.67it/s]3744856it [05:38, 29743.92it/s]3748053it [05:38, 30384.11it/s]3751094it [05:39, 29682.13it/s]3754067it [05:39, 29662.17it/s]3757037it [05:39, 29353.81it/s]3760231it [05:39, 30106.80it/s]3763245it [05:39, 30009.80it/s]3766249it [05:39, 29206.10it/s]3769365it [05:39, 29764.56it/s]3772347it [05:39, 29742.42it/s]3775325it [05:39, 29141.99it/s]3778409it [05:39, 29596.12it/s]3781618it [05:40, 30304.15it/s]3784653it [05:40, 29572.38it/s]3787617it [05:40, 28763.32it/s]3790515it [05:40, 28824.96it/s]3793529it [05:40, 29194.22it/s]3796454it [05:40, 28920.60it/s]3799350it [05:40, 28319.46it/s]3802436it [05:40, 29058.29it/s]3805347it [05:40, 28494.99it/s]3808240it [05:40, 28593.15it/s]3811104it [05:41, 28018.51it/s]3813924it [05:41, 28070.06it/s]3816916it [05:41, 28583.11it/s]3819778it [05:41, 27863.56it/s]3822570it [05:41, 27303.84it/s]3825306it [05:41, 26926.89it/s]3828003it [05:41, 26262.42it/s]3830634it [05:41, 26130.97it/s]3833265it [05:41, 26161.44it/s]3835929it [05:42, 26287.17it/s]3838560it [05:42, 26059.00it/s]3841185it [05:42, 26084.43it/s]3843795it [05:42, 25953.85it/s]3846421it [05:42, 26044.07it/s]3849026it [05:42, 25987.10it/s]3851626it [05:42, 25889.18it/s]3854216it [05:42, 25647.56it/s]3856782it [05:42, 24899.34it/s]3859324it [05:42, 25020.05it/s]3861939it [05:43, 25350.66it/s]3864674it [05:43, 25920.50it/s]3867269it [05:43, 25476.51it/s]3869820it [05:43, 24959.21it/s]3872320it [05:43, 23950.75it/s]3874725it [05:43, 23600.49it/s]3877091it [05:43, 23041.49it/s]3879400it [05:43, 22319.99it/s]3881638it [05:43, 21524.28it/s]3883797it [05:44, 21304.77it/s]3885957it [05:44, 21362.40it/s]3888096it [05:44, 21292.23it/s]3890227it [05:44, 21068.87it/s]3892335it [05:44, 20675.67it/s]3894418it [05:44, 20720.06it/s]3896492it [05:44, 20480.27it/s]3898541it [05:44, 19748.11it/s]3900521it [05:44, 19211.11it/s]3902491it [05:44, 19348.59it/s]3904430it [05:45, 19060.86it/s]3906398it [05:45, 19238.07it/s]3908325it [05:45, 19064.63it/s]3910234it [05:45, 18814.90it/s]3912117it [05:45, 18330.82it/s]3914093it [05:45, 18743.52it/s]3916384it [05:45, 19959.92it/s]3918386it [05:45, 19240.06it/s]3920319it [05:45, 19110.81it/s]3922236it [05:46, 19107.41it/s]3924151it [05:46, 18956.51it/s]3926292it [05:46, 19674.94it/s]3928264it [05:46, 19258.92it/s]3930194it [05:46, 19125.93it/s]3932175it [05:46, 19324.85it/s]3934110it [05:46, 18667.60it/s]3935983it [05:46, 18379.07it/s]3937825it [05:46, 18278.04it/s]3939733it [05:46, 18502.63it/s]3941586it [05:47, 18297.51it/s]3943603it [05:47, 18845.15it/s]3945719it [05:47, 19511.58it/s]3947673it [05:47, 19229.71it/s]3949599it [05:47, 19209.03it/s]3951522it [05:47, 19030.47it/s]3953447it [05:47, 19063.02it/s]3955355it [05:47, 19055.52it/s]3957421it [05:47, 19512.27it/s]3959482it [05:47, 19816.37it/s]3961527it [05:48, 19999.18it/s]3963528it [05:48, 19992.01it/s]3965622it [05:48, 20261.33it/s]3967649it [05:48, 19870.17it/s]3969638it [05:48, 19762.80it/s]3971991it [05:48, 20872.11it/s]3974945it [05:48, 23442.97it/s]3977577it [05:48, 24260.97it/s]3980029it [05:48, 24322.28it/s]3982692it [05:48, 25005.55it/s]3985652it [05:49, 26378.50it/s]3988502it [05:49, 27002.14it/s]3991265it [05:49, 27175.27it/s]3994174it [05:49, 27715.54it/s]3996947it [05:49, 27165.14it/s]3999799it [05:49, 27564.23it/s]4003126it [05:49, 29234.73it/s]4007126it [05:49, 32417.28it/s]4010661it [05:49, 33289.17it/s]4013994it [05:49, 31028.49it/s]4017130it [05:50, 28474.02it/s]4020035it [05:50, 28088.32it/s]4022882it [05:50, 26977.14it/s]4025609it [05:50, 26140.35it/s]4028243it [05:50, 25374.18it/s]4030794it [05:50, 25058.49it/s]4033308it [05:50, 25011.75it/s]4035814it [05:50, 24960.87it/s]4038314it [05:50, 24510.77it/s]4040891it [05:51, 24869.14it/s]4043543it [05:51, 25343.16it/s]4046081it [05:51, 25321.08it/s]4049011it [05:51, 26496.16it/s]4051779it [05:51, 26846.40it/s]4054467it [05:51, 26196.03it/s]4057092it [05:51, 25490.28it/s]4060321it [05:51, 27432.27it/s]4063578it [05:51, 28933.20it/s]4066484it [05:52, 28349.50it/s]4069329it [05:52, 26990.83it/s]4072277it [05:52, 27696.88it/s]4075563it [05:52, 29138.58it/s]4078494it [05:52, 28523.14it/s]4081360it [05:52, 27238.87it/s]4084103it [05:52, 26934.78it/s]4086870it [05:52, 27111.73it/s]4089591it [05:52, 26577.53it/s]4092256it [05:52, 26019.96it/s]4095159it [05:53, 26883.21it/s]4098002it [05:53, 27329.87it/s]4100742it [05:53, 27320.31it/s]4103479it [05:53, 27203.34it/s]4106203it [05:53, 26711.79it/s]4108878it [05:53, 25944.62it/s]4111479it [05:53, 25808.19it/s]4114064it [05:53, 25145.56it/s]4116584it [05:53, 24385.17it/s]4119029it [05:54, 24277.59it/s]4121533it [05:54, 24497.15it/s]4124441it [05:54, 25834.00it/s]4127156it [05:54, 26203.45it/s]4129782it [05:54, 22584.02it/s]4132130it [05:54, 19012.21it/s]4134519it [05:54, 20186.12it/s]4136668it [05:54, 19259.25it/s]4138686it [05:55, 18288.09it/s]4140580it [05:55, 18144.55it/s]4142438it [05:55, 15698.28it/s]4144083it [05:55, 14704.51it/s]4145607it [05:55, 14179.65it/s]4147058it [05:55, 13663.30it/s]4148444it [05:55, 13378.74it/s]4149793it [05:55, 13202.55it/s]4151120it [05:55, 13177.50it/s]4152442it [05:56, 12904.95it/s]4153735it [05:56, 12690.51it/s]4155040it [05:56, 12786.28it/s]4156320it [05:56, 12678.48it/s]4157589it [05:56, 12487.47it/s]4158839it [05:56, 12408.30it/s]4160091it [05:56, 12423.50it/s]4161378it [05:56, 12539.56it/s]4162646it [05:56, 12580.35it/s]4163919it [05:56, 12609.41it/s]4165181it [05:57, 12506.12it/s]4166432it [05:57, 12292.89it/s]4167701it [05:57, 12404.28it/s]4168943it [05:57, 12265.48it/s]4170171it [05:57, 12206.09it/s]4171407it [05:57, 12247.70it/s]4172656it [05:57, 12319.13it/s]4173936it [05:57, 12451.05it/s]4175230it [05:57, 12581.91it/s]4176489it [05:58, 12489.71it/s]4177739it [05:58, 12390.42it/s]4178979it [05:58, 12374.73it/s]4180217it [05:58, 12158.86it/s]4181434it [05:58, 12148.05it/s]4182773it [05:58, 12514.84it/s]4184044it [05:58, 12556.19it/s]4185301it [05:58, 12557.88it/s]4186558it [05:58, 12525.29it/s]4187824it [05:58, 12564.31it/s]4189118it [05:59, 12668.67it/s]4190386it [05:59, 12474.86it/s]4191671it [05:59, 12579.59it/s]4193041it [05:59, 12911.59it/s]4194333it [05:59, 12735.28it/s]4195648it [05:59, 12847.05it/s]4196990it [05:59, 12999.29it/s]4198291it [05:59, 12693.54it/s]4199563it [05:59, 12699.00it/s]4200835it [05:59, 12653.94it/s]4202102it [06:00, 12305.63it/s]4203335it [06:00, 12170.01it/s]4204636it [06:00, 12404.86it/s]4205879it [06:00, 12261.80it/s]4207107it [06:00, 12206.52it/s]4208353it [06:00, 12273.42it/s]4209582it [06:00, 12274.48it/s]4210810it [06:00, 12226.17it/s]4212033it [06:00, 12159.34it/s]4213250it [06:00, 12141.52it/s]4214465it [06:01, 12007.48it/s]4215671it [06:01, 12005.69it/s]4216942it [06:01, 12196.71it/s]4218162it [06:01, 11996.22it/s]4219363it [06:01, 11942.73it/s]4220559it [06:01, 11946.14it/s]4221754it [06:01, 11794.90it/s]4222944it [06:01, 11824.22it/s]4224230it [06:01, 12117.96it/s]4225714it [06:01, 12918.07it/s]4227035it [06:02, 13004.43it/s]4228337it [06:02, 12790.90it/s]4229618it [06:02, 12388.98it/s]4230861it [06:02, 12096.45it/s]4232223it [06:02, 12525.84it/s]4233480it [06:02, 12315.98it/s]4234783it [06:02, 12521.92it/s]4236038it [06:02, 12373.02it/s]4237278it [06:02, 12121.89it/s]4238493it [06:03, 11889.59it/s]4239696it [06:03, 11928.72it/s]4240891it [06:03, 11818.07it/s]4242110it [06:03, 11921.99it/s]4243333it [06:03, 11999.53it/s]4244565it [06:03, 12083.59it/s]4245826it [06:03, 12239.84it/s]4247051it [06:03, 12223.48it/s]4248309it [06:03, 12323.77it/s]4249545it [06:03, 12333.65it/s]4250779it [06:04, 12331.37it/s]4252013it [06:04, 12182.49it/s]4253266it [06:04, 12270.04it/s]4254617it [06:04, 12638.50it/s]4256070it [06:04, 13196.89it/s]4257391it [06:04, 12974.05it/s]4258690it [06:04, 12799.86it/s]4259972it [06:04, 12674.24it/s]4261241it [06:04, 12606.29it/s]4262503it [06:04, 12317.47it/s]4263778it [06:05, 12430.98it/s]4265074it [06:05, 12572.29it/s]4266440it [06:05, 12884.96it/s]4267730it [06:05, 12475.79it/s]4269176it [06:05, 13039.77it/s]4270634it [06:05, 13487.95it/s]4271987it [06:05, 13122.76it/s]4273304it [06:05, 12971.32it/s]4274605it [06:05, 12896.79it/s]4275900it [06:05, 12911.04it/s]4277232it [06:06, 13022.61it/s]4278536it [06:06, 12217.77it/s]4279814it [06:06, 12365.21it/s]4281059it [06:06, 12187.55it/s]4282399it [06:06, 12526.30it/s]4283799it [06:06, 12943.42it/s]4285099it [06:06, 12718.42it/s]4286412it [06:06, 12832.08it/s]4287832it [06:06, 13233.37it/s]4289226it [06:07, 13437.71it/s]4290573it [06:07, 13125.05it/s]4291889it [06:07, 12936.57it/s]4293185it [06:07, 12831.96it/s]4294506it [06:07, 12940.97it/s]4295802it [06:07, 12718.49it/s]4297092it [06:07, 12769.92it/s]4298484it [06:07, 13106.58it/s]4299862it [06:07, 13300.34it/s]4301194it [06:07, 13009.62it/s]4302498it [06:08, 12735.56it/s]4303774it [06:08, 12690.90it/s]4305106it [06:08, 12874.39it/s]4306490it [06:08, 13152.10it/s]4307922it [06:08, 13489.20it/s]4309273it [06:08, 13126.37it/s]4310589it [06:08, 12902.95it/s]4311882it [06:08, 12854.40it/s]4313169it [06:08, 12841.28it/s]4314455it [06:08, 12718.65it/s]4315728it [06:09, 12357.76it/s]4316991it [06:09, 12436.42it/s]4318261it [06:09, 12497.08it/s]4319513it [06:09, 12401.69it/s]4320794it [06:09, 12513.15it/s]4322047it [06:09, 12272.59it/s]4323276it [06:09, 12059.91it/s]4324533it [06:09, 12199.28it/s]4325872it [06:09, 12548.88it/s]4327183it [06:10, 12708.40it/s]4328456it [06:10, 12562.72it/s]4329714it [06:10, 12473.01it/s]4330963it [06:10, 12233.18it/s]4332257it [06:10, 12431.52it/s]4333502it [06:10, 12398.38it/s]4334743it [06:10, 12321.68it/s]4336100it [06:10, 12682.36it/s]4337439it [06:10, 12888.81it/s]4338823it [06:10, 13170.99it/s]4340141it [06:11, 12954.67it/s]4341438it [06:11, 12689.10it/s]4342709it [06:11, 12628.97it/s]4343974it [06:11, 12606.32it/s]4345236it [06:11, 5105.94it/s] 4346183it [06:12, 3605.47it/s]4346902it [06:13, 2365.10it/s]4348157it [06:13, 3267.15it/s]4349221it [06:13, 4095.22it/s]4350236it [06:13, 4928.79it/s]4351130it [06:13, 5575.73it/s]4352020it [06:13, 4593.06it/s]4353341it [06:13, 6032.49it/s]4354785it [06:14, 7653.42it/s]4355943it [06:14, 7709.80it/s]4356921it [06:14, 7880.64it/s]4358226it [06:14, 9069.94it/s]4359479it [06:14, 9923.58it/s]4360586it [06:14, 10145.88it/s]4361766it [06:14, 10588.07it/s]4363010it [06:14, 11103.22it/s]4364275it [06:14, 11540.93it/s]4365474it [06:15, 11670.33it/s]4366794it [06:15, 12108.70it/s]4368191it [06:15, 12649.60it/s]4369471it [06:15, 12580.95it/s]4370740it [06:15, 12575.64it/s]4372005it [06:15, 12017.52it/s]4373217it [06:15, 5922.59it/s] 4374200it [06:16, 6577.23it/s]4375478it [06:16, 7771.84it/s]4376521it [06:16, 5498.82it/s]4377343it [06:16, 5938.91it/s]4378618it [06:16, 7248.35it/s]4379569it [06:16, 6768.89it/s]4380736it [06:16, 7813.53it/s]4381766it [06:17, 8393.71it/s]4382820it [06:17, 8918.93it/s]4383810it [06:17, 6362.08it/s]4385123it [06:17, 7760.36it/s]4386080it [06:17, 6958.32it/s]4386912it [06:17, 6629.87it/s]4387669it [06:18, 6214.91it/s]4389020it [06:18, 7838.84it/s]4390241it [06:18, 8888.56it/s]4391226it [06:18, 8713.38it/s]4392358it [06:18, 9319.62it/s]4393813it [06:18, 10717.11it/s]4395361it [06:18, 12032.69it/s]4396614it [06:18, 9012.25it/s] 4397659it [06:19, 5646.72it/s]4398472it [06:19, 5338.27it/s]4399176it [06:19, 4712.38it/s]4399768it [06:19, 4681.00it/s]4401278it [06:19, 6648.31it/s]4402747it [06:19, 8354.49it/s]4404296it [06:20, 10010.38it/s]4405772it [06:20, 11191.10it/s]4407258it [06:20, 12154.05it/s]4408781it [06:20, 12981.68it/s]4410333it [06:20, 13692.96it/s]4412016it [06:20, 14588.95it/s]4413671it [06:20, 15151.17it/s]4415225it [06:20, 15079.40it/s]4416761it [06:20, 14796.68it/s]4418261it [06:21, 14813.01it/s]4419770it [06:21, 14877.96it/s]4421297it [06:21, 14986.07it/s]4422803it [06:21, 14827.17it/s]4424291it [06:21, 14794.56it/s]4425775it [06:21, 14742.76it/s]4427252it [06:21, 14662.45it/s]4428726it [06:21, 14684.45it/s]4430215it [06:21, 14745.18it/s]4431857it [06:21, 15243.92it/s]4433436it [06:22, 15389.78it/s]4434976it [06:22, 15235.98it/s]4436501it [06:22, 14951.93it/s]4437998it [06:22, 14893.63it/s]4439533it [06:22, 15027.83it/s]4441037it [06:22, 14918.56it/s]4442552it [06:22, 14983.56it/s]4444051it [06:22, 14853.56it/s]4445537it [06:22, 14825.21it/s]4447020it [06:22, 14701.54it/s]4448491it [06:23, 14691.96it/s]4449961it [06:23, 14457.99it/s]4451472it [06:23, 14646.77it/s]4453213it [06:23, 15464.25it/s]4454762it [06:23, 15268.43it/s]4456291it [06:23, 15174.58it/s]4457810it [06:23, 14946.58it/s]4459306it [06:23, 14695.92it/s]4460777it [06:23, 14555.30it/s]4462336it [06:23, 14853.13it/s]4463863it [06:24, 14973.10it/s]4465362it [06:24, 14835.65it/s]4466900it [06:24, 14991.89it/s]4468401it [06:24, 14996.97it/s]4469911it [06:24, 15020.41it/s]4471414it [06:24, 11225.99it/s]4472678it [06:24, 11300.70it/s]4473936it [06:24, 11621.18it/s]4475348it [06:24, 12263.80it/s]4476830it [06:25, 12962.91it/s]4478231it [06:25, 13257.39it/s]4479594it [06:25, 13327.46it/s]4481009it [06:25, 13551.33it/s]4482498it [06:25, 13942.88it/s]4484019it [06:25, 14315.93it/s]4485488it [06:25, 14410.45it/s]4486937it [06:25, 14301.24it/s]4488373it [06:25, 14176.60it/s]4489830it [06:25, 14290.35it/s]4491297it [06:26, 14393.57it/s]4492821it [06:26, 14644.72it/s]4494335it [06:26, 14782.14it/s]4495815it [06:26, 14762.90it/s]4497384it [06:26, 15039.58it/s]4498889it [06:26, 15029.06it/s]4500393it [06:26, 14866.81it/s]4501881it [06:26, 14864.01it/s]4503442it [06:26, 15072.90it/s]4504983it [06:27, 15171.16it/s]4506501it [06:27, 6472.35it/s] 4507647it [06:28, 3835.81it/s]4508500it [06:28, 3357.52it/s]4509165it [06:28, 3452.07it/s]4510479it [06:28, 4628.90it/s]4511501it [06:28, 5434.94it/s]4512791it [06:29, 6729.47it/s]4514141it [06:29, 8069.33it/s]4515307it [06:29, 8861.27it/s]4516558it [06:29, 9731.16it/s]4517787it [06:29, 10376.14it/s]4518975it [06:29, 10773.32it/s]4520207it [06:29, 11184.87it/s]4521417it [06:29, 11441.98it/s]4522616it [06:29, 11591.02it/s]4523814it [06:29, 11664.90it/s]4525081it [06:30, 11958.53it/s]4526297it [06:30, 11807.15it/s]4527515it [06:30, 11916.16it/s]4528821it [06:30, 12253.32it/s]4530186it [06:30, 12666.15it/s]4531459it [06:30, 12441.63it/s]4532709it [06:30, 12388.29it/s]4534027it [06:30, 12619.67it/s]4535292it [06:30, 12413.51it/s]4536536it [06:30, 12369.21it/s]4537776it [06:31, 12377.85it/s]4539015it [06:31, 12359.13it/s]4540252it [06:31, 12277.65it/s]4541491it [06:31, 12302.61it/s]4542781it [06:31, 12479.41it/s]4544030it [06:31, 12402.20it/s]4545271it [06:31, 12371.73it/s]4546624it [06:31, 12709.08it/s]4547938it [06:31, 12836.64it/s]4549333it [06:32, 13165.30it/s]4550650it [06:32, 12858.75it/s]4551938it [06:32, 12751.58it/s]4553222it [06:32, 12777.25it/s]4554501it [06:32, 12270.74it/s]4555764it [06:32, 12374.04it/s]4557041it [06:32, 12485.96it/s]4558316it [06:32, 12561.94it/s]4559610it [06:32, 12671.82it/s]4560886it [06:32, 12697.67it/s]4562157it [06:33, 12593.21it/s]4563438it [06:33, 12636.88it/s]4564703it [06:33, 12332.49it/s]4565939it [06:33, 12180.79it/s]4567159it [06:33, 12054.26it/s]4568430it [06:33, 12240.37it/s]4569778it [06:33, 12598.79it/s]4571040it [06:33, 12300.97it/s]4572325it [06:33, 12461.21it/s]4573574it [06:33, 12429.38it/s]4574860it [06:34, 12555.51it/s]4576391it [06:34, 13370.14it/s]4577805it [06:34, 13598.92it/s]4579240it [06:34, 13820.67it/s]4580687it [06:34, 14014.17it/s]4582242it [06:34, 14472.85it/s]4583817it [06:34, 14833.07it/s]4585352it [06:34, 14973.51it/s]4586850it [06:34, 13073.13it/s]4588402it [06:35, 13736.71it/s]4589868it [06:35, 13991.80it/s]4591373it [06:35, 14292.43it/s]4592961it [06:35, 14751.65it/s]4594453it [06:35, 14766.18it/s]4595985it [06:35, 14928.06it/s]4597487it [06:35, 14850.12it/s]4599082it [06:35, 15170.26it/s]4600604it [06:35, 14734.26it/s]4602084it [06:35, 14622.35it/s]4603635it [06:36, 14880.90it/s]4605127it [06:36, 14019.30it/s]4606563it [06:36, 14108.21it/s]4608010it [06:36, 14199.28it/s]4609437it [06:36, 14157.04it/s]4610858it [06:36, 14090.36it/s]4612334it [06:36, 14279.75it/s]4613834it [06:36, 14484.48it/s]4615285it [06:36, 14292.56it/s]4616761it [06:36, 14425.67it/s]4618214it [06:37, 14451.97it/s]4619661it [06:37, 13128.77it/s]4621084it [06:37, 13434.69it/s]4622545it [06:37, 13762.18it/s]4624097it [06:37, 14269.69it/s]4625716it [06:37, 14822.94it/s]4627267it [06:37, 15024.09it/s]4628777it [06:37, 14990.58it/s]4630282it [06:37, 14775.50it/s]4631764it [06:38, 14745.54it/s]4633242it [06:38, 14496.77it/s]4634695it [06:38, 14324.00it/s]4636137it [06:38, 14312.43it/s]4637667it [06:38, 14600.81it/s]4639155it [06:38, 14681.69it/s]4640625it [06:38, 14084.58it/s]4642040it [06:38, 13762.51it/s]4643421it [06:38, 13387.59it/s]4644764it [06:38, 13399.54it/s]4646107it [06:39, 13188.85it/s]4647429it [06:39, 12848.43it/s]4648973it [06:39, 13586.22it/s]4650470it [06:39, 13979.03it/s]4651873it [06:39, 12857.61it/s]4653180it [06:39, 12916.10it/s]4654486it [06:39, 12447.81it/s]4655743it [06:39, 10211.30it/s]4656897it [06:39, 10538.75it/s]4658155it [06:40, 11067.40it/s]4659372it [06:40, 11343.17it/s]4660636it [06:40, 11702.99it/s]4661865it [06:40, 11869.95it/s]4663073it [06:40, 11794.90it/s]4664267it [06:40, 11722.17it/s]4665529it [06:40, 11980.23it/s]4666779it [06:40, 12131.65it/s]4668081it [06:40, 12377.17it/s]4669323it [06:40, 12363.34it/s]4670563it [06:41, 12326.63it/s]4671928it [06:41, 12699.84it/s]4673290it [06:41, 12972.99it/s]4674672it [06:41, 13208.05it/s]4676040it [06:41, 13327.68it/s]4677383it [06:41, 13356.79it/s]4678749it [06:41, 13445.68it/s]4680187it [06:41, 13724.30it/s]4681744it [06:41, 14272.84it/s]4683172it [06:42, 13922.13it/s]4684567it [06:42, 13338.88it/s]4685929it [06:42, 13377.27it/s]4687370it [06:42, 13669.36it/s]4688741it [06:42, 12366.65it/s]4690003it [06:42, 10758.95it/s]4691403it [06:42, 11575.38it/s]4692850it [06:42, 12338.40it/s]4694299it [06:42, 12929.12it/s]4695629it [06:43, 10668.12it/s]4696783it [06:43, 8994.02it/s] 4698177it [06:43, 10113.79it/s]4699416it [06:43, 10669.74it/s]4700568it [06:43, 7386.37it/s] 4701497it [06:43, 7556.54it/s]4702791it [06:43, 8728.37it/s]4703893it [06:44, 8800.13it/s]4704873it [06:44, 5565.22it/s]4705642it [06:44, 3532.39it/s]4706228it [06:45, 2622.97it/s]4706677it [06:45, 2054.98it/s]4707022it [06:46, 1984.38it/s]4707314it [06:46, 1989.85it/s]4707579it [06:46, 1831.54it/s]4708241it [06:46, 2431.09it/s]4709637it [06:46, 4375.19it/s]4710677it [06:46, 5542.86it/s]4711433it [06:46, 5584.98it/s]4712134it [06:47, 4258.17it/s]4712848it [06:47, 4799.50it/s]4714289it [06:47, 6832.43it/s]4715150it [06:47, 6453.95it/s]4716161it [06:47, 7180.32it/s]4717619it [06:47, 8969.39it/s]4718762it [06:47, 8732.27it/s]4719719it [06:47, 8479.88it/s]4720752it [06:48, 8945.45it/s]4722144it [06:48, 10266.90it/s]4723666it [06:48, 11605.59it/s]4725079it [06:48, 11199.71it/s]4726238it [06:48, 10958.20it/s]4727675it [06:48, 11877.20it/s]4729095it [06:48, 12524.55it/s]4730373it [06:48, 10706.98it/s]4731802it [06:48, 11010.81it/s]4733228it [06:49, 11847.63it/s]4734731it [06:49, 12704.14it/s]4736277it [06:49, 13457.50it/s]4737679it [06:49, 13611.73it/s]4739192it [06:49, 14049.27it/s]4740725it [06:49, 14417.59it/s]4742182it [06:49, 14233.30it/s]4743632it [06:49, 14307.55it/s]4745147it [06:49, 14553.30it/s]4746622it [06:49, 14603.92it/s]4748129it [06:50, 14742.13it/s]4749676it [06:50, 14950.68it/s]4751179it [06:50, 14973.34it/s]4752678it [06:50, 14868.26it/s]4754167it [06:50, 14767.94it/s]4755688it [06:50, 14897.39it/s]4757179it [06:50, 10491.39it/s]4758606it [06:50, 11359.77it/s]4760009it [06:51, 12012.84it/s]4761331it [06:51, 11468.14it/s]4762720it [06:51, 12088.54it/s]4764214it [06:51, 12855.49it/s]4765816it [06:51, 13725.15it/s]4767305it [06:51, 14055.51it/s]4768822it [06:51, 14376.81it/s]4770455it [06:51, 14946.34it/s]4771970it [06:51, 14947.76it/s]4773506it [06:51, 15067.35it/s]4775029it [06:52, 15105.89it/s]4776562it [06:52, 15171.36it/s]4778085it [06:52, 14245.91it/s]4779525it [06:52, 8867.30it/s] 4781028it [06:52, 10111.57it/s]4782475it [06:52, 11085.29it/s]4783931it [06:52, 11907.61it/s]4785298it [06:52, 12352.44it/s]4786683it [06:53, 12752.11it/s]4788079it [06:53, 13077.94it/s]4789567it [06:53, 13581.05it/s]4791159it [06:53, 14249.92it/s]4792659it [06:53, 14458.44it/s]4794210it [06:53, 14766.94it/s]4795706it [06:53, 14553.90it/s]4797176it [06:53, 14568.70it/s]4798643it [06:53, 14470.89it/s]4800149it [06:54, 14643.64it/s]4801774it [06:54, 15116.95it/s]4803290it [06:54, 15087.13it/s]4804802it [06:54, 15063.11it/s]4806343it [06:54, 15152.69it/s]4807860it [06:54, 14867.11it/s]4809349it [06:54, 14852.92it/s]4810836it [06:54, 14537.75it/s]4812292it [06:55, 6039.00it/s] 4813387it [06:55, 6150.74it/s]4814879it [06:55, 7563.85it/s]4816335it [06:55, 8867.22it/s]4817713it [06:55, 9902.51it/s]4819148it [06:55, 10922.60it/s]4820465it [06:56, 10128.90it/s]4821811it [06:56, 10921.22it/s]4823099it [06:56, 11407.69it/s]4824344it [06:56, 9365.00it/s] 4825686it [06:56, 10310.27it/s]4827043it [06:56, 11120.72it/s]4828527it [06:56, 12092.37it/s]4829999it [06:56, 12807.37it/s]4831430it [06:56, 13217.96it/s]4832879it [06:57, 13573.86it/s]4834336it [06:57, 13861.66it/s]4835796it [06:57, 14075.08it/s]4837382it [06:57, 14592.87it/s]4838970it [06:57, 14971.70it/s]4840490it [06:57, 15037.26it/s]4842001it [06:57, 14692.51it/s]4843477it [06:57, 11179.40it/s]4845018it [06:57, 12200.83it/s]4846537it [06:58, 12957.62it/s]4848020it [06:58, 13457.76it/s]4849467it [06:58, 13723.93it/s]4850892it [06:58, 13765.20it/s]4852341it [06:58, 13955.20it/s]4853882it [06:58, 14376.20it/s]4855340it [06:58, 14208.22it/s]4856775it [06:58, 13761.12it/s]4858216it [06:58, 13946.03it/s]4859769it [06:58, 14403.52it/s]4861255it [06:59, 14521.21it/s]4862713it [06:59, 11112.46it/s]4863948it [06:59, 6065.04it/s] 4865069it [06:59, 6696.78it/s]4866028it [06:59, 7212.54it/s]4866981it [07:00, 7616.03it/s]4868085it [07:00, 7330.69it/s]4869473it [07:00, 8759.68it/s]4870942it [07:00, 10167.39it/s]4872516it [07:00, 11576.83it/s]4874099it [07:00, 12699.66it/s]4875645it [07:00, 13456.92it/s]4877192it [07:00, 14017.88it/s]4878651it [07:01, 9312.69it/s] 4880127it [07:01, 10463.12it/s]4881541it [07:01, 11307.85it/s]4882975it [07:01, 12062.59it/s]4884430it [07:01, 12702.40it/s]4885818it [07:01, 13022.01it/s]4887199it [07:01, 13113.87it/s]4888588it [07:01, 13327.15it/s]4890017it [07:01, 13592.40it/s]4891405it [07:01, 13644.41it/s]4892790it [07:02, 13232.24it/s]4894133it [07:02, 13281.22it/s]4895543it [07:02, 13517.93it/s]4896921it [07:02, 13594.74it/s]4898287it [07:02, 13458.57it/s]4899638it [07:02, 13429.57it/s]4901062it [07:02, 13668.96it/s]4902432it [07:02, 13638.55it/s]4903798it [07:02, 13604.47it/s]4905233it [07:03, 13811.92it/s]4906662it [07:03, 13943.82it/s]4908059it [07:03, 13950.67it/s]4909455it [07:03, 7512.37it/s] 4910541it [07:03, 7603.54it/s]4911817it [07:03, 8624.06it/s]4913068it [07:03, 9363.60it/s]4914178it [07:04, 8990.08it/s]4915561it [07:04, 10142.55it/s]4916937it [07:04, 11052.63it/s]4918316it [07:04, 11771.51it/s]4919688it [07:04, 12307.72it/s]4920984it [07:04, 12480.40it/s]4922378it [07:04, 12885.05it/s]4923738it [07:04, 13090.32it/s]4925170it [07:04, 13449.14it/s]4926641it [07:04, 13819.57it/s]4928091it [07:05, 14003.83it/s]4929500it [07:05, 13903.51it/s]4930897it [07:05, 13869.83it/s]4932289it [07:05, 13668.01it/s]4933660it [07:05, 13657.01it/s]4935167it [07:05, 14073.53it/s]4936662it [07:05, 14328.52it/s]4938127it [07:05, 14423.10it/s]4939571it [07:05, 14322.32it/s]4941005it [07:06, 7527.98it/s] 4942461it [07:06, 8798.86it/s]4943952it [07:06, 10060.49it/s]4945437it [07:06, 11150.72it/s]4946947it [07:06, 12120.05it/s]4948411it [07:06, 12773.86it/s]4949877it [07:06, 13272.05it/s]4951309it [07:07, 13535.38it/s]4952797it [07:07, 13917.23it/s]4954435it [07:07, 14618.89it/s]4955938it [07:07, 14439.14it/s]4957411it [07:07, 14260.54it/s]4958858it [07:07, 14097.67it/s]4960283it [07:07, 10745.81it/s]4961655it [07:07, 10476.78it/s]4962792it [07:07, 10478.40it/s]4964261it [07:08, 11529.92it/s]4965617it [07:08, 12060.03it/s]4967074it [07:08, 12744.51it/s]4968549it [07:08, 13306.59it/s]4970075it [07:08, 13853.40it/s]4971550it [07:08, 14108.17it/s]4972981it [07:08, 11909.44it/s]4974243it [07:08, 11237.67it/s]4975420it [07:09, 10334.01it/s]4976870it [07:09, 11371.15it/s]4978322it [07:09, 12191.69it/s]4979589it [07:09, 11615.55it/s]4981148it [07:09, 12681.10it/s]4982756it [07:09, 13623.80it/s]4984251it [07:09, 14000.05it/s]4985710it [07:09, 14170.17it/s]4987146it [07:09, 14066.08it/s]4988735it [07:09, 14587.59it/s]4990205it [07:10, 14612.08it/s]4991674it [07:10, 13965.09it/s]4993120it [07:10, 14106.59it/s]4994539it [07:10, 13785.79it/s]4995993it [07:10, 14000.77it/s]4997496it [07:10, 14287.38it/s]4999135it [07:10, 14905.13it/s]5000630it [07:10, 14784.28it/s]5002112it [07:10, 14379.54it/s]5003555it [07:10, 14308.77it/s]5004999it [07:11, 14346.94it/s]5006510it [07:11, 14571.35it/s]5007969it [07:11, 14391.89it/s]5009426it [07:11, 14429.11it/s]5010871it [07:11, 14327.09it/s]5012305it [07:11, 14321.71it/s]5013738it [07:11, 14182.62it/s]5015204it [07:11, 14319.07it/s]5016674it [07:11, 14428.39it/s]5018118it [07:11, 14402.05it/s]5019568it [07:12, 14420.94it/s]5021011it [07:12, 11529.84it/s]5022420it [07:12, 12174.86it/s]5023843it [07:12, 12721.40it/s]5025327it [07:12, 13299.24it/s]5026804it [07:12, 13705.95it/s]5028210it [07:12, 13754.79it/s]5029611it [07:12, 13363.49it/s]5031042it [07:12, 13616.17it/s]5032500it [07:13, 13889.93it/s]5033960it [07:13, 14096.04it/s]5035378it [07:13, 13930.20it/s]5036848it [07:13, 14149.67it/s]5038346it [07:13, 14394.68it/s]5039790it [07:13, 14251.58it/s]5041218it [07:13, 14037.72it/s]5042625it [07:13, 13877.66it/s]5044015it [07:13, 13837.86it/s]5045516it [07:14, 14175.14it/s]5046935it [07:14, 14077.07it/s]5048352it [07:14, 14102.25it/s]5049791it [07:14, 14184.82it/s]5051214it [07:14, 14192.10it/s]5052792it [07:14, 14648.58it/s]5054329it [07:14, 14858.52it/s]5055816it [07:14, 14650.11it/s]5057282it [07:14, 14621.20it/s]5058745it [07:14, 14619.01it/s]5060208it [07:15, 14593.21it/s]5061676it [07:15, 14617.10it/s]5063189it [07:15, 14769.93it/s]5064667it [07:15, 14655.90it/s]5066133it [07:15, 14503.44it/s]5067613it [07:15, 14590.72it/s]5069073it [07:15, 14238.99it/s]5070499it [07:15, 10188.34it/s]5071679it [07:16, 9547.81it/s] 5073217it [07:16, 10885.21it/s]5074651it [07:16, 11730.79it/s]5076009it [07:16, 12171.73it/s]5077305it [07:16, 11995.38it/s]5078728it [07:16, 12603.22it/s]5080156it [07:16, 13072.71it/s]5081548it [07:16, 13311.12it/s]5083035it [07:16, 13761.37it/s]5084555it [07:16, 14168.33it/s]5086012it [07:17, 14285.02it/s]5087530it [07:17, 14541.99it/s]5088992it [07:17, 14494.39it/s]5090447it [07:17, 14258.72it/s]5091878it [07:17, 14145.55it/s]5093316it [07:17, 14212.41it/s]5094740it [07:17, 14216.16it/s]5096167it [07:17, 14231.81it/s]5097592it [07:17, 14226.52it/s]5099016it [07:17, 14068.41it/s]5100453it [07:18, 14153.10it/s]5101870it [07:18, 14090.94it/s]5103306it [07:18, 14164.10it/s]5104750it [07:18, 14246.05it/s]5106191it [07:18, 14294.31it/s]5107646it [07:18, 14361.90it/s]5109083it [07:18, 14012.26it/s]5110568it [07:18, 14258.04it/s]5112005it [07:18, 14285.86it/s]5113439it [07:18, 14300.90it/s]5114871it [07:19, 14150.43it/s]5116367it [07:19, 14390.03it/s]5117831it [07:19, 14452.22it/s]5119277it [07:19, 14352.88it/s]5120737it [07:19, 14425.63it/s]5122205it [07:19, 14501.03it/s]5123660it [07:19, 14510.41it/s]5125168it [07:19, 14667.74it/s]5126635it [07:19, 14641.43it/s]5128100it [07:19, 14494.63it/s]5129550it [07:20, 14293.27it/s]5130983it [07:20, 14303.25it/s]5132514it [07:20, 14599.81it/s]5134034it [07:20, 14765.09it/s]5135512it [07:20, 14560.97it/s]5136970it [07:20, 14451.89it/s]5138482it [07:20, 14649.01it/s]5139948it [07:20, 14498.74it/s]5141399it [07:20, 14380.65it/s]5142875it [07:20, 14484.60it/s]5144340it [07:21, 14532.71it/s]5145794it [07:21, 14462.40it/s]5147241it [07:21, 14438.13it/s]5148777it [07:21, 14709.99it/s]5150249it [07:21, 14666.30it/s]5151775it [07:21, 14842.87it/s]5153260it [07:21, 14612.84it/s]5154723it [07:21, 14451.70it/s]5156300it [07:21, 14839.79it/s]5157786it [07:22, 14710.86it/s]5159278it [07:22, 14760.66it/s]5160774it [07:22, 14819.66it/s]5162308it [07:22, 14973.93it/s]5163806it [07:22, 14794.24it/s]5165328it [07:22, 14918.05it/s]5166833it [07:22, 14956.71it/s]5168330it [07:22, 14708.48it/s]5169803it [07:22, 14574.71it/s]5171262it [07:22, 14540.74it/s]5172717it [07:23, 14499.81it/s]5174168it [07:23, 14347.29it/s]5175604it [07:23, 14349.20it/s]5177040it [07:23, 13948.86it/s]5178462it [07:23, 14027.83it/s]5179967it [07:23, 14328.00it/s]5181402it [07:23, 14292.65it/s]5182833it [07:23, 14159.08it/s]5184290it [07:23, 14272.24it/s]5185719it [07:23, 14196.16it/s]5187140it [07:24, 13994.68it/s]5188606it [07:24, 14188.58it/s]5190162it [07:24, 14589.58it/s]5191658it [07:24, 14699.51it/s]5193129it [07:24, 14401.21it/s]5194571it [07:24, 14382.94it/s]5196011it [07:24, 14256.11it/s]5197452it [07:24, 14299.36it/s]5198883it [07:24, 14113.15it/s]5200296it [07:24, 13950.99it/s]5201692it [07:25, 13797.28it/s]5203073it [07:25, 13589.18it/s]5204449it [07:25, 13632.35it/s]5205813it [07:25, 13485.81it/s]5207178it [07:25, 13523.67it/s]5208635it [07:25, 13821.99it/s]5210077it [07:25, 13998.19it/s]5211490it [07:25, 14024.23it/s]5212986it [07:25, 14295.78it/s]5214448it [07:25, 14391.36it/s]5215901it [07:26, 14432.03it/s]5217345it [07:26, 14343.94it/s]5218795it [07:26, 14389.59it/s]5220235it [07:26, 14325.07it/s]5221800it [07:26, 14718.99it/s]5223333it [07:26, 14890.94it/s]5224920it [07:26, 15175.34it/s]5226462it [07:26, 15246.92it/s]5227987it [07:26, 15090.70it/s]5229497it [07:26, 14873.41it/s]5230993it [07:27, 14892.87it/s]5232483it [07:27, 14539.35it/s]5233939it [07:27, 14541.86it/s]5235440it [07:27, 14673.62it/s]5236909it [07:27, 14635.35it/s]5238374it [07:27, 14522.91it/s]5239827it [07:27, 14507.24it/s]5241298it [07:27, 14549.78it/s]5242754it [07:27, 14500.34it/s]5244295it [07:28, 14770.32it/s]5245773it [07:28, 14688.18it/s]5247243it [07:28, 14549.46it/s]5248699it [07:28, 14420.91it/s]5250226it [07:28, 14670.58it/s]5251754it [07:28, 14829.72it/s]5253259it [07:28, 14882.63it/s]5254748it [07:28, 14504.47it/s]5256295it [07:28, 14779.19it/s]5257776it [07:28, 14677.00it/s]5259246it [07:29, 14558.19it/s]5260703it [07:29, 14397.97it/s]5262189it [07:29, 14524.11it/s]5263651it [07:29, 14543.10it/s]5265177it [07:29, 14741.98it/s]5266679it [07:29, 14811.53it/s]5268161it [07:29, 14735.11it/s]5269635it [07:29, 14360.53it/s]5271074it [07:29, 14310.94it/s]5272599it [07:29, 14575.61it/s]5274073it [07:30, 14603.77it/s]5275535it [07:30, 14496.77it/s]5276986it [07:30, 14475.64it/s]5278458it [07:30, 14531.74it/s]5279912it [07:30, 14479.70it/s]5281361it [07:30, 14373.06it/s]5282799it [07:30, 14029.44it/s]5284311it [07:30, 14347.68it/s]5285840it [07:30, 14612.74it/s]5287304it [07:30, 14451.82it/s]5288751it [07:31, 14412.77it/s]5290194it [07:31, 14305.42it/s]5291626it [07:31, 14168.94it/s]5293044it [07:31, 14047.31it/s]5294450it [07:31, 13867.83it/s]5295838it [07:31, 13617.91it/s]5297212it [07:31, 13653.12it/s]5298579it [07:31, 13645.70it/s]5299987it [07:31, 13773.42it/s]5301444it [07:31, 14002.03it/s]5302889it [07:32, 14134.62it/s]5304303it [07:32, 14105.94it/s]5305771it [07:32, 14269.73it/s]5307229it [07:32, 14352.87it/s]5308665it [07:32, 14335.06it/s]5310121it [07:32, 14395.14it/s]5311561it [07:32, 14311.77it/s]5313084it [07:32, 14577.99it/s]5314543it [07:32, 14348.54it/s]5315979it [07:32, 14331.24it/s]5317504it [07:33, 14593.98it/s]5318965it [07:33, 14577.45it/s]5320424it [07:33, 14232.95it/s]5321867it [07:33, 14285.50it/s]5323356it [07:33, 14459.82it/s]5324884it [07:33, 14696.18it/s]5326355it [07:33, 14385.49it/s]5327796it [07:33, 14136.13it/s]5329352it [07:33, 14545.71it/s]5330891it [07:34, 14784.56it/s]5332378it [07:34, 14796.42it/s]5333887it [07:34, 14882.38it/s]5335380it [07:34, 14871.50it/s]5336957it [07:34, 15123.93it/s]5338471it [07:34, 15014.77it/s]5339994it [07:34, 15077.23it/s]5341503it [07:34, 14859.17it/s]5342990it [07:34, 14385.36it/s]5344432it [07:34, 14228.64it/s]5346250it [07:35, 15374.31it/s]5347970it [07:35, 15909.37it/s]5349566it [07:35, 15505.06it/s]5351122it [07:35, 15077.81it/s]5352635it [07:35, 14897.48it/s]5354129it [07:35, 14784.15it/s]5355642it [07:35, 14875.31it/s]5357132it [07:35, 14826.44it/s]5358616it [07:35, 14662.00it/s]5360108it [07:35, 14737.56it/s]5361659it [07:36, 14951.21it/s]5363209it [07:36, 15099.61it/s]5364720it [07:36, 14988.66it/s]5366220it [07:36, 14938.23it/s]5367796it [07:36, 15180.72it/s]5369315it [07:36, 15103.17it/s]5370826it [07:36, 14754.48it/s]5372304it [07:36, 14627.07it/s]5373768it [07:36, 14434.48it/s]5375213it [07:36, 14393.70it/s]5376654it [07:37, 14395.84it/s]5378095it [07:37, 14364.47it/s]5379532it [07:37, 14300.78it/s]5380963it [07:37, 14289.95it/s]5382393it [07:37, 14264.57it/s]5383851it [07:37, 14356.97it/s]5385351it [07:37, 14537.67it/s]5386805it [07:37, 14379.51it/s]5388244it [07:37, 14169.24it/s]5389707it [07:38, 14304.04it/s]5391146it [07:38, 14321.89it/s]5392613it [07:38, 14413.22it/s]5394055it [07:38, 14283.60it/s]5395541it [07:38, 14448.01it/s]5397041it [07:38, 14605.91it/s]5398533it [07:38, 14693.80it/s]5400097it [07:38, 14975.16it/s]5401599it [07:38, 14981.74it/s]5403098it [07:38, 14755.70it/s]5404575it [07:39, 14756.63it/s]5406052it [07:39, 14539.89it/s]5407507it [07:39, 14531.70it/s]5408961it [07:39, 14377.14it/s]5410400it [07:39, 14341.63it/s]5411835it [07:39, 14167.15it/s]5413288it [07:39, 14273.96it/s]5414716it [07:39, 14199.78it/s]5416155it [07:39, 14254.65it/s]5417586it [07:39, 14267.80it/s]5419042it [07:40, 14354.52it/s]5420478it [07:40, 14230.12it/s]5421902it [07:40, 14054.76it/s]5423309it [07:40, 14026.48it/s]5424805it [07:40, 14296.43it/s]5426241it [07:40, 14284.93it/s]5427670it [07:40, 14225.94it/s]5429099it [07:40, 14244.31it/s]5430524it [07:40, 14231.60it/s]5431948it [07:40, 14036.79it/s]5433447it [07:41, 14316.28it/s]5434880it [07:41, 14165.37it/s]5436352it [07:41, 14329.18it/s]5437786it [07:41, 14263.32it/s]5439213it [07:41, 14261.54it/s]5440711it [07:41, 14471.03it/s]5442190it [07:41, 14565.60it/s]5443647it [07:41, 14305.93it/s]5445079it [07:41, 14263.22it/s]5446522it [07:41, 14312.16it/s]5448006it [07:42, 14467.63it/s]5449454it [07:42, 14262.13it/s]5450882it [07:42, 14200.23it/s]5452303it [07:42, 14120.24it/s]5453716it [07:42, 13830.45it/s]5455101it [07:42, 13768.81it/s]5456524it [07:42, 13896.68it/s]5457924it [07:42, 13926.62it/s]5459318it [07:42, 13473.94it/s]5460724it [07:42, 13636.04it/s]5462091it [07:43, 13600.50it/s]5463453it [07:43, 13549.33it/s]5464841it [07:43, 13643.69it/s]5466292it [07:43, 13900.60it/s]5467748it [07:43, 14094.10it/s]5469159it [07:43, 13909.98it/s]5470567it [07:43, 13933.66it/s]5471975it [07:43, 13966.25it/s]5473399it [07:43, 14033.36it/s]5474812it [07:44, 14057.48it/s]5476311it [07:44, 14330.46it/s]5477745it [07:44, 14142.62it/s]5479214it [07:44, 14302.44it/s]5480682it [07:44, 14414.55it/s]5482125it [07:44, 14301.10it/s]5483556it [07:44, 14231.73it/s]5484980it [07:44, 14155.85it/s]5486485it [07:44, 14419.96it/s]5487994it [07:44, 14616.58it/s]5489457it [07:45, 14398.32it/s]5490898it [07:45, 14297.96it/s]5492422it [07:45, 14574.64it/s]5493881it [07:45, 14287.53it/s]5495312it [07:45, 14063.79it/s]5496720it [07:45, 14039.64it/s]5498125it [07:45, 13946.05it/s]5499521it [07:45, 13923.60it/s]5500914it [07:45, 13864.44it/s]5502301it [07:45, 13757.44it/s]5503724it [07:46, 13878.40it/s]5505113it [07:46, 13759.99it/s]5506494it [07:46, 13774.10it/s]5507872it [07:46, 13679.03it/s]5509296it [07:46, 13842.20it/s]5510783it [07:46, 14146.45it/s]5512199it [07:46, 14053.94it/s]5513605it [07:46, 14034.53it/s]5515076it [07:46, 14235.46it/s]5516635it [07:46, 14629.31it/s]5518145it [07:47, 14767.03it/s]5519725it [07:47, 15069.29it/s]5521233it [07:47, 14956.48it/s]5522730it [07:47, 14826.53it/s]5524214it [07:47, 14502.31it/s]5525666it [07:47, 14429.76it/s]5527110it [07:47, 14366.78it/s]5528589it [07:47, 14484.99it/s]5530177it [07:47, 14883.41it/s]5531689it [07:47, 14936.87it/s]5533297it [07:48, 15276.82it/s]5534826it [07:48, 14991.81it/s]5536372it [07:48, 15129.41it/s]5537887it [07:48, 15073.55it/s]5539396it [07:48, 15068.70it/s]5540904it [07:48, 15063.18it/s]5542479it [07:48, 15267.61it/s]5544007it [07:48, 15217.97it/s]5545530it [07:48, 15185.98it/s]5547049it [07:48, 14957.30it/s]5548546it [07:49, 14786.26it/s]5550220it [07:49, 15359.07it/s]5551758it [07:49, 15006.56it/s]5553262it [07:49, 14634.93it/s]5554753it [07:49, 14703.69it/s]5556226it [07:49, 14577.56it/s]5557686it [07:49, 14467.42it/s]5559180it [07:49, 14604.96it/s]5560643it [07:49, 14611.38it/s]5562105it [07:50, 14419.99it/s]5563548it [07:50, 14356.61it/s]5565085it [07:50, 14654.74it/s]5566662it [07:50, 14983.86it/s]5568162it [07:50, 14959.69it/s]5569659it [07:50, 14931.67it/s]5571153it [07:50, 14723.05it/s]5572627it [07:50, 14364.40it/s]5574132it [07:50, 14554.13it/s]5575640it [07:50, 14702.58it/s]5577112it [07:51, 14158.40it/s]5578533it [07:51, 13880.66it/s]5580034it [07:51, 14197.93it/s]5581481it [07:51, 14272.66it/s]5582975it [07:51, 14468.30it/s]5584496it [07:51, 14685.86it/s]5585967it [07:51, 14680.47it/s]5587437it [07:51, 14684.64it/s]5588907it [07:51, 14391.89it/s]5590349it [07:51, 14301.14it/s]5591781it [07:52, 14051.83it/s]5593188it [07:52, 13661.89it/s]5594557it [07:52, 13395.69it/s]5595899it [07:52, 13079.03it/s]5597209it [07:52, 12785.07it/s]5598490it [07:52, 12592.45it/s]5599751it [07:52, 12348.95it/s]5601049it [07:52, 12517.45it/s]5602389it [07:52, 12766.16it/s]5603826it [07:53, 13224.04it/s]5605235it [07:53, 13478.56it/s]5606680it [07:53, 13762.63it/s]5608110it [07:53, 13922.30it/s]5609518it [07:53, 13964.42it/s]5610966it [07:53, 14111.32it/s]5612409it [07:53, 14206.49it/s]5613878it [07:53, 14350.00it/s]5615388it [07:53, 14565.86it/s]5616845it [07:53, 14091.11it/s]5618258it [07:54, 13631.73it/s]5619626it [07:54, 13288.44it/s]5621070it [07:54, 13616.91it/s]5622578it [07:54, 14041.03it/s]5624053it [07:54, 14245.51it/s]5625536it [07:54, 14387.72it/s]5627025it [07:54, 14536.16it/s]5628538it [07:54, 14711.79it/s]5630011it [07:54, 14454.04it/s]5631459it [07:54, 13710.23it/s]5632839it [07:55, 13007.54it/s]5634176it [07:55, 13097.44it/s]5635586it [07:55, 13377.04it/s]5637052it [07:55, 13746.67it/s]5638533it [07:55, 14055.05it/s]5639948it [07:55, 14081.32it/s]5641397it [07:55, 14194.79it/s]5642886it [07:55, 14398.62it/s]5644329it [07:55, 14358.83it/s]5645767it [07:56, 13875.40it/s]5647159it [07:56, 13550.40it/s]5648518it [07:56, 13202.07it/s]5649842it [07:56, 12758.69it/s]5651122it [07:56, 12304.66it/s]5652357it [07:56, 12255.80it/s]5653725it [07:56, 12661.67it/s]5655198it [07:56, 13258.39it/s]5656664it [07:56, 13663.31it/s]5658282it [07:56, 14392.05it/s]5659800it [07:57, 14615.78it/s]5661345it [07:57, 14862.08it/s]5662834it [07:57, 14863.92it/s]5664323it [07:57, 14786.81it/s]5665803it [07:57, 14506.99it/s]5667256it [07:57, 14424.70it/s]5668772it [07:57, 14626.28it/s]5670236it [07:57, 13864.37it/s]5671631it [07:57, 13165.40it/s]5673038it [07:58, 13416.69it/s]5674390it [07:58, 13367.38it/s]5675767it [07:58, 13478.85it/s]5677230it [07:58, 13805.41it/s]5678615it [07:58, 13688.71it/s]5680080it [07:58, 13970.83it/s]5681496it [07:58, 14018.30it/s]5683035it [07:58, 14421.60it/s]5684527it [07:58, 14563.21it/s]5685985it [07:58, 14540.22it/s]5687440it [07:59, 14304.27it/s]5688872it [07:59, 13645.85it/s]5690351it [07:59, 13973.00it/s]5691839it [07:59, 14227.14it/s]5693277it [07:59, 14260.28it/s]5694759it [07:59, 14419.93it/s]5696234it [07:59, 14513.29it/s]5697733it [07:59, 14653.38it/s]5699200it [07:59, 14505.77it/s]5700652it [07:59, 14287.95it/s]5702132it [08:00, 14437.89it/s]5703578it [08:00, 14157.33it/s]5704996it [08:00, 13936.20it/s]5706392it [08:00, 12837.59it/s]5707692it [08:01, 4076.44it/s] 5708647it [08:02, 2440.46it/s]5709346it [08:02, 2100.35it/s]5709875it [08:03, 1779.09it/s]5710277it [08:03, 1791.98it/s]5710614it [08:03, 1840.90it/s]5710915it [08:03, 1793.25it/s]5711173it [08:03, 1803.79it/s]5711410it [08:04, 1817.35it/s]5711632it [08:04, 1682.90it/s]5711827it [08:04, 1560.11it/s]5711999it [08:04, 1358.97it/s]5712147it [08:04, 1177.51it/s]5712274it [08:04, 1110.86it/s]5712426it [08:05, 1176.51it/s]5712550it [08:05, 1118.75it/s]5712756it [08:05, 1268.77it/s]5712888it [08:05, 1231.49it/s]5713014it [08:05, 1115.87it/s]5713129it [08:05, 1113.31it/s]5713307it [08:05, 1281.32it/s]5713454it [08:05, 1184.55it/s]5713658it [08:06, 1338.16it/s]5713853it [08:06, 1405.88it/s]5714068it [08:06, 1573.51it/s]5714260it [08:06, 1635.58it/s]5714993it [08:06, 3175.83it/s]5716269it [08:06, 5848.74it/s]5717499it [08:06, 7685.92it/s]5718785it [08:06, 9176.26it/s]5720265it [08:06, 10808.97it/s]5721843it [08:06, 12266.75it/s]5723344it [08:07, 13063.59it/s]5724881it [08:07, 13743.42it/s]5726385it [08:07, 14129.32it/s]5727940it [08:07, 14545.46it/s]5729581it [08:07, 15101.70it/s]5731125it [08:07, 15202.60it/s]5732649it [08:07, 15006.54it/s]5734153it [08:07, 14900.51it/s]5735701it [08:07, 15062.29it/s]5737209it [08:07, 14839.67it/s]5738695it [08:08, 14228.38it/s]5740124it [08:08, 14171.04it/s]5741612it [08:08, 14375.82it/s]5743053it [08:08, 14305.71it/s]5744486it [08:08, 13952.84it/s]5745885it [08:08, 13947.94it/s]5747407it [08:08, 14320.55it/s]5748876it [08:08, 14414.82it/s]5750336it [08:08, 14468.71it/s]5751785it [08:09, 13648.78it/s]5753160it [08:09, 13196.87it/s]5754610it [08:09, 13562.36it/s]5756052it [08:09, 13803.02it/s]5757440it [08:09, 13781.58it/s]5758838it [08:09, 13839.26it/s]5760311it [08:09, 14093.86it/s]5761724it [08:09, 14095.46it/s]5763136it [08:09, 14027.23it/s]5764616it [08:09, 14240.76it/s]5766042it [08:10, 13924.52it/s]5767560it [08:10, 14292.94it/s]5769028it [08:10, 14403.84it/s]5770471it [08:10, 14237.48it/s]5771897it [08:10, 14186.04it/s]5773317it [08:10, 14109.32it/s]5774729it [08:10, 14086.98it/s]5776139it [08:10, 14066.42it/s]5777576it [08:10, 14156.56it/s]5779039it [08:10, 14295.96it/s]5780496it [08:11, 14361.90it/s]5782003it [08:11, 14572.67it/s]5783461it [08:11, 14364.60it/s]5784963it [08:11, 14558.03it/s]5786431it [08:11, 14591.22it/s]5787891it [08:11, 13976.47it/s]5789295it [08:11, 13433.74it/s]5790646it [08:11, 13118.64it/s]5791964it [08:11, 13022.19it/s]5793469it [08:11, 13603.11it/s]5794917it [08:12, 13856.98it/s]5796318it [08:12, 13892.89it/s]5797711it [08:12, 13778.89it/s]5799092it [08:12, 13689.97it/s]5800494it [08:12, 13775.25it/s]5801986it [08:12, 14110.80it/s]5803399it [08:12, 14108.73it/s]5804811it [08:13, 7930.21it/s] 5805917it [08:13, 3696.21it/s]5806924it [08:13, 4375.94it/s]5807979it [08:14, 5192.27it/s]5808907it [08:14, 5071.43it/s]5809729it [08:14, 5588.26it/s]5810530it [08:14, 5778.52it/s]5811284it [08:14, 5661.97it/s]5812243it [08:14, 6500.60it/s]5813448it [08:14, 7547.27it/s]5814303it [08:15, 5837.68it/s]5815066it [08:15, 6203.59it/s]5815789it [08:15, 5977.54it/s]5817207it [08:15, 7883.83it/s]5818100it [08:15, 8053.66it/s]5818982it [08:15, 7052.51it/s]5819854it [08:15, 7450.63it/s]5820923it [08:15, 8275.32it/s]5821807it [08:16, 6976.19it/s]5822575it [08:16, 4924.20it/s]5823193it [08:16, 4071.02it/s]5823703it [08:16, 3449.04it/s]5824590it [08:16, 4372.81it/s]5825244it [08:16, 4796.79it/s]5825834it [08:17, 3739.46it/s]5826948it [08:17, 5059.10it/s]5827596it [08:17, 5149.19it/s]5829130it [08:17, 7424.64it/s]5830022it [08:17, 7529.59it/s]5830889it [08:17, 7814.85it/s]5831750it [08:17, 7814.11it/s]5832833it [08:17, 8622.91it/s]5833744it [08:18, 7378.34it/s]5834921it [08:18, 8468.93it/s]5836421it [08:18, 10185.88it/s]5837510it [08:18, 7414.16it/s] 5838405it [08:18, 7033.08it/s]5839225it [08:18, 7282.67it/s]5840477it [08:18, 8397.91it/s]5841481it [08:19, 8137.14it/s]5842372it [08:19, 8227.85it/s]5843236it [08:19, 7393.02it/s]5844079it [08:19, 7586.36it/s]5845389it [08:19, 9019.23it/s]5846358it [08:19, 9195.09it/s]5847311it [08:19, 6998.27it/s]5848109it [08:20, 4660.04it/s]5848924it [08:20, 5271.97it/s]5849609it [08:20, 5480.22it/s]5850572it [08:20, 5877.28it/s]5851246it [08:20, 5891.77it/s]5852085it [08:20, 6481.27it/s]5852791it [08:20, 6554.37it/s]5853489it [08:21, 5504.97it/s]5854094it [08:21, 4942.62it/s]5854979it [08:21, 5836.63it/s]5855761it [08:21, 6325.19it/s]5856445it [08:21, 5180.95it/s]5857883it [08:21, 7293.35it/s]5859246it [08:21, 8855.19it/s]5860243it [08:21, 7834.14it/s]5861123it [08:22, 7664.48it/s]5862243it [08:22, 8301.47it/s]5863235it [08:22, 8586.56it/s]5864135it [08:22, 6417.08it/s]5864881it [08:22, 6528.53it/s]5866180it [08:22, 7669.41it/s]5867339it [08:22, 8010.04it/s]5868187it [08:23, 7945.86it/s]5869014it [08:23, 7038.47it/s]5869752it [08:23, 6362.94it/s]5871107it [08:23, 8053.87it/s]5872460it [08:23, 9197.04it/s]5873678it [08:23, 9966.05it/s]5874883it [08:23, 10524.38it/s]5876223it [08:23, 11321.92it/s]5877663it [08:23, 12197.39it/s]5878978it [08:24, 12472.03it/s]5880486it [08:24, 13221.90it/s]5882174it [08:24, 14290.33it/s]5883765it [08:24, 14768.15it/s]5885478it [08:24, 15459.66it/s]5887190it [08:24, 15953.92it/s]5888792it [08:24, 15763.07it/s]5890373it [08:24, 15570.44it/s]5891934it [08:24, 15309.36it/s]5893469it [08:24, 15078.14it/s]5895046it [08:25, 15268.73it/s]5896594it [08:25, 15330.57it/s]5898129it [08:25, 15122.40it/s]5899643it [08:25, 14893.35it/s]5901134it [08:25, 14634.85it/s]5902599it [08:25, 14303.81it/s]5904073it [08:25, 14429.23it/s]5905518it [08:25, 13838.79it/s]5906908it [08:26, 4994.93it/s] 5907939it [08:27, 2206.78it/s]5909322it [08:27, 2979.69it/s]5910801it [08:28, 4003.82it/s]5912359it [08:28, 5278.77it/s]5913869it [08:28, 4413.80it/s]5915291it [08:28, 5537.68it/s]5916747it [08:28, 6808.02it/s]5918262it [08:28, 8204.70it/s]5919730it [08:29, 9447.51it/s]5921078it [08:29, 10141.11it/s]5922396it [08:29, 10767.22it/s]5923702it [08:29, 11149.15it/s]5924983it [08:29, 11325.48it/s]5926331it [08:29, 11896.07it/s]5927948it [08:29, 13061.49it/s]5929432it [08:29, 13559.75it/s]5930898it [08:29, 13873.89it/s]5932392it [08:29, 14181.21it/s]5933888it [08:30, 14408.28it/s]5935470it [08:30, 14824.61it/s]5937005it [08:30, 14963.55it/s]5938591it [08:30, 15225.27it/s]5940122it [08:30, 15225.57it/s]5941650it [08:30, 15043.84it/s]5943159it [08:30, 14703.90it/s]5944634it [08:31, 5509.08it/s] 5945733it [08:31, 4897.42it/s]5946632it [08:31, 5374.17it/s]5947495it [08:31, 5643.12it/s]5948985it [08:31, 7278.16it/s]5949997it [08:32, 7827.11it/s]5951005it [08:32, 7059.91it/s]5952447it [08:32, 8624.19it/s]5953959it [08:32, 10136.91it/s]5955463it [08:32, 11360.68it/s]5956985it [08:32, 12374.95it/s]5958338it [08:32, 11374.07it/s]5959687it [08:32, 11916.85it/s]5961006it [08:32, 12252.40it/s]5962288it [08:33, 12113.05it/s]5963563it [08:33, 12283.48it/s]5965057it [08:33, 13039.74it/s]5966581it [08:33, 13676.38it/s]5968014it [08:33, 13859.13it/s]5969490it [08:33, 14111.99it/s]5970912it [08:33, 14135.79it/s]5972333it [08:33, 13847.78it/s]5973792it [08:33, 14064.87it/s]5975204it [08:34, 12163.13it/s]5976705it [08:34, 12921.98it/s]5978168it [08:34, 13393.09it/s]5979636it [08:34, 13744.95it/s]5981130it [08:34, 14084.07it/s]5982602it [08:34, 14254.78it/s]5984153it [08:34, 14622.70it/s]5985720it [08:34, 14924.71it/s]5987221it [08:34, 14934.53it/s]5988721it [08:34, 14776.03it/s]5990245it [08:35, 14898.96it/s]5991738it [08:35, 14649.59it/s]5993206it [08:35, 14338.68it/s]5994643it [08:36, 3030.21it/s] 5995680it [08:37, 2784.92it/s]5996799it [08:37, 3450.86it/s]5997668it [08:38, 2241.61it/s]5998307it [08:38, 2058.00it/s]5998800it [08:39, 1529.75it/s]5999166it [08:39, 1428.49it/s]5999454it [08:39, 1521.58it/s]5999728it [08:39, 1589.09it/s]6000024it [08:39, 1757.07it/s]6000598it [08:40, 2341.51it/s]6000952it [08:40, 1663.30it/s]6001226it [08:40, 1433.47it/s]6001643it [08:40, 1807.19it/s]6002050it [08:40, 2158.35it/s]6002362it [08:41, 2003.48it/s]6002642it [08:41, 2136.85it/s]6002911it [08:41, 1986.91it/s]6003148it [08:41, 1398.79it/s]6003361it [08:41, 1521.42it/s]6003557it [08:41, 1407.68it/s]6003783it [08:42, 1530.24it/s]6003962it [08:42, 1477.65it/s]6004299it [08:42, 1850.07it/s]6004506it [08:42, 1890.93it/s]6004712it [08:42, 1300.33it/s]6004979it [08:42, 1523.91it/s]6005165it [08:42, 1501.87it/s]6005338it [08:43, 1500.27it/s]6005548it [08:43, 1585.48it/s]6005719it [08:43, 1481.82it/s]6005877it [08:43, 1480.46it/s]6006032it [08:43, 1365.52it/s]6006179it [08:43, 1375.68it/s]6006321it [08:43, 1342.89it/s]6006458it [08:43, 1310.72it/s]6006595it [08:44, 1313.13it/s]6006728it [08:44, 1266.60it/s]6006856it [08:44, 1253.52it/s]6006982it [08:44, 1149.74it/s]6007214it [08:44, 1446.36it/s]6007363it [08:44, 1255.03it/s]6007566it [08:44, 1381.26it/s]6007710it [08:44, 1392.38it/s]6008013it [08:44, 1828.30it/s]6008777it [08:45, 3302.48it/s]6009991it [08:45, 5732.34it/s]6010713it [08:45, 6143.36it/s]6011348it [08:45, 5610.25it/s]6012303it [08:45, 6675.67it/s]6013332it [08:45, 7682.73it/s]6014797it [08:45, 9660.31it/s]6016285it [08:45, 11168.52it/s]6017801it [08:45, 12327.62it/s]6019228it [08:46, 12898.90it/s]6020704it [08:46, 13449.53it/s]6022141it [08:46, 13722.14it/s]6023601it [08:46, 13969.81it/s]6025011it [08:46, 13996.26it/s]6026472it [08:46, 14163.40it/s]6027919it [08:46, 14249.85it/s]6029347it [08:46, 14197.90it/s]6030822it [08:46, 14362.01it/s]6032260it [08:46, 14350.71it/s]6033696it [08:47, 14329.99it/s]6035130it [08:47, 13890.11it/s]6036629it [08:47, 14211.86it/s]6038054it [08:47, 9686.99it/s] 6039217it [08:47, 8769.63it/s]6040237it [08:47, 8950.75it/s]6041474it [08:47, 9748.74it/s]6042659it [08:47, 10273.27it/s]6043765it [08:48, 8598.83it/s] 6045285it [08:48, 10155.16it/s]6046410it [08:48, 10387.89it/s]6047839it [08:48, 11412.15it/s]6049338it [08:48, 12390.62it/s]6050828it [08:48, 13094.21it/s]6052232it [08:48, 13359.87it/s]6053830it [08:48, 14100.69it/s]6055307it [08:48, 14296.26it/s]6056755it [08:49, 13886.91it/s]6058159it [08:49, 13796.40it/s]6059555it [08:49, 13843.73it/s]6061042it [08:49, 14143.38it/s]6062567it [08:49, 14469.94it/s]6064080it [08:49, 14641.67it/s]6065567it [08:49, 14709.44it/s]6067041it [08:49, 14593.05it/s]6068537it [08:49, 14699.57it/s]6070021it [08:49, 14741.16it/s]6071497it [08:50, 14715.59it/s]6072970it [08:50, 13798.19it/s]6074362it [08:50, 13126.45it/s]6075688it [08:50, 12834.49it/s]6076981it [08:50, 12655.36it/s]6078253it [08:50, 12586.19it/s]6079552it [08:50, 12685.91it/s]6080824it [08:50, 12659.16it/s]6082152it [08:50, 12834.31it/s]6083611it [08:51, 13349.80it/s]6085067it [08:51, 13707.64it/s]6086603it [08:51, 14198.06it/s]6088094it [08:51, 14408.10it/s]6089537it [08:51, 14351.06it/s]6090974it [08:51, 14257.08it/s]6092536it [08:51, 14659.73it/s]6094026it [08:51, 14731.01it/s]6095500it [08:51, 14644.44it/s]6096966it [08:51, 14476.10it/s]6098415it [08:52, 14301.03it/s]6099846it [08:52, 13942.72it/s]6101301it [08:52, 14118.07it/s]6102777it [08:52, 14306.25it/s]6104287it [08:52, 14539.70it/s]6105822it [08:52, 14780.07it/s]6107357it [08:52, 14944.47it/s]6108876it [08:52, 15010.73it/s]6110378it [08:52, 14506.11it/s]6111837it [08:52, 14526.35it/s]6113293it [08:53, 14523.78it/s]6114781it [08:53, 14624.06it/s]6116245it [08:53, 14598.76it/s]6117706it [08:53, 14600.57it/s]6119167it [08:53, 14521.22it/s]6120620it [08:53, 14372.62it/s]6122058it [08:53, 14206.94it/s]6123480it [08:53, 14194.67it/s]6124900it [08:53, 13359.48it/s]6126347it [08:54, 13664.87it/s]6127722it [08:54, 12315.54it/s]6129198it [08:54, 12974.46it/s]6130703it [08:54, 13533.36it/s]6132080it [08:54, 13246.95it/s]6133422it [08:54, 12834.11it/s]6134727it [08:54, 12894.41it/s]6136026it [08:54, 12776.64it/s]6137427it [08:54, 13122.64it/s]6138922it [08:54, 13654.68it/s]6140359it [08:55, 13863.73it/s]6141877it [08:55, 14252.69it/s]6143306it [08:55, 14055.67it/s]6144806it [08:55, 14333.29it/s]6146242it [08:55, 14253.93it/s]6147670it [08:55, 14160.64it/s]6149213it [08:55, 14522.19it/s]6150667it [08:55, 14291.85it/s]6152098it [08:55, 14128.83it/s]6153541it [08:55, 14216.76it/s]6154964it [08:56, 14000.54it/s]6156399it [08:56, 14102.10it/s]6157832it [08:56, 14154.33it/s]6159256it [08:56, 14167.10it/s]6160706it [08:56, 14264.29it/s]6162176it [08:56, 14386.95it/s]6163616it [08:56, 13903.38it/s]6165066it [08:56, 14074.03it/s]6166477it [08:56, 14045.55it/s]6167979it [08:57, 14327.75it/s]6169414it [08:57, 13757.12it/s]6170959it [08:57, 14240.16it/s]6172389it [08:57, 14179.50it/s]6173903it [08:57, 14457.16it/s]6175437it [08:57, 14705.70it/s]6176937it [08:57, 14790.75it/s]6178419it [08:57, 14631.15it/s]6179884it [08:57, 14492.30it/s]6181453it [08:57, 14840.90it/s]6182939it [08:58, 14403.91it/s]6184383it [08:58, 13325.41it/s]6185732it [08:58, 12975.61it/s]6187041it [08:58, 12935.51it/s]6188373it [08:58, 13026.89it/s]6189682it [08:58, 12909.09it/s]6190977it [08:58, 12766.77it/s]6192257it [08:58, 12520.46it/s]6193636it [08:58, 12886.50it/s]6195009it [08:59, 13131.96it/s]6196669it [08:59, 14140.92it/s]6198112it [08:59, 14224.81it/s]6199538it [08:59, 14197.34it/s]6200965it [08:59, 14210.14it/s]6202450it [08:59, 14398.15it/s]6203922it [08:59, 14493.82it/s]6205373it [08:59, 14289.68it/s]6206838it [08:59, 14396.34it/s]6208279it [08:59, 14369.59it/s]6209717it [09:00, 14121.40it/s]6211131it [09:00, 13544.15it/s]6212711it [09:00, 14184.79it/s]6214188it [09:00, 14349.79it/s]6215638it [09:00, 14392.89it/s]6217161it [09:00, 14628.21it/s]6218627it [09:00, 14450.49it/s]6220209it [09:00, 14853.50it/s]6221697it [09:00, 14789.34it/s]6223178it [09:00, 14611.86it/s]6224642it [09:01, 14616.62it/s]6226105it [09:01, 14449.45it/s]6227551it [09:01, 14426.88it/s]6228995it [09:01, 13961.98it/s]6230395it [09:01, 13588.32it/s]6231758it [09:01, 13500.51it/s]6233218it [09:01, 13818.49it/s]6234615it [09:01, 13861.68it/s]6236029it [09:01, 13934.96it/s]6237458it [09:01, 14038.10it/s]6238907it [09:02, 14163.21it/s]6240397it [09:02, 14376.83it/s]6241877it [09:02, 14501.21it/s]6243341it [09:02, 14542.51it/s]6244810it [09:02, 14567.26it/s]6246268it [09:02, 14101.31it/s]6247682it [09:02, 13710.63it/s]6249058it [09:02, 13331.29it/s]6250396it [09:02, 13070.46it/s]6251706it [09:03, 12820.55it/s]6252991it [09:03, 12755.50it/s]6254502it [09:03, 13431.41it/s]6255934it [09:03, 13690.68it/s]6257383it [09:03, 13925.43it/s]6258876it [09:03, 14211.43it/s]6260385it [09:03, 14469.73it/s]6261869it [09:03, 14578.09it/s]6263406it [09:03, 14813.12it/s]6264889it [09:03, 14189.64it/s]6266348it [09:04, 14305.43it/s]6267784it [09:04, 13926.54it/s]6269313it [09:04, 14315.35it/s]6270772it [09:04, 14395.32it/s]6272216it [09:04, 14245.25it/s]6273658it [09:04, 14287.79it/s]6275089it [09:04, 14258.90it/s]6276588it [09:04, 14475.23it/s]6278037it [09:04, 14307.96it/s]6279469it [09:04, 13697.77it/s]6280845it [09:05, 13081.71it/s]6282162it [09:05, 12801.02it/s]6283497it [09:05, 12943.25it/s]6284796it [09:05, 12924.61it/s]6286106it [09:05, 12974.54it/s]6287406it [09:05, 12897.39it/s]6288698it [09:05, 12572.72it/s]6289973it [09:05, 12623.33it/s]6291238it [09:05, 12387.96it/s]6292680it [09:06, 12967.04it/s]6294162it [09:06, 13506.99it/s]6295662it [09:06, 13947.83it/s]6297123it [09:06, 14143.60it/s]6298551it [09:06, 14177.83it/s]6299990it [09:06, 14240.55it/s]6301487it [09:06, 14458.30it/s]6302934it [09:06, 14404.78it/s]6304376it [09:06, 14271.15it/s]6305804it [09:07, 10944.06it/s]6307016it [09:07, 11072.26it/s]6308235it [09:07, 11359.28it/s]6309481it [09:07, 11644.29it/s]6310780it [09:07, 12016.65it/s]6312061it [09:07, 12241.02it/s]6313312it [09:07, 12132.03it/s]6314544it [09:07, 11836.50it/s]6315742it [09:07, 11811.89it/s]6317318it [09:07, 12949.92it/s]6318780it [09:08, 13437.07it/s]6320260it [09:08, 13832.13it/s]6321747it [09:08, 14132.09it/s]6323223it [09:08, 14313.82it/s]6324659it [09:08, 14238.35it/s]6326086it [09:08, 14019.58it/s]6327527it [09:08, 14129.44it/s]6329014it [09:08, 14346.11it/s]6330451it [09:08, 13311.18it/s]6331798it [09:08, 12950.21it/s]6333110it [09:09, 12997.57it/s]6334504it [09:09, 13266.91it/s]6335897it [09:09, 13442.99it/s]6337287it [09:09, 13576.64it/s]6338739it [09:09, 13843.89it/s]6340127it [09:09, 13661.80it/s]6341534it [09:09, 13779.96it/s]6342915it [09:09, 13283.85it/s]6344249it [09:09, 12738.52it/s]6345530it [09:10, 12728.55it/s]6346808it [09:10, 12436.11it/s]6348257it [09:10, 13012.04it/s]6349729it [09:10, 13506.27it/s]6351188it [09:10, 13823.56it/s]6352635it [09:10, 14003.76it/s]6354039it [09:10, 13808.74it/s]6355423it [09:10, 13012.18it/s]6356765it [09:10, 13116.25it/s]6358085it [09:10, 12661.40it/s]6359413it [09:11, 12822.43it/s]6360845it [09:11, 13248.36it/s]6362264it [09:11, 13515.40it/s]6363706it [09:11, 13780.63it/s]6365151it [09:11, 13967.55it/s]6366582it [09:11, 14053.45it/s]6367990it [09:11, 13959.44it/s]6369388it [09:11, 12921.32it/s]6370696it [09:11, 12056.91it/s]6371922it [09:12, 11749.96it/s]6373110it [09:12, 11547.55it/s]6374274it [09:12, 11395.36it/s]6375419it [09:12, 10922.53it/s]6376517it [09:12, 10848.11it/s]6377606it [09:12, 10797.06it/s]6378709it [09:12, 10862.31it/s]6379832it [09:12, 10953.00it/s]6380976it [09:12, 11088.06it/s]6382193it [09:12, 11400.04it/s]6383365it [09:13, 11485.81it/s]6384515it [09:13, 11486.84it/s]6385767it [09:13, 11794.08it/s]6386948it [09:13, 11779.33it/s]6388127it [09:13, 11556.63it/s]6389369it [09:13, 11810.26it/s]6390590it [09:13, 11928.45it/s]6391826it [09:13, 12053.96it/s]6393115it [09:13, 12287.22it/s]6394345it [09:13, 11849.17it/s]6395534it [09:14, 11324.35it/s]6396701it [09:14, 11413.88it/s]6397990it [09:14, 11836.83it/s]6399213it [09:14, 11940.08it/s]6400524it [09:14, 12275.38it/s]6401755it [09:14, 12285.33it/s]6402986it [09:14, 12285.26it/s]6404217it [09:14, 12154.72it/s]6405434it [09:14, 12009.22it/s]6406724it [09:15, 12263.74it/s]6407952it [09:15, 12121.05it/s]6409166it [09:15, 11859.01it/s]6410354it [09:15, 11825.77it/s]6411661it [09:15, 12187.52it/s]6412954it [09:15, 12401.99it/s]6414196it [09:15, 12247.40it/s]6415513it [09:15, 12519.02it/s]6416804it [09:15, 12634.63it/s]6418069it [09:15, 12580.16it/s]6419357it [09:16, 12659.42it/s]6420673it [09:16, 12808.35it/s]6421977it [09:16, 12871.04it/s]6423265it [09:16, 12829.10it/s]6424549it [09:16, 12831.60it/s]6425833it [09:16, 12639.63it/s]6427098it [09:16, 12594.49it/s]6428376it [09:16, 12637.49it/s]6429722it [09:16, 12870.87it/s]6431010it [09:16, 12441.73it/s]6432258it [09:17, 12256.74it/s]6433487it [09:17, 12256.14it/s]6434715it [09:17, 12160.94it/s]6435989it [09:17, 12321.99it/s]6437230it [09:17, 12344.00it/s]6438599it [09:17, 12742.98it/s]6440849it [09:17, 15646.46it/s]6443435it [09:17, 18690.89it/s]6445967it [09:17, 20667.36it/s]6448038it [09:17, 19999.37it/s]6450045it [09:18, 16091.78it/s]6451778it [09:18, 14082.81it/s]6453306it [09:18, 12653.64it/s]6454667it [09:18, 11528.45it/s]6455890it [09:18, 11067.88it/s]6457041it [09:18, 10759.69it/s]6458143it [09:19, 5890.01it/s] 6458989it [09:19, 4552.05it/s]6459656it [09:20, 3608.47it/s]6460181it [09:20, 2642.04it/s]6460584it [09:20, 2379.31it/s]6460914it [09:20, 2358.27it/s]6461228it [09:20, 2348.41it/s]6461525it [09:21, 2433.45it/s]6461806it [09:21, 2394.67it/s]6462070it [09:21, 2043.13it/s]6462296it [09:21, 1966.35it/s]6462617it [09:21, 2218.22it/s]6462961it [09:21, 2495.58it/s]6463233it [09:21, 2488.43it/s]6463498it [09:22, 2266.81it/s]6463738it [09:22, 2160.20it/s]6463964it [09:22, 2183.79it/s]6464822it [09:22, 3858.43it/s]6465455it [09:22, 3941.54it/s]6467023it [09:22, 6891.41it/s]6467778it [09:24, 1254.71it/s]6468319it [09:26, 765.83it/s] 6468708it [09:27, 643.73it/s]6469163it [09:27, 803.65it/s]6469549it [09:27, 977.09it/s]6469886it [09:27, 1124.46it/s]6470195it [09:27, 1208.46it/s]6470502it [09:27, 1414.09it/s]6470780it [09:27, 1596.86it/s]6471097it [09:27, 1822.07it/s]6471439it [09:28, 2119.38it/s]6471738it [09:28, 2289.53it/s]6472135it [09:28, 2675.56it/s]6472462it [09:28, 2524.50it/s]6472757it [09:28, 2071.29it/s]6473006it [09:28, 2152.20it/s]6473254it [09:28, 2106.88it/s]6473487it [09:29, 1020.94it/s]6473905it [09:29, 1450.79it/s]6474148it [09:29, 1180.49it/s]6474425it [09:29, 1414.02it/s]6474777it [09:30, 1727.15it/s]6475079it [09:30, 1957.62it/s]6475335it [09:30, 1982.74it/s]6475622it [09:30, 2182.39it/s]6475877it [09:30, 1651.81it/s]6476598it [09:30, 2774.97it/s]6477328it [09:30, 3787.67it/s]6479474it [09:30, 8071.78it/s]6482117it [09:31, 12792.87it/s]6486049it [09:31, 19917.35it/s]6489747it [09:31, 24634.84it/s]6493115it [09:31, 27181.13it/s]6496557it [09:31, 29265.81it/s]6500014it [09:31, 30812.40it/s]6503612it [09:31, 32316.04it/s]6507240it [09:31, 33487.82it/s]6510828it [09:31, 34198.07it/s]6514519it [09:31, 35004.06it/s]6518152it [09:32, 35388.95it/s]6521851it [09:32, 35865.51it/s]6525449it [09:32, 35640.41it/s]6529022it [09:32, 35640.35it/s]6532592it [09:32, 35406.53it/s]6536232it [09:32, 35698.16it/s]6539851it [09:32, 35837.42it/s]6543592it [09:32, 36300.84it/s]6547300it [09:32, 36515.46it/s]6550953it [09:32, 36083.66it/s]6554564it [09:33, 34627.48it/s]6558269it [09:33, 35327.62it/s]6561814it [09:33, 35310.14it/s]6565506it [09:33, 35773.85it/s]6569157it [09:33, 35983.67it/s]6572956it [09:33, 36578.45it/s]6577456it [09:33, 39051.53it/s]6581366it [09:33, 38570.63it/s]6585227it [09:33, 37653.10it/s]6588999it [09:33, 36991.67it/s]6592704it [09:34, 34045.08it/s]6596153it [09:34, 16896.00it/s]6598788it [09:34, 12397.49it/s]6600831it [09:35, 10287.42it/s]6602447it [09:35, 9196.33it/s] 6603768it [09:35, 8456.63it/s]6604879it [09:35, 7949.52it/s]6605843it [09:36, 7728.09it/s]6606724it [09:36, 7829.64it/s]6607590it [09:36, 7352.73it/s]6608376it [09:36, 7241.09it/s]6609132it [09:36, 7148.54it/s]6609867it [09:36, 6972.51it/s]6610576it [09:36, 6850.82it/s]6611268it [09:36, 6835.10it/s]6611956it [09:37, 6748.49it/s]6612633it [09:37, 6700.33it/s]6613373it [09:37, 6893.24it/s]6614065it [09:37, 6735.78it/s]6614741it [09:37, 6641.38it/s]6615435it [09:37, 6717.29it/s]6616188it [09:37, 6947.76it/s]6616885it [09:37, 6749.87it/s]6617599it [09:37, 6858.57it/s]6618292it [09:37, 6879.07it/s]6618982it [09:38, 6787.00it/s]6619783it [09:38, 7144.99it/s]6620500it [09:38, 7091.23it/s]6621227it [09:38, 7140.08it/s]6621942it [09:38, 6884.85it/s]6622633it [09:38, 6711.30it/s]6623307it [09:38, 6683.49it/s]6623985it [09:38, 6707.10it/s]6624657it [09:38, 6571.32it/s]6625316it [09:38, 6526.07it/s]6625970it [09:39, 6358.46it/s]6626705it [09:39, 6644.44it/s]6627398it [09:39, 6718.83it/s]6628072it [09:39, 6419.53it/s]6628756it [09:39, 6535.27it/s]6629413it [09:39, 6502.34it/s]6630066it [09:39, 6445.25it/s]6630712it [09:39, 6365.53it/s]6631350it [09:39, 6275.30it/s]6632007it [09:40, 6358.43it/s]6632644it [09:40, 6265.68it/s]6633358it [09:40, 6520.66it/s]6634012it [09:40, 6474.55it/s]6634667it [09:40, 6495.59it/s]6635332it [09:40, 6534.81it/s]6635989it [09:40, 6538.63it/s]6636644it [09:40, 6466.57it/s]6637292it [09:40, 6467.09it/s]6637939it [09:40, 6466.55it/s]6638586it [09:41, 6423.79it/s]6639244it [09:41, 6465.56it/s]6639918it [09:41, 6546.43it/s]6640573it [09:41, 6454.54it/s]6641219it [09:41, 6369.95it/s]6641857it [09:41, 6320.70it/s]6642510it [09:41, 6377.81it/s]6643219it [09:41, 6583.88it/s]6643964it [09:41, 6838.41it/s]6644657it [09:41, 6859.05it/s]6645344it [09:42, 6825.55it/s]6646111it [09:42, 7074.74it/s]6646841it [09:42, 7141.17it/s]6647556it [09:42, 5280.89it/s]6648155it [09:42, 5256.61it/s]6648837it [09:42, 5636.97it/s]6649493it [09:42, 5878.36it/s]6650224it [09:42, 6265.28it/s]6650959it [09:42, 6568.23it/s]6651637it [09:43, 6106.46it/s]6652343it [09:43, 6361.07it/s]6653111it [09:43, 6727.79it/s]6653798it [09:43, 6740.83it/s]6654483it [09:43, 6537.96it/s]6655145it [09:43, 6395.52it/s]6655791it [09:43, 6354.29it/s]6656480it [09:43, 6507.55it/s]6657135it [09:43, 6330.35it/s]6657772it [09:44, 6316.18it/s]6658456it [09:44, 6460.13it/s]6659131it [09:44, 6543.66it/s]6659787it [09:44, 6528.12it/s]6660441it [09:44, 6452.81it/s]6661088it [09:44, 6366.22it/s]6661738it [09:44, 6402.72it/s]6662475it [09:44, 6685.70it/s]6663145it [09:44, 6606.30it/s]6663807it [09:44, 6506.67it/s]6664478it [09:45, 6560.68it/s]6665146it [09:45, 6594.94it/s]6665867it [09:45, 6771.62it/s]6666559it [09:45, 6812.69it/s]6667283it [09:45, 6939.38it/s]6668026it [09:45, 7083.09it/s]6668761it [09:45, 7160.01it/s]6669478it [09:45, 7040.09it/s]6670183it [09:45, 7004.87it/s]6670884it [09:45, 6922.72it/s]6671577it [09:46, 6726.67it/s]6672251it [09:46, 6393.77it/s]6672894it [09:46, 6260.48it/s]6673523it [09:46, 6262.70it/s]6674227it [09:46, 6485.81it/s]6674924it [09:46, 6624.43it/s]6675620it [09:46, 6722.42it/s]6676294it [09:46, 6614.26it/s]6676957it [09:46, 6583.10it/s]6677635it [09:47, 6630.95it/s]6678299it [09:47, 6480.96it/s]6678949it [09:47, 6454.17it/s]6679596it [09:47, 6398.93it/s]6680237it [09:47, 6375.23it/s]6680896it [09:47, 6435.26it/s]6681557it [09:47, 6483.66it/s]6682237it [09:47, 6576.64it/s]6682895it [09:47, 6417.40it/s]6683538it [09:47, 6219.45it/s]6684202it [09:48, 6340.63it/s]6684899it [09:48, 6519.13it/s]6685594it [09:48, 6644.39it/s]6686260it [09:48, 6579.01it/s]6686957it [09:48, 6690.15it/s]6687649it [09:48, 6749.85it/s]6688325it [09:48, 6524.17it/s]6688980it [09:48, 6355.33it/s]6689618it [09:48, 6342.08it/s]6690263it [09:49, 6371.82it/s]6690999it [09:49, 6654.46it/s]6691703it [09:49, 6767.88it/s]6692387it [09:49, 6785.46it/s]6693137it [09:49, 6993.66it/s]6693838it [09:49, 6867.70it/s]6694526it [09:49, 6804.18it/s]6695208it [09:49, 6674.05it/s]6695890it [09:49, 6716.18it/s]6696563it [09:49, 6570.50it/s]6697222it [09:50, 6441.83it/s]6697868it [09:50, 6385.02it/s]6698548it [09:50, 6502.64it/s]6699200it [09:50, 6429.22it/s]6699846it [09:50, 6436.90it/s]6700491it [09:50, 6338.14it/s]6701136it [09:50, 6363.98it/s]6701780it [09:50, 6384.44it/s]6702438it [09:50, 6442.32it/s]6703083it [09:50, 6437.59it/s]6703727it [09:51, 6301.15it/s]6704358it [09:51, 6201.83it/s]6704983it [09:51, 6207.82it/s]6705605it [09:51, 6206.86it/s]6706249it [09:51, 6271.68it/s]6706877it [09:51, 6207.35it/s]6707516it [09:51, 6257.43it/s]6708167it [09:51, 6329.75it/s]6708801it [09:51, 6223.75it/s]6709424it [09:51, 6101.14it/s]6710035it [09:52, 6056.73it/s]6710676it [09:52, 6151.95it/s]6711325it [09:52, 6249.23it/s]6711964it [09:52, 6279.98it/s]6712684it [09:52, 6551.15it/s]6713394it [09:52, 6706.24it/s]6714081it [09:52, 6745.91it/s]6714756it [09:52, 6517.35it/s]6715414it [09:52, 6527.89it/s]6716070it [09:52, 6533.24it/s]6716731it [09:53, 6543.89it/s]6717387it [09:53, 6464.09it/s]6718036it [09:53, 6466.16it/s]6718684it [09:53, 6414.58it/s]6719326it [09:53, 6353.03it/s]6720003it [09:53, 6473.88it/s]6720652it [09:53, 6476.38it/s]6721334it [09:53, 6576.96it/s]6721996it [09:53, 6584.10it/s]6722704it [09:54, 6730.87it/s]6723378it [09:54, 6611.82it/s]6724109it [09:54, 6815.17it/s]6724792it [09:54, 6504.67it/s]6725446it [09:54, 5745.70it/s]6726038it [09:54, 5363.18it/s]6726589it [09:54, 5104.47it/s]6727110it [09:54, 5014.21it/s]6727618it [09:54, 4979.31it/s]6728121it [09:55, 4877.54it/s]6728617it [09:55, 4894.25it/s]6729109it [09:55, 4757.89it/s]6729587it [09:55, 4692.33it/s]6730089it [09:55, 4781.26it/s]6730608it [09:55, 4898.50it/s]6731100it [09:55, 4802.18it/s]6731582it [09:55, 4788.53it/s]6732062it [09:55, 4646.97it/s]6732528it [09:55, 4587.92it/s]6733000it [09:56, 4619.91it/s]6733463it [09:56, 4509.81it/s]6733923it [09:56, 4535.24it/s]6734378it [09:56, 4495.95it/s]6734829it [09:56, 4397.22it/s]6735270it [09:56, 4338.74it/s]6735705it [09:56, 4324.14it/s]6736141it [09:56, 4334.50it/s]6736575it [09:56, 4255.20it/s]6737008it [09:57, 4268.75it/s]6737439it [09:57, 4280.51it/s]6737869it [09:57, 4281.19it/s]6738298it [09:57, 4268.20it/s]6738788it [09:57, 4453.07it/s]6739236it [09:57, 4459.61it/s]6739683it [09:57, 4394.62it/s]6740146it [09:57, 4459.93it/s]6740617it [09:57, 4531.00it/s]6741081it [09:57, 4562.89it/s]6741538it [09:58, 4514.38it/s]6741990it [09:58, 4487.94it/s]6742449it [09:58, 4511.53it/s]6742909it [09:58, 4533.21it/s]6743400it [09:58, 4644.87it/s]6743865it [09:58, 4628.89it/s]6744398it [09:58, 4833.92it/s]6744894it [09:58, 4870.33it/s]6745382it [09:58, 4819.03it/s]6745865it [09:58, 4817.74it/s]6746347it [09:59, 4692.81it/s]6746830it [09:59, 4732.57it/s]6747308it [09:59, 4741.98it/s]6747783it [09:59, 4633.63it/s]6748284it [09:59, 4740.48it/s]6748759it [09:59, 4708.13it/s]6749231it [09:59, 4641.09it/s]6749707it [09:59, 4674.90it/s]6750204it [09:59, 4760.63it/s]6750683it [09:59, 4766.53it/s]6751160it [10:00, 4711.24it/s]6751649it [10:00, 4763.10it/s]6752126it [10:00, 4721.19it/s]6752599it [10:00, 4640.52it/s]6753064it [10:00, 4527.65it/s]6753518it [10:00, 4498.45it/s]6753969it [10:00, 4439.93it/s]6754432it [10:00, 4490.28it/s]6754899it [10:00, 4537.18it/s]6755371it [10:01, 4590.72it/s]6755831it [10:01, 4384.64it/s]6756272it [10:01, 4330.14it/s]6756748it [10:01, 4452.98it/s]6757219it [10:01, 4521.41it/s]6757673it [10:01, 4499.66it/s]6758125it [10:01, 4504.14it/s]6758576it [10:01, 4488.65it/s]6759075it [10:01, 4631.51it/s]6759606it [10:01, 4832.50it/s]6760090it [10:02, 4805.50it/s]6760571it [10:02, 4701.07it/s]6761053it [10:02, 4728.79it/s]6761565it [10:02, 4842.73it/s]6762050it [10:02, 4667.22it/s]6762519it [10:02, 4595.18it/s]6763036it [10:02, 4757.70it/s]6763566it [10:02, 4915.92it/s]6764059it [10:02, 4894.34it/s]6764550it [10:02, 4710.21it/s]6765023it [10:03, 4633.10it/s]6765488it [10:03, 4498.75it/s]6765965it [10:03, 4575.16it/s]6766469it [10:03, 4708.28it/s]6766942it [10:03, 4709.87it/s]6767414it [10:03, 4687.00it/s]6767924it [10:03, 4802.72it/s]6768423it [10:03, 4855.44it/s]6768910it [10:03, 4820.22it/s]6769393it [10:04, 4715.79it/s]6769903it [10:04, 4825.22it/s]6770406it [10:04, 4883.81it/s]6770895it [10:04, 4710.57it/s]6771368it [10:04, 4600.90it/s]6771830it [10:04, 4576.61it/s]6772332it [10:04, 4704.81it/s]6772804it [10:04, 4686.98it/s]6773274it [10:04, 4634.45it/s]6773738it [10:04, 4575.46it/s]6774196it [10:05, 4540.15it/s]6774651it [10:05, 4537.52it/s]6775105it [10:05, 4453.03it/s]6775551it [10:05, 4414.13it/s]6776003it [10:05, 4439.25it/s]6776448it [10:05, 4353.17it/s]6776884it [10:05, 4328.21it/s]6777383it [10:05, 4518.94it/s]6777836it [10:05, 4515.05it/s]6778288it [10:05, 4509.34it/s]6778740it [10:06, 4469.24it/s]6779219it [10:06, 4563.03it/s]6779686it [10:06, 4591.21it/s]6780146it [10:06, 4547.35it/s]6780601it [10:06, 4521.80it/s]6781054it [10:06, 4505.56it/s]6781508it [10:06, 4510.73it/s]6781960it [10:06, 4485.60it/s]6782409it [10:06, 4433.06it/s]6782853it [10:06, 4413.71it/s]6783302it [10:07, 4433.89it/s]6783746it [10:07, 4397.88it/s]6784186it [10:07, 4299.09it/s]6784639it [10:07, 4363.57it/s]6785153it [10:07, 4584.35it/s]6785613it [10:07, 4485.17it/s]6786094it [10:07, 4577.08it/s]6786553it [10:07, 4311.69it/s]6786988it [10:07, 4067.38it/s]6787460it [10:08, 4245.52it/s]6787890it [10:08, 3703.75it/s]6788275it [10:08, 3405.94it/s]6788628it [10:08, 3015.24it/s]6789121it [10:08, 3475.19it/s]6789560it [10:08, 3705.37it/s]6790006it [10:08, 3902.40it/s]6790442it [10:08, 4023.64it/s]6790928it [10:08, 4252.21it/s]6791385it [10:09, 4342.62it/s]6791827it [10:09, 4279.88it/s]6792261it [10:09, 4243.26it/s]6792689it [10:09, 4245.57it/s]6793119it [10:09, 4258.79it/s]6793568it [10:09, 4321.46it/s]6794014it [10:09, 4358.32it/s]6794485it [10:09, 4459.67it/s]6794976it [10:09, 4588.73it/s]6795436it [10:10, 2125.04it/s]6795786it [10:10, 1366.38it/s]6796051it [10:11, 1226.57it/s]6796263it [10:11, 1283.25it/s]6796459it [10:11, 1176.53it/s]6796623it [10:11, 859.05it/s] 6796750it [10:12, 650.19it/s]6796915it [10:12, 765.07it/s]6797082it [10:12, 819.98it/s]6797247it [10:12, 949.20it/s]6797376it [10:12, 942.49it/s]6797602it [10:13, 1180.74it/s]6797747it [10:13, 805.23it/s] 6797861it [10:13, 652.24it/s]6798145it [10:13, 959.42it/s]6798281it [10:14, 609.81it/s]6798385it [10:14, 593.16it/s]6798474it [10:14, 576.13it/s]6798552it [10:14, 549.80it/s]6798621it [10:14, 552.29it/s]6798686it [10:15, 491.94it/s]6798742it [10:15, 477.57it/s]6798811it [10:15, 520.15it/s]6798868it [10:15, 406.12it/s]6798941it [10:15, 449.53it/s]6799010it [10:15, 488.48it/s]6799065it [10:15, 437.50it/s]6799113it [10:16, 392.76it/s]6799156it [10:16, 339.40it/s]6799229it [10:16, 411.19it/s]6799351it [10:16, 572.61it/s]6799439it [10:16, 629.02it/s]6799508it [10:16, 481.83it/s]6799565it [10:17, 477.20it/s]6799991it [10:17, 1316.06it/s]6800443it [10:17, 2085.56it/s]6800891it [10:17, 2694.77it/s]6801388it [10:17, 3299.90it/s]6801862it [10:17, 3695.62it/s]6802324it [10:17, 3952.42it/s]6802772it [10:17, 4100.57it/s]6803222it [10:17, 4213.21it/s]6803688it [10:17, 4341.75it/s]6804149it [10:18, 4417.43it/s]6804597it [10:18, 4411.92it/s]6805076it [10:18, 4518.75it/s]6805531it [10:18, 4494.20it/s]6806018it [10:18, 4605.30it/s]6806503it [10:18, 4675.39it/s]6806979it [10:18, 4694.56it/s]6807450it [10:18, 4626.47it/s]6807946it [10:18, 4720.81it/s]6808436it [10:18, 4768.20it/s]6808914it [10:19, 4586.95it/s]6809375it [10:19, 4448.27it/s]6809822it [10:19, 4441.72it/s]6810293it [10:19, 4515.95it/s]6810746it [10:19, 4489.79it/s]6811235it [10:19, 4603.81it/s]6811697it [10:19, 4452.56it/s]6812201it [10:19, 4622.09it/s]6812665it [10:19, 4537.85it/s]6813121it [10:19, 4471.43it/s]6813614it [10:20, 4597.99it/s]6814077it [10:20, 4595.71it/s]6814538it [10:20, 4598.76it/s]6814999it [10:20, 4540.07it/s]6815454it [10:20, 4440.01it/s]6815899it [10:20, 4425.39it/s]6816344it [10:20, 4432.43it/s]6816812it [10:20, 4501.78it/s]6817263it [10:20, 4490.74it/s]6817713it [10:21, 4490.61it/s]6818163it [10:21, 4452.82it/s]6819047it [10:21, 5751.87it/s]6820087it [10:21, 7134.19it/s]6821215it [10:21, 8369.44it/s]6822238it [10:21, 8922.18it/s]6823323it [10:21, 9489.72it/s]6824280it [10:21, 9505.42it/s]6825387it [10:21, 9965.13it/s]6826406it [10:21, 10031.11it/s]6827528it [10:22, 10380.15it/s]6828567it [10:22, 10210.21it/s]6829589it [10:22, 10151.78it/s]6830748it [10:22, 10573.28it/s]6831979it [10:22, 11086.65it/s]6833187it [10:22, 11375.42it/s]6834364it [10:22, 11488.85it/s]6835586it [10:22, 11707.21it/s]6836758it [10:22, 11266.23it/s]6837901it [10:22, 11313.48it/s]6839036it [10:23, 11059.42it/s]6840145it [10:23, 11032.64it/s]6841302it [10:23, 11189.33it/s]6842423it [10:23, 11036.74it/s]6843529it [10:23, 10576.47it/s]6844591it [10:23, 10457.60it/s]6845640it [10:23, 10459.67it/s]6846688it [10:23, 10245.11it/s]6847715it [10:23, 10204.97it/s]6848737it [10:23, 9800.30it/s] 6849833it [10:24, 10126.55it/s]6850945it [10:24, 10413.29it/s]6852366it [10:24, 11521.60it/s]6853815it [10:24, 12385.89it/s]6855059it [10:24, 12338.67it/s]6856297it [10:24, 11741.42it/s]6857480it [10:24, 11368.65it/s]6858624it [10:24, 11314.76it/s]6859761it [10:24, 11162.25it/s]6860881it [10:25, 10613.92it/s]6861949it [10:25, 10060.38it/s]6862963it [10:25, 9647.93it/s] 6863935it [10:25, 9220.07it/s]6864898it [10:25, 9330.52it/s]6865836it [10:25, 9177.85it/s]6866862it [10:25, 9478.95it/s]6867814it [10:25, 9409.17it/s]6868758it [10:25, 9357.16it/s]6869696it [10:26, 9055.97it/s]6870630it [10:26, 9136.76it/s]6871546it [10:26, 8986.31it/s]6872447it [10:26, 8891.80it/s]6873338it [10:26, 8743.77it/s]6874214it [10:26, 8696.67it/s]6875085it [10:26, 8651.34it/s]6875951it [10:26, 8333.97it/s]6876787it [10:26, 7998.43it/s]6877591it [10:26, 7948.52it/s]6878393it [10:27, 7968.77it/s]6879289it [10:27, 8250.94it/s]6880117it [10:27, 8186.61it/s]6880938it [10:27, 8093.79it/s]6881749it [10:27, 8095.74it/s]6882560it [10:27, 8005.25it/s]6883362it [10:27, 7844.57it/s]6884208it [10:27, 8015.69it/s]6885011it [10:27, 7885.93it/s]6885852it [10:28, 8037.58it/s]6886657it [10:28, 7739.29it/s]6887434it [10:28, 7417.32it/s]6888180it [10:28, 7131.63it/s]6888897it [10:28, 6950.18it/s]6889617it [10:28, 7019.93it/s]6890322it [10:28, 6934.35it/s]6891017it [10:28, 6915.94it/s]6891749it [10:28, 7020.28it/s]6892534it [10:28, 7258.13it/s]6893999it [10:29, 9430.96it/s]6895610it [10:29, 11382.97it/s]6897082it [10:29, 12373.23it/s]6898463it [10:29, 12800.53it/s]6899790it [10:29, 12928.40it/s]6901437it [10:29, 13958.20it/s]6903291it [10:29, 15322.86it/s]6905246it [10:29, 16566.26it/s]6907303it [10:29, 17763.24it/s]6909259it [10:29, 18293.70it/s]6911420it [10:30, 19286.36it/s]6913458it [10:30, 19613.30it/s]6915585it [10:30, 20100.67it/s]6917771it [10:30, 20615.77it/s]6919833it [10:30, 19294.78it/s]6921780it [10:30, 16234.06it/s]6923493it [10:30, 15770.40it/s]6925250it [10:30, 16235.40it/s]6927165it [10:30, 17021.25it/s]6929322it [10:31, 18277.75it/s]6931534it [10:31, 19363.59it/s]6933615it [10:31, 19774.96it/s]6935618it [10:31, 19450.64it/s]6937582it [10:31, 18065.65it/s]6939419it [10:31, 14463.54it/s]6940992it [10:31, 13284.51it/s]6942416it [10:31, 12069.65it/s]6943696it [10:32, 11653.57it/s]6944908it [10:32, 11592.39it/s]6946099it [10:32, 11434.69it/s]6947273it [10:32, 11513.99it/s]6948440it [10:32, 11499.22it/s]6949647it [10:32, 11645.84it/s]6950879it [10:32, 11837.16it/s]6952070it [10:32, 11528.12it/s]6953229it [10:32, 11173.20it/s]6954360it [10:33, 11211.39it/s]6955485it [10:33, 11057.67it/s]6956594it [10:33, 10918.37it/s]6957688it [10:33, 10656.41it/s]6958800it [10:33, 10788.73it/s]6959881it [10:33, 10731.70it/s]6960956it [10:33, 10415.92it/s]6962087it [10:33, 10673.61it/s]6963183it [10:33, 10749.75it/s]6964260it [10:33, 10592.89it/s]6965321it [10:34, 10323.13it/s]6966356it [10:34, 10094.30it/s]6967388it [10:34, 10151.84it/s]6968405it [10:34, 10125.68it/s]6969440it [10:34, 10185.47it/s]6970460it [10:34, 10082.65it/s]6971469it [10:34, 9901.51it/s] 6972461it [10:34, 9812.29it/s]6973443it [10:34, 9751.38it/s]6974419it [10:35, 9458.93it/s]6975374it [10:35, 9484.93it/s]6976354it [10:35, 9576.77it/s]6977349it [10:35, 9686.47it/s]6978321it [10:35, 9679.65it/s]6979408it [10:35, 10032.86it/s]6980413it [10:35, 10033.71it/s]6981426it [10:35, 10061.33it/s]6982439it [10:35, 10081.33it/s]6983555it [10:35, 10395.18it/s]6984625it [10:36, 10485.91it/s]6985674it [10:36, 10215.96it/s]6986698it [10:36, 9995.89it/s] 6987747it [10:36, 10138.31it/s]6988763it [10:36, 10012.88it/s]6989772it [10:36, 10034.97it/s]6990812it [10:36, 10140.75it/s]6991827it [10:36, 9921.49it/s] 6992821it [10:36, 9705.18it/s]6993794it [10:36, 9694.04it/s]6994775it [10:37, 9726.91it/s]6995806it [10:37, 9893.09it/s]6996797it [10:37, 9623.46it/s]6997777it [10:37, 9672.26it/s]6998746it [10:37, 9614.91it/s]6999740it [10:37, 9693.83it/s]7000725it [10:37, 9735.73it/s]7001700it [10:37, 9707.75it/s]7002728it [10:37, 9877.70it/s]7003755it [10:37, 9979.07it/s]7004879it [10:38, 10344.38it/s]7006039it [10:38, 10718.78it/s]7007112it [10:38, 10521.07it/s]7008166it [10:38, 10526.10it/s]7009220it [10:38, 10343.44it/s]7010256it [10:38, 10209.04it/s]7011375it [10:38, 10496.28it/s]7012474it [10:38, 10640.49it/s]7013743it [10:38, 11237.05it/s]7014941it [10:39, 11444.05it/s]7016169it [10:39, 11691.61it/s]7017505it [10:39, 12173.42it/s]7018724it [10:39, 11994.73it/s]7019925it [10:39, 11824.52it/s]7021109it [10:39, 11467.90it/s]7022305it [10:39, 11610.09it/s]7023469it [10:39, 11513.63it/s]7024622it [10:39, 10991.72it/s]7025727it [10:39, 10908.37it/s]7026822it [10:40, 10775.06it/s]7027902it [10:40, 10320.56it/s]7028939it [10:40, 10072.77it/s]7029950it [10:40, 9653.83it/s] 7030991it [10:40, 9858.71it/s]7032045it [10:40, 10050.50it/s]7033085it [10:40, 10151.01it/s]7034104it [10:40, 9810.76it/s] 7035090it [10:40, 9670.31it/s]7036064it [10:41, 9686.82it/s]7037035it [10:41, 9527.78it/s]7037990it [10:41, 9357.55it/s]7038958it [10:41, 9439.15it/s]7039932it [10:41, 9518.19it/s]7040885it [10:41, 9515.20it/s]7041838it [10:41, 9311.80it/s]7042784it [10:41, 9343.63it/s]7043977it [10:41, 10098.42it/s]7045246it [10:41, 10864.78it/s]7046959it [10:42, 12718.72it/s]7048662it [10:42, 14002.68it/s]7050461it [10:42, 15191.11it/s]7052289it [10:42, 16114.05it/s]7054222it [10:42, 17070.61it/s]7055976it [10:42, 17211.00it/s]7057777it [10:42, 17449.88it/s]7059525it [10:42, 17441.44it/s]7061270it [10:42, 17086.40it/s]7063010it [10:42, 17157.32it/s]7064728it [10:43, 15938.07it/s]7066340it [10:43, 14888.47it/s]7067852it [10:43, 14175.37it/s]7069288it [10:43, 12670.75it/s]7070590it [10:43, 12012.98it/s]7071815it [10:43, 11291.80it/s]7072962it [10:43, 10413.89it/s]7074020it [10:43, 10045.25it/s]7075061it [10:44, 10134.74it/s]7076149it [10:44, 10333.34it/s]7077283it [10:44, 10610.92it/s]7078352it [10:44, 10579.04it/s]7079612it [10:44, 11158.85it/s]7080735it [10:44, 10978.46it/s]7081838it [10:44, 10981.78it/s]7082940it [10:44, 10989.30it/s]7084056it [10:44, 11033.90it/s]7085179it [10:44, 11091.52it/s]7086344it [10:45, 11250.33it/s]7086503it [10:45, 10985.26it/s]
文件总行数: 7086503
读取数据:   0%|          | 0/7086503 [00:00<?, ?it/s]读取数据:   0%|          | 87/7086503 [00:00<2:15:55, 868.88it/s]读取数据:   0%|          | 458/7086503 [00:00<46:32, 2537.91it/s]读取数据:   0%|          | 903/7086503 [00:00<34:49, 3390.75it/s]读取数据:   0%|          | 1560/7086503 [00:00<25:28, 4635.17it/s]读取数据:   0%|          | 2432/7086503 [00:00<19:22, 6096.02it/s]读取数据:   0%|          | 3199/7086503 [00:00<17:48, 6628.81it/s]读取数据:   0%|          | 4047/7086503 [00:00<16:19, 7229.72it/s]读取数据:   0%|          | 4884/7086503 [00:00<15:33, 7588.76it/s]读取数据:   0%|          | 5742/7086503 [00:00<14:56, 7897.53it/s]读取数据:   0%|          | 6608/7086503 [00:01<14:31, 8119.41it/s]读取数据:   0%|          | 7420/7086503 [00:01<15:23, 7665.67it/s]读取数据:   0%|          | 8261/7086503 [00:01<14:58, 7881.74it/s]读取数据:   0%|          | 9102/7086503 [00:01<14:40, 8033.82it/s]读取数据:   0%|          | 9911/7086503 [00:01<14:39, 8048.14it/s]读取数据:   0%|          | 10764/7086503 [00:01<14:24, 8189.39it/s]读取数据:   0%|          | 11608/7086503 [00:01<14:16, 8258.56it/s]读取数据:   0%|          | 12436/7086503 [00:01<14:23, 8196.66it/s]读取数据:   0%|          | 13259/7086503 [00:01<14:22, 8196.21it/s]读取数据:   0%|          | 14102/7086503 [00:01<14:16, 8258.79it/s]读取数据:   0%|          | 14929/7086503 [00:02<14:18, 8233.60it/s]读取数据:   0%|          | 15753/7086503 [00:02<14:25, 8165.05it/s]读取数据:   0%|          | 16595/7086503 [00:02<14:18, 8239.90it/s]读取数据:   0%|          | 17425/7086503 [00:02<14:16, 8250.31it/s]读取数据:   0%|          | 18260/7086503 [00:02<14:14, 8275.80it/s]读取数据:   0%|          | 19118/7086503 [00:02<14:04, 8365.02it/s]读取数据:   0%|          | 20001/7086503 [00:02<13:51, 8503.56it/s]读取数据:   0%|          | 20852/7086503 [00:02<13:56, 8450.35it/s]读取数据:   0%|          | 21698/7086503 [00:02<14:01, 8397.88it/s]读取数据:   0%|          | 22561/7086503 [00:02<13:54, 8464.11it/s]读取数据:   0%|          | 23408/7086503 [00:03<14:12, 8289.51it/s]读取数据:   0%|          | 24324/7086503 [00:03<13:47, 8534.40it/s]读取数据:   0%|          | 25179/7086503 [00:03<13:46, 8538.88it/s]读取数据:   0%|          | 26050/7086503 [00:03<13:42, 8588.54it/s]读取数据:   0%|          | 26911/7086503 [00:03<13:41, 8588.62it/s]读取数据:   0%|          | 27771/7086503 [00:03<13:51, 8484.80it/s]读取数据:   0%|          | 28620/7086503 [00:03<14:09, 8307.15it/s]读取数据:   0%|          | 29453/7086503 [00:03<14:08, 8312.98it/s]读取数据:   0%|          | 30324/7086503 [00:03<13:57, 8428.46it/s]读取数据:   0%|          | 31168/7086503 [00:03<14:03, 8364.59it/s]读取数据:   0%|          | 32029/7086503 [00:04<13:56, 8436.72it/s]读取数据:   0%|          | 32889/7086503 [00:04<13:51, 8483.38it/s]读取数据:   0%|          | 33738/7086503 [00:04<14:00, 8392.85it/s]读取数据:   0%|          | 34578/7086503 [00:04<14:00, 8387.96it/s]读取数据:   1%|          | 35435/7086503 [00:04<13:55, 8436.48it/s]读取数据:   1%|          | 36279/7086503 [00:04<14:00, 8387.60it/s]读取数据:   1%|          | 37118/7086503 [00:04<14:05, 8341.98it/s]读取数据:   1%|          | 37957/7086503 [00:04<14:04, 8350.50it/s]读取数据:   1%|          | 38793/7086503 [00:04<14:12, 8262.52it/s]读取数据:   1%|          | 39620/7086503 [00:04<14:18, 8210.74it/s]读取数据:   1%|          | 40472/7086503 [00:05<14:09, 8299.13it/s]读取数据:   1%|          | 41321/7086503 [00:05<14:04, 8340.76it/s]读取数据:   1%|          | 42168/7086503 [00:05<14:01, 8373.13it/s]读取数据:   1%|          | 43006/7086503 [00:05<14:11, 8271.08it/s]读取数据:   1%|          | 43834/7086503 [00:05<14:22, 8167.27it/s]读取数据:   1%|          | 44652/7086503 [00:05<14:27, 8117.88it/s]读取数据:   1%|          | 45465/7086503 [00:05<14:31, 8079.15it/s]读取数据:   1%|          | 46274/7086503 [00:05<14:34, 8053.62it/s]读取数据:   1%|          | 47106/7086503 [00:05<14:25, 8132.29it/s]读取数据:   1%|          | 47920/7086503 [00:05<14:31, 8074.73it/s]读取数据:   1%|          | 48779/7086503 [00:06<14:16, 8219.77it/s]读取数据:   1%|          | 49703/7086503 [00:06<13:45, 8523.00it/s]读取数据:   1%|          | 50556/7086503 [00:06<21:49, 5372.78it/s]读取数据:   1%|          | 51240/7086503 [00:06<20:38, 5679.98it/s]读取数据:   1%|          | 52050/7086503 [00:06<18:48, 6234.61it/s]读取数据:   1%|          | 52770/7086503 [00:06<18:16, 6413.81it/s]读取数据:   1%|          | 53641/7086503 [00:06<16:43, 7011.26it/s]读取数据:   1%|          | 54401/7086503 [00:07<29:07, 4023.52it/s]读取数据:   1%|          | 55230/7086503 [00:07<24:29, 4784.43it/s]读取数据:   1%|          | 56059/7086503 [00:07<21:19, 5495.17it/s]读取数据:   1%|          | 56913/7086503 [00:07<18:57, 6178.85it/s]读取数据:   1%|          | 57765/7086503 [00:07<17:21, 6747.78it/s]读取数据:   1%|          | 58585/7086503 [00:07<16:27, 7118.53it/s]读取数据:   1%|          | 59462/7086503 [00:07<15:29, 7562.13it/s]读取数据:   1%|          | 60304/7086503 [00:07<15:00, 7799.11it/s]读取数据:   1%|          | 61130/7086503 [00:08<15:38, 7487.20it/s]读取数据:   1%|          | 61967/7086503 [00:08<15:08, 7730.87it/s]读取数据:   1%|          | 62767/7086503 [00:08<15:44, 7440.11it/s]读取数据:   1%|          | 63610/7086503 [00:08<15:11, 7701.60it/s]读取数据:   1%|          | 64530/7086503 [00:08<14:23, 8127.36it/s]读取数据:   1%|          | 65360/7086503 [00:08<14:19, 8171.33it/s]读取数据:   1%|          | 66188/7086503 [00:08<14:15, 8202.32it/s]读取数据:   1%|          | 67015/7086503 [00:08<14:16, 8200.25it/s]读取数据:   1%|          | 67852/7086503 [00:08<14:11, 8244.65it/s]读取数据:   1%|          | 68691/7086503 [00:09<14:06, 8285.70it/s]读取数据:   1%|          | 69523/7086503 [00:09<14:05, 8294.87it/s]读取数据:   1%|          | 70355/7086503 [00:09<14:18, 8170.50it/s]读取数据:   1%|          | 71174/7086503 [00:09<14:24, 8115.03it/s]读取数据:   1%|          | 72005/7086503 [00:09<14:18, 8171.84it/s]读取数据:   1%|          | 72852/7086503 [00:09<14:09, 8257.98it/s]读取数据:   1%|          | 73679/7086503 [00:09<14:15, 8201.16it/s]读取数据:   1%|          | 74500/7086503 [00:09<14:24, 8113.55it/s]读取数据:   1%|          | 75312/7086503 [00:09<14:31, 8042.66it/s]读取数据:   1%|          | 76117/7086503 [00:09<14:42, 7946.33it/s]读取数据:   1%|          | 76913/7086503 [00:10<14:45, 7918.00it/s]读取数据:   1%|          | 77722/7086503 [00:10<14:39, 7967.95it/s]读取数据:   1%|          | 78520/7086503 [00:10<15:07, 7726.39it/s]读取数据:   1%|          | 79295/7086503 [00:10<15:07, 7723.84it/s]读取数据:   1%|          | 80236/7086503 [00:10<14:12, 8217.95it/s]读取数据:   1%|          | 81162/7086503 [00:10<13:41, 8523.87it/s]读取数据:   1%|          | 82103/7086503 [00:10<13:17, 8786.27it/s]读取数据:   1%|          | 83041/7086503 [00:10<13:01, 8961.26it/s]读取数据:   1%|          | 83939/7086503 [00:10<13:16, 8792.47it/s]读取数据:   1%|          | 84868/7086503 [00:10<13:03, 8937.97it/s]读取数据:   1%|          | 85764/7086503 [00:11<13:06, 8900.16it/s]读取数据:   1%|          | 86685/7086503 [00:11<12:58, 8989.26it/s]读取数据:   1%|          | 87585/7086503 [00:11<12:59, 8975.34it/s]读取数据:   1%|          | 88484/7086503 [00:11<13:03, 8930.96it/s]读取数据:   1%|▏         | 89378/7086503 [00:11<13:07, 8889.30it/s]读取数据:   1%|▏         | 90327/7086503 [00:11<12:51, 9065.13it/s]读取数据:   1%|▏         | 91234/7086503 [00:11<12:57, 8994.72it/s]读取数据:   1%|▏         | 92134/7086503 [00:11<13:02, 8936.80it/s]读取数据:   1%|▏         | 93028/7086503 [00:11<13:13, 8810.99it/s]读取数据:   1%|▏         | 93982/7086503 [00:11<12:55, 9022.16it/s]读取数据:   1%|▏         | 94885/7086503 [00:12<13:10, 8850.01it/s]读取数据:   1%|▏         | 95842/7086503 [00:12<12:51, 9059.86it/s]读取数据:   1%|▏         | 96750/7086503 [00:12<12:53, 9038.00it/s]读取数据:   1%|▏         | 97655/7086503 [00:12<13:08, 8857.90it/s]读取数据:   1%|▏         | 98542/7086503 [00:12<13:10, 8839.20it/s]读取数据:   1%|▏         | 99461/7086503 [00:12<13:01, 8940.69it/s]读取数据:   1%|▏         | 100356/7086503 [00:12<20:49, 5590.78it/s]读取数据:   1%|▏         | 101115/7086503 [00:12<19:22, 6007.71it/s]读取数据:   1%|▏         | 101889/7086503 [00:13<18:10, 6403.81it/s]读取数据:   1%|▏         | 102733/7086503 [00:13<16:51, 6907.01it/s]读取数据:   1%|▏         | 103550/7086503 [00:13<16:05, 7234.68it/s]读取数据:   1%|▏         | 104438/7086503 [00:13<15:09, 7680.33it/s]读取数据:   1%|▏         | 105339/7086503 [00:13<14:27, 8050.97it/s]读取数据:   1%|▏         | 106195/7086503 [00:13<14:12, 8188.97it/s]读取数据:   2%|▏         | 107084/7086503 [00:13<13:51, 8390.83it/s]读取数据:   2%|▏         | 107943/7086503 [00:13<13:48, 8422.43it/s]读取数据:   2%|▏         | 108891/7086503 [00:13<13:19, 8730.34it/s]读取数据:   2%|▏         | 109837/7086503 [00:13<13:00, 8942.33it/s]读取数据:   2%|▏         | 110803/7086503 [00:14<12:42, 9153.99it/s]读取数据:   2%|▏         | 111771/7086503 [00:14<12:29, 9309.78it/s]读取数据:   2%|▏         | 112706/7086503 [00:14<12:39, 9179.21it/s]读取数据:   2%|▏         | 113627/7086503 [00:14<12:57, 8972.67it/s]读取数据:   2%|▏         | 114578/7086503 [00:14<12:43, 9125.90it/s]读取数据:   2%|▏         | 115494/7086503 [00:14<12:51, 9038.86it/s]读取数据:   2%|▏         | 116400/7086503 [00:14<12:55, 8990.95it/s]读取数据:   2%|▏         | 117301/7086503 [00:14<13:09, 8826.97it/s]读取数据:   2%|▏         | 118189/7086503 [00:14<13:08, 8839.63it/s]读取数据:   2%|▏         | 119074/7086503 [00:15<13:10, 8816.80it/s]读取数据:   2%|▏         | 119970/7086503 [00:15<13:06, 8853.97it/s]读取数据:   2%|▏         | 120952/7086503 [00:15<12:42, 9139.77it/s]读取数据:   2%|▏         | 122189/7086503 [00:15<11:29, 10100.65it/s]读取数据:   2%|▏         | 123978/7086503 [00:15<09:20, 12423.65it/s]读取数据:   2%|▏         | 125700/7086503 [00:15<08:22, 13853.11it/s]读取数据:   2%|▏         | 127459/7086503 [00:15<07:44, 14970.68it/s]读取数据:   2%|▏         | 129199/7086503 [00:15<07:23, 15695.95it/s]读取数据:   2%|▏         | 131032/7086503 [00:15<07:01, 16484.79it/s]读取数据:   2%|▏         | 132845/7086503 [00:15<06:49, 16976.74it/s]读取数据:   2%|▏         | 134557/7086503 [00:16<06:48, 17011.98it/s]读取数据:   2%|▏         | 136351/7086503 [00:16<06:42, 17286.70it/s]读取数据:   2%|▏         | 138126/7086503 [00:16<06:38, 17424.41it/s]读取数据:   2%|▏         | 139940/7086503 [00:16<06:33, 17630.92it/s]读取数据:   2%|▏         | 141704/7086503 [00:16<06:46, 17096.09it/s]读取数据:   2%|▏         | 143418/7086503 [00:16<06:46, 17077.19it/s]读取数据:   2%|▏         | 145152/7086503 [00:16<06:44, 17152.81it/s]读取数据:   2%|▏         | 146870/7086503 [00:16<06:47, 17012.41it/s]读取数据:   2%|▏         | 148617/7086503 [00:16<06:44, 17146.76it/s]读取数据:   2%|▏         | 150333/7086503 [00:17<10:21, 11153.53it/s]读取数据:   2%|▏         | 152151/7086503 [00:17<09:07, 12672.14it/s]读取数据:   2%|▏         | 153692/7086503 [00:17<08:40, 13314.83it/s]读取数据:   2%|▏         | 155237/7086503 [00:17<08:20, 13851.76it/s]读取数据:   2%|▏         | 157111/7086503 [00:17<07:37, 15141.23it/s]读取数据:   2%|▏         | 158845/7086503 [00:17<07:20, 15744.10it/s]读取数据:   2%|▏         | 160646/7086503 [00:17<07:02, 16381.97it/s]读取数据:   2%|▏         | 162568/7086503 [00:17<06:42, 17193.79it/s]读取数据:   2%|▏         | 164515/7086503 [00:17<06:27, 17852.79it/s]读取数据:   2%|▏         | 166392/7086503 [00:18<06:21, 18120.38it/s]读取数据:   2%|▏         | 168231/7086503 [00:19<33:33, 3436.57it/s] 读取数据:   2%|▏         | 169554/7086503 [00:21<1:09:00, 1670.51it/s]读取数据:   2%|▏         | 170499/7086503 [00:21<1:00:40, 1899.66it/s]读取数据:   2%|▏         | 171294/7086503 [00:22<53:51, 2139.75it/s]  读取数据:   2%|▏         | 171992/7086503 [00:22<48:23, 2381.52it/s]读取数据:   2%|▏         | 172617/7086503 [00:22<43:58, 2620.16it/s]读取数据:   2%|▏         | 173188/7086503 [00:22<40:13, 2864.84it/s]读取数据:   2%|▏         | 173723/7086503 [00:22<36:30, 3155.74it/s]读取数据:   2%|▏         | 174248/7086503 [00:22<33:43, 3416.51it/s]读取数据:   2%|▏         | 174757/7086503 [00:22<32:23, 3556.07it/s]读取数据:   2%|▏         | 175236/7086503 [00:22<30:53, 3729.58it/s]读取数据:   2%|▏         | 175713/7086503 [00:23<29:09, 3951.22it/s]读取数据:   2%|▏         | 176183/7086503 [00:23<28:01, 4110.82it/s]读取数据:   2%|▏         | 176745/7086503 [00:23<25:40, 4486.68it/s]读取数据:   3%|▎         | 177630/7086503 [00:23<20:26, 5631.54it/s]读取数据:   3%|▎         | 178521/7086503 [00:23<17:38, 6526.51it/s]读取数据:   3%|▎         | 179311/7086503 [00:23<16:40, 6903.12it/s]读取数据:   3%|▎         | 180070/7086503 [00:23<16:13, 7093.26it/s]读取数据:   3%|▎         | 180872/7086503 [00:23<15:38, 7360.96it/s]读取数据:   3%|▎         | 181739/7086503 [00:23<14:52, 7738.72it/s]读取数据:   3%|▎         | 182550/7086503 [00:23<14:41, 7835.12it/s]读取数据:   3%|▎         | 183353/7086503 [00:24<14:34, 7889.34it/s]读取数据:   3%|▎         | 184149/7086503 [00:24<22:55, 5018.17it/s]读取数据:   3%|▎         | 184788/7086503 [00:25<56:26, 2038.14it/s]读取数据:   3%|▎         | 185258/7086503 [00:25<1:14:43, 1539.24it/s]读取数据:   3%|▎         | 185611/7086503 [00:26<1:45:15, 1092.61it/s]读取数据:   3%|▎         | 185873/7086503 [00:26<1:49:56, 1046.03it/s]读取数据:   3%|▎         | 186082/7086503 [00:28<3:53:35, 492.35it/s] 读取数据:   3%|▎         | 186232/7086503 [00:28<3:54:07, 491.22it/s]读取数据:   3%|▎         | 186352/7086503 [00:28<3:37:18, 529.21it/s]读取数据:   3%|▎         | 186467/7086503 [00:29<3:27:59, 552.90it/s]读取数据:   3%|▎         | 186614/7086503 [00:29<2:58:56, 642.67it/s]读取数据:   3%|▎         | 186730/7086503 [00:29<2:44:52, 697.45it/s]读取数据:   3%|▎         | 186843/7086503 [00:29<2:51:08, 671.93it/s]读取数据:   3%|▎         | 186940/7086503 [00:29<3:09:28, 606.92it/s]读取数据:   3%|▎         | 187049/7086503 [00:29<2:48:10, 683.78it/s]读取数据:   3%|▎         | 187139/7086503 [00:30<4:44:14, 404.56it/s]读取数据:   3%|▎         | 187285/7086503 [00:30<3:37:46, 528.01it/s]读取数据:   3%|▎         | 187370/7086503 [00:30<3:21:05, 571.83it/s]读取数据:   3%|▎         | 187457/7086503 [00:30<3:06:32, 616.40it/s]读取数据:   3%|▎         | 187540/7086503 [00:30<3:20:53, 572.37it/s]读取数据:   3%|▎         | 187612/7086503 [00:31<5:01:54, 380.84it/s]读取数据:   3%|▎         | 187774/7086503 [00:31<3:21:55, 569.40it/s]读取数据:   3%|▎         | 187862/7086503 [00:31<3:12:42, 596.63it/s]读取数据:   3%|▎         | 187945/7086503 [00:31<3:31:06, 544.61it/s]读取数据:   3%|▎         | 188065/7086503 [00:31<2:51:41, 669.66it/s]读取数据:   3%|▎         | 188151/7086503 [00:31<3:31:12, 544.37it/s]读取数据:   3%|▎         | 188236/7086503 [00:32<3:49:14, 501.52it/s]读取数据:   3%|▎         | 188330/7086503 [00:32<3:19:41, 575.74it/s]读取数据:   3%|▎         | 188459/7086503 [00:32<2:40:42, 715.35it/s]读取数据:   3%|▎         | 188545/7086503 [00:32<2:40:13, 717.50it/s]读取数据:   3%|▎         | 188627/7086503 [00:32<4:11:59, 456.23it/s]读取数据:   3%|▎         | 188691/7086503 [00:33<7:55:46, 241.64it/s]读取数据:   3%|▎         | 188814/7086503 [00:33<5:29:37, 348.77it/s]读取数据:   3%|▎         | 188913/7086503 [00:33<4:24:46, 434.18it/s]读取数据:   3%|▎         | 188992/7086503 [00:34<6:12:48, 308.36it/s]读取数据:   3%|▎         | 190203/7086503 [00:34<1:04:03, 1794.08it/s]读取数据:   3%|▎         | 191477/7086503 [00:34<33:11, 3462.55it/s]  读取数据:   3%|▎         | 192143/7086503 [00:34<29:37, 3878.23it/s]读取数据:   3%|▎         | 192773/7086503 [00:34<27:30, 4177.70it/s]读取数据:   3%|▎         | 194141/7086503 [00:34<18:31, 6198.47it/s]读取数据:   3%|▎         | 195455/7086503 [00:34<14:41, 7814.96it/s]读取数据:   3%|▎         | 196675/7086503 [00:34<12:53, 8908.67it/s]读取数据:   3%|▎         | 198055/7086503 [00:35<11:15, 10194.61it/s]读取数据:   3%|▎         | 199202/7086503 [00:35<11:46, 9754.12it/s] 读取数据:   3%|▎         | 200271/7086503 [00:35<17:49, 6440.48it/s]读取数据:   3%|▎         | 201724/7086503 [00:35<14:17, 8026.45it/s]读取数据:   3%|▎         | 203162/7086503 [00:35<12:11, 9415.59it/s]读取数据:   3%|▎         | 204417/7086503 [00:35<11:17, 10161.39it/s]读取数据:   3%|▎         | 205774/7086503 [00:35<10:24, 11025.17it/s]读取数据:   3%|▎         | 207158/7086503 [00:35<09:44, 11772.52it/s]读取数据:   3%|▎         | 208536/7086503 [00:36<09:18, 12321.44it/s]读取数据:   3%|▎         | 210026/7086503 [00:36<08:47, 13047.56it/s]读取数据:   3%|▎         | 211457/7086503 [00:36<08:32, 13410.09it/s]读取数据:   3%|▎         | 212841/7086503 [00:36<08:34, 13348.74it/s]读取数据:   3%|▎         | 214206/7086503 [00:36<08:37, 13281.18it/s]读取数据:   3%|▎         | 215555/7086503 [00:36<08:51, 12936.47it/s]读取数据:   3%|▎         | 216873/7086503 [00:36<08:48, 13005.85it/s]读取数据:   3%|▎         | 218261/7086503 [00:36<08:38, 13256.90it/s]读取数据:   3%|▎         | 219784/7086503 [00:36<08:16, 13834.59it/s]读取数据:   3%|▎         | 221285/7086503 [00:37<08:04, 14172.90it/s]读取数据:   3%|▎         | 222708/7086503 [00:37<08:12, 13941.61it/s]读取数据:   3%|▎         | 224145/7086503 [00:37<08:07, 14065.42it/s]读取数据:   3%|▎         | 225556/7086503 [00:37<08:25, 13566.44it/s]读取数据:   3%|▎         | 226919/7086503 [00:37<08:38, 13220.53it/s]读取数据:   3%|▎         | 228254/7086503 [00:37<08:37, 13256.12it/s]读取数据:   3%|▎         | 229584/7086503 [00:37<08:53, 12851.87it/s]读取数据:   3%|▎         | 230874/7086503 [00:37<09:03, 12621.67it/s]读取数据:   3%|▎         | 232140/7086503 [00:37<09:10, 12452.78it/s]读取数据:   3%|▎         | 233434/7086503 [00:37<09:04, 12590.32it/s]读取数据:   3%|▎         | 234734/7086503 [00:38<08:59, 12709.51it/s]读取数据:   3%|▎         | 236094/7086503 [00:38<08:48, 12968.65it/s]读取数据:   3%|▎         | 237410/7086503 [00:38<08:46, 13018.85it/s]读取数据:   3%|▎         | 238714/7086503 [00:38<09:06, 12529.99it/s]读取数据:   3%|▎         | 239972/7086503 [00:38<09:18, 12259.82it/s]读取数据:   3%|▎         | 241219/7086503 [00:38<09:15, 12319.46it/s]读取数据:   3%|▎         | 242454/7086503 [00:38<09:17, 12269.80it/s]读取数据:   3%|▎         | 243709/7086503 [00:38<09:14, 12349.29it/s]读取数据:   3%|▎         | 244946/7086503 [00:38<09:16, 12292.87it/s]读取数据:   3%|▎         | 246225/7086503 [00:38<09:10, 12436.85it/s]读取数据:   3%|▎         | 247470/7086503 [00:39<09:15, 12318.24it/s]读取数据:   4%|▎         | 248703/7086503 [00:39<09:24, 12115.50it/s]读取数据:   4%|▎         | 249916/7086503 [00:39<09:27, 12040.34it/s]读取数据:   4%|▎         | 251121/7086503 [00:39<14:29, 7861.45it/s] 读取数据:   4%|▎         | 252396/7086503 [00:39<12:47, 8905.89it/s]读取数据:   4%|▎         | 253563/7086503 [00:39<11:55, 9554.28it/s]读取数据:   4%|▎         | 254752/7086503 [00:39<11:13, 10140.99it/s]读取数据:   4%|▎         | 255874/7086503 [00:39<11:17, 10080.75it/s]读取数据:   4%|▎         | 257139/7086503 [00:40<10:34, 10767.02it/s]读取数据:   4%|▎         | 258457/7086503 [00:40<09:57, 11431.72it/s]读取数据:   4%|▎         | 259711/7086503 [00:40<09:41, 11743.28it/s]读取数据:   4%|▎         | 260922/7086503 [00:40<09:42, 11721.20it/s]读取数据:   4%|▎         | 262147/7086503 [00:40<09:34, 11871.51it/s]读取数据:   4%|▎         | 263353/7086503 [00:40<09:42, 11717.89it/s]读取数据:   4%|▎         | 264538/7086503 [00:40<09:44, 11677.22it/s]读取数据:   4%|▎         | 265734/7086503 [00:40<09:40, 11759.59it/s]读取数据:   4%|▍         | 266917/7086503 [00:40<09:45, 11639.03it/s]读取数据:   4%|▍         | 268086/7086503 [00:41<09:50, 11539.08it/s]读取数据:   4%|▍         | 269251/7086503 [00:41<09:49, 11569.81it/s]读取数据:   4%|▍         | 270447/7086503 [00:41<09:43, 11682.91it/s]读取数据:   4%|▍         | 271646/7086503 [00:41<09:38, 11770.56it/s]读取数据:   4%|▍         | 272860/7086503 [00:41<09:33, 11878.83it/s]读取数据:   4%|▍         | 274049/7086503 [00:41<09:37, 11793.04it/s]读取数据:   4%|▍         | 275245/7086503 [00:41<09:35, 11841.90it/s]读取数据:   4%|▍         | 276506/7086503 [00:41<09:24, 12070.02it/s]读取数据:   4%|▍         | 277736/7086503 [00:41<09:20, 12138.04it/s]读取数据:   4%|▍         | 278951/7086503 [00:41<09:21, 12113.79it/s]读取数据:   4%|▍         | 280163/7086503 [00:42<09:27, 11995.85it/s]读取数据:   4%|▍         | 281364/7086503 [00:42<09:32, 11879.21it/s]读取数据:   4%|▍         | 282553/7086503 [00:42<09:49, 11537.59it/s]读取数据:   4%|▍         | 283709/7086503 [00:42<10:22, 10933.11it/s]读取数据:   4%|▍         | 284877/7086503 [00:42<10:10, 11143.32it/s]读取数据:   4%|▍         | 286118/7086503 [00:42<09:50, 11506.95it/s]读取数据:   4%|▍         | 287275/7086503 [00:42<10:29, 10795.13it/s]读取数据:   4%|▍         | 288418/7086503 [00:42<10:19, 10971.93it/s]读取数据:   4%|▍         | 289596/7086503 [00:42<10:06, 11197.88it/s]读取数据:   4%|▍         | 290724/7086503 [00:42<10:09, 11144.78it/s]读取数据:   4%|▍         | 291978/7086503 [00:43<09:48, 11550.52it/s]读取数据:   4%|▍         | 293325/7086503 [00:43<09:20, 12114.49it/s]读取数据:   4%|▍         | 294638/7086503 [00:43<09:07, 12414.71it/s]读取数据:   4%|▍         | 295931/7086503 [00:43<09:00, 12566.65it/s]读取数据:   4%|▍         | 297191/7086503 [00:43<09:06, 12430.97it/s]读取数据:   4%|▍         | 298437/7086503 [00:43<09:07, 12409.21it/s]读取数据:   4%|▍         | 299680/7086503 [00:43<09:13, 12268.00it/s]读取数据:   4%|▍         | 300909/7086503 [00:43<14:32, 7776.23it/s] 读取数据:   4%|▍         | 302164/7086503 [00:44<12:52, 8780.60it/s]读取数据:   4%|▍         | 303509/7086503 [00:44<11:27, 9860.58it/s]读取数据:   4%|▍         | 304778/7086503 [00:44<10:42, 10562.52it/s]读取数据:   4%|▍         | 305963/7086503 [00:44<10:38, 10622.59it/s]读取数据:   4%|▍         | 307116/7086503 [00:44<10:46, 10482.65it/s]读取数据:   4%|▍         | 308242/7086503 [00:44<10:34, 10686.59it/s]读取数据:   4%|▍         | 309484/7086503 [00:44<10:06, 11167.29it/s]读取数据:   4%|▍         | 310749/7086503 [00:44<09:44, 11586.55it/s]读取数据:   4%|▍         | 311936/7086503 [00:44<09:41, 11659.16it/s]读取数据:   4%|▍         | 313193/7086503 [00:45<09:28, 11924.34it/s]读取数据:   4%|▍         | 314400/7086503 [00:45<10:01, 11264.69it/s]读取数据:   4%|▍         | 315629/7086503 [00:45<09:46, 11553.80it/s]读取数据:   4%|▍         | 316823/7086503 [00:45<09:40, 11662.84it/s]读取数据:   4%|▍         | 318036/7086503 [00:45<09:33, 11797.92it/s]读取数据:   5%|▍         | 319269/7086503 [00:45<09:26, 11953.61it/s]读取数据:   5%|▍         | 320548/7086503 [00:45<09:14, 12199.59it/s]读取数据:   5%|▍         | 321773/7086503 [00:45<09:21, 12039.06it/s]读取数据:   5%|▍         | 322981/7086503 [00:45<10:21, 10891.00it/s]读取数据:   5%|▍         | 324312/7086503 [00:45<09:45, 11557.90it/s]读取数据:   5%|▍         | 325575/7086503 [00:46<09:30, 11857.14it/s]读取数据:   5%|▍         | 326838/7086503 [00:46<09:19, 12076.27it/s]读取数据:   5%|▍         | 328059/7086503 [00:46<09:35, 11738.29it/s]读取数据:   5%|▍         | 329357/7086503 [00:46<09:18, 12093.48it/s]读取数据:   5%|▍         | 330783/7086503 [00:46<08:51, 12709.29it/s]读取数据:   5%|▍         | 332120/7086503 [00:46<08:43, 12902.35it/s]读取数据:   5%|▍         | 333519/7086503 [00:46<08:30, 13216.93it/s]读取数据:   5%|▍         | 334976/7086503 [00:46<08:15, 13616.37it/s]读取数据:   5%|▍         | 336342/7086503 [00:46<09:44, 11551.62it/s]读取数据:   5%|▍         | 337554/7086503 [00:47<11:41, 9626.43it/s] 读取数据:   5%|▍         | 338603/7086503 [00:47<11:32, 9748.52it/s]读取数据:   5%|▍         | 339641/7086503 [00:47<11:33, 9726.83it/s]读取数据:   5%|▍         | 340658/7086503 [00:47<12:01, 9344.34it/s]读取数据:   5%|▍         | 341623/7086503 [00:47<16:20, 6878.82it/s]读取数据:   5%|▍         | 342419/7086503 [00:47<19:46, 5682.84it/s]读取数据:   5%|▍         | 343086/7086503 [00:48<21:39, 5187.49it/s]读取数据:   5%|▍         | 343672/7086503 [00:48<22:44, 4941.30it/s]读取数据:   5%|▍         | 344209/7086503 [00:48<23:42, 4738.44it/s]读取数据:   5%|▍         | 344710/7086503 [00:48<24:31, 4580.55it/s]读取数据:   5%|▍         | 345184/7086503 [00:48<25:10, 4463.21it/s]读取数据:   5%|▍         | 345640/7086503 [00:48<25:46, 4358.74it/s]读取数据:   5%|▍         | 346081/7086503 [00:48<26:21, 4263.13it/s]读取数据:   5%|▍         | 346510/7086503 [00:48<27:00, 4159.44it/s]读取数据:   5%|▍         | 346927/7086503 [00:49<28:34, 3931.30it/s]读取数据:   5%|▍         | 347407/7086503 [00:49<27:02, 4154.00it/s]读取数据:   5%|▍         | 347853/7086503 [00:49<26:30, 4236.55it/s]读取数据:   5%|▍         | 348300/7086503 [00:49<26:06, 4301.11it/s]读取数据:   5%|▍         | 348733/7086503 [00:49<26:44, 4199.70it/s]读取数据:   5%|▍         | 349156/7086503 [00:49<27:18, 4112.27it/s]读取数据:   5%|▍         | 349569/7086503 [00:49<27:32, 4076.69it/s]读取数据:   5%|▍         | 349978/7086503 [00:49<30:26, 3687.71it/s]读取数据:   5%|▍         | 350354/7086503 [00:50<49:28, 2269.54it/s]读取数据:   5%|▍         | 350907/7086503 [00:50<38:48, 2892.70it/s]读取数据:   5%|▍         | 351425/7086503 [00:50<33:15, 3375.21it/s]读取数据:   5%|▍         | 352002/7086503 [00:50<28:31, 3935.45it/s]读取数据:   5%|▍         | 352559/7086503 [00:50<25:50, 4343.56it/s]读取数据:   5%|▍         | 353093/7086503 [00:50<24:22, 4604.64it/s]读取数据:   5%|▍         | 353657/7086503 [00:50<22:57, 4886.90it/s]读取数据:   5%|▍         | 354253/7086503 [00:50<21:37, 5187.20it/s]读取数据:   5%|▌         | 354797/7086503 [00:50<21:22, 5249.86it/s]读取数据:   5%|▌         | 355399/7086503 [00:51<20:30, 5470.72it/s]读取数据:   5%|▌         | 356147/7086503 [00:51<18:30, 6058.55it/s]读取数据:   5%|▌         | 356860/7086503 [00:51<17:35, 6374.27it/s]读取数据:   5%|▌         | 357506/7086503 [00:51<17:39, 6351.48it/s]读取数据:   5%|▌         | 358371/7086503 [00:51<15:56, 7031.28it/s]读取数据:   5%|▌         | 359832/7086503 [00:51<12:04, 9281.83it/s]读取数据:   5%|▌         | 361169/7086503 [00:51<10:40, 10499.20it/s]读取数据:   5%|▌         | 362578/7086503 [00:51<09:41, 11570.14it/s]读取数据:   5%|▌         | 363831/7086503 [00:51<09:27, 11853.70it/s]读取数据:   5%|▌         | 365020/7086503 [00:51<09:47, 11436.38it/s]读取数据:   5%|▌         | 366169/7086503 [00:52<09:47, 11435.06it/s]读取数据:   5%|▌         | 367446/7086503 [00:52<09:28, 11825.11it/s]读取数据:   5%|▌         | 368687/7086503 [00:52<09:19, 11997.83it/s]读取数据:   5%|▌         | 370013/7086503 [00:52<09:02, 12370.37it/s]读取数据:   5%|▌         | 371253/7086503 [00:52<09:07, 12268.32it/s]读取数据:   5%|▌         | 372482/7086503 [00:52<16:50, 6643.66it/s] 读取数据:   5%|▌         | 373438/7086503 [00:53<37:35, 2976.19it/s]读取数据:   5%|▌         | 374141/7086503 [00:54<1:04:02, 1746.99it/s]读取数据:   5%|▌         | 374653/7086503 [00:55<1:06:54, 1671.96it/s]读取数据:   5%|▌         | 375928/7086503 [00:55<44:26, 2516.59it/s]  读取数据:   5%|▌         | 377219/7086503 [00:55<31:36, 3537.06it/s]读取数据:   5%|▌         | 378704/7086503 [00:55<22:40, 4929.10it/s]读取数据:   5%|▌         | 379745/7086503 [00:55<19:30, 5728.44it/s]读取数据:   5%|▌         | 381053/7086503 [00:55<15:55, 7018.27it/s]读取数据:   5%|▌         | 382432/7086503 [00:55<13:20, 8375.29it/s]读取数据:   5%|▌         | 383806/7086503 [00:55<11:40, 9567.83it/s]读取数据:   5%|▌         | 385215/7086503 [00:55<10:28, 10658.47it/s]读取数据:   5%|▌         | 386660/7086503 [00:56<09:36, 11627.36it/s]读取数据:   5%|▌         | 388113/7086503 [00:56<09:00, 12400.13it/s]读取数据:   5%|▌         | 389600/7086503 [00:56<08:31, 13083.41it/s]读取数据:   6%|▌         | 391037/7086503 [00:56<08:17, 13445.47it/s]读取数据:   6%|▌         | 392462/7086503 [00:56<08:09, 13676.74it/s]读取数据:   6%|▌         | 393881/7086503 [00:56<08:16, 13473.40it/s]读取数据:   6%|▌         | 395282/7086503 [00:56<08:11, 13620.20it/s]读取数据:   6%|▌         | 396699/7086503 [00:56<08:05, 13779.08it/s]读取数据:   6%|▌         | 398096/7086503 [00:56<08:05, 13766.97it/s]读取数据:   6%|▌         | 399522/7086503 [00:56<08:00, 13912.21it/s]读取数据:   6%|▌         | 400923/7086503 [00:57<14:33, 7649.52it/s] 读取数据:   6%|▌         | 402266/7086503 [00:57<12:45, 8735.14it/s]读取数据:   6%|▌         | 403508/7086503 [00:57<11:42, 9515.84it/s]读取数据:   6%|▌         | 404880/7086503 [00:57<10:36, 10493.26it/s]读取数据:   6%|▌         | 406164/7086503 [00:57<10:03, 11072.00it/s]读取数据:   6%|▌         | 407537/7086503 [00:57<09:27, 11766.04it/s]读取数据:   6%|▌         | 408827/7086503 [00:57<10:05, 11022.58it/s]读取数据:   6%|▌         | 410167/7086503 [00:58<09:33, 11635.85it/s]读取数据:   6%|▌         | 411465/7086503 [00:58<09:16, 12001.95it/s]读取数据:   6%|▌         | 412851/7086503 [00:58<08:53, 12519.91it/s]读取数据:   6%|▌         | 414214/7086503 [00:58<08:39, 12834.42it/s]读取数据:   6%|▌         | 415698/7086503 [00:58<08:17, 13411.13it/s]读取数据:   6%|▌         | 417217/7086503 [00:58<07:58, 13927.19it/s]读取数据:   6%|▌         | 418717/7086503 [00:58<07:48, 14236.10it/s]读取数据:   6%|▌         | 420154/7086503 [00:58<07:52, 14121.96it/s]读取数据:   6%|▌         | 421576/7086503 [00:58<08:19, 13333.59it/s]读取数据:   6%|▌         | 422925/7086503 [00:58<08:18, 13362.27it/s]读取数据:   6%|▌         | 424272/7086503 [00:59<08:29, 13078.97it/s]读取数据:   6%|▌         | 425624/7086503 [00:59<08:24, 13202.21it/s]读取数据:   6%|▌         | 426951/7086503 [00:59<08:23, 13220.91it/s]读取数据:   6%|▌         | 428278/7086503 [00:59<08:34, 12941.49it/s]读取数据:   6%|▌         | 429576/7086503 [00:59<08:44, 12696.71it/s]读取数据:   6%|▌         | 430874/7086503 [00:59<08:40, 12777.38it/s]读取数据:   6%|▌         | 432155/7086503 [00:59<08:44, 12682.19it/s]读取数据:   6%|▌         | 433425/7086503 [00:59<08:55, 12421.73it/s]读取数据:   6%|▌         | 434669/7086503 [00:59<09:05, 12195.58it/s]读取数据:   6%|▌         | 435891/7086503 [01:00<09:08, 12127.98it/s]读取数据:   6%|▌         | 437197/7086503 [01:00<08:56, 12398.06it/s]读取数据:   6%|▌         | 438521/7086503 [01:00<08:45, 12644.62it/s]读取数据:   6%|▌         | 439833/7086503 [01:00<08:39, 12784.96it/s]读取数据:   6%|▌         | 441199/7086503 [01:00<08:29, 13043.52it/s]读取数据:   6%|▌         | 442505/7086503 [01:00<09:00, 12301.91it/s]读取数据:   6%|▋         | 443745/7086503 [01:00<11:43, 9443.42it/s] 读取数据:   6%|▋         | 444880/7086503 [01:00<11:11, 9888.91it/s]读取数据:   6%|▋         | 446016/7086503 [01:00<10:47, 10261.39it/s]读取数据:   6%|▋         | 447218/7086503 [01:01<10:18, 10729.33it/s]读取数据:   6%|▋         | 448525/7086503 [01:01<09:43, 11373.77it/s]读取数据:   6%|▋         | 449705/7086503 [01:01<09:43, 11376.67it/s]读取数据:   6%|▋         | 450872/7086503 [01:01<15:23, 7182.18it/s] 读取数据:   6%|▋         | 452045/7086503 [01:01<13:38, 8107.56it/s]读取数据:   6%|▋         | 453220/7086503 [01:01<12:23, 8927.62it/s]读取数据:   6%|▋         | 454442/7086503 [01:01<11:21, 9728.97it/s]读取数据:   6%|▋         | 455711/7086503 [01:01<10:31, 10492.00it/s]读取数据:   6%|▋         | 457043/7086503 [01:02<09:49, 11251.25it/s]读取数据:   6%|▋         | 458440/7086503 [01:02<09:12, 12004.37it/s]读取数据:   6%|▋         | 459821/7086503 [01:02<08:49, 12514.95it/s]读取数据:   7%|▋         | 461146/7086503 [01:02<08:40, 12724.48it/s]读取数据:   7%|▋         | 462477/7086503 [01:02<08:34, 12885.59it/s]读取数据:   7%|▋         | 463896/7086503 [01:02<08:19, 13267.96it/s]读取数据:   7%|▋         | 465285/7086503 [01:02<08:12, 13449.85it/s]读取数据:   7%|▋         | 466647/7086503 [01:02<08:10, 13499.61it/s]读取数据:   7%|▋         | 468032/7086503 [01:02<08:06, 13602.12it/s]读取数据:   7%|▋         | 469401/7086503 [01:02<08:05, 13617.59it/s]读取数据:   7%|▋         | 470768/7086503 [01:03<08:43, 12627.78it/s]读取数据:   7%|▋         | 472049/7086503 [01:03<09:30, 11602.40it/s]读取数据:   7%|▋         | 473235/7086503 [01:03<09:59, 11030.48it/s]读取数据:   7%|▋         | 474358/7086503 [01:03<10:13, 10782.45it/s]读取数据:   7%|▋         | 475449/7086503 [01:03<10:29, 10503.92it/s]读取数据:   7%|▋         | 476508/7086503 [01:03<10:30, 10488.94it/s]读取数据:   7%|▋         | 477588/7086503 [01:03<10:25, 10573.20it/s]读取数据:   7%|▋         | 478758/7086503 [01:03<10:06, 10893.04it/s]读取数据:   7%|▋         | 479974/7086503 [01:03<09:47, 11239.08it/s]读取数据:   7%|▋         | 481168/7086503 [01:04<09:37, 11443.84it/s]读取数据:   7%|▋         | 482406/7086503 [01:04<09:23, 11719.00it/s]读取数据:   7%|▋         | 483838/7086503 [01:04<08:49, 12479.70it/s]读取数据:   7%|▋         | 485205/7086503 [01:04<08:34, 12831.96it/s]读取数据:   7%|▋         | 486498/7086503 [01:04<08:33, 12858.39it/s]读取数据:   7%|▋         | 487855/7086503 [01:04<08:24, 13068.72it/s]读取数据:   7%|▋         | 489300/7086503 [01:04<08:09, 13475.72it/s]读取数据:   7%|▋         | 490831/7086503 [01:04<07:50, 14023.74it/s]读取数据:   7%|▋         | 492367/7086503 [01:04<07:37, 14422.50it/s]读取数据:   7%|▋         | 493873/7086503 [01:04<07:31, 14611.30it/s]读取数据:   7%|▋         | 495335/7086503 [01:05<07:33, 14519.38it/s]读取数据:   7%|▋         | 496793/7086503 [01:05<07:33, 14535.81it/s]读取数据:   7%|▋         | 498247/7086503 [01:05<07:49, 14017.70it/s]读取数据:   7%|▋         | 499653/7086503 [01:05<08:04, 13587.44it/s]读取数据:   7%|▋         | 499653/7086503 [01:24<08:04, 13587.44it/s]读取数据:   7%|▋         | 500000/7086503 [02:37<45:39:55, 40.06it/s]读取数据:   7%|▋         | 501619/7086503 [02:37<28:10:45, 64.91it/s]读取数据:   7%|▋         | 503299/7086503 [02:38<17:59:49, 101.61it/s]读取数据:   7%|▋         | 504811/7086503 [02:38<12:19:23, 148.36it/s]读取数据:   7%|▋         | 506211/7086503 [02:38<8:43:07, 209.64it/s] 读取数据:   7%|▋         | 507545/7086503 [02:38<6:16:43, 291.06it/s]读取数据:   7%|▋         | 508719/7086503 [02:38<4:39:13, 392.62it/s]读取数据:   7%|▋         | 509904/7086503 [02:38<3:24:29, 536.03it/s]读取数据:   7%|▋         | 511079/7086503 [02:38<2:29:31, 732.96it/s]读取数据:   7%|▋         | 512252/7086503 [02:38<1:49:24, 1001.54it/s]读取数据:   7%|▋         | 513417/7086503 [02:38<1:20:30, 1360.83it/s]读取数据:   7%|▋         | 514583/7086503 [02:39<59:42, 1834.47it/s]  读取数据:   7%|▋         | 515746/7086503 [02:39<45:01, 2432.04it/s]读取数据:   7%|▋         | 516925/7086503 [02:39<34:20, 3187.58it/s]读取数据:   7%|▋         | 518082/7086503 [02:39<27:05, 4041.49it/s]读取数据:   7%|▋         | 519229/7086503 [02:39<22:03, 4963.55it/s]读取数据:   7%|▋         | 520360/7086503 [02:39<18:27, 5929.86it/s]读取数据:   7%|▋         | 521487/7086503 [02:39<15:54, 6879.84it/s]读取数据:   7%|▋         | 522612/7086503 [02:39<14:04, 7772.91it/s]读取数据:   7%|▋         | 523738/7086503 [02:39<12:46, 8560.51it/s]读取数据:   7%|▋         | 524863/7086503 [02:39<12:01, 9094.82it/s]读取数据:   7%|▋         | 525970/7086503 [02:40<11:24, 9585.36it/s]读取数据:   7%|▋         | 527137/7086503 [02:40<10:47, 10130.23it/s]读取数据:   7%|▋         | 528259/7086503 [02:40<10:37, 10292.14it/s]读取数据:   7%|▋         | 529366/7086503 [02:40<11:16, 9699.16it/s] 读取数据:   7%|▋         | 530487/7086503 [02:40<10:48, 10101.74it/s]读取数据:   8%|▊         | 531596/7086503 [02:40<10:31, 10375.28it/s]读取数据:   8%|▊         | 532697/7086503 [02:40<10:21, 10553.12it/s]读取数据:   8%|▊         | 533804/7086503 [02:40<10:12, 10699.96it/s]读取数据:   8%|▊         | 534893/7086503 [02:40<10:14, 10660.90it/s]读取数据:   8%|▊         | 535988/7086503 [02:41<10:09, 10741.69it/s]读取数据:   8%|▊         | 537072/7086503 [02:41<10:19, 10579.01it/s]读取数据:   8%|▊         | 538187/7086503 [02:41<10:09, 10744.60it/s]读取数据:   8%|▊         | 539267/7086503 [02:41<10:10, 10730.14it/s]读取数据:   8%|▊         | 540385/7086503 [02:41<10:02, 10859.74it/s]读取数据:   8%|▊         | 541550/7086503 [02:41<09:50, 11089.21it/s]读取数据:   8%|▊         | 542721/7086503 [02:41<09:40, 11272.75it/s]读取数据:   8%|▊         | 543862/7086503 [02:41<09:38, 11313.16it/s]读取数据:   8%|▊         | 545014/7086503 [02:41<09:35, 11374.28it/s]读取数据:   8%|▊         | 546165/7086503 [02:41<09:33, 11412.69it/s]读取数据:   8%|▊         | 547494/7086503 [02:42<09:06, 11974.18it/s]读取数据:   8%|▊         | 548790/7086503 [02:42<08:52, 12267.78it/s]读取数据:   8%|▊         | 550018/7086503 [02:42<14:49, 7346.23it/s] 读取数据:   8%|▊         | 551335/7086503 [02:42<12:45, 8533.91it/s]读取数据:   8%|▊         | 552699/7086503 [02:42<11:14, 9685.75it/s]读取数据:   8%|▊         | 554015/7086503 [02:42<10:20, 10530.70it/s]读取数据:   8%|▊         | 555371/7086503 [02:42<09:37, 11312.17it/s]读取数据:   8%|▊         | 556741/7086503 [02:42<09:06, 11955.38it/s]读取数据:   8%|▊         | 558068/7086503 [02:43<08:50, 12317.80it/s]读取数据:   8%|▊         | 559368/7086503 [02:43<08:43, 12467.32it/s]读取数据:   8%|▊         | 560676/7086503 [02:43<08:36, 12643.53it/s]读取数据:   8%|▊         | 562000/7086503 [02:43<08:29, 12816.74it/s]读取数据:   8%|▊         | 563307/7086503 [02:43<08:29, 12793.34it/s]读取数据:   8%|▊         | 564604/7086503 [02:43<08:27, 12843.13it/s]读取数据:   8%|▊         | 565909/7086503 [02:43<08:25, 12903.56it/s]读取数据:   8%|▊         | 567208/7086503 [02:43<08:24, 12915.99it/s]读取数据:   8%|▊         | 568602/7086503 [02:43<08:13, 13219.55it/s]读取数据:   8%|▊         | 569929/7086503 [02:43<08:13, 13217.91it/s]读取数据:   8%|▊         | 571254/7086503 [02:44<08:33, 12695.46it/s]读取数据:   8%|▊         | 572546/7086503 [02:44<08:30, 12760.26it/s]读取数据:   8%|▊         | 573838/7086503 [02:44<08:28, 12804.95it/s]读取数据:   8%|▊         | 575122/7086503 [02:44<09:00, 12038.85it/s]读取数据:   8%|▊         | 576337/7086503 [02:44<09:17, 11667.38it/s]读取数据:   8%|▊         | 577513/7086503 [02:44<13:10, 8232.34it/s] 读取数据:   8%|▊         | 578698/7086503 [02:44<12:00, 9028.76it/s]读取数据:   8%|▊         | 580036/7086503 [02:44<10:46, 10069.89it/s]读取数据:   8%|▊         | 581335/7086503 [02:45<10:01, 10811.19it/s]读取数据:   8%|▊         | 582599/7086503 [02:45<09:35, 11298.73it/s]读取数据:   8%|▊         | 583909/7086503 [02:45<09:11, 11795.07it/s]读取数据:   8%|▊         | 585255/7086503 [02:45<08:50, 12264.52it/s]读取数据:   8%|▊         | 586558/7086503 [02:45<08:40, 12482.25it/s]读取数据:   8%|▊         | 587836/7086503 [02:45<09:53, 10941.80it/s]读取数据:   8%|▊         | 588985/7086503 [02:45<13:35, 7965.51it/s] 读取数据:   8%|▊         | 589929/7086503 [02:46<14:39, 7389.55it/s]读取数据:   8%|▊         | 590771/7086503 [02:46<15:25, 7020.72it/s]读取数据:   8%|▊         | 591542/7086503 [02:46<15:58, 6777.47it/s]读取数据:   8%|▊         | 592265/7086503 [02:46<16:28, 6568.54it/s]读取数据:   8%|▊         | 592951/7086503 [02:46<16:54, 6401.48it/s]读取数据:   8%|▊         | 593609/7086503 [02:46<17:17, 6257.34it/s]读取数据:   8%|▊         | 594246/7086503 [02:46<17:29, 6183.71it/s]读取数据:   8%|▊         | 594871/7086503 [02:46<17:28, 6193.36it/s]读取数据:   8%|▊         | 595496/7086503 [02:46<17:31, 6175.99it/s]读取数据:   8%|▊         | 596119/7086503 [02:47<17:29, 6186.79it/s]读取数据:   8%|▊         | 596740/7086503 [02:47<17:37, 6138.78it/s]读取数据:   8%|▊         | 597356/7086503 [02:47<17:54, 6038.97it/s]读取数据:   8%|▊         | 597961/7086503 [02:47<17:54, 6037.68it/s]读取数据:   8%|▊         | 598587/7086503 [02:47<17:43, 6100.99it/s]读取数据:   8%|▊         | 599198/7086503 [02:47<17:47, 6074.83it/s]读取数据:   8%|▊         | 599806/7086503 [02:47<17:50, 6059.66it/s]读取数据:   8%|▊         | 600413/7086503 [02:48<34:10, 3163.75it/s]读取数据:   8%|▊         | 600893/7086503 [02:48<31:14, 3459.15it/s]读取数据:   8%|▊         | 601739/7086503 [02:48<24:06, 4483.33it/s]读取数据:   9%|▊         | 602542/7086503 [02:48<20:26, 5284.88it/s]读取数据:   9%|▊         | 603298/7086503 [02:48<18:30, 5838.97it/s]读取数据:   9%|▊         | 604055/7086503 [02:48<17:11, 6284.04it/s]读取数据:   9%|▊         | 604806/7086503 [02:48<16:20, 6612.80it/s]读取数据:   9%|▊         | 605524/7086503 [02:48<16:03, 6725.81it/s]读取数据:   9%|▊         | 606271/7086503 [02:48<15:34, 6935.33it/s]读取数据:   9%|▊         | 607081/7086503 [02:48<14:52, 7263.44it/s]读取数据:   9%|▊         | 607877/7086503 [02:49<14:27, 7464.60it/s]读取数据:   9%|▊         | 608679/7086503 [02:49<14:09, 7624.26it/s]读取数据:   9%|▊         | 609453/7086503 [02:49<16:50, 6407.31it/s]读取数据:   9%|▊         | 610135/7086503 [02:49<18:35, 5805.24it/s]读取数据:   9%|▊         | 610752/7086503 [02:49<27:49, 3879.08it/s]读取数据:   9%|▊         | 611875/7086503 [02:49<20:27, 5273.32it/s]读取数据:   9%|▊         | 612963/7086503 [02:49<16:40, 6469.33it/s]读取数据:   9%|▊         | 614115/7086503 [02:50<14:06, 7646.32it/s]读取数据:   9%|▊         | 615308/7086503 [02:50<12:22, 8717.02it/s]读取数据:   9%|▊         | 616435/7086503 [02:50<11:29, 9388.47it/s]读取数据:   9%|▊         | 617599/7086503 [02:50<10:46, 10002.68it/s]读取数据:   9%|▊         | 618821/7086503 [02:50<10:08, 10624.11it/s]读取数据:   9%|▊         | 620008/7086503 [02:50<09:48, 10980.31it/s]读取数据:   9%|▉         | 621175/7086503 [02:50<09:38, 11179.47it/s]读取数据:   9%|▉         | 622361/7086503 [02:50<09:28, 11377.05it/s]读取数据:   9%|▉         | 623534/7086503 [02:50<09:22, 11479.80it/s]读取数据:   9%|▉         | 624697/7086503 [02:50<09:23, 11467.71it/s]读取数据:   9%|▉         | 625873/7086503 [02:51<09:19, 11553.88it/s]读取数据:   9%|▉         | 627036/7086503 [02:51<09:19, 11538.14it/s]读取数据:   9%|▉         | 628202/7086503 [02:51<09:18, 11568.85it/s]读取数据:   9%|▉         | 629380/7086503 [02:51<09:15, 11629.01it/s]读取数据:   9%|▉         | 630546/7086503 [02:51<09:16, 11591.17it/s]读取数据:   9%|▉         | 631709/7086503 [02:51<09:16, 11602.09it/s]读取数据:   9%|▉         | 632874/7086503 [02:51<09:15, 11615.24it/s]读取数据:   9%|▉         | 634087/7086503 [02:51<09:08, 11767.79it/s]读取数据:   9%|▉         | 635271/7086503 [02:51<09:07, 11784.49it/s]读取数据:   9%|▉         | 636475/7086503 [02:51<09:03, 11860.63it/s]读取数据:   9%|▉         | 637662/7086503 [02:52<09:11, 11684.53it/s]读取数据:   9%|▉         | 638849/7086503 [02:52<09:09, 11738.19it/s]读取数据:   9%|▉         | 640024/7086503 [02:52<09:12, 11665.85it/s]读取数据:   9%|▉         | 641207/7086503 [02:52<09:10, 11705.20it/s]读取数据:   9%|▉         | 642388/7086503 [02:52<09:09, 11731.81it/s]读取数据:   9%|▉         | 643562/7086503 [02:52<09:12, 11661.08it/s]读取数据:   9%|▉         | 644765/7086503 [02:52<09:07, 11766.60it/s]读取数据:   9%|▉         | 645942/7086503 [02:52<09:08, 11736.52it/s]读取数据:   9%|▉         | 647116/7086503 [02:52<09:13, 11642.63it/s]读取数据:   9%|▉         | 648292/7086503 [02:53<09:11, 11675.88it/s]读取数据:   9%|▉         | 649476/7086503 [02:53<09:09, 11723.61it/s]读取数据:   9%|▉         | 650649/7086503 [02:53<16:12, 6620.99it/s] 读取数据:   9%|▉         | 651723/7086503 [02:53<14:27, 7417.82it/s]读取数据:   9%|▉         | 652922/7086503 [02:53<12:45, 8405.87it/s]读取数据:   9%|▉         | 654087/7086503 [02:53<11:41, 9172.96it/s]读取数据:   9%|▉         | 655285/7086503 [02:53<10:51, 9878.62it/s]读取数据:   9%|▉         | 656484/7086503 [02:53<10:16, 10437.87it/s]读取数据:   9%|▉         | 657668/7086503 [02:54<09:54, 10821.69it/s]读取数据:   9%|▉         | 658820/7086503 [02:54<09:43, 11013.66it/s]读取数据:   9%|▉         | 660059/7086503 [02:54<09:23, 11407.84it/s]读取数据:   9%|▉         | 661237/7086503 [02:54<09:19, 11484.48it/s]读取数据:   9%|▉         | 662425/7086503 [02:54<09:14, 11591.87it/s]读取数据:   9%|▉         | 663605/7086503 [02:54<09:11, 11651.28it/s]读取数据:   9%|▉         | 664813/7086503 [02:54<09:05, 11776.16it/s]读取数据:   9%|▉         | 666001/7086503 [02:54<09:03, 11805.88it/s]读取数据:   9%|▉         | 667197/7086503 [02:54<09:01, 11849.31it/s]读取数据:   9%|▉         | 668390/7086503 [02:54<09:00, 11871.12it/s]读取数据:   9%|▉         | 669626/7086503 [02:55<08:54, 12015.03it/s]读取数据:   9%|▉         | 670868/7086503 [02:55<08:49, 12127.47it/s]读取数据:   9%|▉         | 672083/7086503 [02:55<08:51, 12067.43it/s]读取数据:  10%|▉         | 673291/7086503 [02:55<08:54, 11996.32it/s]读取数据:  10%|▉         | 674492/7086503 [02:55<09:03, 11790.96it/s]读取数据:  10%|▉         | 675673/7086503 [02:55<09:11, 11628.37it/s]读取数据:  10%|▉         | 676837/7086503 [02:55<09:15, 11541.69it/s]读取数据:  10%|▉         | 678003/7086503 [02:55<09:13, 11571.78it/s]读取数据:  10%|▉         | 679217/7086503 [02:55<09:05, 11739.08it/s]读取数据:  10%|▉         | 680422/7086503 [02:55<09:01, 11831.00it/s]读取数据:  10%|▉         | 681606/7086503 [02:56<09:07, 11703.42it/s]读取数据:  10%|▉         | 682814/7086503 [02:56<09:02, 11801.93it/s]读取数据:  10%|▉         | 683995/7086503 [02:56<09:03, 11781.78it/s]读取数据:  10%|▉         | 685183/7086503 [02:56<09:02, 11809.92it/s]读取数据:  10%|▉         | 686365/7086503 [02:56<09:08, 11669.92it/s]读取数据:  10%|▉         | 687559/7086503 [02:56<09:04, 11742.47it/s]读取数据:  10%|▉         | 688745/7086503 [02:56<09:03, 11774.03it/s]读取数据:  10%|▉         | 689940/7086503 [02:56<09:01, 11821.91it/s]读取数据:  10%|▉         | 691153/7086503 [02:56<08:57, 11908.21it/s]读取数据:  10%|▉         | 692371/7086503 [02:56<08:53, 11988.36it/s]读取数据:  10%|▉         | 693571/7086503 [02:57<08:53, 11972.38it/s]读取数据:  10%|▉         | 694769/7086503 [02:57<08:57, 11896.90it/s]读取数据:  10%|▉         | 695959/7086503 [02:57<08:59, 11855.78it/s]读取数据:  10%|▉         | 697145/7086503 [02:57<09:03, 11748.38it/s]读取数据:  10%|▉         | 698364/7086503 [02:57<08:57, 11878.33it/s]读取数据:  10%|▉         | 699586/7086503 [02:57<08:53, 11978.76it/s]读取数据:  10%|▉         | 700785/7086503 [02:57<15:23, 6915.41it/s] 读取数据:  10%|▉         | 701806/7086503 [02:58<14:03, 7565.18it/s]读取数据:  10%|▉         | 702993/7086503 [02:58<12:30, 8510.16it/s]读取数据:  10%|▉         | 704180/7086503 [02:58<11:25, 9312.38it/s]读取数据:  10%|▉         | 705337/7086503 [02:58<10:45, 9885.38it/s]读取数据:  10%|▉         | 706568/7086503 [02:58<10:06, 10526.43it/s]读取数据:  10%|▉         | 707794/7086503 [02:58<09:39, 10999.41it/s]读取数据:  10%|█         | 708990/7086503 [02:58<09:25, 11269.29it/s]读取数据:  10%|█         | 710265/7086503 [02:58<09:05, 11694.50it/s]读取数据:  10%|█         | 711472/7086503 [02:58<09:00, 11802.14it/s]读取数据:  10%|█         | 712677/7086503 [02:58<09:04, 11695.63it/s]读取数据:  10%|█         | 713872/7086503 [02:59<09:01, 11768.78it/s]读取数据:  10%|█         | 715062/7086503 [02:59<09:05, 11688.23it/s]读取数据:  10%|█         | 716277/7086503 [02:59<08:58, 11823.23it/s]读取数据:  10%|█         | 717520/7086503 [02:59<08:50, 11998.56it/s]读取数据:  10%|█         | 718725/7086503 [02:59<08:54, 11919.37it/s]读取数据:  10%|█         | 719921/7086503 [02:59<08:55, 11885.70it/s]读取数据:  10%|█         | 721132/7086503 [02:59<08:52, 11946.89it/s]读取数据:  10%|█         | 722329/7086503 [02:59<08:53, 11918.55it/s]读取数据:  10%|█         | 723592/7086503 [02:59<08:44, 12129.72it/s]读取数据:  10%|█         | 724806/7086503 [02:59<08:50, 11987.67it/s]读取数据:  10%|█         | 726013/7086503 [03:00<08:49, 12007.69it/s]读取数据:  10%|█         | 727247/7086503 [03:00<08:45, 12099.95it/s]读取数据:  10%|█         | 728460/7086503 [03:00<08:45, 12106.63it/s]读取数据:  10%|█         | 729672/7086503 [03:00<08:46, 12071.53it/s]读取数据:  10%|█         | 730906/7086503 [03:00<08:43, 12149.82it/s]读取数据:  10%|█         | 732149/7086503 [03:00<08:39, 12231.88it/s]读取数据:  10%|█         | 733389/7086503 [03:00<08:37, 12279.36it/s]读取数据:  10%|█         | 734618/7086503 [03:00<08:41, 12189.57it/s]读取数据:  10%|█         | 735845/7086503 [03:00<08:40, 12203.02it/s]读取数据:  10%|█         | 737066/7086503 [03:00<08:42, 12142.95it/s]读取数据:  10%|█         | 738292/7086503 [03:01<08:41, 12174.15it/s]读取数据:  10%|█         | 739510/7086503 [03:01<08:43, 12113.62it/s]读取数据:  10%|█         | 740722/7086503 [03:01<08:47, 12024.93it/s]读取数据:  10%|█         | 741950/7086503 [03:01<08:44, 12099.60it/s]读取数据:  10%|█         | 743208/7086503 [03:01<08:38, 12242.44it/s]读取数据:  11%|█         | 744433/7086503 [03:01<08:43, 12107.55it/s]读取数据:  11%|█         | 745645/7086503 [03:01<08:49, 11969.77it/s]读取数据:  11%|█         | 746895/7086503 [03:01<08:42, 12125.75it/s]读取数据:  11%|█         | 748109/7086503 [03:01<10:21, 10205.52it/s]读取数据:  11%|█         | 749181/7086503 [03:02<11:52, 8896.30it/s] 读取数据:  11%|█         | 750131/7086503 [03:02<24:04, 4385.39it/s]读取数据:  11%|█         | 750849/7086503 [03:02<22:55, 4607.51it/s]读取数据:  11%|█         | 751521/7086503 [03:02<21:37, 4881.73it/s]读取数据:  11%|█         | 752176/7086503 [03:02<20:27, 5161.85it/s]读取数据:  11%|█         | 752824/7086503 [03:03<19:35, 5389.65it/s]读取数据:  11%|█         | 753494/7086503 [03:03<18:32, 5691.41it/s]读取数据:  11%|█         | 754162/7086503 [03:03<17:46, 5935.94it/s]读取数据:  11%|█         | 754833/7086503 [03:03<17:11, 6137.61it/s]读取数据:  11%|█         | 755513/7086503 [03:03<16:42, 6315.36it/s]读取数据:  11%|█         | 756187/7086503 [03:03<16:24, 6432.52it/s]读取数据:  11%|█         | 756855/7086503 [03:03<16:21, 6446.23it/s]读取数据:  11%|█         | 757556/7086503 [03:03<15:58, 6603.12it/s]读取数据:  11%|█         | 758229/7086503 [03:03<15:57, 6608.91it/s]读取数据:  11%|█         | 758899/7086503 [03:03<16:01, 6580.25it/s]读取数据:  11%|█         | 759564/7086503 [03:04<16:04, 6561.18it/s]读取数据:  11%|█         | 760225/7086503 [03:04<16:11, 6508.98it/s]读取数据:  11%|█         | 760879/7086503 [03:04<16:24, 6427.04it/s]读取数据:  11%|█         | 761531/7086503 [03:04<16:20, 6453.09it/s]读取数据:  11%|█         | 762178/7086503 [03:04<16:19, 6457.40it/s]读取数据:  11%|█         | 762825/7086503 [03:04<16:26, 6408.99it/s]读取数据:  11%|█         | 763511/7086503 [03:04<16:06, 6540.97it/s]读取数据:  11%|█         | 764166/7086503 [03:04<16:13, 6493.18it/s]读取数据:  11%|█         | 764816/7086503 [03:04<16:22, 6435.42it/s]读取数据:  11%|█         | 765489/7086503 [03:05<16:10, 6515.10it/s]读取数据:  11%|█         | 766141/7086503 [03:05<16:17, 6468.31it/s]读取数据:  11%|█         | 766799/7086503 [03:05<16:12, 6499.52it/s]读取数据:  11%|█         | 767455/7086503 [03:05<16:09, 6517.08it/s]读取数据:  11%|█         | 768107/7086503 [03:05<16:39, 6320.20it/s]读取数据:  11%|█         | 768756/7086503 [03:05<16:31, 6369.61it/s]读取数据:  11%|█         | 769403/7086503 [03:05<16:27, 6394.43it/s]读取数据:  11%|█         | 770057/7086503 [03:05<16:21, 6437.41it/s]读取数据:  11%|█         | 770702/7086503 [03:05<16:23, 6419.64it/s]读取数据:  11%|█         | 771345/7086503 [03:05<16:42, 6300.06it/s]读取数据:  11%|█         | 772004/7086503 [03:06<16:28, 6384.77it/s]读取数据:  11%|█         | 772659/7086503 [03:06<16:21, 6431.30it/s]读取数据:  11%|█         | 773303/7086503 [03:06<16:29, 6382.20it/s]读取数据:  11%|█         | 773988/7086503 [03:06<16:08, 6520.53it/s]读取数据:  11%|█         | 774645/7086503 [03:06<16:06, 6528.54it/s]读取数据:  11%|█         | 775311/7086503 [03:06<16:01, 6565.45it/s]读取数据:  11%|█         | 775968/7086503 [03:06<16:13, 6484.48it/s]读取数据:  11%|█         | 776617/7086503 [03:06<16:14, 6471.69it/s]读取数据:  11%|█         | 777265/7086503 [03:06<16:22, 6424.11it/s]读取数据:  11%|█         | 778705/7086503 [03:06<11:57, 8786.22it/s]读取数据:  11%|█         | 780122/7086503 [03:07<10:07, 10385.25it/s]读取数据:  11%|█         | 781594/7086503 [03:07<09:00, 11675.67it/s]读取数据:  11%|█         | 783057/7086503 [03:07<08:22, 12554.70it/s]读取数据:  11%|█         | 784511/7086503 [03:07<07:59, 13147.70it/s]读取数据:  11%|█         | 785980/7086503 [03:07<07:42, 13608.61it/s]读取数据:  11%|█         | 787404/7086503 [03:07<07:36, 13797.53it/s]读取数据:  11%|█         | 788857/7086503 [03:07<07:29, 14016.11it/s]读取数据:  11%|█         | 790339/7086503 [03:07<07:21, 14252.32it/s]读取数据:  11%|█         | 791822/7086503 [03:07<07:16, 14424.11it/s]读取数据:  11%|█         | 793298/7086503 [03:07<07:13, 14521.52it/s]读取数据:  11%|█         | 794764/7086503 [03:08<07:12, 14559.33it/s]读取数据:  11%|█         | 796252/7086503 [03:08<07:09, 14654.10it/s]读取数据:  11%|█▏        | 797718/7086503 [03:08<07:09, 14645.25it/s]读取数据:  11%|█▏        | 799204/7086503 [03:08<07:07, 14707.90it/s]读取数据:  11%|█▏        | 800675/7086503 [03:08<12:12, 8580.39it/s] 读取数据:  11%|█▏        | 802192/7086503 [03:08<10:35, 9895.05it/s]读取数据:  11%|█▏        | 803673/7086503 [03:08<09:31, 10986.51it/s]读取数据:  11%|█▏        | 805128/7086503 [03:08<08:50, 11844.73it/s]读取数据:  11%|█▏        | 806603/7086503 [03:09<08:18, 12588.03it/s]读取数据:  11%|█▏        | 808119/7086503 [03:09<07:52, 13275.06it/s]读取数据:  11%|█▏        | 809572/7086503 [03:09<07:40, 13621.87it/s]读取数据:  11%|█▏        | 811043/7086503 [03:09<07:30, 13928.83it/s]读取数据:  11%|█▏        | 812529/7086503 [03:09<07:21, 14196.49it/s]读取数据:  11%|█▏        | 814055/7086503 [03:09<07:12, 14501.96it/s]读取数据:  12%|█▏        | 815535/7086503 [03:09<07:10, 14562.74it/s]读取数据:  12%|█▏        | 817012/7086503 [03:09<07:09, 14612.01it/s]读取数据:  12%|█▏        | 818498/7086503 [03:09<07:06, 14683.44it/s]读取数据:  12%|█▏        | 819990/7086503 [03:09<07:04, 14753.35it/s]读取数据:  12%|█▏        | 821482/7086503 [03:10<07:03, 14801.67it/s]读取数据:  12%|█▏        | 822968/7086503 [03:10<07:03, 14784.42it/s]读取数据:  12%|█▏        | 824459/7086503 [03:10<07:02, 14820.77it/s]读取数据:  12%|█▏        | 825970/7086503 [03:10<07:00, 14905.08it/s]读取数据:  12%|█▏        | 827474/7086503 [03:10<06:58, 14944.96it/s]读取数据:  12%|█▏        | 828984/7086503 [03:10<06:57, 14990.95it/s]读取数据:  12%|█▏        | 830500/7086503 [03:10<06:55, 15041.13it/s]读取数据:  12%|█▏        | 832005/7086503 [03:10<06:59, 14924.46it/s]读取数据:  12%|█▏        | 833499/7086503 [03:10<06:59, 14896.00it/s]读取数据:  12%|█▏        | 834990/7086503 [03:10<07:00, 14878.64it/s]读取数据:  12%|█▏        | 836499/7086503 [03:11<06:58, 14939.15it/s]读取数据:  12%|█▏        | 837994/7086503 [03:11<07:00, 14865.26it/s]读取数据:  12%|█▏        | 839500/7086503 [03:11<06:58, 14916.59it/s]读取数据:  12%|█▏        | 841041/7086503 [03:11<06:54, 15060.75it/s]读取数据:  12%|█▏        | 842548/7086503 [03:11<06:55, 15021.22it/s]读取数据:  12%|█▏        | 844093/7086503 [03:11<06:52, 15148.14it/s]读取数据:  12%|█▏        | 845641/7086503 [03:11<06:49, 15246.77it/s]读取数据:  12%|█▏        | 847182/7086503 [03:11<06:48, 15288.62it/s]读取数据:  12%|█▏        | 848716/7086503 [03:11<06:47, 15303.18it/s]读取数据:  12%|█▏        | 850247/7086503 [03:12<11:48, 8804.05it/s] 读取数据:  12%|█▏        | 851802/7086503 [03:12<10:15, 10133.55it/s]读取数据:  12%|█▏        | 853369/7086503 [03:12<09:09, 11351.01it/s]读取数据:  12%|█▏        | 855009/7086503 [03:12<08:16, 12558.11it/s]读取数据:  12%|█▏        | 856619/7086503 [03:12<07:42, 13458.71it/s]读取数据:  12%|█▏        | 858269/7086503 [03:12<07:16, 14269.24it/s]读取数据:  12%|█▏        | 859819/7086503 [03:12<07:06, 14596.21it/s]读取数据:  12%|█▏        | 861453/7086503 [03:12<06:52, 15085.45it/s]读取数据:  12%|█▏        | 863075/7086503 [03:13<06:43, 15405.51it/s]读取数据:  12%|█▏        | 864708/7086503 [03:13<06:37, 15670.55it/s]读取数据:  12%|█▏        | 866309/7086503 [03:13<06:52, 15085.18it/s]读取数据:  12%|█▏        | 867846/7086503 [03:13<07:07, 14536.76it/s]读取数据:  12%|█▏        | 869322/7086503 [03:13<07:19, 14159.90it/s]读取数据:  12%|█▏        | 870754/7086503 [03:13<07:33, 13721.27it/s]读取数据:  12%|█▏        | 872139/7086503 [03:13<07:40, 13491.32it/s]读取数据:  12%|█▏        | 873496/7086503 [03:13<07:49, 13229.89it/s]读取数据:  12%|█▏        | 874825/7086503 [03:13<07:53, 13109.23it/s]读取数据:  12%|█▏        | 876140/7086503 [03:14<08:12, 12613.81it/s]读取数据:  12%|█▏        | 877406/7086503 [03:14<08:28, 12221.11it/s]读取数据:  12%|█▏        | 878632/7086503 [03:14<08:42, 11883.04it/s]读取数据:  12%|█▏        | 879823/7086503 [03:14<08:54, 11609.44it/s]读取数据:  12%|█▏        | 880986/7086503 [03:14<09:01, 11461.15it/s]读取数据:  12%|█▏        | 882133/7086503 [03:14<09:06, 11362.38it/s]读取数据:  12%|█▏        | 883270/7086503 [03:14<09:11, 11257.26it/s]读取数据:  12%|█▏        | 884470/7086503 [03:14<09:00, 11470.26it/s]读取数据:  12%|█▏        | 885642/7086503 [03:14<08:57, 11537.94it/s]读取数据:  13%|█▎        | 886812/7086503 [03:14<08:55, 11581.32it/s]读取数据:  13%|█▎        | 888002/7086503 [03:15<08:50, 11675.03it/s]读取数据:  13%|█▎        | 889224/7086503 [03:15<08:43, 11836.21it/s]读取数据:  13%|█▎        | 890422/7086503 [03:15<08:41, 11876.36it/s]读取数据:  13%|█▎        | 891611/7086503 [03:15<08:45, 11796.45it/s]读取数据:  13%|█▎        | 892792/7086503 [03:15<08:45, 11781.39it/s]读取数据:  13%|█▎        | 893971/7086503 [03:15<08:48, 11717.45it/s]读取数据:  13%|█▎        | 895177/7086503 [03:15<08:43, 11818.90it/s]读取数据:  13%|█▎        | 896368/7086503 [03:15<08:42, 11842.43it/s]读取数据:  13%|█▎        | 897617/7086503 [03:15<08:34, 12034.35it/s]读取数据:  13%|█▎        | 898821/7086503 [03:15<08:38, 11924.55it/s]读取数据:  13%|█▎        | 900014/7086503 [03:16<15:10, 6792.52it/s] 读取数据:  13%|█▎        | 901179/7086503 [03:16<13:19, 7735.08it/s]读取数据:  13%|█▎        | 902376/7086503 [03:16<11:54, 8654.47it/s]读取数据:  13%|█▎        | 903559/7086503 [03:16<10:57, 9405.84it/s]读取数据:  13%|█▎        | 904733/7086503 [03:16<10:18, 9993.26it/s]读取数据:  13%|█▎        | 906007/7086503 [03:16<09:36, 10716.83it/s]读取数据:  13%|█▎        | 907173/7086503 [03:16<09:23, 10971.00it/s]读取数据:  13%|█▎        | 908339/7086503 [03:17<09:18, 11067.45it/s]读取数据:  13%|█▎        | 909570/7086503 [03:17<09:00, 11419.47it/s]读取数据:  13%|█▎        | 910748/7086503 [03:17<09:06, 11300.21it/s]读取数据:  13%|█▎        | 911972/7086503 [03:17<08:53, 11568.87it/s]读取数据:  13%|█▎        | 913148/7086503 [03:17<08:58, 11472.17it/s]读取数据:  13%|█▎        | 914309/7086503 [03:18<24:43, 4159.61it/s] 读取数据:  13%|█▎        | 915171/7086503 [03:19<58:13, 1766.48it/s]读取数据:  13%|█▎        | 915793/7086503 [03:19<1:00:52, 1689.49it/s]读取数据:  13%|█▎        | 916272/7086503 [03:20<1:07:11, 1530.63it/s]读取数据:  13%|█▎        | 916639/7086503 [03:20<1:06:33, 1544.94it/s]读取数据:  13%|█▎        | 916961/7086503 [03:20<1:00:40, 1694.47it/s]读取数据:  13%|█▎        | 917272/7086503 [03:20<1:02:22, 1648.42it/s]读取数据:  13%|█▎        | 917534/7086503 [03:21<1:06:47, 1539.50it/s]读取数据:  13%|█▎        | 917801/7086503 [03:21<1:01:16, 1677.99it/s]读取数据:  13%|█▎        | 918030/7086503 [03:21<1:23:52, 1225.62it/s]读取数据:  13%|█▎        | 918209/7086503 [03:22<2:54:59, 587.50it/s] 读取数据:  13%|█▎        | 918341/7086503 [03:22<2:41:04, 638.23it/s]读取数据:  13%|█▎        | 918559/7086503 [03:22<2:09:09, 795.88it/s]读取数据:  13%|█▎        | 918763/7086503 [03:22<1:47:41, 954.55it/s]读取数据:  13%|█▎        | 918932/7086503 [03:23<3:05:13, 554.94it/s]读取数据:  13%|█▎        | 919199/7086503 [03:23<2:13:08, 772.00it/s]读取数据:  13%|█▎        | 919504/7086503 [03:23<1:36:41, 1063.02it/s]读取数据:  13%|█▎        | 919793/7086503 [03:23<1:16:43, 1339.65it/s]读取数据:  13%|█▎        | 920024/7086503 [03:24<1:16:01, 1351.99it/s]读取数据:  13%|█▎        | 920227/7086503 [03:24<2:46:20, 617.85it/s] 读取数据:  13%|█▎        | 920377/7086503 [03:25<2:39:43, 643.38it/s]读取数据:  13%|█▎        | 920611/7086503 [03:25<2:26:52, 699.71it/s]读取数据:  13%|█▎        | 920871/7086503 [03:25<1:50:36, 929.03it/s]读取数据:  13%|█▎        | 921100/7086503 [03:25<1:30:59, 1129.31it/s]读取数据:  13%|█▎        | 921709/7086503 [03:25<51:36, 1991.06it/s]  读取数据:  13%|█▎        | 922726/7086503 [03:25<28:24, 3617.19it/s]读取数据:  13%|█▎        | 923909/7086503 [03:25<18:54, 5433.21it/s]读取数据:  13%|█▎        | 925023/7086503 [03:26<15:07, 6792.77it/s]读取数据:  13%|█▎        | 925968/7086503 [03:26<13:45, 7466.88it/s]读取数据:  13%|█▎        | 927117/7086503 [03:26<12:50, 7996.09it/s]读取数据:  13%|█▎        | 928675/7086503 [03:26<10:16, 9989.92it/s]读取数据:  13%|█▎        | 930153/7086503 [03:26<09:04, 11296.44it/s]读取数据:  13%|█▎        | 931681/7086503 [03:26<08:15, 12413.24it/s]读取数据:  13%|█▎        | 933204/7086503 [03:26<07:45, 13218.62it/s]读取数据:  13%|█▎        | 934613/7086503 [03:26<07:36, 13468.20it/s]读取数据:  13%|█▎        | 935993/7086503 [03:26<07:37, 13430.00it/s]读取数据:  13%|█▎        | 937359/7086503 [03:26<07:40, 13364.91it/s]读取数据:  13%|█▎        | 938712/7086503 [03:27<07:40, 13344.23it/s]读取数据:  13%|█▎        | 940058/7086503 [03:27<07:45, 13212.88it/s]读取数据:  13%|█▎        | 941388/7086503 [03:27<07:46, 13161.45it/s]读取数据:  13%|█▎        | 942710/7086503 [03:27<07:56, 12889.32it/s]读取数据:  13%|█▎        | 944004/7086503 [03:27<08:00, 12784.06it/s]读取数据:  13%|█▎        | 945286/7086503 [03:27<08:01, 12767.56it/s]读取数据:  13%|█▎        | 946565/7086503 [03:27<08:03, 12705.08it/s]读取数据:  13%|█▎        | 947878/7086503 [03:27<07:58, 12828.66it/s]读取数据:  13%|█▎        | 949206/7086503 [03:27<07:53, 12961.72it/s]读取数据:  13%|█▎        | 950504/7086503 [03:28<14:13, 7186.30it/s] 读取数据:  13%|█▎        | 951814/7086503 [03:28<12:18, 8310.52it/s]读取数据:  13%|█▎        | 953088/7086503 [03:28<11:02, 9256.51it/s]读取数据:  13%|█▎        | 954347/7086503 [03:28<10:11, 10035.71it/s]读取数据:  13%|█▎        | 955674/7086503 [03:28<09:25, 10845.70it/s]读取数据:  14%|█▎        | 956975/7086503 [03:28<08:57, 11412.48it/s]读取数据:  14%|█▎        | 958293/7086503 [03:28<08:35, 11893.95it/s]读取数据:  14%|█▎        | 959574/7086503 [03:28<08:24, 12150.88it/s]读取数据:  14%|█▎        | 960847/7086503 [03:29<08:17, 12313.44it/s]读取数据:  14%|█▎        | 962157/7086503 [03:29<08:08, 12541.57it/s]读取数据:  14%|█▎        | 963454/7086503 [03:29<08:03, 12666.38it/s]读取数据:  14%|█▎        | 964742/7086503 [03:29<08:01, 12706.21it/s]读取数据:  14%|█▎        | 966028/7086503 [03:29<08:06, 12583.37it/s]读取数据:  14%|█▎        | 967315/7086503 [03:29<08:03, 12663.04it/s]读取数据:  14%|█▎        | 968703/7086503 [03:29<07:49, 13019.43it/s]读取数据:  14%|█▎        | 970016/7086503 [03:29<07:48, 13050.24it/s]读取数据:  14%|█▎        | 971333/7086503 [03:29<07:47, 13084.49it/s]读取数据:  14%|█▎        | 972666/7086503 [03:29<07:44, 13156.73it/s]读取数据:  14%|█▎        | 973984/7086503 [03:30<07:45, 13141.90it/s]读取数据:  14%|█▍        | 975582/7086503 [03:30<07:16, 13988.37it/s]读取数据:  14%|█▍        | 977258/7086503 [03:30<06:52, 14817.26it/s]读取数据:  14%|█▍        | 978957/7086503 [03:30<06:34, 15466.12it/s]读取数据:  14%|█▍        | 980505/7086503 [03:30<06:57, 14637.64it/s]读取数据:  14%|█▍        | 981979/7086503 [03:30<07:29, 13578.67it/s]读取数据:  14%|█▍        | 983357/7086503 [03:30<07:54, 12859.25it/s]读取数据:  14%|█▍        | 984661/7086503 [03:30<08:04, 12600.28it/s]读取数据:  14%|█▍        | 985933/7086503 [03:30<08:18, 12233.15it/s]读取数据:  14%|█▍        | 987164/7086503 [03:31<08:28, 11997.52it/s]读取数据:  14%|█▍        | 988369/7086503 [03:31<08:29, 11966.89it/s]读取数据:  14%|█▍        | 989574/7086503 [03:31<08:28, 11989.72it/s]读取数据:  14%|█▍        | 990776/7086503 [03:31<08:37, 11783.28it/s]读取数据:  14%|█▍        | 991956/7086503 [03:31<08:42, 11673.71it/s]读取数据:  14%|█▍        | 993125/7086503 [03:31<08:48, 11539.90it/s]读取数据:  14%|█▍        | 994319/7086503 [03:31<08:42, 11655.45it/s]读取数据:  14%|█▍        | 995488/7086503 [03:31<08:42, 11664.70it/s]读取数据:  14%|█▍        | 996666/7086503 [03:31<08:40, 11698.34it/s]读取数据:  14%|█▍        | 997837/7086503 [03:32<08:41, 11685.88it/s]读取数据:  14%|█▍        | 999006/7086503 [03:32<08:45, 11577.57it/s]读取数据:  14%|█▍        | 999006/7086503 [03:44<08:45, 11577.57it/s]读取数据:  14%|█▍        | 1000000/7086503 [07:03<95:27:31, 17.71it/s]读取数据:  14%|█▍        | 1000994/7086503 [07:03<69:15:23, 24.41it/s]读取数据:  14%|█▍        | 1002153/7086503 [07:03<47:32:34, 35.55it/s]读取数据:  14%|█▍        | 1003432/7086503 [07:03<31:50:10, 53.08it/s]读取数据:  14%|█▍        | 1004658/7086503 [07:03<21:56:32, 76.99it/s]读取数据:  14%|█▍        | 1005845/7086503 [07:03<15:22:10, 109.90it/s]读取数据:  14%|█▍        | 1007018/7086503 [07:03<10:49:20, 156.04it/s]读取数据:  14%|█▍        | 1008191/7086503 [07:04<7:37:52, 221.25it/s] 读取数据:  14%|█▍        | 1009344/7086503 [07:04<5:25:04, 311.58it/s]读取数据:  14%|█▍        | 1010491/7086503 [07:04<3:51:29, 437.46it/s]读取数据:  14%|█▍        | 1011635/7086503 [07:04<2:45:27, 611.91it/s]读取数据:  14%|█▍        | 1012815/7086503 [07:04<1:57:43, 859.82it/s]读取数据:  14%|█▍        | 1013967/7086503 [07:04<1:25:21, 1185.66it/s]读取数据:  14%|█▍        | 1015137/7086503 [07:04<1:02:12, 1626.72it/s]读取数据:  14%|█▍        | 1016287/7086503 [07:04<47:47, 2116.90it/s]  读取数据:  14%|█▍        | 1017312/7086503 [07:05<38:20, 2637.82it/s]读取数据:  14%|█▍        | 1018255/7086503 [07:05<31:42, 3189.12it/s]读取数据:  14%|█▍        | 1019143/7086503 [07:05<27:01, 3741.58it/s]读取数据:  14%|█▍        | 1019983/7086503 [07:05<23:40, 4271.54it/s]读取数据:  14%|█▍        | 1020784/7086503 [07:05<21:20, 4736.45it/s]读取数据:  14%|█▍        | 1021549/7086503 [07:05<19:33, 5167.71it/s]读取数据:  14%|█▍        | 1022292/7086503 [07:05<18:09, 5565.05it/s]读取数据:  14%|█▍        | 1023024/7086503 [07:05<17:22, 5816.60it/s]读取数据:  14%|█▍        | 1023735/7086503 [07:05<16:45, 6027.83it/s]读取数据:  14%|█▍        | 1024433/7086503 [07:06<16:18, 6198.41it/s]读取数据:  14%|█▍        | 1025122/7086503 [07:06<15:58, 6322.94it/s]读取数据:  14%|█▍        | 1025804/7086503 [07:06<15:49, 6384.52it/s]读取数据:  14%|█▍        | 1026481/7086503 [07:06<15:34, 6487.84it/s]读取数据:  14%|█▍        | 1027156/7086503 [07:06<15:25, 6547.36it/s]读取数据:  15%|█▍        | 1027865/7086503 [07:06<15:03, 6703.07it/s]读取数据:  15%|█▍        | 1028549/7086503 [07:06<14:59, 6732.55it/s]读取数据:  15%|█▍        | 1029249/7086503 [07:06<14:49, 6809.40it/s]读取数据:  15%|█▍        | 1029966/7086503 [07:06<14:36, 6913.66it/s]读取数据:  15%|█▍        | 1030663/7086503 [07:06<14:39, 6885.17it/s]读取数据:  15%|█▍        | 1031355/7086503 [07:07<14:39, 6887.88it/s]读取数据:  15%|█▍        | 1032064/7086503 [07:07<14:32, 6940.22it/s]读取数据:  15%|█▍        | 1032760/7086503 [07:07<14:41, 6869.26it/s]读取数据:  15%|█▍        | 1033587/7086503 [07:07<13:51, 7283.77it/s]读取数据:  15%|█▍        | 1034387/7086503 [07:07<13:27, 7494.41it/s]读取数据:  15%|█▍        | 1035138/7086503 [07:07<13:43, 7346.33it/s]读取数据:  15%|█▍        | 1035875/7086503 [07:07<13:54, 7249.18it/s]读取数据:  15%|█▍        | 1036602/7086503 [07:07<13:54, 7248.96it/s]读取数据:  15%|█▍        | 1037328/7086503 [07:07<13:58, 7218.47it/s]读取数据:  15%|█▍        | 1038051/7086503 [07:07<14:11, 7103.11it/s]读取数据:  15%|█▍        | 1038762/7086503 [07:08<14:16, 7058.06it/s]读取数据:  15%|█▍        | 1039469/7086503 [07:08<14:19, 7036.72it/s]读取数据:  15%|█▍        | 1040173/7086503 [07:08<14:32, 6930.97it/s]读取数据:  15%|█▍        | 1040887/7086503 [07:08<14:24, 6989.25it/s]读取数据:  15%|█▍        | 1041587/7086503 [07:08<14:46, 6820.69it/s]读取数据:  15%|█▍        | 1042271/7086503 [07:08<15:29, 6501.57it/s]读取数据:  15%|█▍        | 1042925/7086503 [07:08<15:49, 6364.40it/s]读取数据:  15%|█▍        | 1043564/7086503 [07:08<16:03, 6272.22it/s]读取数据:  15%|█▍        | 1044193/7086503 [07:08<16:08, 6240.21it/s]读取数据:  15%|█▍        | 1044818/7086503 [07:09<16:26, 6124.51it/s]读取数据:  15%|█▍        | 1045432/7086503 [07:09<16:42, 6023.45it/s]读取数据:  15%|█▍        | 1046035/7086503 [07:09<16:57, 5938.92it/s]读取数据:  15%|█▍        | 1046630/7086503 [07:09<16:59, 5922.53it/s]读取数据:  15%|█▍        | 1047223/7086503 [07:09<17:09, 5868.03it/s]读取数据:  15%|█▍        | 1047810/7086503 [07:09<17:16, 5823.24it/s]读取数据:  15%|█▍        | 1048393/7086503 [07:09<17:31, 5739.92it/s]读取数据:  15%|█▍        | 1048978/7086503 [07:09<17:26, 5768.29it/s]读取数据:  15%|█▍        | 1049555/7086503 [07:09<17:27, 5764.04it/s]读取数据:  15%|█▍        | 1050132/7086503 [07:10<33:47, 2977.77it/s]读取数据:  15%|█▍        | 1050618/7086503 [07:10<30:22, 3312.69it/s]读取数据:  15%|█▍        | 1051096/7086503 [07:10<27:51, 3610.20it/s]读取数据:  15%|█▍        | 1051576/7086503 [07:10<25:57, 3875.31it/s]读取数据:  15%|█▍        | 1052054/7086503 [07:10<24:34, 4092.35it/s]读取数据:  15%|█▍        | 1052541/7086503 [07:10<23:25, 4292.64it/s]读取数据:  15%|█▍        | 1053022/7086503 [07:10<22:41, 4431.06it/s]读取数据:  15%|█▍        | 1053500/7086503 [07:10<22:14, 4522.05it/s]读取数据:  15%|█▍        | 1054000/7086503 [07:11<21:35, 4657.42it/s]读取数据:  15%|█▍        | 1054488/7086503 [07:11<21:17, 4719.90it/s]读取数据:  15%|█▍        | 1054973/7086503 [07:11<21:15, 4729.92it/s]读取数据:  15%|█▍        | 1055455/7086503 [07:11<21:25, 4692.18it/s]读取数据:  15%|█▍        | 1055931/7086503 [07:11<21:29, 4676.66it/s]读取数据:  15%|█▍        | 1056404/7086503 [07:11<21:44, 4621.21it/s]读取数据:  15%|█▍        | 1056870/7086503 [07:11<21:55, 4584.93it/s]读取数据:  15%|█▍        | 1057381/7086503 [07:11<21:12, 4737.77it/s]读取数据:  15%|█▍        | 1057936/7086503 [07:11<20:11, 4975.39it/s]读取数据:  15%|█▍        | 1058485/7086503 [07:11<19:35, 5126.21it/s]读取数据:  15%|█▍        | 1059047/7086503 [07:12<19:03, 5271.96it/s]读取数据:  15%|█▍        | 1059596/7086503 [07:12<18:49, 5335.24it/s]读取数据:  15%|█▍        | 1060142/7086503 [07:12<18:41, 5372.14it/s]读取数据:  15%|█▍        | 1060685/7086503 [07:12<18:38, 5387.46it/s]读取数据:  15%|█▍        | 1061249/7086503 [07:12<18:23, 5460.12it/s]读取数据:  15%|█▍        | 1061806/7086503 [07:12<18:17, 5491.20it/s]读取数据:  15%|█▍        | 1062366/7086503 [07:12<18:11, 5521.39it/s]读取数据:  15%|█▍        | 1062920/7086503 [07:12<18:10, 5525.35it/s]读取数据:  15%|█▌        | 1063475/7086503 [07:12<18:08, 5532.25it/s]读取数据:  15%|█▌        | 1064029/7086503 [07:12<18:16, 5492.14it/s]读取数据:  15%|█▌        | 1064598/7086503 [07:13<18:04, 5550.20it/s]读取数据:  15%|█▌        | 1065154/7086503 [07:13<18:09, 5528.44it/s]读取数据:  15%|█▌        | 1065726/7086503 [07:13<17:58, 5581.57it/s]读取数据:  15%|█▌        | 1066285/7086503 [07:13<18:06, 5539.00it/s]读取数据:  15%|█▌        | 1066859/7086503 [07:13<17:55, 5598.26it/s]读取数据:  15%|█▌        | 1067421/7086503 [07:13<17:54, 5600.62it/s]读取数据:  15%|█▌        | 1067982/7086503 [07:13<18:12, 5509.85it/s]读取数据:  15%|█▌        | 1068534/7086503 [07:13<18:41, 5367.62it/s]读取数据:  15%|█▌        | 1069105/7086503 [07:13<18:20, 5466.24it/s]读取数据:  15%|█▌        | 1069654/7086503 [07:14<18:19, 5473.03it/s]读取数据:  15%|█▌        | 1070202/7086503 [07:14<18:27, 5434.23it/s]读取数据:  15%|█▌        | 1070746/7086503 [07:14<18:28, 5427.72it/s]读取数据:  15%|█▌        | 1071291/7086503 [07:14<18:27, 5432.93it/s]读取数据:  15%|█▌        | 1071836/7086503 [07:14<18:27, 5432.39it/s]读取数据:  15%|█▌        | 1072380/7086503 [07:14<18:28, 5427.32it/s]读取数据:  15%|█▌        | 1072925/7086503 [07:14<18:26, 5432.59it/s]读取数据:  15%|█▌        | 1073469/7086503 [07:14<19:01, 5268.28it/s]读取数据:  15%|█▌        | 1073998/7086503 [07:14<18:59, 5274.30it/s]读取数据:  15%|█▌        | 1074558/7086503 [07:14<18:39, 5369.09it/s]读取数据:  15%|█▌        | 1075131/7086503 [07:15<18:17, 5475.72it/s]读取数据:  15%|█▌        | 1075708/7086503 [07:15<18:00, 5560.54it/s]读取数据:  15%|█▌        | 1076300/7086503 [07:15<17:41, 5664.27it/s]读取数据:  15%|█▌        | 1076887/7086503 [07:15<17:30, 5722.85it/s]读取数据:  15%|█▌        | 1077487/7086503 [07:15<17:15, 5805.23it/s]读取数据:  15%|█▌        | 1078068/7086503 [07:15<17:25, 5745.44it/s]读取数据:  15%|█▌        | 1078662/7086503 [07:15<17:15, 5800.87it/s]读取数据:  15%|█▌        | 1079261/7086503 [07:15<17:05, 5857.09it/s]读取数据:  15%|█▌        | 1079847/7086503 [07:15<17:07, 5846.56it/s]读取数据:  15%|█▌        | 1080432/7086503 [07:15<17:14, 5804.71it/s]读取数据:  15%|█▌        | 1081030/7086503 [07:16<17:05, 5854.50it/s]读取数据:  15%|█▌        | 1081616/7086503 [07:16<17:16, 5794.58it/s]读取数据:  15%|█▌        | 1082202/7086503 [07:16<17:12, 5813.31it/s]读取数据:  15%|█▌        | 1082825/7086503 [07:16<16:51, 5936.35it/s]读取数据:  15%|█▌        | 1083532/7086503 [07:16<15:57, 6271.80it/s]读取数据:  15%|█▌        | 1084184/7086503 [07:16<15:45, 6345.10it/s]读取数据:  15%|█▌        | 1084870/7086503 [07:16<15:23, 6498.73it/s]读取数据:  15%|█▌        | 1085577/7086503 [07:16<14:59, 6668.51it/s]读取数据:  15%|█▌        | 1086255/7086503 [07:16<14:55, 6700.77it/s]读取数据:  15%|█▌        | 1086935/7086503 [07:16<14:52, 6725.83it/s]读取数据:  15%|█▌        | 1087642/7086503 [07:17<14:39, 6824.10it/s]读取数据:  15%|█▌        | 1088341/7086503 [07:17<14:32, 6873.13it/s]读取数据:  15%|█▌        | 1089046/7086503 [07:17<14:26, 6919.64it/s]读取数据:  15%|█▌        | 1089767/7086503 [07:17<14:16, 7001.21it/s]读取数据:  15%|█▌        | 1090471/7086503 [07:17<14:15, 7012.00it/s]读取数据:  15%|█▌        | 1091173/7086503 [07:17<14:27, 6914.10it/s]读取数据:  15%|█▌        | 1091865/7086503 [07:17<15:03, 6633.42it/s]读取数据:  15%|█▌        | 1092531/7086503 [07:17<15:33, 6422.48it/s]读取数据:  15%|█▌        | 1093176/7086503 [07:17<15:59, 6243.37it/s]读取数据:  15%|█▌        | 1093808/7086503 [07:17<15:56, 6263.32it/s]读取数据:  15%|█▌        | 1094436/7086503 [07:18<15:59, 6247.20it/s]读取数据:  15%|█▌        | 1095062/7086503 [07:18<16:01, 6231.82it/s]读取数据:  15%|█▌        | 1095686/7086503 [07:18<16:13, 6157.05it/s]读取数据:  15%|█▌        | 1096303/7086503 [07:18<16:14, 6144.37it/s]读取数据:  15%|█▌        | 1096937/7086503 [07:18<16:06, 6198.40it/s]读取数据:  15%|█▌        | 1097562/7086503 [07:18<16:04, 6210.36it/s]读取数据:  15%|█▌        | 1098247/7086503 [07:18<15:36, 6394.57it/s]读取数据:  16%|█▌        | 1098887/7086503 [07:18<15:39, 6374.66it/s]读取数据:  16%|█▌        | 1099525/7086503 [07:18<16:00, 6235.89it/s]读取数据:  16%|█▌        | 1100150/7086503 [07:19<29:40, 3362.93it/s]读取数据:  16%|█▌        | 1100734/7086503 [07:19<26:07, 3818.86it/s]读取数据:  16%|█▌        | 1101332/7086503 [07:19<23:21, 4269.18it/s]读取数据:  16%|█▌        | 1101936/7086503 [07:19<21:20, 4675.20it/s]读取数据:  16%|█▌        | 1102506/7086503 [07:19<20:14, 4927.65it/s]读取数据:  16%|█▌        | 1103205/7086503 [07:19<18:15, 5464.13it/s]读取数据:  16%|█▌        | 1104359/7086503 [07:19<14:01, 7109.74it/s]读取数据:  16%|█▌        | 1105466/7086503 [07:19<12:08, 8214.48it/s]读取数据:  16%|█▌        | 1106615/7086503 [07:20<10:53, 9147.50it/s]读取数据:  16%|█▌        | 1107777/7086503 [07:20<10:06, 9862.83it/s]读取数据:  16%|█▌        | 1108999/7086503 [07:20<09:26, 10545.27it/s]读取数据:  16%|█▌        | 1110076/7086503 [07:20<10:00, 9951.06it/s] 读取数据:  16%|█▌        | 1111094/7086503 [07:20<13:06, 7597.59it/s]读取数据:  16%|█▌        | 1111950/7086503 [07:20<15:41, 6344.80it/s]读取数据:  16%|█▌        | 1112679/7086503 [07:20<17:20, 5741.57it/s]读取数据:  16%|█▌        | 1113321/7086503 [07:21<18:14, 5457.13it/s]读取数据:  16%|█▌        | 1113911/7086503 [07:21<19:11, 5186.41it/s]读取数据:  16%|█▌        | 1114471/7086503 [07:21<18:51, 5276.39it/s]读取数据:  16%|█▌        | 1115022/7086503 [07:21<18:56, 5253.19it/s]读取数据:  16%|█▌        | 1116311/7086503 [07:21<13:48, 7203.44it/s]读取数据:  16%|█▌        | 1117388/7086503 [07:21<12:11, 8155.12it/s]读取数据:  16%|█▌        | 1118497/7086503 [07:21<11:05, 8965.68it/s]读取数据:  16%|█▌        | 1119542/7086503 [07:21<10:35, 9385.63it/s]读取数据:  16%|█▌        | 1120583/7086503 [07:21<10:16, 9674.63it/s]读取数据:  16%|█▌        | 1121781/7086503 [07:22<09:36, 10343.92it/s]读取数据:  16%|█▌        | 1123005/7086503 [07:22<09:07, 10900.86it/s]读取数据:  16%|█▌        | 1124163/7086503 [07:22<08:57, 11101.30it/s]读取数据:  16%|█▌        | 1125379/7086503 [07:22<08:42, 11414.83it/s]读取数据:  16%|█▌        | 1126528/7086503 [07:22<08:58, 11063.25it/s]读取数据:  16%|█▌        | 1127642/7086503 [07:22<08:59, 11041.45it/s]读取数据:  16%|█▌        | 1128779/7086503 [07:22<08:55, 11133.50it/s]读取数据:  16%|█▌        | 1129896/7086503 [07:22<08:55, 11113.73it/s]读取数据:  16%|█▌        | 1131010/7086503 [07:22<09:05, 10911.86it/s]读取数据:  16%|█▌        | 1132104/7086503 [07:22<09:28, 10472.60it/s]读取数据:  16%|█▌        | 1133156/7086503 [07:23<09:30, 10433.67it/s]读取数据:  16%|█▌        | 1134203/7086503 [07:23<09:31, 10407.50it/s]读取数据:  16%|█▌        | 1135320/7086503 [07:23<09:19, 10629.44it/s]读取数据:  16%|█▌        | 1136386/7086503 [07:23<09:23, 10563.47it/s]读取数据:  16%|█▌        | 1137450/7086503 [07:23<09:22, 10584.54it/s]读取数据:  16%|█▌        | 1138513/7086503 [07:23<09:21, 10596.25it/s]读取数据:  16%|█▌        | 1139574/7086503 [07:23<09:23, 10548.81it/s]读取数据:  16%|█▌        | 1140685/7086503 [07:23<09:14, 10714.65it/s]读取数据:  16%|█▌        | 1141765/7086503 [07:23<09:13, 10738.06it/s]读取数据:  16%|█▌        | 1142840/7086503 [07:24<10:52, 9110.78it/s] 读取数据:  16%|█▌        | 1143794/7086503 [07:24<12:13, 8099.54it/s]读取数据:  16%|█▌        | 1144650/7086503 [07:24<13:10, 7520.30it/s]读取数据:  16%|█▌        | 1145437/7086503 [07:24<13:40, 7238.01it/s]读取数据:  16%|█▌        | 1146184/7086503 [07:24<13:58, 7082.54it/s]读取数据:  16%|█▌        | 1146907/7086503 [07:24<14:31, 6813.25it/s]读取数据:  16%|█▌        | 1147637/7086503 [07:24<14:15, 6939.87it/s]读取数据:  16%|█▌        | 1148573/7086503 [07:24<13:01, 7594.73it/s]读取数据:  16%|█▌        | 1149501/7086503 [07:24<12:16, 8056.20it/s]读取数据:  16%|█▌        | 1150319/7086503 [07:25<23:02, 4294.26it/s]读取数据:  16%|█▌        | 1151000/7086503 [07:25<20:52, 4740.66it/s]读取数据:  16%|█▋        | 1151669/7086503 [07:25<19:15, 5134.96it/s]读取数据:  16%|█▋        | 1152476/7086503 [07:25<17:04, 5790.93it/s]读取数据:  16%|█▋        | 1153296/7086503 [07:25<15:30, 6374.93it/s]读取数据:  16%|█▋        | 1154172/7086503 [07:25<14:08, 6988.39it/s]读取数据:  16%|█▋        | 1155249/7086503 [07:26<12:21, 8003.66it/s]读取数据:  16%|█▋        | 1156424/7086503 [07:26<10:55, 9041.80it/s]读取数据:  16%|█▋        | 1157644/7086503 [07:26<09:56, 9937.45it/s]读取数据:  16%|█▋        | 1158851/7086503 [07:26<09:21, 10550.64it/s]读取数据:  16%|█▋        | 1160076/7086503 [07:26<08:56, 11044.12it/s]读取数据:  16%|█▋        | 1161227/7086503 [07:26<08:50, 11179.40it/s]读取数据:  16%|█▋        | 1162363/7086503 [07:26<08:56, 11033.16it/s]读取数据:  16%|█▋        | 1163479/7086503 [07:26<09:04, 10870.93it/s]读取数据:  16%|█▋        | 1164576/7086503 [07:26<09:11, 10729.81it/s]读取数据:  16%|█▋        | 1165656/7086503 [07:26<09:16, 10637.13it/s]读取数据:  16%|█▋        | 1166780/7086503 [07:27<09:07, 10812.42it/s]读取数据:  16%|█▋        | 1167865/7086503 [07:27<09:09, 10778.16it/s]读取数据:  16%|█▋        | 1168946/7086503 [07:27<09:11, 10722.91it/s]读取数据:  17%|█▋        | 1170053/7086503 [07:27<09:06, 10823.74it/s]读取数据:  17%|█▋        | 1171157/7086503 [07:27<09:03, 10879.53it/s]读取数据:  17%|█▋        | 1172246/7086503 [07:27<09:06, 10813.15it/s]读取数据:  17%|█▋        | 1173329/7086503 [07:27<09:12, 10698.23it/s]读取数据:  17%|█▋        | 1174404/7086503 [07:27<09:11, 10712.88it/s]读取数据:  17%|█▋        | 1175504/7086503 [07:27<09:07, 10797.34it/s]读取数据:  17%|█▋        | 1176591/7086503 [07:27<09:06, 10815.33it/s]读取数据:  17%|█▋        | 1177694/7086503 [07:28<09:03, 10876.52it/s]读取数据:  17%|█▋        | 1178782/7086503 [07:28<09:14, 10660.07it/s]读取数据:  17%|█▋        | 1179850/7086503 [07:28<09:31, 10335.98it/s]读取数据:  17%|█▋        | 1180887/7086503 [07:28<09:47, 10057.30it/s]读取数据:  17%|█▋        | 1182001/7086503 [07:28<09:29, 10366.68it/s]读取数据:  17%|█▋        | 1183041/7086503 [07:28<09:36, 10244.19it/s]读取数据:  17%|█▋        | 1184068/7086503 [07:28<09:45, 10074.04it/s]读取数据:  17%|█▋        | 1185090/7086503 [07:28<09:43, 10115.41it/s]读取数据:  17%|█▋        | 1186103/7086503 [07:28<09:54, 9926.96it/s] 读取数据:  17%|█▋        | 1187098/7086503 [07:28<10:03, 9779.71it/s]读取数据:  17%|█▋        | 1188078/7086503 [07:29<10:10, 9655.59it/s]读取数据:  17%|█▋        | 1189045/7086503 [07:29<10:13, 9610.26it/s]读取数据:  17%|█▋        | 1190007/7086503 [07:29<10:16, 9565.06it/s]读取数据:  17%|█▋        | 1190964/7086503 [07:29<10:21, 9490.97it/s]读取数据:  17%|█▋        | 1191914/7086503 [07:29<10:24, 9444.75it/s]读取数据:  17%|█▋        | 1192859/7086503 [07:29<10:24, 9444.93it/s]读取数据:  17%|█▋        | 1193804/7086503 [07:29<10:26, 9408.67it/s]读取数据:  17%|█▋        | 1194756/7086503 [07:29<10:24, 9435.82it/s]读取数据:  17%|█▋        | 1196094/7086503 [07:29<09:15, 10606.70it/s]读取数据:  17%|█▋        | 1198362/7086503 [07:30<06:54, 14200.40it/s]读取数据:  17%|█▋        | 1200000/7086503 [07:30<11:37, 8441.16it/s] 读取数据:  17%|█▋        | 1201874/7086503 [07:30<09:23, 10447.51it/s]读取数据:  17%|█▋        | 1203230/7086503 [07:30<09:52, 9925.06it/s] 读取数据:  17%|█▋        | 1204441/7086503 [07:30<10:33, 9280.13it/s]读取数据:  17%|█▋        | 1205522/7086503 [07:30<11:10, 8776.09it/s]读取数据:  17%|█▋        | 1206504/7086503 [07:31<11:34, 8467.59it/s]读取数据:  17%|█▋        | 1207421/7086503 [07:31<12:07, 8082.53it/s]读取数据:  17%|█▋        | 1208275/7086503 [07:31<12:32, 7807.13it/s]读取数据:  17%|█▋        | 1209085/7086503 [07:31<13:06, 7475.12it/s]读取数据:  17%|█▋        | 1209851/7086503 [07:31<13:38, 7182.24it/s]读取数据:  17%|█▋        | 1210580/7086503 [07:31<13:51, 7069.85it/s]读取数据:  17%|█▋        | 1211293/7086503 [07:31<13:56, 7022.37it/s]读取数据:  17%|█▋        | 1211999/7086503 [07:31<14:00, 6990.42it/s]读取数据:  17%|█▋        | 1212701/7086503 [07:31<14:00, 6989.85it/s]读取数据:  17%|█▋        | 1213402/7086503 [07:32<14:03, 6959.73it/s]读取数据:  17%|█▋        | 1214099/7086503 [07:32<14:10, 6906.22it/s]读取数据:  17%|█▋        | 1215130/7086503 [07:32<12:24, 7886.07it/s]读取数据:  17%|█▋        | 1216349/7086503 [07:32<10:42, 9143.06it/s]读取数据:  17%|█▋        | 1217545/7086503 [07:32<09:48, 9968.90it/s]读取数据:  17%|█▋        | 1218777/7086503 [07:32<09:10, 10663.99it/s]读取数据:  17%|█▋        | 1220048/7086503 [07:32<08:40, 11271.36it/s]读取数据:  17%|█▋        | 1221241/7086503 [07:32<08:31, 11460.79it/s]读取数据:  17%|█▋        | 1222390/7086503 [07:32<08:58, 10886.35it/s]读取数据:  17%|█▋        | 1223487/7086503 [07:32<09:14, 10572.11it/s]读取数据:  17%|█▋        | 1224551/7086503 [07:33<09:30, 10278.91it/s]读取数据:  17%|█▋        | 1225585/7086503 [07:33<09:41, 10077.97it/s]读取数据:  17%|█▋        | 1226597/7086503 [07:33<09:47, 9973.90it/s] 读取数据:  17%|█▋        | 1227597/7086503 [07:33<10:03, 9700.80it/s]读取数据:  17%|█▋        | 1228641/7086503 [07:33<09:51, 9910.63it/s]读取数据:  17%|█▋        | 1229635/7086503 [07:33<09:54, 9849.71it/s]读取数据:  17%|█▋        | 1230622/7086503 [07:33<09:56, 9820.49it/s]读取数据:  17%|█▋        | 1231606/7086503 [07:33<09:56, 9807.69it/s]读取数据:  17%|█▋        | 1232610/7086503 [07:33<09:52, 9874.11it/s]读取数据:  17%|█▋        | 1233599/7086503 [07:34<09:56, 9806.05it/s]读取数据:  17%|█▋        | 1234587/7086503 [07:34<09:55, 9820.49it/s]读取数据:  17%|█▋        | 1235570/7086503 [07:34<10:09, 9593.38it/s]读取数据:  17%|█▋        | 1236572/7086503 [07:34<10:02, 9717.14it/s]读取数据:  17%|█▋        | 1237552/7086503 [07:34<10:00, 9737.92it/s]读取数据:  17%|█▋        | 1238528/7086503 [07:34<10:00, 9741.76it/s]读取数据:  17%|█▋        | 1239544/7086503 [07:34<09:53, 9857.74it/s]读取数据:  18%|█▊        | 1240531/7086503 [07:34<09:56, 9799.34it/s]读取数据:  18%|█▊        | 1241512/7086503 [07:34<09:57, 9789.64it/s]读取数据:  18%|█▊        | 1242535/7086503 [07:34<09:49, 9919.77it/s]读取数据:  18%|█▊        | 1243528/7086503 [07:35<09:59, 9743.80it/s]读取数据:  18%|█▊        | 1244559/7086503 [07:35<09:49, 9907.47it/s]读取数据:  18%|█▊        | 1245553/7086503 [07:35<09:49, 9910.56it/s]读取数据:  18%|█▊        | 1246545/7086503 [07:35<09:51, 9868.99it/s]读取数据:  18%|█▊        | 1247544/7086503 [07:35<09:49, 9901.94it/s]读取数据:  18%|█▊        | 1248535/7086503 [07:35<09:51, 9871.27it/s]读取数据:  18%|█▊        | 1249523/7086503 [07:35<09:58, 9745.46it/s]读取数据:  18%|█▊        | 1250498/7086503 [07:36<20:16, 4799.25it/s]读取数据:  18%|█▊        | 1251246/7086503 [07:36<20:12, 4811.94it/s]读取数据:  18%|█▊        | 1251915/7086503 [07:36<20:09, 4825.83it/s]读取数据:  18%|█▊        | 1252530/7086503 [07:36<20:08, 4828.49it/s]读取数据:  18%|█▊        | 1253106/7086503 [07:36<20:15, 4797.62it/s]读取数据:  18%|█▊        | 1253650/7086503 [07:36<20:22, 4771.02it/s]读取数据:  18%|█▊        | 1254172/7086503 [07:36<20:17, 4790.93it/s]读取数据:  18%|█▊        | 1254683/7086503 [07:36<20:19, 4782.47it/s]读取数据:  18%|█▊        | 1255184/7086503 [07:37<20:27, 4749.84it/s]读取数据:  18%|█▊        | 1255674/7086503 [07:37<20:43, 4688.15it/s]读取数据:  18%|█▊        | 1256153/7086503 [07:37<20:42, 4692.81it/s]读取数据:  18%|█▊        | 1256630/7086503 [07:37<20:46, 4676.33it/s]读取数据:  18%|█▊        | 1257356/7086503 [07:37<17:58, 5404.92it/s]读取数据:  18%|█▊        | 1258248/7086503 [07:37<15:08, 6412.85it/s]读取数据:  18%|█▊        | 1259241/7086503 [07:37<13:03, 7436.64it/s]读取数据:  18%|█▊        | 1260180/7086503 [07:37<12:07, 8006.22it/s]读取数据:  18%|█▊        | 1261044/7086503 [07:37<11:51, 8192.95it/s]读取数据:  18%|█▊        | 1261870/7086503 [07:37<12:02, 8056.79it/s]读取数据:  18%|█▊        | 1262689/7086503 [07:38<11:59, 8092.86it/s]读取数据:  18%|█▊        | 1263502/7086503 [07:38<12:21, 7849.15it/s]读取数据:  18%|█▊        | 1264291/7086503 [07:38<12:38, 7679.53it/s]读取数据:  18%|█▊        | 1265185/7086503 [07:38<12:04, 8037.55it/s]读取数据:  18%|█▊        | 1266429/7086503 [07:38<10:24, 9319.19it/s]读取数据:  18%|█▊        | 1267669/7086503 [07:38<09:29, 10224.37it/s]读取数据:  18%|█▊        | 1268983/7086503 [07:38<08:44, 11085.12it/s]读取数据:  18%|█▊        | 1270288/7086503 [07:38<08:18, 11668.20it/s]读取数据:  18%|█▊        | 1271581/7086503 [07:38<08:03, 12033.25it/s]读取数据:  18%|█▊        | 1273007/7086503 [07:39<07:38, 12691.72it/s]读取数据:  18%|█▊        | 1274569/7086503 [07:39<07:08, 13562.14it/s]读取数据:  18%|█▊        | 1276163/7086503 [07:39<06:47, 14272.35it/s]读取数据:  18%|█▊        | 1277724/7086503 [07:39<06:35, 14672.31it/s]读取数据:  18%|█▊        | 1279274/7086503 [07:39<06:29, 14920.01it/s]读取数据:  18%|█▊        | 1280767/7086503 [07:39<06:35, 14678.33it/s]读取数据:  18%|█▊        | 1282237/7086503 [07:39<06:58, 13875.52it/s]读取数据:  18%|█▊        | 1283635/7086503 [07:39<07:24, 13045.90it/s]读取数据:  18%|█▊        | 1284954/7086503 [07:39<08:07, 11890.37it/s]读取数据:  18%|█▊        | 1286168/7086503 [07:40<08:43, 11090.40it/s]读取数据:  18%|█▊        | 1287299/7086503 [07:40<08:45, 11027.95it/s]读取数据:  18%|█▊        | 1288541/7086503 [07:40<08:28, 11399.23it/s]读取数据:  18%|█▊        | 1290038/7086503 [07:40<07:48, 12385.01it/s]读取数据:  18%|█▊        | 1291435/7086503 [07:40<07:31, 12833.67it/s]读取数据:  18%|█▊        | 1292927/7086503 [07:40<07:11, 13434.93it/s]读取数据:  18%|█▊        | 1294406/7086503 [07:40<06:58, 13829.23it/s]读取数据:  18%|█▊        | 1295800/7086503 [07:40<07:13, 13347.76it/s]读取数据:  18%|█▊        | 1297146/7086503 [07:40<07:44, 12462.50it/s]读取数据:  18%|█▊        | 1298410/7086503 [07:40<08:08, 11850.71it/s]读取数据:  18%|█▊        | 1299610/7086503 [07:41<08:22, 11518.00it/s]读取数据:  18%|█▊        | 1300772/7086503 [07:41<15:36, 6179.27it/s] 读取数据:  18%|█▊        | 1301832/7086503 [07:41<13:52, 6944.61it/s]读取数据:  18%|█▊        | 1302896/7086503 [07:41<12:33, 7676.63it/s]读取数据:  18%|█▊        | 1304166/7086503 [07:41<10:58, 8781.12it/s]读取数据:  18%|█▊        | 1305430/7086503 [07:41<09:55, 9704.94it/s]读取数据:  18%|█▊        | 1306713/7086503 [07:42<09:10, 10500.95it/s]读取数据:  18%|█▊        | 1308051/7086503 [07:42<08:32, 11268.82it/s]读取数据:  18%|█▊        | 1309274/7086503 [07:42<08:21, 11511.88it/s]读取数据:  18%|█▊        | 1310561/7086503 [07:42<08:05, 11895.44it/s]读取数据:  19%|█▊        | 1311837/7086503 [07:42<07:55, 12142.69it/s]读取数据:  19%|█▊        | 1313088/7086503 [07:42<07:55, 12131.18it/s]读取数据:  19%|█▊        | 1314327/7086503 [07:42<07:53, 12199.64it/s]读取数据:  19%|█▊        | 1315582/7086503 [07:42<07:49, 12301.78it/s]读取数据:  19%|█▊        | 1316825/7086503 [07:42<07:48, 12326.90it/s]读取数据:  19%|█▊        | 1318070/7086503 [07:42<07:46, 12361.08it/s]读取数据:  19%|█▊        | 1319333/7086503 [07:43<07:43, 12439.78it/s]读取数据:  19%|█▊        | 1320627/7086503 [07:43<07:38, 12587.97it/s]读取数据:  19%|█▊        | 1321890/7086503 [07:43<07:42, 12466.54it/s]读取数据:  19%|█▊        | 1323209/7086503 [07:43<07:34, 12673.37it/s]读取数据:  19%|█▊        | 1324479/7086503 [07:43<07:37, 12586.30it/s]读取数据:  19%|█▊        | 1325750/7086503 [07:43<07:36, 12622.67it/s]读取数据:  19%|█▊        | 1327050/7086503 [07:43<07:32, 12733.77it/s]读取数据:  19%|█▊        | 1328329/7086503 [07:43<07:31, 12749.61it/s]读取数据:  19%|█▉        | 1329605/7086503 [07:43<08:13, 11669.62it/s]读取数据:  19%|█▉        | 1330790/7086503 [07:44<09:10, 10452.17it/s]读取数据:  19%|█▉        | 1331868/7086503 [07:44<09:44, 9842.88it/s] 读取数据:  19%|█▉        | 1332878/7086503 [07:44<10:17, 9318.80it/s]读取数据:  19%|█▉        | 1333829/7086503 [07:44<10:42, 8955.67it/s]读取数据:  19%|█▉        | 1334737/7086503 [07:44<11:08, 8607.67it/s]读取数据:  19%|█▉        | 1335606/7086503 [07:44<11:32, 8302.91it/s]读取数据:  19%|█▉        | 1336441/7086503 [07:44<11:55, 8033.07it/s]读取数据:  19%|█▉        | 1337247/7086503 [07:44<12:05, 7921.13it/s]读取数据:  19%|█▉        | 1338040/7086503 [07:44<12:12, 7846.62it/s]读取数据:  19%|█▉        | 1338825/7086503 [07:45<12:20, 7757.15it/s]读取数据:  19%|█▉        | 1339601/7086503 [07:45<12:30, 7662.12it/s]读取数据:  19%|█▉        | 1340367/7086503 [07:45<12:38, 7572.19it/s]读取数据:  19%|█▉        | 1341143/7086503 [07:45<12:33, 7624.86it/s]读取数据:  19%|█▉        | 1341906/7086503 [07:45<12:34, 7614.56it/s]读取数据:  19%|█▉        | 1342705/7086503 [07:45<12:23, 7724.08it/s]读取数据:  19%|█▉        | 1343478/7086503 [07:45<12:31, 7645.96it/s]读取数据:  19%|█▉        | 1344283/7086503 [07:45<12:19, 7764.70it/s]读取数据:  19%|█▉        | 1345060/7086503 [07:45<12:19, 7764.25it/s]读取数据:  19%|█▉        | 1345837/7086503 [07:45<12:21, 7745.87it/s]读取数据:  19%|█▉        | 1346619/7086503 [07:46<12:19, 7761.85it/s]读取数据:  19%|█▉        | 1347403/7086503 [07:46<12:17, 7782.72it/s]读取数据:  19%|█▉        | 1348182/7086503 [07:46<12:23, 7720.81it/s]读取数据:  19%|█▉        | 1348955/7086503 [07:46<12:26, 7687.14it/s]读取数据:  19%|█▉        | 1349724/7086503 [07:46<12:29, 7651.53it/s]读取数据:  19%|█▉        | 1350490/7086503 [07:46<27:07, 3524.23it/s]读取数据:  19%|█▉        | 1351073/7086503 [07:47<26:06, 3660.46it/s]读取数据:  19%|█▉        | 1351606/7086503 [07:47<25:22, 3767.30it/s]读取数据:  19%|█▉        | 1352103/7086503 [07:47<24:32, 3894.40it/s]读取数据:  19%|█▉        | 1352582/7086503 [07:47<24:04, 3968.88it/s]读取数据:  19%|█▉        | 1353044/7086503 [07:47<23:13, 4113.65it/s]读取数据:  19%|█▉        | 1353530/7086503 [07:47<22:14, 4295.65it/s]读取数据:  19%|█▉        | 1354019/7086503 [07:47<21:29, 4445.75it/s]读取数据:  19%|█▉        | 1354512/7086503 [07:47<20:53, 4573.78it/s]读取数据:  19%|█▉        | 1355007/7086503 [07:47<20:25, 4675.89it/s]读取数据:  19%|█▉        | 1355500/7086503 [07:48<20:07, 4746.58it/s]读取数据:  19%|█▉        | 1356040/7086503 [07:48<19:21, 4933.76it/s]读取数据:  19%|█▉        | 1356582/7086503 [07:48<18:48, 5075.30it/s]读取数据:  19%|█▉        | 1357157/7086503 [07:48<18:06, 5273.01it/s]读取数据:  19%|█▉        | 1357716/7086503 [07:48<17:47, 5364.86it/s]读取数据:  19%|█▉        | 1358286/7086503 [07:48<17:28, 5464.09it/s]读取数据:  19%|█▉        | 1358870/7086503 [07:48<17:07, 5575.06it/s]读取数据:  19%|█▉        | 1359469/7086503 [07:48<16:45, 5695.90it/s]读取数据:  19%|█▉        | 1360096/7086503 [07:48<16:16, 5864.77it/s]读取数据:  19%|█▉        | 1360729/7086503 [07:48<15:54, 5999.98it/s]读取数据:  19%|█▉        | 1361330/7086503 [07:49<15:57, 5979.07it/s]读取数据:  19%|█▉        | 1361968/7086503 [07:49<15:38, 6098.40it/s]读取数据:  19%|█▉        | 1362918/7086503 [07:49<13:24, 7113.97it/s]读取数据:  19%|█▉        | 1363909/7086503 [07:49<11:59, 7948.14it/s]读取数据:  19%|█▉        | 1364932/7086503 [07:49<11:02, 8630.36it/s]读取数据:  19%|█▉        | 1366005/7086503 [07:49<10:18, 9249.73it/s]读取数据:  19%|█▉        | 1367054/7086503 [07:49<09:54, 9619.90it/s]读取数据:  19%|█▉        | 1368154/7086503 [07:49<09:29, 10032.84it/s]读取数据:  19%|█▉        | 1369216/7086503 [07:49<09:20, 10207.47it/s]读取数据:  19%|█▉        | 1370252/7086503 [07:49<09:17, 10250.15it/s]读取数据:  19%|█▉        | 1371299/7086503 [07:50<09:14, 10310.48it/s]读取数据:  19%|█▉        | 1372363/7086503 [07:50<09:08, 10408.32it/s]读取数据:  19%|█▉        | 1373404/7086503 [07:50<09:08, 10407.59it/s]读取数据:  19%|█▉        | 1374481/7086503 [07:50<09:03, 10516.09it/s]读取数据:  19%|█▉        | 1375554/7086503 [07:50<08:59, 10577.73it/s]读取数据:  19%|█▉        | 1376612/7086503 [07:50<09:07, 10427.16it/s]读取数据:  19%|█▉        | 1377656/7086503 [07:50<09:12, 10334.48it/s]读取数据:  19%|█▉        | 1378690/7086503 [07:50<09:34, 9927.50it/s] 读取数据:  19%|█▉        | 1379687/7086503 [07:50<10:11, 9333.47it/s]读取数据:  19%|█▉        | 1380629/7086503 [07:51<10:51, 8756.37it/s]读取数据:  19%|█▉        | 1381515/7086503 [07:51<12:06, 7854.86it/s]读取数据:  20%|█▉        | 1382321/7086503 [07:51<12:44, 7459.88it/s]读取数据:  20%|█▉        | 1383081/7086503 [07:51<13:08, 7230.07it/s]读取数据:  20%|█▉        | 1383813/7086503 [07:51<13:47, 6893.95it/s]读取数据:  20%|█▉        | 1384509/7086503 [07:51<14:07, 6728.25it/s]读取数据:  20%|█▉        | 1385185/7086503 [07:51<14:14, 6671.49it/s]读取数据:  20%|█▉        | 1385854/7086503 [07:51<14:29, 6557.08it/s]读取数据:  20%|█▉        | 1386511/7086503 [07:51<14:56, 6357.63it/s]读取数据:  20%|█▉        | 1387148/7086503 [07:52<15:12, 6247.65it/s]读取数据:  20%|█▉        | 1387792/7086503 [07:52<15:04, 6301.44it/s]读取数据:  20%|█▉        | 1388423/7086503 [07:52<15:05, 6291.83it/s]读取数据:  20%|█▉        | 1389058/7086503 [07:52<15:03, 6307.81it/s]读取数据:  20%|█▉        | 1389695/7086503 [07:52<15:01, 6321.05it/s]读取数据:  20%|█▉        | 1390335/7086503 [07:52<14:57, 6344.23it/s]读取数据:  20%|█▉        | 1390996/7086503 [07:52<14:47, 6418.79it/s]读取数据:  20%|█▉        | 1391646/7086503 [07:52<14:43, 6442.55it/s]读取数据:  20%|█▉        | 1392293/7086503 [07:52<14:42, 6450.49it/s]读取数据:  20%|█▉        | 1392941/7086503 [07:52<14:41, 6455.88it/s]读取数据:  20%|█▉        | 1393587/7086503 [07:53<15:19, 6190.45it/s]读取数据:  20%|█▉        | 1394209/7086503 [07:53<15:19, 6188.15it/s]读取数据:  20%|█▉        | 1394830/7086503 [07:53<15:23, 6163.87it/s]读取数据:  20%|█▉        | 1395448/7086503 [07:53<15:26, 6142.54it/s]读取数据:  20%|█▉        | 1396064/7086503 [07:53<15:28, 6130.06it/s]读取数据:  20%|█▉        | 1396678/7086503 [07:53<15:34, 6086.52it/s]读取数据:  20%|█▉        | 1397300/7086503 [07:53<15:28, 6125.54it/s]读取数据:  20%|█▉        | 1397933/7086503 [07:53<15:20, 6182.37it/s]读取数据:  20%|█▉        | 1398555/7086503 [07:53<15:18, 6189.45it/s]读取数据:  20%|█▉        | 1399182/7086503 [07:53<15:15, 6212.55it/s]读取数据:  20%|█▉        | 1400000/7086503 [07:54<27:45, 3414.12it/s]读取数据:  20%|█▉        | 1400492/7086503 [07:54<26:28, 3579.68it/s]读取数据:  20%|█▉        | 1400984/7086503 [07:54<24:39, 3841.97it/s]读取数据:  20%|█▉        | 1401462/7086503 [07:54<24:06, 3929.28it/s]读取数据:  20%|█▉        | 1401923/7086503 [07:54<23:22, 4052.91it/s]读取数据:  20%|█▉        | 1402407/7086503 [07:54<22:18, 4245.63it/s]读取数据:  20%|█▉        | 1402871/7086503 [07:55<21:58, 4310.12it/s]读取数据:  20%|█▉        | 1403331/7086503 [07:55<21:55, 4321.72it/s]读取数据:  20%|█▉        | 1403783/7086503 [07:55<22:08, 4277.34it/s]读取数据:  20%|█▉        | 1404227/7086503 [07:55<21:55, 4320.80it/s]读取数据:  20%|█▉        | 1404728/7086503 [07:55<20:58, 4513.85it/s]读取数据:  20%|█▉        | 1405188/7086503 [07:55<21:05, 4488.24it/s]读取数据:  20%|█▉        | 1405655/7086503 [07:55<20:51, 4538.36it/s]读取数据:  20%|█▉        | 1406152/7086503 [07:55<20:17, 4664.51it/s]读取数据:  20%|█▉        | 1406622/7086503 [07:55<20:25, 4635.62it/s]读取数据:  20%|█▉        | 1407107/7086503 [07:55<20:09, 4697.50it/s]读取数据:  20%|█▉        | 1407579/7086503 [07:56<21:08, 4475.85it/s]读取数据:  20%|█▉        | 1408030/7086503 [07:56<21:23, 4425.21it/s]读取数据:  20%|█▉        | 1408483/7086503 [07:56<21:14, 4453.69it/s]读取数据:  20%|█▉        | 1408957/7086503 [07:56<20:52, 4534.45it/s]读取数据:  20%|█▉        | 1409427/7086503 [07:56<20:38, 4582.10it/s]读取数据:  20%|█▉        | 1409912/7086503 [07:56<20:18, 4658.26it/s]读取数据:  20%|█▉        | 1410406/7086503 [07:56<19:58, 4737.69it/s]读取数据:  20%|█▉        | 1410911/7086503 [07:56<19:35, 4828.53it/s]读取数据:  20%|█▉        | 1411405/7086503 [07:56<19:27, 4860.25it/s]读取数据:  20%|█▉        | 1411914/7086503 [07:57<19:12, 4924.74it/s]读取数据:  20%|█▉        | 1412448/7086503 [07:57<18:44, 5047.31it/s]读取数据:  20%|█▉        | 1412959/7086503 [07:57<18:40, 5063.61it/s]读取数据:  20%|█▉        | 1413477/7086503 [07:57<18:33, 5094.87it/s]读取数据:  20%|█▉        | 1414002/7086503 [07:57<18:24, 5137.55it/s]读取数据:  20%|█▉        | 1414538/7086503 [07:57<18:10, 5203.38it/s]读取数据:  20%|█▉        | 1415076/7086503 [07:57<17:59, 5253.40it/s]读取数据:  20%|█▉        | 1415602/7086503 [07:57<18:02, 5237.66it/s]读取数据:  20%|█▉        | 1416142/7086503 [07:57<17:53, 5284.25it/s]读取数据:  20%|█▉        | 1416671/7086503 [07:57<18:00, 5248.41it/s]读取数据:  20%|█▉        | 1417203/7086503 [07:58<17:56, 5268.83it/s]读取数据:  20%|██        | 1417755/7086503 [07:58<17:41, 5341.93it/s]读取数据:  20%|██        | 1418311/7086503 [07:58<17:28, 5406.74it/s]读取数据:  20%|██        | 1418852/7086503 [07:58<17:37, 5358.20it/s]读取数据:  20%|██        | 1419411/7086503 [07:58<17:24, 5425.54it/s]读取数据:  20%|██        | 1419954/7086503 [07:58<17:26, 5412.96it/s]读取数据:  20%|██        | 1420496/7086503 [07:58<17:34, 5375.19it/s]读取数据:  20%|██        | 1421034/7086503 [07:58<17:42, 5333.04it/s]读取数据:  20%|██        | 1421569/7086503 [07:58<17:41, 5336.68it/s]读取数据:  20%|██        | 1422119/7086503 [07:58<17:31, 5385.14it/s]读取数据:  20%|██        | 1422658/7086503 [07:59<17:34, 5368.59it/s]读取数据:  20%|██        | 1423195/7086503 [07:59<17:44, 5321.70it/s]读取数据:  20%|██        | 1423728/7086503 [07:59<17:59, 5245.17it/s]读取数据:  20%|██        | 1424253/7086503 [07:59<18:15, 5170.59it/s]读取数据:  20%|██        | 1424771/7086503 [07:59<18:21, 5138.59it/s]读取数据:  20%|██        | 1425288/7086503 [07:59<18:20, 5145.43it/s]读取数据:  20%|██        | 1425814/7086503 [07:59<18:12, 5179.05it/s]读取数据:  20%|██        | 1426342/7086503 [07:59<18:06, 5207.81it/s]读取数据:  20%|██        | 1426864/7086503 [07:59<18:06, 5210.89it/s]读取数据:  20%|██        | 1427395/7086503 [07:59<18:00, 5239.17it/s]读取数据:  20%|██        | 1427929/7086503 [08:00<17:54, 5268.49it/s]读取数据:  20%|██        | 1428461/7086503 [08:00<17:50, 5282.96it/s]读取数据:  20%|██        | 1429004/7086503 [08:00<17:42, 5323.88it/s]读取数据:  20%|██        | 1429543/7086503 [08:00<17:39, 5340.38it/s]读取数据:  20%|██        | 1430078/7086503 [08:00<17:46, 5304.30it/s]读取数据:  20%|██        | 1430623/7086503 [08:00<17:38, 5345.68it/s]读取数据:  20%|██        | 1431176/7086503 [08:00<17:27, 5400.07it/s]读取数据:  20%|██        | 1431717/7086503 [08:00<17:29, 5389.45it/s]读取数据:  20%|██        | 1432257/7086503 [08:00<17:43, 5316.91it/s]读取数据:  20%|██        | 1432789/7086503 [08:00<17:56, 5251.57it/s]读取数据:  20%|██        | 1433326/7086503 [08:01<17:49, 5283.76it/s]读取数据:  20%|██        | 1433855/7086503 [08:01<17:56, 5250.83it/s]读取数据:  20%|██        | 1434381/7086503 [08:01<17:58, 5238.32it/s]读取数据:  20%|██        | 1434905/7086503 [08:01<18:12, 5175.00it/s]读取数据:  20%|██        | 1435423/7086503 [08:01<18:22, 5126.19it/s]读取数据:  20%|██        | 1435936/7086503 [08:01<18:22, 5124.85it/s]读取数据:  20%|██        | 1436449/7086503 [08:01<18:35, 5065.81it/s]读取数据:  20%|██        | 1436992/7086503 [08:01<18:12, 5170.19it/s]读取数据:  20%|██        | 1437510/7086503 [08:01<18:12, 5169.68it/s]读取数据:  20%|██        | 1438039/7086503 [08:01<18:05, 5204.64it/s]读取数据:  20%|██        | 1438560/7086503 [08:02<18:08, 5190.37it/s]读取数据:  20%|██        | 1439109/7086503 [08:02<17:50, 5276.83it/s]读取数据:  20%|██        | 1439680/7086503 [08:02<17:25, 5401.46it/s]读取数据:  20%|██        | 1440232/7086503 [08:02<17:18, 5436.37it/s]读取数据:  20%|██        | 1440776/7086503 [08:02<17:24, 5403.77it/s]读取数据:  20%|██        | 1441317/7086503 [08:02<17:24, 5403.08it/s]读取数据:  20%|██        | 1441860/7086503 [08:02<17:23, 5410.82it/s]读取数据:  20%|██        | 1442402/7086503 [08:02<17:24, 5404.94it/s]读取数据:  20%|██        | 1442943/7086503 [08:02<17:31, 5364.85it/s]读取数据:  20%|██        | 1443480/7086503 [08:02<17:44, 5298.96it/s]读取数据:  20%|██        | 1444027/7086503 [08:03<17:34, 5349.40it/s]读取数据:  20%|██        | 1444573/7086503 [08:03<17:29, 5375.95it/s]读取数据:  20%|██        | 1445148/7086503 [08:03<17:08, 5487.20it/s]读取数据:  20%|██        | 1445787/7086503 [08:03<16:20, 5751.93it/s]读取数据:  20%|██        | 1446467/7086503 [08:03<15:30, 6064.06it/s]读取数据:  20%|██        | 1447126/7086503 [08:03<15:07, 6215.51it/s]读取数据:  20%|██        | 1447797/7086503 [08:03<14:46, 6362.36it/s]读取数据:  20%|██        | 1448463/7086503 [08:03<14:34, 6450.49it/s]读取数据:  20%|██        | 1449142/7086503 [08:03<14:20, 6550.33it/s]读取数据:  20%|██        | 1449821/7086503 [08:03<14:11, 6620.88it/s]读取数据:  20%|██        | 1450484/7086503 [08:04<29:06, 3226.65it/s]读取数据:  20%|██        | 1451047/7086503 [08:04<25:47, 3641.18it/s]读取数据:  20%|██        | 1451629/7086503 [08:04<23:03, 4071.92it/s]读取数据:  20%|██        | 1452269/7086503 [08:04<20:29, 4583.55it/s]读取数据:  21%|██        | 1452840/7086503 [08:04<20:01, 4689.29it/s]读取数据:  21%|██        | 1453483/7086503 [08:04<18:20, 5119.75it/s]读取数据:  21%|██        | 1454078/7086503 [08:05<17:35, 5336.63it/s]读取数据:  21%|██        | 1454714/7086503 [08:05<16:42, 5615.08it/s]读取数据:  21%|██        | 1455322/7086503 [08:05<16:20, 5743.03it/s]读取数据:  21%|██        | 1455967/7086503 [08:05<15:47, 5944.49it/s]读取数据:  21%|██        | 1456603/7086503 [08:05<15:28, 6064.16it/s]读取数据:  21%|██        | 1457245/7086503 [08:05<15:12, 6167.93it/s]读取数据:  21%|██        | 1457894/7086503 [08:05<14:59, 6259.37it/s]读取数据:  21%|██        | 1458533/7086503 [08:05<14:53, 6297.01it/s]读取数据:  21%|██        | 1459186/7086503 [08:05<14:43, 6366.16it/s]读取数据:  21%|██        | 1459827/7086503 [08:05<14:43, 6371.29it/s]读取数据:  21%|██        | 1460501/7086503 [08:06<14:28, 6481.21it/s]读取数据:  21%|██        | 1461158/7086503 [08:06<14:24, 6506.16it/s]读取数据:  21%|██        | 1461830/7086503 [08:06<14:16, 6569.53it/s]读取数据:  21%|██        | 1462500/7086503 [08:06<14:11, 6606.92it/s]读取数据:  21%|██        | 1463200/7086503 [08:06<13:56, 6723.43it/s]读取数据:  21%|██        | 1463873/7086503 [08:06<14:05, 6646.47it/s]读取数据:  21%|██        | 1464547/7086503 [08:06<14:02, 6672.23it/s]读取数据:  21%|██        | 1465218/7086503 [08:06<14:01, 6682.82it/s]读取数据:  21%|██        | 1465908/7086503 [08:06<13:53, 6746.05it/s]读取数据:  21%|██        | 1466583/7086503 [08:06<13:57, 6706.45it/s]读取数据:  21%|██        | 1467254/7086503 [08:07<14:02, 6668.59it/s]读取数据:  21%|██        | 1467922/7086503 [08:07<14:07, 6630.81it/s]读取数据:  21%|██        | 1468599/7086503 [08:07<14:02, 6670.88it/s]读取数据:  21%|██        | 1469276/7086503 [08:07<13:58, 6700.09it/s]读取数据:  21%|██        | 1469977/7086503 [08:07<13:47, 6791.05it/s]读取数据:  21%|██        | 1470657/7086503 [08:07<13:57, 6704.91it/s]读取数据:  21%|██        | 1471349/7086503 [08:07<13:49, 6765.42it/s]读取数据:  21%|██        | 1472051/7086503 [08:07<13:40, 6839.57it/s]读取数据:  21%|██        | 1472762/7086503 [08:07<13:31, 6918.24it/s]读取数据:  21%|██        | 1473517/7086503 [08:07<13:09, 7105.86it/s]读取数据:  21%|██        | 1474291/7086503 [08:08<12:49, 7293.52it/s]读取数据:  21%|██        | 1475111/7086503 [08:08<12:21, 7564.61it/s]读取数据:  21%|██        | 1476012/7086503 [08:08<11:41, 7995.24it/s]读取数据:  21%|██        | 1476957/7086503 [08:08<11:05, 8430.13it/s]读取数据:  21%|██        | 1478021/7086503 [08:08<10:16, 9090.27it/s]读取数据:  21%|██        | 1479082/7086503 [08:08<09:47, 9537.48it/s]读取数据:  21%|██        | 1480559/7086503 [08:08<08:24, 11104.30it/s]读取数据:  21%|██        | 1482188/7086503 [08:08<07:22, 12654.33it/s]读取数据:  21%|██        | 1483951/7086503 [08:08<06:36, 14144.17it/s]读取数据:  21%|██        | 1485619/7086503 [08:08<06:15, 14900.68it/s]读取数据:  21%|██        | 1487433/7086503 [08:09<05:52, 15870.39it/s]读取数据:  21%|██        | 1489482/7086503 [08:09<05:24, 17254.85it/s]读取数据:  21%|██        | 1491543/7086503 [08:09<05:06, 18259.08it/s]读取数据:  21%|██        | 1493600/7086503 [08:09<04:55, 18950.09it/s]读取数据:  21%|██        | 1495649/7086503 [08:09<04:48, 19408.57it/s]读取数据:  21%|██        | 1497823/7086503 [08:09<04:37, 20107.12it/s]读取数据:  21%|██        | 1499985/7086503 [08:09<04:31, 20560.06it/s]读取数据:  21%|██        | 1499985/7086503 [08:25<04:31, 20560.06it/s]读取数据:  21%|██        | 1500000/7086503 [13:53<110:48:24, 14.00it/s]读取数据:  21%|██        | 1500076/7086503 [13:53<108:24:25, 14.31it/s]读取数据:  21%|██        | 1501538/7086503 [13:53<67:35:24, 22.95it/s] 读取数据:  21%|██        | 1502717/7086503 [13:53<47:08:24, 32.90it/s]读取数据:  21%|██        | 1503884/7086503 [13:53<33:02:14, 46.94it/s]读取数据:  21%|██        | 1505059/7086503 [13:53<23:06:52, 67.07it/s]读取数据:  21%|██▏       | 1506205/7086503 [13:53<16:19:34, 94.94it/s]读取数据:  21%|██▏       | 1507275/7086503 [13:54<11:45:23, 131.82it/s]读取数据:  21%|██▏       | 1508377/7086503 [13:54<8:20:51, 185.62it/s] 读取数据:  21%|██▏       | 1509510/7086503 [13:54<5:52:15, 263.87it/s]读取数据:  21%|██▏       | 1510740/7086503 [13:54<4:02:22, 383.41it/s]读取数据:  21%|██▏       | 1512206/7086503 [13:54<2:39:19, 583.09it/s]读取数据:  21%|██▏       | 1513706/7086503 [13:54<1:47:18, 865.54it/s]读取数据:  21%|██▏       | 1514997/7086503 [13:54<1:18:19, 1185.49it/s]读取数据:  21%|██▏       | 1516506/7086503 [13:54<54:31, 1702.70it/s]  读取数据:  21%|██▏       | 1518039/7086503 [13:54<38:50, 2389.60it/s]读取数据:  21%|██▏       | 1519674/7086503 [13:55<27:54, 3324.90it/s]读取数据:  21%|██▏       | 1521117/7086503 [13:55<22:22, 4146.76it/s]读取数据:  21%|██▏       | 1522903/7086503 [13:55<16:29, 5623.46it/s]读取数据:  22%|██▏       | 1524697/7086503 [13:55<12:45, 7265.46it/s]读取数据:  22%|██▏       | 1526313/7086503 [13:55<10:40, 8687.67it/s]读取数据:  22%|██▏       | 1528138/7086503 [13:55<08:51, 10448.69it/s]读取数据:  22%|██▏       | 1529790/7086503 [13:55<07:54, 11720.24it/s]读取数据:  22%|██▏       | 1531437/7086503 [13:55<07:24, 12494.23it/s]读取数据:  22%|██▏       | 1533035/7086503 [13:56<09:21, 9891.28it/s] 读取数据:  22%|██▏       | 1534570/7086503 [13:56<08:24, 11008.51it/s]读取数据:  22%|██▏       | 1536060/7086503 [13:56<07:47, 11883.68it/s]读取数据:  22%|██▏       | 1537473/7086503 [13:56<08:25, 10979.12it/s]读取数据:  22%|██▏       | 1539465/7086503 [13:56<07:03, 13083.53it/s]读取数据:  22%|██▏       | 1540948/7086503 [13:56<08:04, 11437.75it/s]读取数据:  22%|██▏       | 1543045/7086503 [13:56<06:45, 13660.69it/s]读取数据:  22%|██▏       | 1544920/7086503 [13:56<06:11, 14929.65it/s]读取数据:  22%|██▏       | 1546558/7086503 [13:57<08:02, 11491.25it/s]读取数据:  22%|██▏       | 1548155/7086503 [13:57<07:23, 12475.78it/s]读取数据:  22%|██▏       | 1549589/7086503 [13:57<07:09, 12886.11it/s]读取数据:  22%|██▏       | 1551018/7086503 [13:57<14:22, 6419.46it/s] 读取数据:  22%|██▏       | 1552101/7086503 [13:57<13:15, 6954.30it/s]读取数据:  22%|██▏       | 1553149/7086503 [13:58<12:12, 7550.36it/s]读取数据:  22%|██▏       | 1554194/7086503 [13:58<11:54, 7737.61it/s]读取数据:  22%|██▏       | 1555395/7086503 [13:58<10:39, 8643.43it/s]读取数据:  22%|██▏       | 1556841/7086503 [13:58<09:13, 9997.19it/s]读取数据:  22%|██▏       | 1558511/7086503 [13:58<07:53, 11669.94it/s]读取数据:  22%|██▏       | 1560223/7086503 [13:58<07:01, 13100.63it/s]读取数据:  22%|██▏       | 1561709/7086503 [13:58<06:46, 13579.77it/s]读取数据:  22%|██▏       | 1563771/7086503 [13:58<05:55, 15554.57it/s]读取数据:  22%|██▏       | 1565405/7086503 [13:58<06:11, 14875.52it/s]读取数据:  22%|██▏       | 1566954/7086503 [13:58<06:10, 14897.46it/s]读取数据:  22%|██▏       | 1568487/7086503 [13:59<06:31, 14111.76it/s]读取数据:  22%|██▏       | 1570194/7086503 [13:59<06:09, 14924.00it/s]读取数据:  22%|██▏       | 1571720/7086503 [13:59<06:12, 14802.21it/s]读取数据:  22%|██▏       | 1573223/7086503 [13:59<06:45, 13605.78it/s]读取数据:  22%|██▏       | 1574615/7086503 [13:59<06:50, 13438.75it/s]读取数据:  22%|██▏       | 1576196/7086503 [13:59<06:31, 14090.45it/s]读取数据:  22%|██▏       | 1578142/7086503 [13:59<05:53, 15602.02it/s]读取数据:  22%|██▏       | 1579726/7086503 [13:59<05:55, 15483.24it/s]读取数据:  22%|██▏       | 1581291/7086503 [13:59<06:41, 13707.46it/s]读取数据:  22%|██▏       | 1583136/7086503 [14:00<06:07, 14969.78it/s]读取数据:  22%|██▏       | 1584717/7086503 [14:00<06:01, 15201.35it/s]读取数据:  22%|██▏       | 1586273/7086503 [14:00<08:13, 11140.18it/s]读取数据:  22%|██▏       | 1587632/7086503 [14:00<07:50, 11696.55it/s]读取数据:  22%|██▏       | 1588943/7086503 [14:00<08:04, 11358.00it/s]读取数据:  22%|██▏       | 1590177/7086503 [14:00<08:57, 10224.85it/s]读取数据:  22%|██▏       | 1591512/7086503 [14:00<08:21, 10968.03it/s]读取数据:  22%|██▏       | 1593474/7086503 [14:01<06:57, 13154.64it/s]读取数据:  23%|██▎       | 1594891/7086503 [14:01<06:49, 13421.12it/s]读取数据:  23%|██▎       | 1596841/7086503 [14:01<06:03, 15085.18it/s]读取数据:  23%|██▎       | 1598956/7086503 [14:01<05:26, 16795.84it/s]读取数据:  23%|██▎       | 1600691/7086503 [14:01<11:56, 7659.26it/s] 读取数据:  23%|██▎       | 1602107/7086503 [14:01<10:32, 8675.64it/s]读取数据:  23%|██▎       | 1603452/7086503 [14:02<09:50, 9277.64it/s]读取数据:  23%|██▎       | 1605382/7086503 [14:02<08:04, 11301.63it/s]读取数据:  23%|██▎       | 1607168/7086503 [14:02<07:09, 12763.16it/s]读取数据:  23%|██▎       | 1608746/7086503 [14:02<06:45, 13492.55it/s]读取数据:  23%|██▎       | 1610319/7086503 [14:02<06:45, 13501.64it/s]读取数据:  23%|██▎       | 1612162/7086503 [14:02<06:10, 14784.24it/s]读取数据:  23%|██▎       | 1614088/7086503 [14:02<05:42, 15997.38it/s]读取数据:  23%|██▎       | 1616631/7086503 [14:02<04:53, 18631.01it/s]读取数据:  23%|██▎       | 1619036/7086503 [14:02<04:31, 20163.99it/s]读取数据:  23%|██▎       | 1621125/7086503 [14:02<04:29, 20262.03it/s]读取数据:  23%|██▎       | 1624507/7086503 [14:03<03:45, 24211.35it/s]读取数据:  23%|██▎       | 1628277/7086503 [14:03<03:13, 28174.83it/s]读取数据:  23%|██▎       | 1631136/7086503 [14:03<03:37, 25098.52it/s]读取数据:  23%|██▎       | 1634563/7086503 [14:03<03:17, 27597.77it/s]读取数据:  23%|██▎       | 1637412/7086503 [14:03<03:18, 27404.71it/s]读取数据:  23%|██▎       | 1640214/7086503 [14:03<03:52, 23451.78it/s]读取数据:  23%|██▎       | 1642694/7086503 [14:03<04:12, 21559.22it/s]读取数据:  23%|██▎       | 1644959/7086503 [14:03<04:39, 19453.81it/s]读取数据:  23%|██▎       | 1647000/7086503 [14:04<05:00, 18075.75it/s]读取数据:  23%|██▎       | 1648876/7086503 [14:04<05:14, 17316.56it/s]读取数据:  23%|██▎       | 1650650/7086503 [14:04<11:06, 8156.77it/s] 读取数据:  23%|██▎       | 1651986/7086503 [14:04<10:53, 8316.21it/s]读取数据:  23%|██▎       | 1653191/7086503 [14:05<10:38, 8502.87it/s]读取数据:  23%|██▎       | 1654331/7086503 [14:05<10:02, 9017.24it/s]读取数据:  23%|██▎       | 1656032/7086503 [14:05<08:30, 10635.15it/s]读取数据:  23%|██▎       | 1658299/7086503 [14:05<06:47, 13328.83it/s]读取数据:  23%|██▎       | 1660664/7086503 [14:05<05:42, 15829.83it/s]读取数据:  23%|██▎       | 1662890/7086503 [14:05<05:10, 17483.57it/s]读取数据:  24%|██▎       | 1666147/7086503 [14:05<04:11, 21538.49it/s]读取数据:  24%|██▎       | 1669450/7086503 [14:05<03:39, 24723.75it/s]读取数据:  24%|██▎       | 1672076/7086503 [14:05<04:21, 20729.20it/s]读取数据:  24%|██▎       | 1674364/7086503 [14:06<04:41, 19227.38it/s]读取数据:  24%|██▎       | 1676448/7086503 [14:06<04:54, 18371.52it/s]读取数据:  24%|██▎       | 1678396/7086503 [14:06<05:16, 17102.93it/s]读取数据:  24%|██▎       | 1680188/7086503 [14:06<05:19, 16896.40it/s]读取数据:  24%|██▎       | 1681932/7086503 [14:06<05:23, 16708.87it/s]读取数据:  24%|██▍       | 1683639/7086503 [14:06<05:29, 16412.01it/s]读取数据:  24%|██▍       | 1685303/7086503 [14:06<05:35, 16086.45it/s]读取数据:  24%|██▍       | 1686926/7086503 [14:06<05:39, 15914.77it/s]读取数据:  24%|██▍       | 1688527/7086503 [14:06<05:45, 15635.78it/s]读取数据:  24%|██▍       | 1690096/7086503 [14:07<05:47, 15545.94it/s]读取数据:  24%|██▍       | 1691654/7086503 [14:07<05:49, 15446.20it/s]读取数据:  24%|██▍       | 1693201/7086503 [14:07<05:59, 14993.45it/s]读取数据:  24%|██▍       | 1694703/7086503 [14:07<06:12, 14480.69it/s]读取数据:  24%|██▍       | 1696155/7086503 [14:07<06:22, 14091.48it/s]读取数据:  24%|██▍       | 1697567/7086503 [14:07<06:28, 13880.22it/s]读取数据:  24%|██▍       | 1698957/7086503 [14:07<06:35, 13607.43it/s]读取数据:  24%|██▍       | 1700319/7086503 [14:08<15:16, 5877.03it/s] 读取数据:  24%|██▍       | 1701646/7086503 [14:08<12:51, 6979.61it/s]读取数据:  24%|██▍       | 1704180/7086503 [14:08<08:47, 10204.36it/s]读取数据:  24%|██▍       | 1707525/7086503 [14:08<06:01, 14866.64it/s]读取数据:  24%|██▍       | 1711023/7086503 [14:08<04:37, 19344.00it/s]读取数据:  24%|██▍       | 1713530/7086503 [14:08<04:43, 18935.27it/s]读取数据:  24%|██▍       | 1715825/7086503 [14:08<04:36, 19396.66it/s]读取数据:  24%|██▍       | 1718053/7086503 [14:09<04:32, 19712.81it/s]读取数据:  24%|██▍       | 1720231/7086503 [14:09<04:51, 18393.19it/s]读取数据:  24%|██▍       | 1722226/7086503 [14:09<04:46, 18697.76it/s]读取数据:  24%|██▍       | 1724276/7086503 [14:09<04:39, 19171.23it/s]读取数据:  24%|██▍       | 1726506/7086503 [14:09<04:27, 20026.83it/s]读取数据:  24%|██▍       | 1728668/7086503 [14:09<04:21, 20472.63it/s]读取数据:  24%|██▍       | 1730837/7086503 [14:09<04:17, 20819.71it/s]读取数据:  24%|██▍       | 1733059/7086503 [14:09<04:12, 21225.86it/s]读取数据:  24%|██▍       | 1735210/7086503 [14:09<04:16, 20880.58it/s]读取数据:  25%|██▍       | 1737512/7086503 [14:10<04:08, 21486.97it/s]读取数据:  25%|██▍       | 1739992/7086503 [14:10<03:58, 22458.33it/s]读取数据:  25%|██▍       | 1742263/7086503 [14:10<03:57, 22532.09it/s]读取数据:  25%|██▍       | 1744562/7086503 [14:10<03:55, 22659.76it/s]读取数据:  25%|██▍       | 1747020/7086503 [14:10<03:49, 23231.02it/s]读取数据:  25%|██▍       | 1749384/7086503 [14:10<03:48, 23349.84it/s]读取数据:  25%|██▍       | 1751723/7086503 [14:11<09:11, 9678.38it/s] 读取数据:  25%|██▍       | 1753483/7086503 [14:11<08:30, 10444.12it/s]读取数据:  25%|██▍       | 1755131/7086503 [14:11<07:48, 11373.88it/s]读取数据:  25%|██▍       | 1756754/7086503 [14:11<07:19, 12132.60it/s]读取数据:  25%|██▍       | 1758430/7086503 [14:11<06:45, 13125.21it/s]读取数据:  25%|██▍       | 1760292/7086503 [14:11<06:09, 14415.73it/s]读取数据:  25%|██▍       | 1762285/7086503 [14:11<05:36, 15801.86it/s]读取数据:  25%|██▍       | 1764435/7086503 [14:11<05:07, 17302.89it/s]读取数据:  25%|██▍       | 1766325/7086503 [14:11<05:00, 17712.24it/s]读取数据:  25%|██▍       | 1768258/7086503 [14:12<04:52, 18166.56it/s]读取数据:  25%|██▍       | 1770220/7086503 [14:12<04:46, 18581.99it/s]读取数据:  25%|██▌       | 1772306/7086503 [14:12<04:36, 19238.88it/s]读取数据:  25%|██▌       | 1774350/7086503 [14:12<04:31, 19587.19it/s]读取数据:  25%|██▌       | 1776470/7086503 [14:12<04:24, 20059.92it/s]读取数据:  25%|██▌       | 1778708/7086503 [14:12<04:15, 20747.24it/s]读取数据:  25%|██▌       | 1780805/7086503 [14:12<04:15, 20805.41it/s]读取数据:  25%|██▌       | 1783019/7086503 [14:12<04:10, 21202.58it/s]读取数据:  25%|██▌       | 1785148/7086503 [14:12<04:10, 21188.89it/s]读取数据:  25%|██▌       | 1787273/7086503 [14:12<04:20, 20331.97it/s]读取数据:  25%|██▌       | 1789318/7086503 [14:13<04:22, 20185.89it/s]读取数据:  25%|██▌       | 1791425/7086503 [14:13<04:19, 20442.63it/s]读取数据:  25%|██▌       | 1793594/7086503 [14:13<04:14, 20808.26it/s]读取数据:  25%|██▌       | 1795875/7086503 [14:13<04:07, 21398.54it/s]读取数据:  25%|██▌       | 1798096/7086503 [14:13<04:04, 21639.00it/s]读取数据:  25%|██▌       | 1800264/7086503 [14:13<08:44, 10074.39it/s]读取数据:  25%|██▌       | 1801915/7086503 [14:14<08:00, 10991.45it/s]读取数据:  25%|██▌       | 1803530/7086503 [14:14<07:22, 11933.87it/s]读取数据:  25%|██▌       | 1805224/7086503 [14:14<06:46, 12995.04it/s]读取数据:  26%|██▌       | 1807086/7086503 [14:14<06:09, 14301.77it/s]读取数据:  26%|██▌       | 1809161/7086503 [14:14<05:31, 15909.08it/s]读取数据:  26%|██▌       | 1811456/7086503 [14:14<04:57, 17757.01it/s]读取数据:  26%|██▌       | 1813692/7086503 [14:14<04:37, 19012.26it/s]读取数据:  26%|██▌       | 1815918/7086503 [14:14<04:24, 19919.74it/s]读取数据:  26%|██▌       | 1818142/7086503 [14:14<04:15, 20581.29it/s]读取数据:  26%|██▌       | 1820277/7086503 [14:14<04:19, 20292.36it/s]读取数据:  26%|██▌       | 1822361/7086503 [14:15<04:18, 20378.80it/s]读取数据:  26%|██▌       | 1824489/7086503 [14:15<04:14, 20640.53it/s]读取数据:  26%|██▌       | 1826743/7086503 [14:15<04:08, 21194.78it/s]读取数据:  26%|██▌       | 1828930/7086503 [14:15<04:05, 21381.50it/s]读取数据:  26%|██▌       | 1831100/7086503 [14:15<04:04, 21473.42it/s]读取数据:  26%|██▌       | 1833290/7086503 [14:15<04:03, 21594.63it/s]读取数据:  26%|██▌       | 1835545/7086503 [14:15<04:00, 21878.32it/s]读取数据:  26%|██▌       | 1837813/7086503 [14:15<03:57, 22117.55it/s]读取数据:  26%|██▌       | 1840353/7086503 [14:15<03:47, 23097.12it/s]读取数据:  26%|██▌       | 1842666/7086503 [14:15<03:56, 22185.51it/s]读取数据:  26%|██▌       | 1844895/7086503 [14:16<04:09, 20982.82it/s]读取数据:  26%|██▌       | 1847012/7086503 [14:16<04:10, 20908.71it/s]读取数据:  26%|██▌       | 1849132/7086503 [14:16<04:09, 20989.73it/s]读取数据:  26%|██▌       | 1851240/7086503 [14:16<09:05, 9598.70it/s] 读取数据:  26%|██▌       | 1852985/7086503 [14:16<08:02, 10847.59it/s]读取数据:  26%|██▌       | 1854822/7086503 [14:17<07:07, 12239.11it/s]读取数据:  26%|██▌       | 1856938/7086503 [14:17<06:10, 14104.39it/s]读取数据:  26%|██▌       | 1859177/7086503 [14:17<05:26, 16010.02it/s]读取数据:  26%|██▋       | 1861405/7086503 [14:17<04:57, 17558.33it/s]读取数据:  26%|██▋       | 1863709/7086503 [14:17<04:35, 18988.69it/s]读取数据:  26%|██▋       | 1866022/7086503 [14:17<04:19, 20109.00it/s]读取数据:  26%|██▋       | 1868493/7086503 [14:17<04:03, 21394.37it/s]读取数据:  26%|██▋       | 1870901/7086503 [14:17<03:55, 22160.37it/s]读取数据:  26%|██▋       | 1873224/7086503 [14:17<03:52, 22468.98it/s]读取数据:  26%|██▋       | 1875535/7086503 [14:17<03:50, 22602.15it/s]读取数据:  26%|██▋       | 1877864/7086503 [14:18<03:48, 22803.28it/s]读取数据:  27%|██▋       | 1880212/7086503 [14:18<03:46, 23003.19it/s]读取数据:  27%|██▋       | 1882535/7086503 [14:18<03:47, 22847.98it/s]读取数据:  27%|██▋       | 1884836/7086503 [14:18<03:51, 22436.71it/s]读取数据:  27%|██▋       | 1887093/7086503 [14:18<03:54, 22138.60it/s]读取数据:  27%|██▋       | 1889440/7086503 [14:18<03:50, 22526.42it/s]读取数据:  27%|██▋       | 1891755/7086503 [14:18<03:48, 22708.64it/s]读取数据:  27%|██▋       | 1894235/7086503 [14:18<03:42, 23322.48it/s]读取数据:  27%|██▋       | 1896690/7086503 [14:18<03:39, 23683.59it/s]读取数据:  27%|██▋       | 1899182/7086503 [14:18<03:35, 24050.99it/s]读取数据:  27%|██▋       | 1901590/7086503 [14:19<09:07, 9467.65it/s] 读取数据:  27%|██▋       | 1903578/7086503 [14:19<07:52, 10963.56it/s]读取数据:  27%|██▋       | 1905676/7086503 [14:19<06:49, 12666.57it/s]读取数据:  27%|██▋       | 1908019/7086503 [14:19<05:50, 14772.05it/s]读取数据:  27%|██▋       | 1910408/7086503 [14:19<05:08, 16761.69it/s]读取数据:  27%|██▋       | 1912562/7086503 [14:20<09:37, 8960.38it/s] 读取数据:  27%|██▋       | 1914194/7086503 [14:21<14:18, 6022.00it/s]读取数据:  27%|██▋       | 1915425/7086503 [14:21<17:15, 4996.15it/s]读取数据:  27%|██▋       | 1916376/7086503 [14:21<19:23, 4442.99it/s]读取数据:  27%|██▋       | 1917131/7086503 [14:22<21:14, 4056.18it/s]读取数据:  27%|██▋       | 1917746/7086503 [14:22<23:05, 3731.65it/s]读取数据:  27%|██▋       | 1918256/7086503 [14:22<24:39, 3493.11it/s]读取数据:  27%|██▋       | 1918693/7086503 [14:22<25:51, 3330.35it/s]读取数据:  27%|██▋       | 1919080/7086503 [14:22<26:46, 3215.90it/s]读取数据:  27%|██▋       | 1919434/7086503 [14:22<27:39, 3112.95it/s]读取数据:  27%|██▋       | 1919764/7086503 [14:22<28:26, 3028.04it/s]读取数据:  27%|██▋       | 1920077/7086503 [14:23<28:57, 2973.76it/s]读取数据:  27%|██▋       | 1920380/7086503 [14:23<29:43, 2896.92it/s]读取数据:  27%|██▋       | 1920672/7086503 [14:23<30:41, 2805.21it/s]读取数据:  27%|██▋       | 1920953/7086503 [14:23<31:19, 2748.67it/s]读取数据:  27%|██▋       | 1921229/7086503 [14:23<31:17, 2751.53it/s]读取数据:  27%|██▋       | 1921504/7086503 [14:23<31:36, 2722.95it/s]读取数据:  27%|██▋       | 1921776/7086503 [14:23<31:43, 2713.61it/s]读取数据:  27%|██▋       | 1922047/7086503 [14:23<32:15, 2667.76it/s]读取数据:  27%|██▋       | 1922314/7086503 [14:23<32:35, 2641.23it/s]读取数据:  27%|██▋       | 1922578/7086503 [14:24<32:50, 2621.06it/s]读取数据:  27%|██▋       | 1922840/7086503 [14:24<33:28, 2570.47it/s]读取数据:  27%|██▋       | 1923097/7086503 [14:24<33:41, 2554.72it/s]读取数据:  27%|██▋       | 1923353/7086503 [14:24<33:41, 2553.73it/s]读取数据:  27%|██▋       | 1923614/7086503 [14:24<33:30, 2567.89it/s]读取数据:  27%|██▋       | 1923871/7086503 [14:24<33:38, 2557.85it/s]读取数据:  27%|██▋       | 1924127/7086503 [14:24<33:44, 2550.36it/s]读取数据:  27%|██▋       | 1924389/7086503 [14:24<33:29, 2569.11it/s]读取数据:  27%|██▋       | 1924646/7086503 [14:24<33:33, 2563.29it/s]读取数据:  27%|██▋       | 1924909/7086503 [14:24<33:21, 2579.32it/s]读取数据:  27%|██▋       | 1925167/7086503 [14:25<33:44, 2549.72it/s]读取数据:  27%|██▋       | 1925428/7086503 [14:25<33:31, 2565.81it/s]读取数据:  27%|██▋       | 1925691/7086503 [14:25<33:18, 2582.38it/s]读取数据:  27%|██▋       | 1925953/7086503 [14:25<33:12, 2589.71it/s]读取数据:  27%|██▋       | 1926213/7086503 [14:25<33:31, 2565.25it/s]读取数据:  27%|██▋       | 1926470/7086503 [14:25<33:32, 2564.48it/s]读取数据:  27%|██▋       | 1926727/7086503 [14:25<33:31, 2565.27it/s]读取数据:  27%|██▋       | 1926994/7086503 [14:25<33:07, 2595.76it/s]读取数据:  27%|██▋       | 1927254/7086503 [14:25<33:34, 2560.72it/s]读取数据:  27%|██▋       | 1927511/7086503 [14:25<34:20, 2503.22it/s]读取数据:  27%|██▋       | 1927775/7086503 [14:26<33:49, 2541.84it/s]读取数据:  27%|██▋       | 1928031/7086503 [14:26<33:47, 2544.17it/s]读取数据:  27%|██▋       | 1928286/7086503 [14:26<33:56, 2532.97it/s]读取数据:  27%|██▋       | 1928557/7086503 [14:26<33:16, 2582.90it/s]读取数据:  27%|██▋       | 1928816/7086503 [14:26<33:26, 2570.20it/s]读取数据:  27%|██▋       | 1929074/7086503 [14:26<33:34, 2559.59it/s]读取数据:  27%|██▋       | 1929331/7086503 [14:26<33:34, 2560.40it/s]读取数据:  27%|██▋       | 1929588/7086503 [14:26<34:17, 2506.36it/s]读取数据:  27%|██▋       | 1929840/7086503 [14:26<34:16, 2507.73it/s]读取数据:  27%|██▋       | 1930091/7086503 [14:27<34:38, 2480.32it/s]读取数据:  27%|██▋       | 1930340/7086503 [14:27<35:24, 2426.48it/s]读取数据:  27%|██▋       | 1930583/7086503 [14:27<36:26, 2357.76it/s]读取数据:  27%|██▋       | 1930820/7086503 [14:27<37:54, 2266.43it/s]读取数据:  27%|██▋       | 1931048/7086503 [14:27<39:30, 2175.07it/s]读取数据:  27%|██▋       | 1931267/7086503 [14:27<40:37, 2114.97it/s]读取数据:  27%|██▋       | 1931480/7086503 [14:27<41:13, 2083.84it/s]读取数据:  27%|██▋       | 1931689/7086503 [14:27<41:42, 2059.51it/s]读取数据:  27%|██▋       | 1931917/7086503 [14:27<40:31, 2120.07it/s]读取数据:  27%|██▋       | 1932139/7086503 [14:27<40:00, 2146.98it/s]读取数据:  27%|██▋       | 1932406/7086503 [14:28<37:23, 2297.04it/s]读取数据:  27%|██▋       | 1932637/7086503 [14:28<43:07, 1991.86it/s]读取数据:  27%|██▋       | 1932850/7086503 [14:28<42:30, 2020.90it/s]读取数据:  27%|██▋       | 1933058/7086503 [14:28<42:17, 2030.80it/s]读取数据:  27%|██▋       | 1933266/7086503 [14:28<47:11, 1819.75it/s]读取数据:  27%|██▋       | 1933497/7086503 [14:28<44:06, 1947.12it/s]读取数据:  27%|██▋       | 1933698/7086503 [14:28<49:11, 1745.81it/s]读取数据:  27%|██▋       | 1933907/7086503 [14:28<46:50, 1833.29it/s]读取数据:  27%|██▋       | 1934097/7086503 [14:29<46:54, 1830.56it/s]读取数据:  27%|██▋       | 1934307/7086503 [14:29<45:04, 1904.71it/s]读取数据:  27%|██▋       | 1934544/7086503 [14:29<42:11, 2035.53it/s]读取数据:  27%|██▋       | 1934816/7086503 [14:29<38:30, 2229.44it/s]读取数据:  27%|██▋       | 1935043/7086503 [14:29<38:44, 2215.87it/s]读取数据:  27%|██▋       | 1935316/7086503 [14:29<36:18, 2364.38it/s]读取数据:  27%|██▋       | 1935555/7086503 [14:30<1:28:48, 966.68it/s]读取数据:  27%|██▋       | 1935807/7086503 [14:30<1:11:58, 1192.58it/s]读取数据:  27%|██▋       | 1936013/7086503 [14:30<1:03:58, 1341.93it/s]读取数据:  27%|██▋       | 1936216/7086503 [14:30<58:33, 1465.93it/s]  读取数据:  27%|██▋       | 1936429/7086503 [14:30<53:17, 1610.48it/s]读取数据:  27%|██▋       | 1936636/7086503 [14:30<49:55, 1719.06it/s]读取数据:  27%|██▋       | 1936870/7086503 [14:30<45:44, 1876.28it/s]读取数据:  27%|██▋       | 1937088/7086503 [14:30<43:52, 1956.28it/s]读取数据:  27%|██▋       | 1937303/7086503 [14:30<43:45, 1961.16it/s]读取数据:  27%|██▋       | 1937520/7086503 [14:31<42:33, 2016.13it/s]读取数据:  27%|██▋       | 1937732/7086503 [14:31<43:38, 1966.47it/s]读取数据:  27%|██▋       | 1937936/7086503 [14:31<50:57, 1683.89it/s]读取数据:  27%|██▋       | 1938116/7086503 [14:31<50:19, 1705.21it/s]读取数据:  27%|██▋       | 1938295/7086503 [14:31<1:05:39, 1306.72it/s]读取数据:  27%|██▋       | 1938465/7086503 [14:31<1:01:59, 1383.95it/s]读取数据:  27%|██▋       | 1938708/7086503 [14:31<52:31, 1633.57it/s]  读取数据:  27%|██▋       | 1938919/7086503 [14:31<48:56, 1752.75it/s]读取数据:  27%|██▋       | 1939109/7086503 [14:32<48:24, 1772.22it/s]读取数据:  27%|██▋       | 1939297/7086503 [14:32<48:28, 1769.48it/s]读取数据:  27%|██▋       | 1939481/7086503 [14:32<48:04, 1784.57it/s]读取数据:  27%|██▋       | 1939665/7086503 [14:32<47:42, 1798.02it/s]读取数据:  27%|██▋       | 1939869/7086503 [14:32<45:57, 1866.46it/s]读取数据:  27%|██▋       | 1940059/7086503 [14:32<58:42, 1461.13it/s]读取数据:  27%|██▋       | 1940221/7086503 [14:32<1:00:37, 1414.97it/s]读取数据:  27%|██▋       | 1940374/7086503 [14:32<1:09:34, 1232.81it/s]读取数据:  27%|██▋       | 1940559/7086503 [14:33<1:02:21, 1375.30it/s]读取数据:  27%|██▋       | 1940766/7086503 [14:33<55:25, 1547.39it/s]  读取数据:  27%|██▋       | 1940997/7086503 [14:33<49:07, 1745.94it/s]读取数据:  27%|██▋       | 1941239/7086503 [14:33<44:28, 1928.04it/s]读取数据:  27%|██▋       | 1941442/7086503 [14:33<50:15, 1706.11it/s]读取数据:  27%|██▋       | 1941624/7086503 [14:33<55:35, 1542.27it/s]读取数据:  27%|██▋       | 1941788/7086503 [14:33<1:14:35, 1149.60it/s]读取数据:  27%|██▋       | 1942044/7086503 [14:34<59:34, 1439.02it/s]  读取数据:  27%|██▋       | 1942283/7086503 [14:34<51:51, 1653.48it/s]读取数据:  27%|██▋       | 1942474/7086503 [14:34<57:58, 1478.75it/s]读取数据:  27%|██▋       | 1942683/7086503 [14:34<52:56, 1619.52it/s]读取数据:  27%|██▋       | 1942894/7086503 [14:34<49:16, 1739.80it/s]读取数据:  27%|██▋       | 1943097/7086503 [14:34<47:13, 1814.94it/s]读取数据:  27%|██▋       | 1943333/7086503 [14:34<43:40, 1962.54it/s]读取数据:  27%|██▋       | 1943580/7086503 [14:34<40:45, 2103.01it/s]读取数据:  27%|██▋       | 1943799/7086503 [14:34<40:58, 2092.02it/s]读取数据:  27%|██▋       | 1944040/7086503 [14:34<39:15, 2182.91it/s]读取数据:  27%|██▋       | 1944269/7086503 [14:35<38:44, 2212.02it/s]读取数据:  27%|██▋       | 1944497/7086503 [14:35<38:28, 2227.40it/s]读取数据:  27%|██▋       | 1944730/7086503 [14:35<38:00, 2254.75it/s]读取数据:  27%|██▋       | 1944958/7086503 [14:35<45:42, 1874.77it/s]读取数据:  27%|██▋       | 1945205/7086503 [14:35<42:14, 2028.89it/s]读取数据:  27%|██▋       | 1945419/7086503 [14:35<42:31, 2014.91it/s]读取数据:  27%|██▋       | 1945679/7086503 [14:35<39:23, 2175.23it/s]读取数据:  27%|██▋       | 1945906/7086503 [14:35<38:54, 2201.73it/s]读取数据:  27%|██▋       | 1946152/7086503 [14:35<37:43, 2271.38it/s]读取数据:  27%|██▋       | 1946383/7086503 [14:36<47:27, 1805.15it/s]读取数据:  27%|██▋       | 1946621/7086503 [14:36<44:02, 1944.88it/s]读取数据:  27%|██▋       | 1946831/7086503 [14:36<50:12, 1706.19it/s]读取数据:  27%|██▋       | 1947017/7086503 [14:36<1:07:06, 1276.32it/s]读取数据:  27%|██▋       | 1947208/7086503 [14:36<1:01:05, 1402.10it/s]读取数据:  27%|██▋       | 1947378/7086503 [14:36<58:19, 1468.63it/s]  读取数据:  27%|██▋       | 1947553/7086503 [14:36<57:26, 1491.05it/s]读取数据:  27%|██▋       | 1947716/7086503 [14:37<1:01:15, 1398.04it/s]读取数据:  27%|██▋       | 1947970/7086503 [14:37<51:01, 1678.53it/s]  读取数据:  27%|██▋       | 1948200/7086503 [14:37<46:32, 1839.74it/s]读取数据:  27%|██▋       | 1948415/7086503 [14:37<44:33, 1922.11it/s]读取数据:  27%|██▋       | 1948640/7086503 [14:37<42:33, 2012.23it/s]读取数据:  28%|██▊       | 1948874/7086503 [14:37<40:40, 2105.49it/s]读取数据:  28%|██▊       | 1949090/7086503 [14:37<53:30, 1600.43it/s]读取数据:  28%|██▊       | 1949272/7086503 [14:37<55:40, 1537.74it/s]读取数据:  28%|██▊       | 1949441/7086503 [14:38<1:02:57, 1359.87it/s]读取数据:  28%|██▊       | 1949590/7086503 [14:38<1:04:30, 1327.09it/s]读取数据:  28%|██▊       | 1949811/7086503 [14:38<55:46, 1535.16it/s]  读取数据:  28%|██▊       | 1950000/7086503 [14:39<2:30:13, 569.88it/s]读取数据:  28%|██▊       | 1950123/7086503 [14:39<3:12:35, 444.49it/s]读取数据:  28%|██▊       | 1950225/7086503 [14:39<2:50:41, 501.53it/s]读取数据:  28%|██▊       | 1950321/7086503 [14:39<2:50:38, 501.67it/s]读取数据:  28%|██▊       | 1950437/7086503 [14:40<2:24:28, 592.47it/s]读取数据:  28%|██▊       | 1950530/7086503 [14:40<2:21:28, 605.04it/s]读取数据:  28%|██▊       | 1950633/7086503 [14:40<2:09:39, 660.19it/s]读取数据:  28%|██▊       | 1950718/7086503 [14:40<2:21:45, 603.79it/s]读取数据:  28%|██▊       | 1950792/7086503 [14:40<2:24:54, 590.69it/s]读取数据:  28%|██▊       | 1950902/7086503 [14:40<2:02:46, 697.14it/s]读取数据:  28%|██▊       | 1950983/7086503 [14:40<2:01:53, 702.21it/s]读取数据:  28%|██▊       | 1951063/7086503 [14:40<1:57:59, 725.39it/s]读取数据:  28%|██▊       | 1951147/7086503 [14:41<1:58:51, 720.13it/s]读取数据:  28%|██▊       | 1951224/7086503 [14:41<2:36:34, 546.64it/s]读取数据:  28%|██▊       | 1951351/7086503 [14:41<2:01:46, 702.83it/s]读取数据:  28%|██▊       | 1951453/7086503 [14:41<1:50:13, 776.45it/s]读取数据:  28%|██▊       | 1951563/7086503 [14:41<1:39:47, 857.65it/s]读取数据:  28%|██▊       | 1951658/7086503 [14:41<2:16:02, 629.06it/s]读取数据:  28%|██▊       | 1951746/7086503 [14:41<2:05:33, 681.61it/s]读取数据:  28%|██▊       | 1951827/7086503 [14:42<2:03:21, 693.74it/s]读取数据:  28%|██▊       | 1951934/7086503 [14:42<1:49:04, 784.51it/s]读取数据:  28%|██▊       | 1952044/7086503 [14:42<1:39:02, 864.05it/s]读取数据:  28%|██▊       | 1952138/7086503 [14:42<2:19:02, 615.41it/s]读取数据:  28%|██▊       | 1952273/7086503 [14:42<1:51:14, 769.28it/s]读取数据:  28%|██▊       | 1952387/7086503 [14:42<1:40:13, 853.70it/s]读取数据:  28%|██▊       | 1952487/7086503 [14:43<2:54:29, 490.36it/s]读取数据:  28%|██▊       | 1952564/7086503 [14:43<3:20:15, 427.28it/s]读取数据:  28%|██▊       | 1952627/7086503 [14:43<3:11:00, 447.98it/s]读取数据:  28%|██▊       | 1952757/7086503 [14:43<2:22:34, 600.16it/s]读取数据:  28%|██▊       | 1952838/7086503 [14:43<2:22:21, 601.00it/s]读取数据:  28%|██▊       | 1952913/7086503 [14:44<2:56:15, 485.41it/s]读取数据:  28%|██▊       | 1953040/7086503 [14:44<2:14:52, 634.35it/s]读取数据:  28%|██▊       | 1953122/7086503 [14:44<2:17:31, 622.12it/s]读取数据:  28%|██▊       | 1953223/7086503 [14:44<2:01:50, 702.16it/s]读取数据:  28%|██▊       | 1953305/7086503 [14:44<2:36:42, 545.95it/s]读取数据:  28%|██▊       | 1953373/7086503 [14:44<3:13:06, 443.01it/s]读取数据:  28%|██▊       | 1953432/7086503 [14:44<3:02:07, 469.72it/s]读取数据:  28%|██▊       | 1953489/7086503 [14:45<2:59:11, 477.44it/s]读取数据:  28%|██▊       | 1953544/7086503 [14:45<3:03:18, 466.68it/s]读取数据:  28%|██▊       | 1953596/7086503 [14:45<4:48:34, 296.44it/s]读取数据:  28%|██▊       | 1953639/7086503 [14:45<4:57:29, 287.57it/s]读取数据:  28%|██▊       | 1953675/7086503 [14:45<5:02:05, 283.18it/s]读取数据:  28%|██▊       | 1953737/7086503 [14:45<4:07:12, 346.06it/s]读取数据:  28%|██▊       | 1953809/7086503 [14:46<3:20:30, 426.65it/s]读取数据:  28%|██▊       | 1953892/7086503 [14:46<2:44:19, 520.55it/s]读取数据:  28%|██▊       | 1953952/7086503 [14:46<3:25:16, 416.70it/s]读取数据:  28%|██▊       | 1954013/7086503 [14:46<3:06:44, 458.07it/s]读取数据:  28%|██▊       | 1954146/7086503 [14:46<2:08:53, 663.67it/s]读取数据:  28%|██▊       | 1954270/7086503 [14:46<1:45:58, 807.20it/s]读取数据:  28%|██▊       | 1954367/7086503 [14:46<2:09:15, 661.72it/s]读取数据:  28%|██▊       | 1954445/7086503 [14:47<4:43:20, 301.88it/s]读取数据:  28%|██▊       | 1954515/7086503 [14:47<4:04:23, 349.99it/s]读取数据:  28%|██▊       | 1954603/7086503 [14:47<3:19:05, 429.61it/s]读取数据:  28%|██▊       | 1954709/7086503 [14:47<2:38:24, 539.92it/s]读取数据:  28%|██▊       | 1954789/7086503 [14:48<2:58:37, 478.81it/s]读取数据:  28%|██▊       | 1954913/7086503 [14:48<2:17:33, 621.77it/s]读取数据:  28%|██▊       | 1955033/7086503 [14:48<1:54:59, 743.78it/s]读取数据:  28%|██▊       | 1955159/7086503 [14:48<1:39:08, 862.63it/s]读取数据:  28%|██▊       | 1955281/7086503 [14:48<1:29:59, 950.40it/s]读取数据:  28%|██▊       | 1955391/7086503 [14:48<1:27:29, 977.39it/s]读取数据:  28%|██▊       | 1955499/7086503 [14:48<1:37:32, 876.73it/s]读取数据:  28%|██▊       | 1955607/7086503 [14:48<1:32:19, 926.28it/s]读取数据:  28%|██▊       | 1955707/7086503 [14:48<1:44:09, 821.06it/s]读取数据:  28%|██▊       | 1955796/7086503 [14:49<3:02:56, 467.43it/s]读取数据:  28%|██▊       | 1955865/7086503 [14:49<3:42:31, 384.29it/s]读取数据:  28%|██▊       | 1955921/7086503 [14:49<4:19:09, 329.96it/s]读取数据:  28%|██▊       | 1956017/7086503 [14:50<3:22:03, 423.19it/s]读取数据:  28%|██▊       | 1956116/7086503 [14:50<2:44:14, 520.60it/s]读取数据:  28%|██▊       | 1956188/7086503 [14:50<3:08:18, 454.05it/s]读取数据:  28%|██▊       | 1956287/7086503 [14:50<2:34:34, 553.14it/s]读取数据:  28%|██▊       | 1956388/7086503 [14:50<2:11:45, 648.94it/s]读取数据:  28%|██▊       | 1956481/7086503 [14:50<1:59:54, 713.09it/s]读取数据:  28%|██▊       | 1956601/7086503 [14:50<1:42:37, 833.13it/s]读取数据:  28%|██▊       | 1956696/7086503 [14:50<1:40:35, 849.89it/s]读取数据:  28%|██▊       | 1956807/7086503 [14:50<1:34:31, 904.55it/s]读取数据:  28%|██▊       | 1956912/7086503 [14:51<1:30:36, 943.49it/s]读取数据:  28%|██▊       | 1957011/7086503 [14:51<1:37:10, 879.84it/s]读取数据:  28%|██▊       | 1957137/7086503 [14:51<1:27:04, 981.70it/s]读取数据:  28%|██▊       | 1957240/7086503 [14:51<1:29:48, 951.90it/s]读取数据:  28%|██▊       | 1957338/7086503 [14:51<1:33:59, 909.54it/s]读取数据:  28%|██▊       | 1957469/7086503 [14:51<1:24:02, 1017.09it/s]读取数据:  28%|██▊       | 1957604/7086503 [14:51<1:17:07, 1108.37it/s]读取数据:  28%|██▊       | 1957722/7086503 [14:51<1:15:45, 1128.36it/s]读取数据:  28%|██▊       | 1957837/7086503 [14:51<1:16:54, 1111.41it/s]读取数据:  28%|██▊       | 1957981/7086503 [14:52<1:10:59, 1203.99it/s]读取数据:  28%|██▊       | 1958103/7086503 [14:52<1:14:06, 1153.28it/s]读取数据:  28%|██▊       | 1958220/7086503 [14:52<1:14:02, 1154.32it/s]读取数据:  28%|██▊       | 1958352/7086503 [14:52<1:11:08, 1201.38it/s]读取数据:  28%|██▊       | 1958492/7086503 [14:52<1:08:00, 1256.83it/s]读取数据:  28%|██▊       | 1958619/7086503 [14:52<1:31:57, 929.35it/s] 读取数据:  28%|██▊       | 1958725/7086503 [14:52<1:31:28, 934.34it/s]读取数据:  28%|██▊       | 1958855/7086503 [14:52<1:23:27, 1023.94it/s]读取数据:  28%|██▊       | 1958992/7086503 [14:53<1:17:19, 1105.12it/s]读取数据:  28%|██▊       | 1959110/7086503 [14:53<1:20:13, 1065.17it/s]读取数据:  28%|██▊       | 1959243/7086503 [14:53<1:15:14, 1135.70it/s]读取数据:  28%|██▊       | 1959390/7086503 [14:53<1:09:35, 1227.85it/s]读取数据:  28%|██▊       | 1959519/7086503 [14:53<1:08:36, 1245.42it/s]读取数据:  28%|██▊       | 1959647/7086503 [14:53<1:09:26, 1230.53it/s]读取数据:  28%|██▊       | 1959772/7086503 [14:53<1:10:14, 1216.53it/s]读取数据:  28%|██▊       | 1959907/7086503 [14:53<1:08:16, 1251.56it/s]读取数据:  28%|██▊       | 1960034/7086503 [14:53<1:07:59, 1256.54it/s]读取数据:  28%|██▊       | 1960172/7086503 [14:53<1:06:11, 1290.78it/s]读取数据:  28%|██▊       | 1960312/7086503 [14:54<1:04:38, 1321.70it/s]读取数据:  28%|██▊       | 1960445/7086503 [14:54<1:12:34, 1177.22it/s]读取数据:  28%|██▊       | 1960583/7086503 [14:54<1:09:20, 1231.90it/s]读取数据:  28%|██▊       | 1960709/7086503 [14:54<1:16:15, 1120.24it/s]读取数据:  28%|██▊       | 1960836/7086503 [14:54<1:13:44, 1158.59it/s]读取数据:  28%|██▊       | 1960968/7086503 [14:54<1:11:05, 1201.58it/s]读取数据:  28%|██▊       | 1961091/7086503 [14:54<1:11:15, 1198.65it/s]读取数据:  28%|██▊       | 1961213/7086503 [14:54<1:31:02, 938.24it/s] 读取数据:  28%|██▊       | 1961371/7086503 [14:55<1:18:16, 1091.38it/s]读取数据:  28%|██▊       | 1961496/7086503 [14:55<1:15:38, 1129.34it/s]读取数据:  28%|██▊       | 1961617/7086503 [14:55<1:14:38, 1144.31it/s]读取数据:  28%|██▊       | 1961756/7086503 [14:55<1:10:32, 1210.80it/s]读取数据:  28%|██▊       | 1961889/7086503 [14:55<1:08:41, 1243.35it/s]读取数据:  28%|██▊       | 1962025/7086503 [14:55<1:06:55, 1276.23it/s]读取数据:  28%|██▊       | 1962156/7086503 [14:55<1:07:03, 1273.66it/s]读取数据:  28%|██▊       | 1962286/7086503 [14:55<1:08:21, 1249.21it/s]读取数据:  28%|██▊       | 1962413/7086503 [14:55<1:11:09, 1200.10it/s]读取数据:  28%|██▊       | 1962564/7086503 [14:55<1:06:54, 1276.27it/s]读取数据:  28%|██▊       | 1962693/7086503 [14:56<1:06:51, 1277.20it/s]读取数据:  28%|██▊       | 1962833/7086503 [14:56<1:05:11, 1309.90it/s]读取数据:  28%|██▊       | 1962965/7086503 [14:56<1:06:00, 1293.51it/s]读取数据:  28%|██▊       | 1963111/7086503 [14:56<1:03:43, 1339.87it/s]读取数据:  28%|██▊       | 1963246/7086503 [14:56<1:06:25, 1285.51it/s]读取数据:  28%|██▊       | 1963376/7086503 [14:56<1:08:13, 1251.66it/s]读取数据:  28%|██▊       | 1963525/7086503 [14:56<1:04:44, 1318.79it/s]读取数据:  28%|██▊       | 1963674/7086503 [14:56<1:04:15, 1328.78it/s]读取数据:  28%|██▊       | 1963808/7086503 [14:56<1:06:41, 1280.07it/s]读取数据:  28%|██▊       | 1963937/7086503 [14:57<1:10:02, 1218.80it/s]读取数据:  28%|██▊       | 1964079/7086503 [14:57<1:07:02, 1273.58it/s]读取数据:  28%|██▊       | 1964230/7086503 [14:57<1:03:46, 1338.76it/s]读取数据:  28%|██▊       | 1964365/7086503 [14:57<1:04:50, 1316.72it/s]读取数据:  28%|██▊       | 1964506/7086503 [14:57<1:03:35, 1342.56it/s]读取数据:  28%|██▊       | 1964665/7086503 [14:57<1:00:23, 1413.69it/s]读取数据:  28%|██▊       | 1964808/7086503 [14:57<1:00:51, 1402.56it/s]读取数据:  28%|██▊       | 1964949/7086503 [14:57<1:07:31, 1264.15it/s]读取数据:  28%|██▊       | 1965117/7086503 [14:57<1:01:58, 1377.38it/s]读取数据:  28%|██▊       | 1965268/7086503 [14:58<1:00:24, 1412.98it/s]读取数据:  28%|██▊       | 1965412/7086503 [14:58<1:03:18, 1348.03it/s]读取数据:  28%|██▊       | 1965549/7086503 [14:58<1:03:26, 1345.28it/s]读取数据:  28%|██▊       | 1965685/7086503 [14:58<1:26:37, 985.26it/s] 读取数据:  28%|██▊       | 1965798/7086503 [14:58<1:26:26, 987.22it/s]读取数据:  28%|██▊       | 1965951/7086503 [14:58<1:16:24, 1116.98it/s]读取数据:  28%|██▊       | 1966082/7086503 [14:58<1:13:14, 1165.19it/s]读取数据:  28%|██▊       | 1966207/7086503 [14:58<1:12:06, 1183.35it/s]读取数据:  28%|██▊       | 1966367/7086503 [14:58<1:05:47, 1296.96it/s]读取数据:  28%|██▊       | 1966510/7086503 [14:59<1:03:57, 1334.03it/s]读取数据:  28%|██▊       | 1966648/7086503 [14:59<1:03:40, 1340.16it/s]读取数据:  28%|██▊       | 1966806/7086503 [14:59<1:00:32, 1409.44it/s]读取数据:  28%|██▊       | 1966950/7086503 [14:59<1:02:30, 1364.98it/s]读取数据:  28%|██▊       | 1967089/7086503 [14:59<1:03:56, 1334.55it/s]读取数据:  28%|██▊       | 1967224/7086503 [14:59<1:03:56, 1334.20it/s]读取数据:  28%|██▊       | 1967359/7086503 [14:59<1:03:53, 1335.47it/s]读取数据:  28%|██▊       | 1967494/7086503 [14:59<1:06:13, 1288.29it/s]读取数据:  28%|██▊       | 1967649/7086503 [14:59<1:02:40, 1361.23it/s]读取数据:  28%|██▊       | 1967799/7086503 [15:00<1:00:52, 1401.38it/s]读取数据:  28%|██▊       | 1967953/7086503 [15:00<59:09, 1441.86it/s]  读取数据:  28%|██▊       | 1968098/7086503 [15:00<59:14, 1440.12it/s]读取数据:  28%|██▊       | 1968243/7086503 [15:00<1:02:26, 1366.31it/s]读取数据:  28%|██▊       | 1968381/7086503 [15:00<1:04:38, 1319.69it/s]读取数据:  28%|██▊       | 1968514/7086503 [15:00<1:06:37, 1280.38it/s]读取数据:  28%|██▊       | 1968662/7086503 [15:00<1:03:50, 1336.00it/s]读取数据:  28%|██▊       | 1968824/7086503 [15:00<1:00:12, 1416.56it/s]读取数据:  28%|██▊       | 1968967/7086503 [15:00<1:03:37, 1340.63it/s]读取数据:  28%|██▊       | 1969128/7086503 [15:00<1:01:59, 1375.95it/s]读取数据:  28%|██▊       | 1969272/7086503 [15:01<1:01:13, 1393.03it/s]读取数据:  28%|██▊       | 1969427/7086503 [15:01<59:21, 1436.65it/s]  读取数据:  28%|██▊       | 1969572/7086503 [15:01<1:01:54, 1377.72it/s]读取数据:  28%|██▊       | 1969711/7086503 [15:01<1:03:08, 1350.68it/s]读取数据:  28%|██▊       | 1969847/7086503 [15:01<1:10:27, 1210.43it/s]读取数据:  28%|██▊       | 1970009/7086503 [15:01<1:04:51, 1314.70it/s]读取数据:  28%|██▊       | 1970150/7086503 [15:01<1:03:35, 1340.83it/s]读取数据:  28%|██▊       | 1970287/7086503 [15:01<1:19:11, 1076.65it/s]读取数据:  28%|██▊       | 1970419/7086503 [15:02<1:19:49, 1068.28it/s]读取数据:  28%|██▊       | 1970562/7086503 [15:02<1:13:42, 1156.67it/s]读取数据:  28%|██▊       | 1970694/7086503 [15:02<1:11:10, 1197.81it/s]读取数据:  28%|██▊       | 1970819/7086503 [15:02<1:14:02, 1151.58it/s]读取数据:  28%|██▊       | 1970938/7086503 [15:02<1:13:28, 1160.31it/s]读取数据:  28%|██▊       | 1971070/7086503 [15:02<1:11:06, 1199.05it/s]读取数据:  28%|██▊       | 1971206/7086503 [15:02<1:09:10, 1232.46it/s]读取数据:  28%|██▊       | 1971331/7086503 [15:02<1:12:43, 1172.24it/s]读取数据:  28%|██▊       | 1971477/7086503 [15:02<1:08:13, 1249.58it/s]读取数据:  28%|██▊       | 1971621/7086503 [15:03<1:06:59, 1272.40it/s]读取数据:  28%|██▊       | 1971750/7086503 [15:03<1:07:52, 1256.07it/s]读取数据:  28%|██▊       | 1971887/7086503 [15:03<1:06:34, 1280.55it/s]读取数据:  28%|██▊       | 1972019/7086503 [15:03<1:06:01, 1291.21it/s]读取数据:  28%|██▊       | 1972160/7086503 [15:03<1:04:20, 1324.62it/s]读取数据:  28%|██▊       | 1972296/7086503 [15:03<1:03:51, 1334.83it/s]读取数据:  28%|██▊       | 1972430/7086503 [15:03<1:05:51, 1294.32it/s]读取数据:  28%|██▊       | 1972567/7086503 [15:03<1:06:33, 1280.53it/s]读取数据:  28%|██▊       | 1972711/7086503 [15:03<1:04:21, 1324.41it/s]读取数据:  28%|██▊       | 1972849/7086503 [15:03<1:03:42, 1337.75it/s]读取数据:  28%|██▊       | 1972984/7086503 [15:04<1:06:23, 1283.64it/s]读取数据:  28%|██▊       | 1973113/7086503 [15:04<1:10:31, 1208.41it/s]读取数据:  28%|██▊       | 1973235/7086503 [15:04<1:10:43, 1205.05it/s]读取数据:  28%|██▊       | 1973357/7086503 [15:04<1:15:46, 1124.64it/s]读取数据:  28%|██▊       | 1973471/7086503 [15:04<1:18:00, 1092.38it/s]读取数据:  28%|██▊       | 1973582/7086503 [15:04<1:22:23, 1034.26it/s]读取数据:  28%|██▊       | 1973738/7086503 [15:04<1:12:30, 1175.10it/s]读取数据:  28%|██▊       | 1973877/7086503 [15:04<1:09:06, 1233.00it/s]读取数据:  28%|██▊       | 1974003/7086503 [15:05<1:17:17, 1102.54it/s]读取数据:  28%|██▊       | 1974117/7086503 [15:05<1:20:07, 1063.43it/s]读取数据:  28%|██▊       | 1974226/7086503 [15:05<1:21:05, 1050.76it/s]读取数据:  28%|██▊       | 1974340/7086503 [15:05<1:19:22, 1073.37it/s]读取数据:  28%|██▊       | 1974449/7086503 [15:05<1:21:24, 1046.67it/s]读取数据:  28%|██▊       | 1974555/7086503 [15:05<1:22:02, 1038.58it/s]读取数据:  28%|██▊       | 1974683/7086503 [15:05<1:17:03, 1105.64it/s]读取数据:  28%|██▊       | 1974878/7086503 [15:05<1:03:15, 1346.92it/s]读取数据:  28%|██▊       | 1975015/7086503 [15:05<1:03:25, 1343.34it/s]读取数据:  28%|██▊       | 1975158/7086503 [15:05<1:02:17, 1367.55it/s]读取数据:  28%|██▊       | 1975296/7086503 [15:06<1:04:13, 1326.52it/s]读取数据:  28%|██▊       | 1975433/7086503 [15:06<1:03:39, 1337.98it/s]读取数据:  28%|██▊       | 1975568/7086503 [15:06<1:07:03, 1270.23it/s]读取数据:  28%|██▊       | 1975717/7086503 [15:06<1:03:56, 1332.32it/s]读取数据:  28%|██▊       | 1975852/7086503 [15:06<1:05:45, 1295.47it/s]读取数据:  28%|██▊       | 1976022/7086503 [15:06<1:00:23, 1410.19it/s]读取数据:  28%|██▊       | 1976165/7086503 [15:06<1:01:03, 1394.99it/s]读取数据:  28%|██▊       | 1976309/7086503 [15:06<1:00:36, 1405.37it/s]读取数据:  28%|██▊       | 1976467/7086503 [15:06<58:35, 1453.77it/s]  读取数据:  28%|██▊       | 1976613/7086503 [15:07<1:01:44, 1379.20it/s]读取数据:  28%|██▊       | 1976753/7086503 [15:07<1:03:15, 1346.26it/s]读取数据:  28%|██▊       | 1976889/7086503 [15:07<1:05:17, 1304.46it/s]读取数据:  28%|██▊       | 1977031/7086503 [15:07<1:03:46, 1335.30it/s]读取数据:  28%|██▊       | 1977166/7086503 [15:07<1:04:14, 1325.50it/s]读取数据:  28%|██▊       | 1977308/7086503 [15:07<1:02:57, 1352.51it/s]读取数据:  28%|██▊       | 1977444/7086503 [15:07<1:07:08, 1268.38it/s]读取数据:  28%|██▊       | 1977573/7086503 [15:07<1:07:53, 1254.32it/s]读取数据:  28%|██▊       | 1977702/7086503 [15:07<1:07:33, 1260.30it/s]读取数据:  28%|██▊       | 1977838/7086503 [15:07<1:06:04, 1288.58it/s]读取数据:  28%|██▊       | 1977968/7086503 [15:08<1:08:16, 1247.08it/s]读取数据:  28%|██▊       | 1978094/7086503 [15:08<1:09:26, 1226.13it/s]读取数据:  28%|██▊       | 1978218/7086503 [15:08<1:13:01, 1165.83it/s]读取数据:  28%|██▊       | 1978338/7086503 [15:08<1:12:27, 1174.94it/s]读取数据:  28%|██▊       | 1978457/7086503 [15:08<1:15:12, 1132.01it/s]读取数据:  28%|██▊       | 1978571/7086503 [15:08<1:15:27, 1128.13it/s]读取数据:  28%|██▊       | 1978711/7086503 [15:08<1:10:39, 1204.69it/s]读取数据:  28%|██▊       | 1978833/7086503 [15:08<1:10:43, 1203.57it/s]读取数据:  28%|██▊       | 1979020/7086503 [15:08<1:01:04, 1393.64it/s]读取数据:  28%|██▊       | 1979179/7086503 [15:09<58:45, 1448.51it/s]  读取数据:  28%|██▊       | 1979337/7086503 [15:09<57:16, 1485.95it/s]读取数据:  28%|██▊       | 1979504/7086503 [15:09<55:15, 1540.15it/s]读取数据:  28%|██▊       | 1979659/7086503 [15:09<57:49, 1471.99it/s]读取数据:  28%|██▊       | 1979816/7086503 [15:09<56:46, 1498.96it/s]读取数据:  28%|██▊       | 1979967/7086503 [15:09<59:41, 1425.63it/s]读取数据:  28%|██▊       | 1980111/7086503 [15:09<1:00:07, 1415.46it/s]读取数据:  28%|██▊       | 1980254/7086503 [15:09<1:03:07, 1348.14it/s]读取数据:  28%|██▊       | 1980405/7086503 [15:09<1:01:06, 1392.54it/s]读取数据:  28%|██▊       | 1980546/7086503 [15:09<1:02:03, 1371.13it/s]读取数据:  28%|██▊       | 1980684/7086503 [15:10<1:07:56, 1252.40it/s]读取数据:  28%|██▊       | 1980812/7086503 [15:10<1:07:32, 1259.75it/s]读取数据:  28%|██▊       | 1980957/7086503 [15:10<1:05:08, 1306.12it/s]读取数据:  28%|██▊       | 1981089/7086503 [15:10<1:05:48, 1292.85it/s]读取数据:  28%|██▊       | 1981220/7086503 [15:10<1:10:05, 1213.91it/s]读取数据:  28%|██▊       | 1981343/7086503 [15:10<1:11:57, 1182.30it/s]读取数据:  28%|██▊       | 1981463/7086503 [15:10<1:12:09, 1179.10it/s]读取数据:  28%|██▊       | 1981585/7086503 [15:10<1:11:39, 1187.27it/s]读取数据:  28%|██▊       | 1981707/7086503 [15:10<1:11:09, 1195.59it/s]读取数据:  28%|██▊       | 1981827/7086503 [15:11<1:12:25, 1174.67it/s]读取数据:  28%|██▊       | 1981945/7086503 [15:11<1:16:05, 1117.96it/s]读取数据:  28%|██▊       | 1982064/7086503 [15:11<1:14:54, 1135.77it/s]读取数据:  28%|██▊       | 1982179/7086503 [15:11<1:16:47, 1107.79it/s]读取数据:  28%|██▊       | 1982309/7086503 [15:11<1:13:19, 1160.25it/s]读取数据:  28%|██▊       | 1982426/7086503 [15:11<1:14:21, 1144.15it/s]读取数据:  28%|██▊       | 1982542/7086503 [15:11<1:14:05, 1148.10it/s]读取数据:  28%|██▊       | 1982658/7086503 [15:11<1:16:01, 1118.84it/s]读取数据:  28%|██▊       | 1982771/7086503 [15:11<1:18:07, 1088.85it/s]读取数据:  28%|██▊       | 1982891/7086503 [15:12<1:15:54, 1120.49it/s]读取数据:  28%|██▊       | 1983004/7086503 [15:12<1:15:53, 1120.72it/s]读取数据:  28%|██▊       | 1983125/7086503 [15:12<1:14:17, 1144.85it/s]读取数据:  28%|██▊       | 1983240/7086503 [15:12<1:15:46, 1122.38it/s]读取数据:  28%|██▊       | 1983367/7086503 [15:12<1:12:59, 1165.33it/s]读取数据:  28%|██▊       | 1983484/7086503 [15:12<1:14:11, 1146.36it/s]读取数据:  28%|██▊       | 1983599/7086503 [15:12<1:14:10, 1146.58it/s]读取数据:  28%|██▊       | 1983714/7086503 [15:12<1:16:03, 1118.06it/s]读取数据:  28%|██▊       | 1983827/7086503 [15:12<1:17:06, 1102.98it/s]读取数据:  28%|██▊       | 1983944/7086503 [15:12<1:15:53, 1120.68it/s]读取数据:  28%|██▊       | 1984072/7086503 [15:13<1:12:52, 1166.97it/s]读取数据:  28%|██▊       | 1984226/7086503 [15:13<1:06:40, 1275.37it/s]读取数据:  28%|██▊       | 1984358/7086503 [15:13<1:06:01, 1288.00it/s]读取数据:  28%|██▊       | 1984488/7086503 [15:13<1:05:51, 1291.19it/s]读取数据:  28%|██▊       | 1984618/7086503 [15:13<1:07:38, 1257.03it/s]读取数据:  28%|██▊       | 1984745/7086503 [15:13<1:08:15, 1245.61it/s]读取数据:  28%|██▊       | 1984870/7086503 [15:13<1:08:29, 1241.42it/s]读取数据:  28%|██▊       | 1984995/7086503 [15:13<1:09:26, 1224.28it/s]读取数据:  28%|██▊       | 1985142/7086503 [15:13<1:05:43, 1293.53it/s]读取数据:  28%|██▊       | 1985272/7086503 [15:13<1:06:12, 1284.05it/s]读取数据:  28%|██▊       | 1985421/7086503 [15:14<1:03:16, 1343.55it/s]读取数据:  28%|██▊       | 1985556/7086503 [15:14<1:03:34, 1337.09it/s]读取数据:  28%|██▊       | 1985690/7086503 [15:14<1:24:26, 1006.83it/s]读取数据:  28%|██▊       | 1985816/7086503 [15:14<1:19:40, 1066.88it/s]读取数据:  28%|██▊       | 1985994/7086503 [15:14<1:08:04, 1248.66it/s]读取数据:  28%|██▊       | 1986129/7086503 [15:14<1:09:22, 1225.24it/s]读取数据:  28%|██▊       | 1986267/7086503 [15:14<1:07:15, 1263.88it/s]读取数据:  28%|██▊       | 1986402/7086503 [15:14<1:06:11, 1284.32it/s]读取数据:  28%|██▊       | 1986546/7086503 [15:15<1:03:59, 1328.20it/s]读取数据:  28%|██▊       | 1986682/7086503 [15:15<1:10:19, 1208.55it/s]读取数据:  28%|██▊       | 1986807/7086503 [15:15<1:15:03, 1132.28it/s]读取数据:  28%|██▊       | 1986933/7086503 [15:15<1:12:59, 1164.50it/s]读取数据:  28%|██▊       | 1987053/7086503 [15:15<1:15:58, 1118.65it/s]读取数据:  28%|██▊       | 1987186/7086503 [15:15<1:12:16, 1175.82it/s]读取数据:  28%|██▊       | 1987306/7086503 [15:15<1:12:25, 1173.31it/s]读取数据:  28%|██▊       | 1987435/7086503 [15:15<1:10:26, 1206.38it/s]读取数据:  28%|██▊       | 1987557/7086503 [15:15<1:16:06, 1116.64it/s]读取数据:  28%|██▊       | 1987671/7086503 [15:16<1:22:00, 1036.27it/s]读取数据:  28%|██▊       | 1987783/7086503 [15:16<1:20:17, 1058.32it/s]读取数据:  28%|██▊       | 1987901/7086503 [15:16<1:19:41, 1066.33it/s]读取数据:  28%|██▊       | 1988009/7086503 [15:16<1:23:34, 1016.70it/s]读取数据:  28%|██▊       | 1988147/7086503 [15:16<1:16:08, 1116.09it/s]读取数据:  28%|██▊       | 1988275/7086503 [15:16<1:13:08, 1161.67it/s]读取数据:  28%|██▊       | 1988401/7086503 [15:16<1:11:25, 1189.74it/s]读取数据:  28%|██▊       | 1988522/7086503 [15:16<1:15:37, 1123.54it/s]读取数据:  28%|██▊       | 1988636/7086503 [15:16<1:16:28, 1111.03it/s]读取数据:  28%|██▊       | 1988751/7086503 [15:17<1:15:48, 1120.79it/s]读取数据:  28%|██▊       | 1988871/7086503 [15:17<1:14:20, 1142.72it/s]读取数据:  28%|██▊       | 1989001/7086503 [15:17<1:11:59, 1180.21it/s]读取数据:  28%|██▊       | 1989144/7086503 [15:17<1:07:53, 1251.29it/s]读取数据:  28%|██▊       | 1989270/7086503 [15:17<1:07:45, 1253.81it/s]读取数据:  28%|██▊       | 1989396/7086503 [15:17<1:08:03, 1248.07it/s]读取数据:  28%|██▊       | 1989523/7086503 [15:17<1:07:44, 1254.14it/s]读取数据:  28%|██▊       | 1989649/7086503 [15:17<1:13:08, 1161.43it/s]读取数据:  28%|██▊       | 1989781/7086503 [15:17<1:10:27, 1205.55it/s]读取数据:  28%|██▊       | 1989903/7086503 [15:17<1:10:48, 1199.59it/s]读取数据:  28%|██▊       | 1990027/7086503 [15:18<1:10:12, 1209.81it/s]读取数据:  28%|██▊       | 1990171/7086503 [15:18<1:06:42, 1273.29it/s]读取数据:  28%|██▊       | 1990299/7086503 [15:18<1:10:36, 1202.79it/s]读取数据:  28%|██▊       | 1990421/7086503 [15:18<1:15:11, 1129.45it/s]读取数据:  28%|██▊       | 1990552/7086503 [15:18<1:12:08, 1177.17it/s]读取数据:  28%|██▊       | 1990672/7086503 [15:18<1:37:04, 874.89it/s] 读取数据:  28%|██▊       | 1990789/7086503 [15:18<1:34:15, 901.00it/s]读取数据:  28%|██▊       | 1990935/7086503 [15:18<1:22:22, 1030.98it/s]读取数据:  28%|██▊       | 1991073/7086503 [15:19<1:15:53, 1119.05it/s]读取数据:  28%|██▊       | 1991207/7086503 [15:19<1:12:23, 1173.20it/s]读取数据:  28%|██▊       | 1991338/7086503 [15:19<1:10:59, 1196.29it/s]读取数据:  28%|██▊       | 1991489/7086503 [15:19<1:06:15, 1281.69it/s]读取数据:  28%|██▊       | 1991621/7086503 [15:19<1:06:12, 1282.46it/s]读取数据:  28%|██▊       | 1991752/7086503 [15:19<1:07:02, 1266.68it/s]读取数据:  28%|██▊       | 1991889/7086503 [15:19<1:05:31, 1295.78it/s]读取数据:  28%|██▊       | 1992021/7086503 [15:19<1:06:26, 1277.87it/s]读取数据:  28%|██▊       | 1992150/7086503 [15:19<1:12:26, 1172.02it/s]读取数据:  28%|██▊       | 1992270/7086503 [15:20<1:12:28, 1171.47it/s]读取数据:  28%|██▊       | 1992435/7086503 [15:20<1:09:05, 1228.91it/s]读取数据:  28%|██▊       | 1992559/7086503 [15:20<1:15:42, 1121.32it/s]读取数据:  28%|██▊       | 1992673/7086503 [15:20<1:16:32, 1109.14it/s]读取数据:  28%|██▊       | 1992885/7086503 [15:20<1:01:31, 1379.81it/s]读取数据:  28%|██▊       | 1993027/7086503 [15:20<1:04:53, 1308.18it/s]读取数据:  28%|██▊       | 1993176/7086503 [15:20<1:02:31, 1357.54it/s]读取数据:  28%|██▊       | 1993315/7086503 [15:20<1:17:00, 1102.25it/s]读取数据:  28%|██▊       | 1993451/7086503 [15:20<1:12:52, 1164.92it/s]读取数据:  28%|██▊       | 1993581/7086503 [15:21<1:10:45, 1199.60it/s]读取数据:  28%|██▊       | 1993746/7086503 [15:21<1:04:20, 1319.26it/s]读取数据:  28%|██▊       | 1993884/7086503 [15:21<1:04:25, 1317.55it/s]读取数据:  28%|██▊       | 1994020/7086503 [15:21<1:07:40, 1254.09it/s]读取数据:  28%|██▊       | 1994172/7086503 [15:21<1:04:01, 1325.59it/s]读取数据:  28%|██▊       | 1994315/7086503 [15:21<1:02:42, 1353.38it/s]读取数据:  28%|██▊       | 1994462/7086503 [15:21<1:01:17, 1384.68it/s]读取数据:  28%|██▊       | 1994603/7086503 [15:21<1:02:00, 1368.58it/s]读取数据:  28%|██▊       | 1994747/7086503 [15:21<1:01:06, 1388.59it/s]读取数据:  28%|██▊       | 1994900/7086503 [15:22<59:26, 1427.77it/s]  读取数据:  28%|██▊       | 1995047/7086503 [15:22<58:56, 1439.65it/s]读取数据:  28%|██▊       | 1995192/7086503 [15:22<1:00:17, 1407.31it/s]读取数据:  28%|██▊       | 1995336/7086503 [15:22<1:00:01, 1413.76it/s]读取数据:  28%|██▊       | 1995491/7086503 [15:22<58:25, 1452.33it/s]  读取数据:  28%|██▊       | 1995637/7086503 [15:22<59:40, 1421.80it/s]读取数据:  28%|██▊       | 1995780/7086503 [15:22<1:02:09, 1364.95it/s]读取数据:  28%|██▊       | 1995918/7086503 [15:22<1:38:40, 859.88it/s] 读取数据:  28%|██▊       | 1996028/7086503 [15:23<1:33:58, 902.73it/s]读取数据:  28%|██▊       | 1996137/7086503 [15:23<1:31:17, 929.34it/s]读取数据:  28%|██▊       | 1996300/7086503 [15:23<1:17:23, 1096.24it/s]读取数据:  28%|██▊       | 1996473/7086503 [15:23<1:08:19, 1241.74it/s]读取数据:  28%|██▊       | 1996631/7086503 [15:23<1:03:48, 1329.63it/s]读取数据:  28%|██▊       | 1996792/7086503 [15:23<1:00:22, 1405.00it/s]读取数据:  28%|██▊       | 1996942/7086503 [15:23<59:15, 1431.52it/s]  读取数据:  28%|██▊       | 1997104/7086503 [15:23<57:06, 1485.29it/s]读取数据:  28%|██▊       | 1997257/7086503 [15:23<57:12, 1482.50it/s]读取数据:  28%|██▊       | 1997408/7086503 [15:24<1:07:16, 1260.86it/s]读取数据:  28%|██▊       | 1997546/7086503 [15:24<1:05:39, 1291.65it/s]读取数据:  28%|██▊       | 1997681/7086503 [15:24<1:09:22, 1222.66it/s]读取数据:  28%|██▊       | 1997808/7086503 [15:24<1:10:54, 1196.13it/s]读取数据:  28%|██▊       | 1997931/7086503 [15:24<1:11:42, 1182.57it/s]读取数据:  28%|██▊       | 1998084/7086503 [15:24<1:06:27, 1275.96it/s]读取数据:  28%|██▊       | 1998233/7086503 [15:24<1:03:28, 1336.05it/s]读取数据:  28%|██▊       | 1998406/7086503 [15:24<58:34, 1447.70it/s]  读取数据:  28%|██▊       | 1998553/7086503 [15:24<1:02:42, 1352.40it/s]读取数据:  28%|██▊       | 1998691/7086503 [15:25<1:03:39, 1331.92it/s]读取数据:  28%|██▊       | 1998826/7086503 [15:25<1:40:55, 840.17it/s] 读取数据:  28%|██▊       | 1998969/7086503 [15:25<1:28:30, 958.02it/s]读取数据:  28%|██▊       | 1999158/7086503 [15:25<1:12:48, 1164.64it/s]读取数据:  28%|██▊       | 1999298/7086503 [15:25<1:10:50, 1196.97it/s]读取数据:  28%|██▊       | 1999440/7086503 [15:25<1:07:43, 1251.95it/s]读取数据:  28%|██▊       | 1999618/7086503 [15:25<1:01:03, 1388.68it/s]读取数据:  28%|██▊       | 1999768/7086503 [15:25<1:02:09, 1363.96it/s]读取数据:  28%|██▊       | 1999945/7086503 [15:26<57:32, 1473.34it/s]  读取数据:  28%|██▊       | 1999945/7086503 [15:45<57:32, 1473.34it/s]读取数据:  28%|██▊       | 2000000/7086503 [22:04<1301:44:39,  1.09it/s]读取数据:  28%|██▊       | 2000001/7086503 [22:04<1298:24:51,  1.09it/s]读取数据:  28%|██▊       | 2000109/7086503 [22:04<861:41:51,  1.64it/s] 读取数据:  28%|██▊       | 2000209/7086503 [22:04<597:05:08,  2.37it/s]读取数据:  28%|██▊       | 2000292/7086503 [22:05<437:47:02,  3.23it/s]读取数据:  28%|██▊       | 2000374/7086503 [22:05<318:13:40,  4.44it/s]读取数据:  28%|██▊       | 2000463/7086503 [22:05<223:46:31,  6.31it/s]读取数据:  28%|██▊       | 2000547/7086503 [22:05<160:06:04,  8.82it/s]读取数据:  28%|██▊       | 2000657/7086503 [22:05<104:38:30, 13.50it/s]读取数据:  28%|██▊       | 2000748/7086503 [22:05<74:37:50, 18.93it/s] 读取数据:  28%|██▊       | 2000834/7086503 [22:05<54:09:18, 26.09it/s]读取数据:  28%|██▊       | 2000927/7086503 [22:05<38:10:54, 37.00it/s]读取数据:  28%|██▊       | 2001008/7086503 [22:05<28:11:27, 50.11it/s]读取数据:  28%|██▊       | 2001089/7086503 [22:06<20:46:06, 68.02it/s]读取数据:  28%|██▊       | 2001200/7086503 [22:06<13:50:25, 102.06it/s]读取数据:  28%|██▊       | 2001293/7086503 [22:06<10:10:14, 138.89it/s]读取数据:  28%|██▊       | 2001385/7086503 [22:06<7:42:33, 183.23it/s] 读取数据:  28%|██▊       | 2001471/7086503 [22:06<6:05:13, 232.05it/s]读取数据:  28%|██▊       | 2001562/7086503 [22:06<4:43:37, 298.81it/s]读取数据:  28%|██▊       | 2001652/7086503 [22:06<3:47:15, 372.91it/s]读取数据:  28%|██▊       | 2001746/7086503 [22:06<3:05:15, 457.44it/s]读取数据:  28%|██▊       | 2001834/7086503 [22:06<2:55:25, 483.10it/s]读取数据:  28%|██▊       | 2001913/7086503 [22:07<2:56:32, 480.03it/s]读取数据:  28%|██▊       | 2001983/7086503 [22:07<2:48:53, 501.76it/s]读取数据:  28%|██▊       | 2002049/7086503 [22:07<2:47:46, 505.07it/s]读取数据:  28%|██▊       | 2002155/7086503 [22:07<2:15:25, 625.75it/s]读取数据:  28%|██▊       | 2002262/7086503 [22:07<2:03:07, 688.24it/s]读取数据:  28%|██▊       | 2002340/7086503 [22:07<2:28:32, 570.48it/s]读取数据:  28%|██▊       | 2002430/7086503 [22:07<2:12:05, 641.46it/s]读取数据:  28%|██▊       | 2002504/7086503 [22:07<2:14:11, 631.45it/s]读取数据:  28%|██▊       | 2002610/7086503 [22:08<1:55:15, 735.19it/s]读取数据:  28%|██▊       | 2002729/7086503 [22:08<1:39:26, 852.05it/s]读取数据:  28%|██▊       | 2002821/7086503 [22:08<1:51:01, 763.10it/s]读取数据:  28%|██▊       | 2002912/7086503 [22:08<1:46:09, 798.12it/s]读取数据:  28%|██▊       | 2003012/7086503 [22:08<1:39:37, 850.38it/s]读取数据:  28%|██▊       | 2003141/7086503 [22:08<1:27:19, 970.22it/s]读取数据:  28%|██▊       | 2003243/7086503 [22:08<1:26:19, 981.50it/s]读取数据:  28%|██▊       | 2003345/7086503 [22:08<1:45:01, 806.68it/s]读取数据:  28%|██▊       | 2003464/7086503 [22:09<1:34:00, 901.14it/s]读取数据:  28%|██▊       | 2003561/7086503 [22:09<4:20:01, 325.81it/s]读取数据:  28%|██▊       | 2003675/7086503 [22:09<3:21:15, 420.93it/s]读取数据:  28%|██▊       | 2003762/7086503 [22:10<2:56:20, 480.41it/s]读取数据:  28%|██▊       | 2003846/7086503 [22:10<2:48:07, 503.86it/s]读取数据:  28%|██▊       | 2003947/7086503 [22:10<2:22:21, 595.01it/s]读取数据:  28%|██▊       | 2004057/7086503 [22:10<2:01:27, 697.45it/s]读取数据:  28%|██▊       | 2004148/7086503 [22:10<2:11:59, 641.79it/s]读取数据:  28%|██▊       | 2004232/7086503 [22:10<2:05:22, 675.61it/s]读取数据:  28%|██▊       | 2004312/7086503 [22:10<2:10:14, 650.36it/s]读取数据:  28%|██▊       | 2004407/7086503 [22:10<1:57:25, 721.32it/s]读取数据:  28%|██▊       | 2004514/7086503 [22:10<1:44:45, 808.51it/s]读取数据:  28%|██▊       | 2004602/7086503 [22:11<2:18:21, 612.16it/s]读取数据:  28%|██▊       | 2004696/7086503 [22:11<2:04:12, 681.94it/s]读取数据:  28%|██▊       | 2004793/7086503 [22:11<1:53:11, 748.24it/s]读取数据:  28%|██▊       | 2004877/7086503 [22:11<1:50:26, 766.92it/s]读取数据:  28%|██▊       | 2005027/7086503 [22:11<1:28:11, 960.26it/s]读取数据:  28%|██▊       | 2005131/7086503 [22:11<1:30:16, 938.12it/s]读取数据:  28%|██▊       | 2005248/7086503 [22:11<1:24:44, 999.44it/s]读取数据:  28%|██▊       | 2005365/7086503 [22:11<1:20:56, 1046.21it/s]读取数据:  28%|██▊       | 2005489/7086503 [22:12<1:17:10, 1097.31it/s]读取数据:  28%|██▊       | 2005602/7086503 [22:12<1:34:23, 897.06it/s] 读取数据:  28%|██▊       | 2005719/7086503 [22:12<1:27:44, 965.10it/s]读取数据:  28%|██▊       | 2005838/7086503 [22:12<1:22:43, 1023.68it/s]读取数据:  28%|██▊       | 2005954/7086503 [22:12<1:19:51, 1060.27it/s]读取数据:  28%|██▊       | 2006080/7086503 [22:12<1:16:03, 1113.35it/s]读取数据:  28%|██▊       | 2006195/7086503 [22:12<1:16:14, 1110.50it/s]读取数据:  28%|██▊       | 2006309/7086503 [22:12<1:22:19, 1028.47it/s]读取数据:  28%|██▊       | 2006415/7086503 [22:13<1:34:16, 898.17it/s] 读取数据:  28%|██▊       | 2006539/7086503 [22:13<1:26:02, 984.11it/s]读取数据:  28%|██▊       | 2006643/7086503 [22:13<1:37:23, 869.38it/s]读取数据:  28%|██▊       | 2006744/7086503 [22:13<1:33:40, 903.84it/s]读取数据:  28%|██▊       | 2006867/7086503 [22:13<1:27:21, 969.05it/s]读取数据:  28%|██▊       | 2006968/7086503 [22:13<1:36:37, 876.14it/s]读取数据:  28%|██▊       | 2007086/7086503 [22:13<1:28:49, 953.13it/s]读取数据:  28%|██▊       | 2007186/7086503 [22:13<1:48:30, 780.18it/s]读取数据:  28%|██▊       | 2007299/7086503 [22:14<1:38:17, 861.27it/s]读取数据:  28%|██▊       | 2007393/7086503 [22:14<1:43:07, 820.81it/s]读取数据:  28%|██▊       | 2007481/7086503 [22:14<2:01:21, 697.53it/s]读取数据:  28%|██▊       | 2007582/7086503 [22:14<1:50:08, 768.54it/s]读取数据:  28%|██▊       | 2007686/7086503 [22:14<1:41:28, 834.23it/s]读取数据:  28%|██▊       | 2007797/7086503 [22:14<1:33:30, 905.29it/s]读取数据:  28%|██▊       | 2007905/7086503 [22:14<1:28:58, 951.37it/s]读取数据:  28%|██▊       | 2008005/7086503 [22:14<1:37:23, 869.13it/s]读取数据:  28%|██▊       | 2008112/7086503 [22:14<1:31:53, 921.04it/s]读取数据:  28%|██▊       | 2008208/7086503 [22:15<1:42:29, 825.79it/s]读取数据:  28%|██▊       | 2008343/7086503 [22:15<1:28:09, 960.02it/s]读取数据:  28%|██▊       | 2008482/7086503 [22:15<1:18:49, 1073.62it/s]读取数据:  28%|██▊       | 2008599/7086503 [22:15<1:17:14, 1095.57it/s]读取数据:  28%|██▊       | 2008730/7086503 [22:15<1:13:20, 1153.88it/s]读取数据:  28%|██▊       | 2008850/7086503 [22:15<1:12:33, 1166.33it/s]读取数据:  28%|██▊       | 2008969/7086503 [22:15<1:13:04, 1158.18it/s]读取数据:  28%|██▊       | 2009087/7086503 [22:15<1:39:34, 849.91it/s] 读取数据:  28%|██▊       | 2009221/7086503 [22:16<1:27:49, 963.52it/s]读取数据:  28%|██▊       | 2009350/7086503 [22:16<1:20:59, 1044.86it/s]读取数据:  28%|██▊       | 2009497/7086503 [22:16<1:13:10, 1156.37it/s]读取数据:  28%|██▊       | 2009622/7086503 [22:16<1:26:11, 981.76it/s] 读取数据:  28%|██▊       | 2009739/7086503 [22:16<1:22:27, 1026.17it/s]读取数据:  28%|██▊       | 2009863/7086503 [22:16<1:18:19, 1080.22it/s]读取数据:  28%|██▊       | 2009978/7086503 [22:16<1:37:07, 871.19it/s] 读取数据:  28%|██▊       | 2010109/7086503 [22:16<1:26:55, 973.41it/s]读取数据:  28%|██▊       | 2010249/7086503 [22:17<1:18:19, 1080.16it/s]读取数据:  28%|██▊       | 2010391/7086503 [22:17<1:12:24, 1168.40it/s]读取数据:  28%|██▊       | 2010516/7086503 [22:17<1:27:40, 965.01it/s] 读取数据:  28%|██▊       | 2010637/7086503 [22:17<1:22:47, 1021.82it/s]读取数据:  28%|██▊       | 2010749/7086503 [22:17<1:22:10, 1029.51it/s]读取数据:  28%|██▊       | 2010899/7086503 [22:17<1:13:26, 1151.84it/s]读取数据:  28%|██▊       | 2011021/7086503 [22:17<1:15:40, 1117.93it/s]读取数据:  28%|██▊       | 2011138/7086503 [22:17<1:17:24, 1092.67it/s]读取数据:  28%|██▊       | 2011251/7086503 [22:17<1:22:22, 1026.95it/s]读取数据:  28%|██▊       | 2011386/7086503 [22:18<1:16:10, 1110.45it/s]读取数据:  28%|██▊       | 2011524/7086503 [22:18<1:11:30, 1182.72it/s]读取数据:  28%|██▊       | 2011645/7086503 [22:18<1:20:55, 1045.20it/s]读取数据:  28%|██▊       | 2011754/7086503 [22:18<1:22:36, 1023.89it/s]读取数据:  28%|██▊       | 2011860/7086503 [22:18<1:41:04, 836.83it/s] 读取数据:  28%|██▊       | 2011972/7086503 [22:18<1:33:42, 902.58it/s]读取数据:  28%|██▊       | 2012127/7086503 [22:18<1:19:29, 1064.02it/s]读取数据:  28%|██▊       | 2012242/7086503 [22:18<1:25:33, 988.51it/s] 读取数据:  28%|██▊       | 2012374/7086503 [22:19<1:18:48, 1073.06it/s]读取数据:  28%|██▊       | 2012516/7086503 [22:19<1:12:42, 1163.21it/s]读取数据:  28%|██▊       | 2012638/7086503 [22:19<1:15:25, 1121.06it/s]读取数据:  28%|██▊       | 2012762/7086503 [22:19<1:13:21, 1152.69it/s]读取数据:  28%|██▊       | 2012884/7086503 [22:19<1:13:47, 1145.90it/s]读取数据:  28%|██▊       | 2013013/7086503 [22:19<1:11:21, 1185.03it/s]读取数据:  28%|██▊       | 2013143/7086503 [22:19<1:09:27, 1217.36it/s]读取数据:  28%|██▊       | 2013285/7086503 [22:19<1:06:16, 1275.86it/s]读取数据:  28%|██▊       | 2013426/7086503 [22:19<1:04:24, 1312.69it/s]读取数据:  28%|██▊       | 2013559/7086503 [22:19<1:04:30, 1310.61it/s]读取数据:  28%|██▊       | 2013691/7086503 [22:20<1:05:43, 1286.35it/s]读取数据:  28%|██▊       | 2013831/7086503 [22:20<1:04:13, 1316.49it/s]读取数据:  28%|██▊       | 2013964/7086503 [22:20<1:04:39, 1307.61it/s]读取数据:  28%|██▊       | 2014096/7086503 [22:20<1:24:58, 994.96it/s] 读取数据:  28%|██▊       | 2014215/7086503 [22:20<1:21:14, 1040.53it/s]读取数据:  28%|██▊       | 2014345/7086503 [22:20<1:16:25, 1106.12it/s]读取数据:  28%|██▊       | 2014463/7086503 [22:20<1:19:57, 1057.20it/s]读取数据:  28%|██▊       | 2014603/7086503 [22:20<1:13:38, 1147.75it/s]读取数据:  28%|██▊       | 2014735/7086503 [22:21<1:10:49, 1193.48it/s]读取数据:  28%|██▊       | 2014876/7086503 [22:21<1:07:24, 1253.85it/s]读取数据:  28%|██▊       | 2015005/7086503 [22:21<1:25:13, 991.85it/s] 读取数据:  28%|██▊       | 2015149/7086503 [22:21<1:16:49, 1100.11it/s]读取数据:  28%|██▊       | 2015269/7086503 [22:21<1:27:14, 968.72it/s] 读取数据:  28%|██▊       | 2015410/7086503 [22:21<1:18:47, 1072.70it/s]读取数据:  28%|██▊       | 2015527/7086503 [22:21<1:27:22, 967.19it/s] 读取数据:  28%|██▊       | 2015648/7086503 [22:21<1:22:27, 1024.84it/s]读取数据:  28%|██▊       | 2015787/7086503 [22:22<1:15:36, 1117.69it/s]读取数据:  28%|██▊       | 2015910/7086503 [22:22<1:13:42, 1146.64it/s]读取数据:  28%|██▊       | 2016051/7086503 [22:22<1:09:21, 1218.48it/s]读取数据:  28%|██▊       | 2016178/7086503 [22:22<1:08:38, 1230.99it/s]读取数据:  28%|██▊       | 2016311/7086503 [22:22<1:07:05, 1259.47it/s]读取数据:  28%|██▊       | 2016439/7086503 [22:22<1:06:50, 1264.34it/s]读取数据:  28%|██▊       | 2016580/7086503 [22:22<1:04:47, 1304.11it/s]读取数据:  28%|██▊       | 2016715/7086503 [22:22<1:04:08, 1317.35it/s]读取数据:  28%|██▊       | 2016849/7086503 [22:22<1:03:52, 1322.82it/s]读取数据:  28%|██▊       | 2017004/7086503 [22:22<1:00:55, 1386.74it/s]读取数据:  28%|██▊       | 2017144/7086503 [22:23<1:02:59, 1341.31it/s]读取数据:  28%|██▊       | 2017291/7086503 [22:23<1:01:16, 1378.69it/s]读取数据:  28%|██▊       | 2017439/7086503 [22:23<1:00:00, 1407.90it/s]读取数据:  28%|██▊       | 2017581/7086503 [22:23<1:04:24, 1311.62it/s]读取数据:  28%|██▊       | 2017714/7086503 [22:23<1:27:26, 966.05it/s] 读取数据:  28%|██▊       | 2017825/7086503 [22:23<1:25:51, 983.97it/s]读取数据:  28%|██▊       | 2017964/7086503 [22:23<1:18:47, 1072.04it/s]读取数据:  28%|██▊       | 2018081/7086503 [22:23<1:28:15, 957.16it/s] 读取数据:  28%|██▊       | 2018210/7086503 [22:24<1:21:24, 1037.53it/s]读取数据:  28%|██▊       | 2018322/7086503 [22:24<1:23:48, 1007.99it/s]读取数据:  28%|██▊       | 2018458/7086503 [22:24<1:16:52, 1098.75it/s]读取数据:  28%|██▊       | 2018573/7086503 [22:24<1:18:57, 1069.81it/s]读取数据:  28%|██▊       | 2018684/7086503 [22:24<1:20:28, 1049.55it/s]读取数据:  28%|██▊       | 2018823/7086503 [22:24<1:14:02, 1140.66it/s]读取数据:  28%|██▊       | 2018940/7086503 [22:24<1:13:33, 1148.32it/s]读取数据:  28%|██▊       | 2019057/7086503 [22:24<1:13:54, 1142.67it/s]读取数据:  28%|██▊       | 2019173/7086503 [22:24<1:13:56, 1142.25it/s]读取数据:  28%|██▊       | 2019289/7086503 [22:25<1:19:59, 1055.69it/s]读取数据:  28%|██▊       | 2019436/7086503 [22:25<1:12:14, 1168.98it/s]读取数据:  28%|██▊       | 2019568/7086503 [22:25<1:09:44, 1210.93it/s]读取数据:  29%|██▊       | 2019723/7086503 [22:25<1:04:34, 1307.80it/s]读取数据:  29%|██▊       | 2019874/7086503 [22:25<1:01:47, 1366.57it/s]读取数据:  29%|██▊       | 2020012/7086503 [22:25<1:02:04, 1360.32it/s]读取数据:  29%|██▊       | 2020149/7086503 [22:25<1:10:49, 1192.29it/s]读取数据:  29%|██▊       | 2020274/7086503 [22:25<1:10:00, 1206.14it/s]读取数据:  29%|██▊       | 2020398/7086503 [22:26<1:43:00, 819.65it/s] 读取数据:  29%|██▊       | 2020518/7086503 [22:26<1:33:52, 899.39it/s]读取数据:  29%|██▊       | 2020625/7086503 [22:26<1:39:39, 847.27it/s]读取数据:  29%|██▊       | 2020740/7086503 [22:26<1:32:17, 914.87it/s]读取数据:  29%|██▊       | 2020859/7086503 [22:26<1:26:00, 981.63it/s]读取数据:  29%|██▊       | 2020998/7086503 [22:26<1:17:36, 1087.89it/s]读取数据:  29%|██▊       | 2021126/7086503 [22:26<1:14:05, 1139.50it/s]读取数据:  29%|██▊       | 2021263/7086503 [22:26<1:10:11, 1202.61it/s]读取数据:  29%|██▊       | 2021388/7086503 [22:27<1:19:09, 1066.56it/s]读取数据:  29%|██▊       | 2021501/7086503 [22:27<1:22:24, 1024.36it/s]读取数据:  29%|██▊       | 2021615/7086503 [22:27<1:20:03, 1054.31it/s]读取数据:  29%|██▊       | 2021724/7086503 [22:27<1:27:58, 959.50it/s] 读取数据:  29%|██▊       | 2021866/7086503 [22:27<1:18:16, 1078.31it/s]读取数据:  29%|██▊       | 2021979/7086503 [22:27<1:27:26, 965.29it/s] 读取数据:  29%|██▊       | 2022097/7086503 [22:27<1:22:46, 1019.67it/s]读取数据:  29%|██▊       | 2022204/7086503 [22:27<1:22:59, 1017.11it/s]读取数据:  29%|██▊       | 2022314/7086503 [22:27<1:21:13, 1039.10it/s]读取数据:  29%|██▊       | 2022448/7086503 [22:28<1:15:18, 1120.63it/s]读取数据:  29%|██▊       | 2022572/7086503 [22:28<1:13:57, 1141.21it/s]读取数据:  29%|██▊       | 2022688/7086503 [22:28<1:17:36, 1087.43it/s]读取数据:  29%|██▊       | 2022799/7086503 [22:28<1:29:47, 939.82it/s] 读取数据:  29%|██▊       | 2022916/7086503 [22:28<1:24:36, 997.41it/s]读取数据:  29%|██▊       | 2023020/7086503 [22:28<1:30:00, 937.68it/s]读取数据:  29%|██▊       | 2023166/7086503 [22:28<1:18:35, 1073.81it/s]读取数据:  29%|██▊       | 2023292/7086503 [22:28<1:15:10, 1122.62it/s]读取数据:  29%|██▊       | 2023433/7086503 [22:28<1:10:14, 1201.27it/s]读取数据:  29%|██▊       | 2023560/7086503 [22:29<1:09:14, 1218.64it/s]读取数据:  29%|██▊       | 2023684/7086503 [22:29<1:09:24, 1215.72it/s]读取数据:  29%|██▊       | 2023808/7086503 [22:29<1:22:25, 1023.76it/s]读取数据:  29%|██▊       | 2023938/7086503 [22:29<1:17:08, 1093.83it/s]读取数据:  29%|██▊       | 2024077/7086503 [22:29<1:12:03, 1170.98it/s]读取数据:  29%|██▊       | 2024216/7086503 [22:29<1:08:34, 1230.46it/s]读取数据:  29%|██▊       | 2024343/7086503 [22:29<1:08:16, 1235.63it/s]读取数据:  29%|██▊       | 2024479/7086503 [22:29<1:06:24, 1270.47it/s]读取数据:  29%|██▊       | 2024609/7086503 [22:30<1:47:43, 783.17it/s] 读取数据:  29%|██▊       | 2024712/7086503 [22:30<1:47:50, 782.23it/s]读取数据:  29%|██▊       | 2024843/7086503 [22:30<1:34:18, 894.47it/s]读取数据:  29%|██▊       | 2024959/7086503 [22:30<1:28:13, 956.26it/s]读取数据:  29%|██▊       | 2025068/7086503 [22:30<1:26:39, 973.53it/s]读取数据:  29%|██▊       | 2025175/7086503 [22:30<1:32:54, 907.88it/s]读取数据:  29%|██▊       | 2025273/7086503 [22:30<1:32:41, 910.08it/s]读取数据:  29%|██▊       | 2025407/7086503 [22:30<1:22:35, 1021.39it/s]读取数据:  29%|██▊       | 2025516/7086503 [22:31<1:21:11, 1038.85it/s]读取数据:  29%|██▊       | 2025624/7086503 [22:31<1:45:01, 803.07it/s] 读取数据:  29%|██▊       | 2025755/7086503 [22:31<1:31:32, 921.31it/s]读取数据:  29%|██▊       | 2025882/7086503 [22:31<1:23:40, 1007.96it/s]读取数据:  29%|██▊       | 2026037/7086503 [22:31<1:13:19, 1150.31it/s]读取数据:  29%|██▊       | 2026161/7086503 [22:31<1:14:17, 1135.13it/s]读取数据:  29%|██▊       | 2026281/7086503 [22:31<1:13:36, 1145.74it/s]读取数据:  29%|██▊       | 2026409/7086503 [22:31<1:11:18, 1182.69it/s]读取数据:  29%|██▊       | 2026555/7086503 [22:31<1:06:55, 1260.07it/s]读取数据:  29%|██▊       | 2026684/7086503 [22:32<1:10:43, 1192.28it/s]读取数据:  29%|██▊       | 2026806/7086503 [22:32<1:11:16, 1183.26it/s]读取数据:  29%|██▊       | 2026927/7086503 [22:32<1:24:48, 994.34it/s] 读取数据:  29%|██▊       | 2027079/7086503 [22:32<1:14:58, 1124.77it/s]读取数据:  29%|██▊       | 2027212/7086503 [22:32<1:15:16, 1120.17it/s]读取数据:  29%|██▊       | 2027329/7086503 [22:32<1:28:30, 952.61it/s] 读取数据:  29%|██▊       | 2027459/7086503 [22:32<1:21:23, 1035.98it/s]读取数据:  29%|██▊       | 2027602/7086503 [22:32<1:14:14, 1135.76it/s]读取数据:  29%|██▊       | 2027736/7086503 [22:33<1:10:53, 1189.32it/s]读取数据:  29%|██▊       | 2027861/7086503 [22:33<1:17:57, 1081.45it/s]读取数据:  29%|██▊       | 2028013/7086503 [22:33<1:10:30, 1195.80it/s]读取数据:  29%|██▊       | 2028159/7086503 [22:33<1:06:35, 1266.16it/s]读取数据:  29%|██▊       | 2028291/7086503 [22:33<1:07:42, 1245.04it/s]读取数据:  29%|██▊       | 2028433/7086503 [22:33<1:05:11, 1293.22it/s]读取数据:  29%|██▊       | 2028584/7086503 [22:33<1:02:18, 1353.10it/s]读取数据:  29%|██▊       | 2028722/7086503 [22:33<1:03:11, 1333.92it/s]读取数据:  29%|██▊       | 2028857/7086503 [22:33<1:03:12, 1333.45it/s]读取数据:  29%|██▊       | 2028992/7086503 [22:33<1:03:16, 1332.20it/s]读取数据:  29%|██▊       | 2029126/7086503 [22:34<1:04:20, 1309.89it/s]读取数据:  29%|██▊       | 2029258/7086503 [22:34<2:21:15, 596.72it/s] 读取数据:  29%|██▊       | 2029395/7086503 [22:34<1:57:11, 719.17it/s]读取数据:  29%|██▊       | 2029506/7086503 [22:34<1:46:55, 788.29it/s]读取数据:  29%|██▊       | 2029618/7086503 [22:34<1:38:22, 856.78it/s]读取数据:  29%|██▊       | 2029738/7086503 [22:35<1:32:38, 909.75it/s]读取数据:  29%|██▊       | 2029848/7086503 [22:35<1:31:09, 924.45it/s]读取数据:  29%|██▊       | 2029991/7086503 [22:35<1:20:13, 1050.38it/s]读取数据:  29%|██▊       | 2030108/7086503 [22:35<1:26:06, 978.68it/s] 读取数据:  29%|██▊       | 2030215/7086503 [22:35<1:52:50, 746.86it/s]读取数据:  29%|██▊       | 2030332/7086503 [22:35<1:40:44, 836.48it/s]读取数据:  29%|██▊       | 2030463/7086503 [22:35<1:29:02, 946.30it/s]读取数据:  29%|██▊       | 2030596/7086503 [22:35<1:20:55, 1041.23it/s]读取数据:  29%|██▊       | 2030723/7086503 [22:36<1:16:41, 1098.79it/s]读取数据:  29%|██▊       | 2030842/7086503 [22:36<1:17:01, 1094.01it/s]读取数据:  29%|██▊       | 2030981/7086503 [22:36<1:11:48, 1173.38it/s]读取数据:  29%|██▊       | 2031110/7086503 [22:36<1:09:59, 1203.88it/s]读取数据:  29%|██▊       | 2031234/7086503 [22:36<1:12:45, 1157.92it/s]读取数据:  29%|██▊       | 2031353/7086503 [22:36<1:31:03, 925.34it/s] 读取数据:  29%|██▊       | 2031506/7086503 [22:36<1:18:47, 1069.19it/s]读取数据:  29%|██▊       | 2031643/7086503 [22:36<1:13:35, 1144.92it/s]读取数据:  29%|██▊       | 2031777/7086503 [22:36<1:10:36, 1193.07it/s]读取数据:  29%|██▊       | 2031908/7086503 [22:37<1:08:45, 1225.12it/s]读取数据:  29%|██▊       | 2032043/7086503 [22:37<1:06:54, 1259.07it/s]读取数据:  29%|██▊       | 2032179/7086503 [22:37<1:05:28, 1286.73it/s]读取数据:  29%|██▊       | 2032312/7086503 [22:37<1:04:52, 1298.36it/s]读取数据:  29%|██▊       | 2032444/7086503 [22:37<1:09:29, 1212.14it/s]读取数据:  29%|██▊       | 2032573/7086503 [22:37<1:08:23, 1231.67it/s]读取数据:  29%|██▊       | 2032712/7086503 [22:37<1:06:02, 1275.43it/s]读取数据:  29%|██▊       | 2032844/7086503 [22:37<1:05:28, 1286.33it/s]读取数据:  29%|██▊       | 2032994/7086503 [22:37<1:02:28, 1348.13it/s]读取数据:  29%|██▊       | 2033130/7086503 [22:37<1:04:09, 1312.70it/s]读取数据:  29%|██▊       | 2033290/7086503 [22:38<1:00:20, 1395.79it/s]读取数据:  29%|██▊       | 2033451/7086503 [22:38<57:47, 1457.28it/s]  读取数据:  29%|██▊       | 2033598/7086503 [22:38<1:00:44, 1386.44it/s]读取数据:  29%|██▊       | 2033745/7086503 [22:38<59:50, 1407.17it/s]  读取数据:  29%|██▊       | 2033897/7086503 [22:38<58:32, 1438.61it/s]读取数据:  29%|██▊       | 2034042/7086503 [22:38<59:21, 1418.59it/s]读取数据:  29%|██▊       | 2034185/7086503 [22:38<1:06:36, 1264.25it/s]读取数据:  29%|██▊       | 2034320/7086503 [22:38<1:05:31, 1285.04it/s]读取数据:  29%|██▊       | 2034454/7086503 [22:38<1:04:51, 1298.34it/s]读取数据:  29%|██▊       | 2034586/7086503 [22:39<1:18:55, 1066.84it/s]读取数据:  29%|██▊       | 2034729/7086503 [22:39<1:12:50, 1155.82it/s]读取数据:  29%|██▊       | 2034856/7086503 [22:39<1:11:07, 1183.86it/s]读取数据:  29%|██▊       | 2034980/7086503 [22:39<1:14:07, 1135.89it/s]读取数据:  29%|██▊       | 2035098/7086503 [22:39<1:14:47, 1125.76it/s]读取数据:  29%|██▊       | 2035229/7086503 [22:39<1:11:59, 1169.39it/s]读取数据:  29%|██▊       | 2035349/7086503 [22:39<1:15:29, 1115.12it/s]读取数据:  29%|██▊       | 2035463/7086503 [22:39<1:18:26, 1073.10it/s]读取数据:  29%|██▊       | 2035612/7086503 [22:39<1:11:01, 1185.31it/s]读取数据:  29%|██▊       | 2035769/7086503 [22:40<1:05:06, 1292.79it/s]读取数据:  29%|██▊       | 2035907/7086503 [22:40<1:03:56, 1316.62it/s]读取数据:  29%|██▊       | 2036041/7086503 [22:40<1:12:56, 1154.07it/s]读取数据:  29%|██▊       | 2036173/7086503 [22:40<1:10:52, 1187.48it/s]读取数据:  29%|██▊       | 2036304/7086503 [22:40<1:08:59, 1220.00it/s]读取数据:  29%|██▊       | 2036429/7086503 [22:40<1:11:33, 1176.20it/s]读取数据:  29%|██▊       | 2036562/7086503 [22:40<1:09:04, 1218.42it/s]读取数据:  29%|██▊       | 2036714/7086503 [22:40<1:04:35, 1303.06it/s]读取数据:  29%|██▊       | 2036850/7086503 [22:40<1:03:55, 1316.66it/s]读取数据:  29%|██▊       | 2036987/7086503 [22:41<1:03:17, 1329.54it/s]读取数据:  29%|██▊       | 2037138/7086503 [22:41<1:00:56, 1380.98it/s]读取数据:  29%|██▊       | 2037277/7086503 [22:41<1:02:38, 1343.46it/s]读取数据:  29%|██▉       | 2037413/7086503 [22:41<1:07:01, 1255.59it/s]读取数据:  29%|██▉       | 2037541/7086503 [22:41<1:08:12, 1233.63it/s]读取数据:  29%|██▉       | 2037683/7086503 [22:41<1:05:27, 1285.56it/s]读取数据:  29%|██▉       | 2037813/7086503 [22:41<1:09:01, 1219.18it/s]读取数据:  29%|██▉       | 2037972/7086503 [22:41<1:03:41, 1320.93it/s]读取数据:  29%|██▉       | 2038116/7086503 [22:41<1:02:12, 1352.64it/s]读取数据:  29%|██▉       | 2038256/7086503 [22:42<1:01:36, 1365.54it/s]读取数据:  29%|██▉       | 2038394/7086503 [22:42<1:23:38, 1005.81it/s]读取数据:  29%|██▉       | 2038509/7086503 [22:42<1:28:30, 950.58it/s] 读取数据:  29%|██▉       | 2038648/7086503 [22:42<1:19:57, 1052.24it/s]读取数据:  29%|██▉       | 2038763/7086503 [22:42<1:21:27, 1032.73it/s]读取数据:  29%|██▉       | 2038900/7086503 [22:42<1:15:11, 1118.79it/s]读取数据:  29%|██▉       | 2039053/7086503 [22:42<1:08:36, 1226.24it/s]读取数据:  29%|██▉       | 2039189/7086503 [22:42<1:06:36, 1262.90it/s]读取数据:  29%|██▉       | 2039330/7086503 [22:43<1:04:38, 1301.21it/s]读取数据:  29%|██▉       | 2039470/7086503 [22:43<1:03:18, 1328.70it/s]读取数据:  29%|██▉       | 2039606/7086503 [22:43<1:04:14, 1309.34it/s]读取数据:  29%|██▉       | 2039739/7086503 [22:43<1:09:37, 1208.10it/s]读取数据:  29%|██▉       | 2039881/7086503 [22:43<1:06:26, 1265.93it/s]读取数据:  29%|██▉       | 2040010/7086503 [22:43<1:20:41, 1042.42it/s]读取数据:  29%|██▉       | 2040148/7086503 [22:43<1:14:45, 1124.93it/s]读取数据:  29%|██▉       | 2040290/7086503 [22:43<1:10:05, 1199.94it/s]读取数据:  29%|██▉       | 2040423/7086503 [22:43<1:08:14, 1232.53it/s]读取数据:  29%|██▉       | 2040551/7086503 [22:44<1:08:53, 1220.79it/s]读取数据:  29%|██▉       | 2040691/7086503 [22:44<1:06:12, 1270.09it/s]读取数据:  29%|██▉       | 2040821/7086503 [22:44<1:22:25, 1020.23it/s]读取数据:  29%|██▉       | 2040933/7086503 [22:44<1:22:49, 1015.25it/s]读取数据:  29%|██▉       | 2041056/7086503 [22:44<1:18:40, 1068.73it/s]读取数据:  29%|██▉       | 2041169/7086503 [22:44<1:41:17, 830.23it/s] 读取数据:  29%|██▉       | 2041264/7086503 [22:44<1:57:28, 715.76it/s]读取数据:  29%|██▉       | 2041365/7086503 [22:45<1:48:06, 777.78it/s]读取数据:  29%|██▉       | 2041453/7086503 [22:45<1:59:57, 700.98it/s]读取数据:  29%|██▉       | 2041586/7086503 [22:45<1:39:48, 842.42it/s]读取数据:  29%|██▉       | 2041706/7086503 [22:45<1:30:32, 928.62it/s]读取数据:  29%|██▉       | 2041836/7086503 [22:45<1:22:14, 1022.35it/s]读取数据:  29%|██▉       | 2041952/7086503 [22:45<1:19:26, 1058.35it/s]读取数据:  29%|██▉       | 2042156/7086503 [22:45<1:03:11, 1330.44it/s]读取数据:  29%|██▉       | 2042402/7086503 [22:45<50:59, 1648.45it/s]  读取数据:  29%|██▉       | 2042573/7086503 [22:45<51:47, 1623.14it/s]读取数据:  29%|██▉       | 2042851/7086503 [22:46<43:01, 1954.01it/s]读取数据:  29%|██▉       | 2043192/7086503 [22:46<35:23, 2375.45it/s]读取数据:  29%|██▉       | 2043619/7086503 [22:46<28:41, 2929.26it/s]读取数据:  29%|██▉       | 2044045/7086503 [22:46<25:18, 3320.58it/s]读取数据:  29%|██▉       | 2044420/7086503 [22:46<24:24, 3443.94it/s]读取数据:  29%|██▉       | 2044794/7086503 [22:46<23:48, 3528.46it/s]读取数据:  29%|██▉       | 2045149/7086503 [22:46<25:38, 3277.12it/s]读取数据:  29%|██▉       | 2045577/7086503 [22:46<23:38, 3554.37it/s]读取数据:  29%|██▉       | 2045967/7086503 [22:46<23:01, 3649.62it/s]读取数据:  29%|██▉       | 2046392/7086503 [22:46<21:59, 3819.38it/s]读取数据:  29%|██▉       | 2046818/7086503 [22:47<21:17, 3946.12it/s]读取数据:  29%|██▉       | 2047267/7086503 [22:47<20:27, 4105.87it/s]读取数据:  29%|██▉       | 2047715/7086503 [22:47<19:55, 4215.63it/s]读取数据:  29%|██▉       | 2048177/7086503 [22:47<19:22, 4333.66it/s]读取数据:  29%|██▉       | 2048664/7086503 [22:47<18:41, 4493.43it/s]读取数据:  29%|██▉       | 2049169/7086503 [22:47<18:01, 4659.20it/s]读取数据:  29%|██▉       | 2049715/7086503 [22:47<17:08, 4896.67it/s]读取数据:  29%|██▉       | 2050206/7086503 [22:49<1:52:26, 746.56it/s]读取数据:  29%|██▉       | 2050557/7086503 [22:49<1:32:05, 911.38it/s]读取数据:  29%|██▉       | 2050901/7086503 [22:49<1:16:27, 1097.76it/s]读取数据:  29%|██▉       | 2051229/7086503 [22:49<1:05:19, 1284.74it/s]读取数据:  29%|██▉       | 2051549/7086503 [22:50<55:11, 1520.35it/s]  读取数据:  29%|██▉       | 2051912/7086503 [22:50<45:42, 1835.59it/s]读取数据:  29%|██▉       | 2052295/7086503 [22:50<38:21, 2186.97it/s]读取数据:  29%|██▉       | 2052671/7086503 [22:50<33:30, 2503.19it/s]读取数据:  29%|██▉       | 2053024/7086503 [22:50<31:25, 2668.87it/s]读取数据:  29%|██▉       | 2053403/7086503 [22:50<28:35, 2934.49it/s]读取数据:  29%|██▉       | 2053764/7086503 [22:50<27:00, 3105.12it/s]读取数据:  29%|██▉       | 2054138/7086503 [22:50<25:37, 3273.62it/s]读取数据:  29%|██▉       | 2054545/7086503 [22:50<24:01, 3491.07it/s]读取数据:  29%|██▉       | 2055002/7086503 [22:50<22:05, 3795.14it/s]读取数据:  29%|██▉       | 2055418/7086503 [22:51<21:31, 3896.34it/s]读取数据:  29%|██▉       | 2055920/7086503 [22:51<19:51, 4222.03it/s]读取数据:  29%|██▉       | 2056404/7086503 [22:51<19:02, 4402.64it/s]读取数据:  29%|██▉       | 2056885/7086503 [22:51<18:32, 4522.86it/s]读取数据:  29%|██▉       | 2057434/7086503 [22:51<17:29, 4792.73it/s]读取数据:  29%|██▉       | 2057953/7086503 [22:51<17:04, 4909.13it/s]读取数据:  29%|██▉       | 2058557/7086503 [22:51<15:58, 5244.26it/s]读取数据:  29%|██▉       | 2059104/7086503 [22:51<15:46, 5310.86it/s]读取数据:  29%|██▉       | 2059637/7086503 [22:51<16:13, 5166.02it/s]读取数据:  29%|██▉       | 2060203/7086503 [22:51<15:46, 5310.41it/s]读取数据:  29%|██▉       | 2060787/7086503 [22:52<15:19, 5466.05it/s]读取数据:  29%|██▉       | 2061387/7086503 [22:52<14:53, 5621.90it/s]读取数据:  29%|██▉       | 2061968/7086503 [22:52<14:45, 5677.40it/s]读取数据:  29%|██▉       | 2062537/7086503 [22:52<16:29, 5079.68it/s]读取数据:  29%|██▉       | 2063058/7086503 [22:52<16:44, 5000.22it/s]读取数据:  29%|██▉       | 2064069/7086503 [22:52<13:02, 6420.74it/s]读取数据:  29%|██▉       | 2065067/7086503 [22:52<11:15, 7430.87it/s]读取数据:  29%|██▉       | 2066066/7086503 [22:52<10:14, 8169.72it/s]读取数据:  29%|██▉       | 2067050/7086503 [22:52<09:39, 8656.50it/s]读取数据:  29%|██▉       | 2067939/7086503 [22:53<09:35, 8723.65it/s]读取数据:  29%|██▉       | 2068886/7086503 [22:53<09:21, 8940.72it/s]读取数据:  29%|██▉       | 2069844/7086503 [22:53<09:09, 9128.26it/s]读取数据:  29%|██▉       | 2070771/7086503 [22:53<09:06, 9170.14it/s]读取数据:  29%|██▉       | 2071692/7086503 [22:53<09:17, 8998.73it/s]读取数据:  29%|██▉       | 2072680/7086503 [22:53<09:01, 9257.44it/s]读取数据:  29%|██▉       | 2073667/7086503 [22:53<08:51, 9433.25it/s]读取数据:  29%|██▉       | 2074613/7086503 [22:53<08:51, 9431.52it/s]读取数据:  29%|██▉       | 2075558/7086503 [22:53<08:51, 9431.14it/s]读取数据:  29%|██▉       | 2076518/7086503 [22:53<08:48, 9479.01it/s]读取数据:  29%|██▉       | 2077469/7086503 [22:54<08:47, 9487.06it/s]读取数据:  29%|██▉       | 2078438/7086503 [22:54<08:44, 9547.52it/s]读取数据:  29%|██▉       | 2083488/7086503 [22:54<03:49, 21807.46it/s]读取数据:  29%|██▉       | 2088672/7086503 [22:54<02:42, 30803.11it/s]读取数据:  30%|██▉       | 2093745/7086503 [22:54<02:15, 36770.68it/s]读取数据:  30%|██▉       | 2098760/7086503 [22:54<02:02, 40779.67it/s]读取数据:  30%|██▉       | 2102841/7086503 [22:55<06:45, 12300.48it/s]读取数据:  30%|██▉       | 2107800/7086503 [22:55<05:00, 16565.81it/s]读取数据:  30%|██▉       | 2112796/7086503 [22:55<03:53, 21256.07it/s]读取数据:  30%|██▉       | 2117869/7086503 [22:55<03:09, 26181.00it/s]读取数据:  30%|██▉       | 2122940/7086503 [22:55<02:40, 30907.77it/s]读取数据:  30%|███       | 2128101/7086503 [22:55<02:20, 35375.35it/s]读取数据:  30%|███       | 2133454/7086503 [22:56<02:04, 39653.97it/s]读取数据:  30%|███       | 2138741/7086503 [22:56<01:55, 42982.52it/s]读取数据:  30%|███       | 2144015/7086503 [22:56<01:48, 45563.38it/s]读取数据:  30%|███       | 2149518/7086503 [22:56<01:42, 48158.98it/s]读取数据:  30%|███       | 2154741/7086503 [22:56<04:05, 20098.68it/s]读取数据:  30%|███       | 2159777/7086503 [22:57<03:22, 24360.06it/s]读取数据:  31%|███       | 2165039/7086503 [22:57<02:49, 29086.59it/s]读取数据:  31%|███       | 2170564/7086503 [22:57<02:24, 34137.19it/s]读取数据:  31%|███       | 2176101/7086503 [22:57<02:06, 38725.33it/s]读取数据:  31%|███       | 2181635/7086503 [22:57<01:55, 42644.79it/s]读取数据:  31%|███       | 2187177/7086503 [22:57<01:46, 45864.40it/s]读取数据:  31%|███       | 2192666/7086503 [22:57<01:41, 48253.34it/s]读取数据:  31%|███       | 2198320/7086503 [22:57<01:36, 50526.25it/s]读取数据:  31%|███       | 2203766/7086503 [22:58<03:56, 20682.11it/s]读取数据:  31%|███       | 2208859/7086503 [22:58<03:16, 24880.05it/s]读取数据:  31%|███       | 2214130/7086503 [22:58<02:45, 29482.68it/s]读取数据:  31%|███▏      | 2219600/7086503 [22:58<02:21, 34302.71it/s]读取数据:  31%|███▏      | 2225114/7086503 [22:58<02:05, 38771.11it/s]读取数据:  31%|███▏      | 2230654/7086503 [22:58<01:53, 42670.23it/s]读取数据:  32%|███▏      | 2236121/7086503 [22:58<01:46, 45681.26it/s]读取数据:  32%|███▏      | 2241667/7086503 [22:59<01:40, 48261.06it/s]读取数据:  32%|███▏      | 2247235/7086503 [22:59<01:36, 50291.97it/s]读取数据:  32%|███▏      | 2252663/7086503 [22:59<03:55, 20529.88it/s]读取数据:  32%|███▏      | 2257643/7086503 [22:59<03:16, 24574.74it/s]读取数据:  32%|███▏      | 2262772/7086503 [22:59<02:46, 28979.33it/s]读取数据:  32%|███▏      | 2268216/7086503 [23:00<02:22, 33831.08it/s]读取数据:  32%|███▏      | 2273776/7086503 [23:00<02:05, 38489.00it/s]读取数据:  32%|███▏      | 2279260/7086503 [23:00<01:53, 42314.52it/s]读取数据:  32%|███▏      | 2284756/7086503 [23:00<01:45, 45483.60it/s]读取数据:  32%|███▏      | 2290300/7086503 [23:00<01:39, 48107.16it/s]读取数据:  32%|███▏      | 2295932/7086503 [23:00<01:35, 50351.91it/s]读取数据:  32%|███▏      | 2301371/7086503 [23:01<04:06, 19439.10it/s]读取数据:  33%|███▎      | 2306100/7086503 [23:01<03:26, 23104.44it/s]读取数据:  33%|███▎      | 2311197/7086503 [23:01<02:53, 27513.51it/s]读取数据:  33%|███▎      | 2316250/7086503 [23:01<02:30, 31756.85it/s]读取数据:  33%|███▎      | 2321486/7086503 [23:01<02:12, 36051.71it/s]读取数据:  33%|███▎      | 2326827/7086503 [23:01<01:58, 40034.74it/s]读取数据:  33%|███▎      | 2332375/7086503 [23:01<01:48, 43847.62it/s]读取数据:  33%|███▎      | 2337835/7086503 [23:01<01:41, 46650.64it/s]读取数据:  33%|███▎      | 2343328/7086503 [23:02<01:37, 48895.84it/s]读取数据:  33%|███▎      | 2348893/7086503 [23:02<01:33, 50779.81it/s]读取数据:  33%|███▎      | 2354287/7086503 [23:02<04:07, 19093.28it/s]读取数据:  33%|███▎      | 2359279/7086503 [23:02<03:24, 23125.80it/s]读取数据:  33%|███▎      | 2364581/7086503 [23:03<02:49, 27832.51it/s]读取数据:  33%|███▎      | 2370078/7086503 [23:03<02:23, 32815.98it/s]读取数据:  34%|███▎      | 2375544/7086503 [23:03<02:06, 37354.78it/s]读取数据:  34%|███▎      | 2381150/7086503 [23:03<01:53, 41636.66it/s]读取数据:  34%|███▎      | 2386650/7086503 [23:03<01:44, 44928.56it/s]读取数据:  34%|███▍      | 2392139/7086503 [23:03<01:38, 47521.86it/s]读取数据:  34%|███▍      | 2397513/7086503 [23:03<01:35, 49206.75it/s]读取数据:  34%|███▍      | 2402876/7086503 [23:04<04:13, 18472.17it/s]读取数据:  34%|███▍      | 2407857/7086503 [23:04<03:28, 22465.67it/s]读取数据:  34%|███▍      | 2413037/7086503 [23:04<02:53, 26983.11it/s]读取数据:  34%|███▍      | 2418479/7086503 [23:04<02:26, 31930.40it/s]读取数据:  34%|███▍      | 2424009/7086503 [23:04<02:06, 36717.37it/s]读取数据:  34%|███▍      | 2429487/7086503 [23:04<01:54, 40806.28it/s]读取数据:  34%|███▍      | 2434906/7086503 [23:05<01:45, 44076.20it/s]读取数据:  34%|███▍      | 2440147/7086503 [23:05<01:42, 45504.07it/s]读取数据:  35%|███▍      | 2445297/7086503 [23:05<01:39, 46804.50it/s]读取数据:  35%|███▍      | 2450411/7086503 [23:05<04:17, 17995.54it/s]读取数据:  35%|███▍      | 2455100/7086503 [23:06<03:33, 21699.10it/s]读取数据:  35%|███▍      | 2460079/7086503 [23:06<02:57, 26046.92it/s]读取数据:  35%|███▍      | 2465248/7086503 [23:06<02:30, 30689.58it/s]读取数据:  35%|███▍      | 2470690/7086503 [23:06<02:09, 35566.08it/s]读取数据:  35%|███▍      | 2475932/7086503 [23:06<01:57, 39389.61it/s]读取数据:  35%|███▌      | 2481408/7086503 [23:06<01:46, 43149.67it/s]读取数据:  35%|███▌      | 2486712/7086503 [23:06<01:40, 45706.97it/s]读取数据:  35%|███▌      | 2491884/7086503 [23:06<01:38, 46754.26it/s]读取数据:  35%|███▌      | 2496988/7086503 [23:06<01:36, 47590.06it/s]读取数据:  35%|███▌      | 2496988/7086503 [23:25<01:36, 47590.06it/s]读取数据:  35%|███▌      | 2500000/7086503 [30:07<35:18:46, 36.08it/s]读取数据:  35%|███▌      | 2504676/7086503 [30:07<24:30:01, 51.95it/s]读取数据:  35%|███▌      | 2509666/7086503 [30:07<16:42:05, 76.12it/s]读取数据:  35%|███▌      | 2514627/7086503 [30:07<11:30:07, 110.41it/s]读取数据:  36%|███▌      | 2519578/7086503 [30:07<7:58:02, 159.22it/s] 读取数据:  36%|███▌      | 2524579/7086503 [30:07<5:31:18, 229.49it/s]读取数据:  36%|███▌      | 2529686/7086503 [30:07<3:48:59, 331.65it/s]读取数据:  36%|███▌      | 2534755/7086503 [30:07<2:39:26, 475.80it/s]读取数据:  36%|███▌      | 2539918/7086503 [30:07<1:50:45, 684.13it/s]读取数据:  36%|███▌      | 2545083/7086503 [30:07<1:17:19, 978.94it/s]读取数据:  36%|███▌      | 2550176/7086503 [30:08<57:07, 1323.40it/s] 读取数据:  36%|███▌      | 2554849/7086503 [30:08<41:23, 1824.57it/s]读取数据:  36%|███▌      | 2559915/7086503 [30:08<29:12, 2582.64it/s]读取数据:  36%|███▌      | 2565261/7086503 [30:08<20:26, 3686.38it/s]读取数据:  36%|███▋      | 2570731/7086503 [30:09<14:25, 5219.86it/s]读取数据:  36%|███▋      | 2576177/7086503 [30:09<10:22, 7247.31it/s]读取数据:  36%|███▋      | 2581695/7086503 [30:09<07:34, 9910.06it/s]读取数据:  37%|███▋      | 2587037/7086503 [30:09<05:43, 13109.09it/s]读取数据:  37%|███▋      | 2592370/7086503 [30:09<04:25, 16931.85it/s]读取数据:  37%|███▋      | 2597639/7086503 [30:09<03:31, 21204.92it/s]读取数据:  37%|███▋      | 2602907/7086503 [30:10<05:33, 13454.20it/s]读取数据:  37%|███▋      | 2607958/7086503 [30:10<04:22, 17086.57it/s]读取数据:  37%|███▋      | 2613183/7086503 [30:10<03:28, 21405.53it/s]读取数据:  37%|███▋      | 2618118/7086503 [30:10<02:54, 25575.80it/s]读取数据:  37%|███▋      | 2623709/7086503 [30:10<02:24, 30906.57it/s]读取数据:  37%|███▋      | 2629215/7086503 [30:10<02:04, 35753.29it/s]读取数据:  37%|███▋      | 2634708/7086503 [30:10<01:51, 40024.99it/s]读取数据:  37%|███▋      | 2640040/7086503 [30:10<01:42, 43234.32it/s]读取数据:  37%|███▋      | 2645372/7086503 [30:11<01:36, 45819.81it/s]读取数据:  37%|███▋      | 2650651/7086503 [30:11<04:05, 18034.52it/s]读取数据:  37%|███▋      | 2655466/7086503 [30:11<03:22, 21844.44it/s]读取数据:  38%|███▊      | 2660592/7086503 [30:11<02:47, 26346.42it/s]读取数据:  38%|███▊      | 2666003/7086503 [30:12<02:21, 31327.71it/s]读取数据:  38%|███▊      | 2671600/7086503 [30:12<02:01, 36354.08it/s]读取数据:  38%|███▊      | 2677075/7086503 [30:12<01:48, 40504.31it/s]读取数据:  38%|███▊      | 2682689/7086503 [30:12<01:39, 44314.80it/s]读取数据:  38%|███▊      | 2688090/7086503 [30:12<01:33, 46816.00it/s]读取数据:  38%|███▊      | 2693495/7086503 [30:12<01:30, 48760.34it/s]读取数据:  38%|███▊      | 2698840/7086503 [30:12<01:27, 49939.64it/s]读取数据:  38%|███▊      | 2704171/7086503 [30:13<03:58, 18353.82it/s]读取数据:  38%|███▊      | 2709276/7086503 [30:13<03:14, 22523.25it/s]读取数据:  38%|███▊      | 2714627/7086503 [30:13<02:40, 27297.70it/s]读取数据:  38%|███▊      | 2720170/7086503 [30:13<02:14, 32372.71it/s]读取数据:  38%|███▊      | 2725633/7086503 [30:13<01:58, 36933.58it/s]读取数据:  39%|███▊      | 2731189/7086503 [30:13<01:45, 41151.44it/s]读取数据:  39%|███▊      | 2736594/7086503 [30:14<01:38, 44303.64it/s]读取数据:  39%|███▊      | 2742010/7086503 [30:14<01:32, 46852.47it/s]读取数据:  39%|███▉      | 2747410/7086503 [30:14<01:28, 48780.73it/s]读取数据:  39%|███▉      | 2752749/7086503 [30:14<03:57, 18211.71it/s]读取数据:  39%|███▉      | 2757784/7086503 [30:15<03:14, 22271.57it/s]读取数据:  39%|███▉      | 2763029/7086503 [30:15<02:40, 26885.19it/s]读取数据:  39%|███▉      | 2768578/7086503 [30:15<02:14, 32012.18it/s]读取数据:  39%|███▉      | 2774075/7086503 [30:15<01:57, 36644.97it/s]读取数据:  39%|███▉      | 2779675/7086503 [30:15<01:45, 41003.03it/s]读取数据:  39%|███▉      | 2785104/7086503 [30:15<01:37, 44237.97it/s]读取数据:  39%|███▉      | 2790571/7086503 [30:15<01:31, 46928.67it/s]读取数据:  39%|███▉      | 2795943/7086503 [30:15<01:27, 48756.87it/s]读取数据:  40%|███▉      | 2801288/7086503 [30:16<03:59, 17919.45it/s]读取数据:  40%|███▉      | 2806233/7086503 [30:16<03:15, 21841.83it/s]读取数据:  40%|███▉      | 2811428/7086503 [30:16<02:42, 26385.31it/s]读取数据:  40%|███▉      | 2816857/7086503 [30:16<02:16, 31333.27it/s]读取数据:  40%|███▉      | 2822405/7086503 [30:16<01:57, 36213.99it/s]读取数据:  40%|███▉      | 2827921/7086503 [30:16<01:45, 40458.59it/s]读取数据:  40%|███▉      | 2833466/7086503 [30:17<01:36, 44092.16it/s]读取数据:  40%|████      | 2838869/7086503 [30:17<01:31, 46647.46it/s]读取数据:  40%|████      | 2844209/7086503 [30:17<01:27, 48461.35it/s]读取数据:  40%|████      | 2849658/7086503 [30:17<01:24, 50131.97it/s]读取数据:  40%|████      | 2855021/7086503 [30:18<04:04, 17293.29it/s]读取数据:  40%|████      | 2860137/7086503 [30:18<03:17, 21377.11it/s]读取数据:  40%|████      | 2865366/7086503 [30:18<02:42, 25920.02it/s]读取数据:  41%|████      | 2870900/7086503 [30:18<02:15, 31024.49it/s]读取数据:  41%|████      | 2876325/7086503 [30:18<01:58, 35637.58it/s]读取数据:  41%|████      | 2881865/7086503 [30:18<01:45, 40002.83it/s]读取数据:  41%|████      | 2887286/7086503 [30:18<01:36, 43410.86it/s]读取数据:  41%|████      | 2892744/7086503 [30:18<01:30, 46261.47it/s]读取数据:  41%|████      | 2898114/7086503 [30:18<01:26, 48246.86it/s]读取数据:  41%|████      | 2903447/7086503 [30:19<03:59, 17489.95it/s]读取数据:  41%|████      | 2908438/7086503 [30:19<03:14, 21447.03it/s]读取数据:  41%|████      | 2913694/7086503 [30:19<02:40, 26065.54it/s]读取数据:  41%|████      | 2919251/7086503 [30:20<02:13, 31227.88it/s]读取数据:  41%|████▏     | 2924635/7086503 [30:20<01:56, 35749.23it/s]读取数据:  41%|████▏     | 2930066/7086503 [30:20<01:44, 39870.24it/s]读取数据:  41%|████▏     | 2935494/7086503 [30:20<01:35, 43340.59it/s]读取数据:  41%|████▏     | 2940720/7086503 [30:21<07:27, 9266.73it/s] 读取数据:  42%|████▏     | 2944474/7086503 [30:23<14:02, 4913.93it/s]读取数据:  42%|████▏     | 2947160/7086503 [30:25<17:59, 3835.14it/s]读取数据:  42%|████▏     | 2949100/7086503 [30:26<20:23, 3382.11it/s]读取数据:  42%|████▏     | 2950521/7086503 [30:27<28:30, 2417.60it/s]读取数据:  42%|████▏     | 2951544/7086503 [30:28<30:28, 2261.21it/s]读取数据:  42%|████▏     | 2952307/7086503 [30:28<31:59, 2153.27it/s]读取数据:  42%|████▏     | 2952890/7086503 [30:29<33:07, 2079.87it/s]读取数据:  42%|████▏     | 2953348/7086503 [30:29<34:10, 2016.15it/s]读取数据:  42%|████▏     | 2953718/7086503 [30:29<34:57, 1970.38it/s]读取数据:  42%|████▏     | 2954028/7086503 [30:29<35:31, 1938.47it/s]读取数据:  42%|████▏     | 2954297/7086503 [30:30<36:47, 1872.17it/s]读取数据:  42%|████▏     | 2954531/7086503 [30:30<38:11, 1802.82it/s]读取数据:  42%|████▏     | 2954740/7086503 [30:30<39:06, 1760.96it/s]读取数据:  42%|████▏     | 2954933/7086503 [30:30<39:53, 1725.87it/s]读取数据:  42%|████▏     | 2955115/7086503 [30:30<40:26, 1702.48it/s]读取数据:  42%|████▏     | 2955291/7086503 [30:30<40:12, 1712.50it/s]读取数据:  42%|████▏     | 2955467/7086503 [30:30<40:09, 1714.37it/s]读取数据:  42%|████▏     | 2955645/7086503 [30:30<39:49, 1728.46it/s]读取数据:  42%|████▏     | 2955821/7086503 [30:31<40:46, 1688.27it/s]读取数据:  42%|████▏     | 2955992/7086503 [30:31<42:07, 1634.26it/s]读取数据:  42%|████▏     | 2956157/7086503 [30:31<42:19, 1626.22it/s]读取数据:  42%|████▏     | 2956335/7086503 [30:31<41:16, 1667.63it/s]读取数据:  42%|████▏     | 2956513/7086503 [30:31<40:34, 1696.63it/s]读取数据:  42%|████▏     | 2956697/7086503 [30:31<39:40, 1734.93it/s]读取数据:  42%|████▏     | 2956872/7086503 [30:31<40:46, 1687.92it/s]读取数据:  42%|████▏     | 2957042/7086503 [30:31<40:51, 1684.47it/s]读取数据:  42%|████▏     | 2957211/7086503 [30:31<41:12, 1670.14it/s]读取数据:  42%|████▏     | 2957394/7086503 [30:31<40:07, 1714.88it/s]读取数据:  42%|████▏     | 2957579/7086503 [30:32<39:15, 1753.11it/s]读取数据:  42%|████▏     | 2957767/7086503 [30:32<38:29, 1787.92it/s]读取数据:  42%|████▏     | 2957947/7086503 [30:32<39:39, 1734.79it/s]读取数据:  42%|████▏     | 2958121/7086503 [30:32<40:01, 1719.34it/s]读取数据:  42%|████▏     | 2958299/7086503 [30:32<39:39, 1734.91it/s]读取数据:  42%|████▏     | 2958485/7086503 [30:32<38:50, 1771.48it/s]读取数据:  42%|████▏     | 2958665/7086503 [30:32<38:42, 1777.21it/s]读取数据:  42%|████▏     | 2958852/7086503 [30:32<38:07, 1804.49it/s]读取数据:  42%|████▏     | 2959037/7086503 [30:32<37:53, 1815.78it/s]读取数据:  42%|████▏     | 2959219/7086503 [30:32<38:36, 1781.82it/s]读取数据:  42%|████▏     | 2959399/7086503 [30:33<38:30, 1786.61it/s]读取数据:  42%|████▏     | 2959578/7086503 [30:33<38:34, 1783.05it/s]读取数据:  42%|████▏     | 2959761/7086503 [30:33<38:19, 1794.36it/s]读取数据:  42%|████▏     | 2959941/7086503 [30:33<39:31, 1739.74it/s]读取数据:  42%|████▏     | 2960125/7086503 [30:33<38:52, 1768.94it/s]读取数据:  42%|████▏     | 2960303/7086503 [30:33<38:59, 1763.81it/s]读取数据:  42%|████▏     | 2960484/7086503 [30:33<38:42, 1776.78it/s]读取数据:  42%|████▏     | 2960662/7086503 [30:33<38:48, 1772.05it/s]读取数据:  42%|████▏     | 2960840/7086503 [30:33<39:05, 1758.66it/s]读取数据:  42%|████▏     | 2961018/7086503 [30:34<39:01, 1761.56it/s]读取数据:  42%|████▏     | 2961201/7086503 [30:34<38:37, 1779.90it/s]读取数据:  42%|████▏     | 2961380/7086503 [30:34<38:59, 1763.23it/s]读取数据:  42%|████▏     | 2961560/7086503 [30:34<38:47, 1771.96it/s]读取数据:  42%|████▏     | 2961738/7086503 [30:34<40:26, 1700.20it/s]读取数据:  42%|████▏     | 2961909/7086503 [30:34<41:49, 1643.68it/s]读取数据:  42%|████▏     | 2962075/7086503 [30:34<41:49, 1643.33it/s]读取数据:  42%|████▏     | 2962240/7086503 [30:34<42:02, 1634.79it/s]读取数据:  42%|████▏     | 2962404/7086503 [30:34<43:08, 1593.16it/s]读取数据:  42%|████▏     | 2962564/7086503 [30:34<43:33, 1577.68it/s]读取数据:  42%|████▏     | 2962724/7086503 [30:35<43:27, 1581.76it/s]读取数据:  42%|████▏     | 2962883/7086503 [30:35<44:10, 1555.95it/s]读取数据:  42%|████▏     | 2963044/7086503 [30:35<43:43, 1571.58it/s]读取数据:  42%|████▏     | 2963219/7086503 [30:35<42:19, 1623.37it/s]读取数据:  42%|████▏     | 2963395/7086503 [30:35<41:22, 1660.78it/s]读取数据:  42%|████▏     | 2963563/7086503 [30:35<41:14, 1666.35it/s]读取数据:  42%|████▏     | 2963730/7086503 [30:35<42:00, 1635.77it/s]读取数据:  42%|████▏     | 2963894/7086503 [30:35<43:01, 1597.27it/s]读取数据:  42%|████▏     | 2964055/7086503 [30:35<42:55, 1600.74it/s]读取数据:  42%|████▏     | 2964216/7086503 [30:35<43:32, 1578.19it/s]读取数据:  42%|████▏     | 2964375/7086503 [30:36<43:53, 1565.49it/s]读取数据:  42%|████▏     | 2964533/7086503 [30:36<43:49, 1567.85it/s]读取数据:  42%|████▏     | 2964714/7086503 [30:36<41:57, 1637.44it/s]读取数据:  42%|████▏     | 2964896/7086503 [30:36<40:39, 1689.30it/s]读取数据:  42%|████▏     | 2965072/7086503 [30:36<40:11, 1709.18it/s]读取数据:  42%|████▏     | 2965244/7086503 [30:36<40:33, 1693.39it/s]读取数据:  42%|████▏     | 2965414/7086503 [30:36<41:25, 1658.06it/s]读取数据:  42%|████▏     | 2965581/7086503 [30:36<42:05, 1631.72it/s]读取数据:  42%|████▏     | 2965760/7086503 [30:36<40:58, 1676.32it/s]读取数据:  42%|████▏     | 2965947/7086503 [30:37<39:39, 1731.79it/s]读取数据:  42%|████▏     | 2966129/7086503 [30:37<39:06, 1756.26it/s]读取数据:  42%|████▏     | 2966314/7086503 [30:37<38:31, 1782.62it/s]读取数据:  42%|████▏     | 2966495/7086503 [30:37<38:22, 1789.11it/s]读取数据:  42%|████▏     | 2966678/7086503 [30:37<38:08, 1800.54it/s]读取数据:  42%|████▏     | 2966862/7086503 [30:37<37:56, 1809.35it/s]读取数据:  42%|████▏     | 2967044/7086503 [30:37<38:19, 1791.51it/s]读取数据:  42%|████▏     | 2967233/7086503 [30:37<37:42, 1820.54it/s]读取数据:  42%|████▏     | 2967419/7086503 [30:37<37:28, 1832.10it/s]读取数据:  42%|████▏     | 2967603/7086503 [30:37<37:51, 1813.21it/s]读取数据:  42%|████▏     | 2967785/7086503 [30:38<37:53, 1811.62it/s]读取数据:  42%|████▏     | 2967967/7086503 [30:38<39:21, 1744.03it/s]读取数据:  42%|████▏     | 2968142/7086503 [30:38<40:08, 1709.81it/s]读取数据:  42%|████▏     | 2968314/7086503 [30:38<40:05, 1712.32it/s]读取数据:  42%|████▏     | 2968499/7086503 [30:38<39:11, 1751.38it/s]读取数据:  42%|████▏     | 2968676/7086503 [30:38<39:05, 1755.37it/s]读取数据:  42%|████▏     | 2968857/7086503 [30:38<38:45, 1770.42it/s]读取数据:  42%|████▏     | 2969047/7086503 [30:38<37:58, 1807.10it/s]读取数据:  42%|████▏     | 2969228/7086503 [30:38<38:16, 1792.54it/s]读取数据:  42%|████▏     | 2969417/7086503 [30:38<37:40, 1821.35it/s]读取数据:  42%|████▏     | 2969609/7086503 [30:39<37:07, 1847.80it/s]读取数据:  42%|████▏     | 2969796/7086503 [30:39<37:03, 1851.83it/s]读取数据:  42%|████▏     | 2969985/7086503 [30:39<36:49, 1863.14it/s]读取数据:  42%|████▏     | 2970178/7086503 [30:39<36:27, 1882.12it/s]读取数据:  42%|████▏     | 2970367/7086503 [30:39<36:47, 1864.53it/s]读取数据:  42%|████▏     | 2970554/7086503 [30:39<36:49, 1862.48it/s]读取数据:  42%|████▏     | 2970745/7086503 [30:39<36:35, 1874.98it/s]读取数据:  42%|████▏     | 2970933/7086503 [30:39<36:37, 1872.45it/s]读取数据:  42%|████▏     | 2971121/7086503 [30:39<37:18, 1838.59it/s]读取数据:  42%|████▏     | 2971306/7086503 [30:39<38:17, 1790.98it/s]读取数据:  42%|████▏     | 2971486/7086503 [30:40<38:45, 1769.69it/s]读取数据:  42%|████▏     | 2971675/7086503 [30:40<38:00, 1804.51it/s]读取数据:  42%|████▏     | 2971866/7086503 [30:40<37:23, 1834.13it/s]读取数据:  42%|████▏     | 2972061/7086503 [30:40<36:42, 1868.29it/s]读取数据:  42%|████▏     | 2972257/7086503 [30:40<36:13, 1892.86it/s]读取数据:  42%|████▏     | 2972448/7086503 [30:40<36:08, 1897.33it/s]读取数据:  42%|████▏     | 2972638/7086503 [30:40<36:18, 1888.30it/s]读取数据:  42%|████▏     | 2972827/7086503 [30:40<37:14, 1840.68it/s]读取数据:  42%|████▏     | 2973012/7086503 [30:40<37:13, 1841.62it/s]读取数据:  42%|████▏     | 2973211/7086503 [30:40<36:24, 1882.73it/s]读取数据:  42%|████▏     | 2973400/7086503 [30:41<38:31, 1779.06it/s]读取数据:  42%|████▏     | 2973582/7086503 [30:41<38:20, 1788.01it/s]读取数据:  42%|████▏     | 2973762/7086503 [30:41<38:31, 1779.03it/s]读取数据:  42%|████▏     | 2973948/7086503 [30:41<38:03, 1801.13it/s]读取数据:  42%|████▏     | 2974144/7086503 [30:41<37:06, 1846.72it/s]读取数据:  42%|████▏     | 2974334/7086503 [30:41<36:48, 1862.16it/s]读取数据:  42%|████▏     | 2974539/7086503 [30:41<35:47, 1914.77it/s]读取数据:  42%|████▏     | 2974731/7086503 [30:41<36:32, 1875.52it/s]读取数据:  42%|████▏     | 2974928/7086503 [30:41<36:01, 1902.30it/s]读取数据:  42%|████▏     | 2975120/7086503 [30:42<35:56, 1906.79it/s]读取数据:  42%|████▏     | 2975311/7086503 [30:42<36:43, 1865.69it/s]读取数据:  42%|████▏     | 2975498/7086503 [30:42<36:52, 1858.09it/s]读取数据:  42%|████▏     | 2975696/7086503 [30:42<36:12, 1892.00it/s]读取数据:  42%|████▏     | 2975895/7086503 [30:42<35:42, 1918.61it/s]读取数据:  42%|████▏     | 2976096/7086503 [30:42<35:13, 1945.09it/s]读取数据:  42%|████▏     | 2976291/7086503 [30:42<36:08, 1895.24it/s]读取数据:  42%|████▏     | 2976481/7086503 [30:42<36:41, 1866.89it/s]读取数据:  42%|████▏     | 2976682/7086503 [30:42<35:54, 1907.93it/s]读取数据:  42%|████▏     | 2976885/7086503 [30:42<35:14, 1943.65it/s]读取数据:  42%|████▏     | 2977086/7086503 [30:43<34:54, 1962.35it/s]读取数据:  42%|████▏     | 2977289/7086503 [30:43<34:36, 1979.17it/s]读取数据:  42%|████▏     | 2977488/7086503 [30:43<34:43, 1971.81it/s]读取数据:  42%|████▏     | 2977692/7086503 [30:43<34:24, 1990.26it/s]读取数据:  42%|████▏     | 2977898/7086503 [30:43<34:03, 2010.71it/s]读取数据:  42%|████▏     | 2978100/7086503 [30:43<34:01, 2012.05it/s]读取数据:  42%|████▏     | 2978305/7086503 [30:43<33:50, 2023.20it/s]读取数据:  42%|████▏     | 2978508/7086503 [30:43<34:13, 2000.80it/s]读取数据:  42%|████▏     | 2978709/7086503 [30:43<34:11, 2001.91it/s]读取数据:  42%|████▏     | 2978910/7086503 [30:43<34:18, 1995.07it/s]读取数据:  42%|████▏     | 2979112/7086503 [30:44<34:11, 2001.80it/s]读取数据:  42%|████▏     | 2979313/7086503 [30:44<34:13, 2000.52it/s]读取数据:  42%|████▏     | 2979514/7086503 [30:44<35:21, 1936.21it/s]读取数据:  42%|████▏     | 2979709/7086503 [30:44<35:52, 1907.94it/s]读取数据:  42%|████▏     | 2979914/7086503 [30:44<35:07, 1948.80it/s]读取数据:  42%|████▏     | 2980115/7086503 [30:44<34:49, 1965.69it/s]读取数据:  42%|████▏     | 2980313/7086503 [30:44<34:44, 1969.44it/s]读取数据:  42%|████▏     | 2980511/7086503 [30:44<34:42, 1971.81it/s]读取数据:  42%|████▏     | 2980716/7086503 [30:44<34:19, 1993.17it/s]读取数据:  42%|████▏     | 2980920/7086503 [30:44<34:06, 2006.60it/s]读取数据:  42%|████▏     | 2981130/7086503 [30:45<33:39, 2032.55it/s]读取数据:  42%|████▏     | 2981334/7086503 [30:45<33:41, 2030.95it/s]读取数据:  42%|████▏     | 2981538/7086503 [30:45<33:46, 2025.25it/s]读取数据:  42%|████▏     | 2981741/7086503 [30:45<34:29, 1983.08it/s]读取数据:  42%|████▏     | 2981940/7086503 [30:45<35:01, 1953.49it/s]读取数据:  42%|████▏     | 2982136/7086503 [30:45<35:21, 1935.00it/s]读取数据:  42%|████▏     | 2982341/7086503 [30:45<34:46, 1966.69it/s]读取数据:  42%|████▏     | 2982538/7086503 [30:45<34:46, 1966.46it/s]读取数据:  42%|████▏     | 2982742/7086503 [30:45<34:25, 1986.82it/s]读取数据:  42%|████▏     | 2982942/7086503 [30:45<34:23, 1988.77it/s]读取数据:  42%|████▏     | 2983152/7086503 [30:46<33:51, 2019.85it/s]读取数据:  42%|████▏     | 2983355/7086503 [30:46<34:41, 1971.48it/s]读取数据:  42%|████▏     | 2983553/7086503 [30:46<35:24, 1931.33it/s]读取数据:  42%|████▏     | 2983747/7086503 [30:46<35:38, 1918.96it/s]读取数据:  42%|████▏     | 2983940/7086503 [30:46<35:48, 1909.47it/s]读取数据:  42%|████▏     | 2984132/7086503 [30:46<36:05, 1894.24it/s]读取数据:  42%|████▏     | 2984332/7086503 [30:46<35:31, 1924.44it/s]读取数据:  42%|████▏     | 2984545/7086503 [30:46<34:27, 1984.15it/s]读取数据:  42%|████▏     | 2984756/7086503 [30:46<33:52, 2018.05it/s]读取数据:  42%|████▏     | 2984968/7086503 [30:47<33:24, 2046.30it/s]读取数据:  42%|████▏     | 2985173/7086503 [30:47<33:29, 2041.39it/s]读取数据:  42%|████▏     | 2985383/7086503 [30:47<33:14, 2056.14it/s]读取数据:  42%|████▏     | 2985601/7086503 [30:47<32:40, 2091.78it/s]读取数据:  42%|████▏     | 2985811/7086503 [30:47<32:56, 2074.95it/s]读取数据:  42%|████▏     | 2986019/7086503 [30:47<32:55, 2075.37it/s]读取数据:  42%|████▏     | 2986235/7086503 [30:47<32:32, 2099.85it/s]读取数据:  42%|████▏     | 2986450/7086503 [30:47<32:21, 2112.12it/s]读取数据:  42%|████▏     | 2986662/7086503 [30:47<32:23, 2109.05it/s]读取数据:  42%|████▏     | 2986873/7086503 [30:47<32:30, 2101.99it/s]读取数据:  42%|████▏     | 2987084/7086503 [30:48<32:32, 2099.38it/s]读取数据:  42%|████▏     | 2987294/7086503 [30:48<33:16, 2053.29it/s]读取数据:  42%|████▏     | 2987500/7086503 [30:48<33:46, 2022.50it/s]读取数据:  42%|████▏     | 2987711/7086503 [30:48<33:23, 2045.74it/s]读取数据:  42%|████▏     | 2987930/7086503 [30:48<32:45, 2085.32it/s]读取数据:  42%|████▏     | 2988144/7086503 [30:48<32:32, 2098.59it/s]读取数据:  42%|████▏     | 2988358/7086503 [30:48<32:23, 2108.49it/s]读取数据:  42%|████▏     | 2988569/7086503 [30:48<32:31, 2100.05it/s]读取数据:  42%|████▏     | 2988781/7086503 [30:48<32:26, 2104.66it/s]读取数据:  42%|████▏     | 2988998/7086503 [30:48<32:11, 2121.46it/s]读取数据:  42%|████▏     | 2989216/7086503 [30:49<31:56, 2137.35it/s]读取数据:  42%|████▏     | 2989430/7086503 [30:49<32:36, 2093.79it/s]读取数据:  42%|████▏     | 2989640/7086503 [30:49<33:11, 2057.02it/s]读取数据:  42%|████▏     | 2989846/7086503 [30:49<33:14, 2054.38it/s]读取数据:  42%|████▏     | 2990065/7086503 [30:49<32:37, 2092.74it/s]读取数据:  42%|████▏     | 2990283/7086503 [30:49<32:15, 2115.94it/s]读取数据:  42%|████▏     | 2990503/7086503 [30:49<31:55, 2137.88it/s]读取数据:  42%|████▏     | 2990718/7086503 [30:49<31:55, 2138.50it/s]读取数据:  42%|████▏     | 2990936/7086503 [30:49<31:45, 2149.53it/s]读取数据:  42%|████▏     | 2991158/7086503 [30:49<31:28, 2168.81it/s]读取数据:  42%|████▏     | 2991375/7086503 [30:50<31:28, 2168.70it/s]读取数据:  42%|████▏     | 2991592/7086503 [30:50<31:49, 2143.99it/s]读取数据:  42%|████▏     | 2991807/7086503 [30:50<32:49, 2078.94it/s]读取数据:  42%|████▏     | 2992017/7086503 [30:50<32:45, 2083.14it/s]读取数据:  42%|████▏     | 2992235/7086503 [30:50<32:19, 2110.53it/s]读取数据:  42%|████▏     | 2992451/7086503 [30:50<32:09, 2121.69it/s]读取数据:  42%|████▏     | 2992664/7086503 [30:50<32:32, 2096.74it/s]读取数据:  42%|████▏     | 2992874/7086503 [30:50<33:00, 2066.93it/s]读取数据:  42%|████▏     | 2993084/7086503 [30:50<32:52, 2075.66it/s]读取数据:  42%|████▏     | 2993302/7086503 [30:50<32:25, 2104.37it/s]读取数据:  42%|████▏     | 2993519/7086503 [30:51<32:07, 2123.00it/s]读取数据:  42%|████▏     | 2993732/7086503 [30:51<32:25, 2103.57it/s]读取数据:  42%|████▏     | 2993943/7086503 [30:51<33:01, 2065.28it/s]读取数据:  42%|████▏     | 2994152/7086503 [30:51<32:55, 2071.15it/s]读取数据:  42%|████▏     | 2994375/7086503 [30:51<32:13, 2116.69it/s]读取数据:  42%|████▏     | 2994592/7086503 [30:51<32:00, 2130.57it/s]读取数据:  42%|████▏     | 2994806/7086503 [30:51<32:04, 2125.56it/s]读取数据:  42%|████▏     | 2995030/7086503 [30:51<31:36, 2156.90it/s]读取数据:  42%|████▏     | 2995253/7086503 [30:51<31:19, 2176.33it/s]读取数据:  42%|████▏     | 2995474/7086503 [30:51<31:12, 2184.36it/s]读取数据:  42%|████▏     | 2995697/7086503 [30:52<31:01, 2197.52it/s]读取数据:  42%|████▏     | 2995917/7086503 [30:52<31:04, 2193.83it/s]读取数据:  42%|████▏     | 2996139/7086503 [30:52<31:00, 2198.79it/s]读取数据:  42%|████▏     | 2996369/7086503 [30:52<30:37, 2226.47it/s]读取数据:  42%|████▏     | 2996595/7086503 [30:52<30:30, 2234.85it/s]读取数据:  42%|████▏     | 2996819/7086503 [30:52<30:39, 2223.24it/s]读取数据:  42%|████▏     | 2997047/7086503 [30:52<30:27, 2237.39it/s]读取数据:  42%|████▏     | 2997275/7086503 [30:52<30:18, 2248.92it/s]读取数据:  42%|████▏     | 2997500/7086503 [30:52<30:41, 2221.03it/s]读取数据:  42%|████▏     | 2997723/7086503 [30:53<31:23, 2170.46it/s]读取数据:  42%|████▏     | 2997941/7086503 [30:53<31:42, 2149.59it/s]读取数据:  42%|████▏     | 2998157/7086503 [30:53<32:08, 2120.20it/s]读取数据:  42%|████▏     | 2998381/7086503 [30:53<31:38, 2153.37it/s]读取数据:  42%|████▏     | 2998608/7086503 [30:53<31:08, 2187.38it/s]读取数据:  42%|████▏     | 2998832/7086503 [30:53<30:55, 2202.76it/s]读取数据:  42%|████▏     | 2999061/7086503 [30:53<30:35, 2227.17it/s]读取数据:  42%|████▏     | 2999288/7086503 [30:53<30:25, 2238.70it/s]读取数据:  42%|████▏     | 2999520/7086503 [30:53<30:06, 2262.33it/s]读取数据:  42%|████▏     | 2999747/7086503 [30:53<30:08, 2259.87it/s]读取数据:  42%|████▏     | 2999974/7086503 [30:54<30:12, 2255.09it/s]读取数据:  42%|████▏     | 2999974/7086503 [31:05<30:12, 2255.09it/s]读取数据:  42%|████▏     | 3000000/7086503 [37:12<771:51:00,  1.47it/s]读取数据:  42%|████▏     | 3000001/7086503 [37:12<772:24:57,  1.47it/s]读取数据:  42%|████▏     | 3000159/7086503 [37:13<489:45:20,  2.32it/s]读取数据:  42%|████▏     | 3000310/7086503 [37:13<326:44:45,  3.47it/s]读取数据:  42%|████▏     | 3000456/7086503 [37:13<223:57:58,  5.07it/s]读取数据:  42%|████▏     | 3000601/7086503 [37:13<155:01:01,  7.32it/s]读取数据:  42%|████▏     | 3000740/7086503 [37:13<109:10:39, 10.40it/s]读取数据:  42%|████▏     | 3000876/7086503 [37:13<77:23:07, 14.67it/s] 读取数据:  42%|████▏     | 3001008/7086503 [37:13<55:14:39, 20.54it/s]读取数据:  42%|████▏     | 3001154/7086503 [37:13<38:09:16, 29.74it/s]读取数据:  42%|████▏     | 3001304/7086503 [37:13<26:21:45, 43.04it/s]读取数据:  42%|████▏     | 3001456/7086503 [37:14<18:20:07, 61.89it/s]读取数据:  42%|████▏     | 3001607/7086503 [37:14<12:55:18, 87.81it/s]读取数据:  42%|████▏     | 3001756/7086503 [37:14<9:14:30, 122.78it/s]读取数据:  42%|████▏     | 3001907/7086503 [37:14<6:39:20, 170.47it/s]读取数据:  42%|████▏     | 3002059/7086503 [37:14<4:51:20, 233.66it/s]读取数据:  42%|████▏     | 3002214/7086503 [37:14<3:35:22, 316.06it/s]读取数据:  42%|████▏     | 3002373/7086503 [37:14<2:41:47, 420.73it/s]读取数据:  42%|████▏     | 3002527/7086503 [37:14<2:06:29, 538.14it/s]读取数据:  42%|████▏     | 3002686/7086503 [37:14<1:40:49, 675.04it/s]读取数据:  42%|████▏     | 3002841/7086503 [37:14<1:25:37, 794.92it/s]读取数据:  42%|████▏     | 3002991/7086503 [37:15<1:14:54, 908.60it/s]读取数据:  42%|████▏     | 3003137/7086503 [37:15<1:06:43, 1019.99it/s]读取数据:  42%|████▏     | 3003297/7086503 [37:15<59:15, 1148.50it/s]  读取数据:  42%|████▏     | 3003454/7086503 [37:15<54:25, 1250.36it/s]读取数据:  42%|████▏     | 3003616/7086503 [37:15<50:37, 1344.24it/s]读取数据:  42%|████▏     | 3003776/7086503 [37:15<48:14, 1410.66it/s]读取数据:  42%|████▏     | 3003933/7086503 [37:15<46:53, 1450.89it/s]读取数据:  42%|████▏     | 3004097/7086503 [37:15<45:18, 1501.53it/s]读取数据:  42%|████▏     | 3004258/7086503 [37:15<44:26, 1531.20it/s]读取数据:  42%|████▏     | 3004420/7086503 [37:15<43:42, 1556.44it/s]读取数据:  42%|████▏     | 3004591/7086503 [37:16<42:32, 1599.46it/s]读取数据:  42%|████▏     | 3004756/7086503 [37:16<42:08, 1614.06it/s]读取数据:  42%|████▏     | 3004928/7086503 [37:16<41:22, 1644.20it/s]读取数据:  42%|████▏     | 3005099/7086503 [37:16<40:57, 1660.80it/s]读取数据:  42%|████▏     | 3005268/7086503 [37:16<40:49, 1666.13it/s]读取数据:  42%|████▏     | 3005440/7086503 [37:16<40:31, 1678.69it/s]读取数据:  42%|████▏     | 3005609/7086503 [37:16<41:52, 1624.31it/s]读取数据:  42%|████▏     | 3005773/7086503 [37:16<43:21, 1568.87it/s]读取数据:  42%|████▏     | 3005933/7086503 [37:16<43:07, 1576.81it/s]读取数据:  42%|████▏     | 3006105/7086503 [37:16<42:01, 1617.98it/s]读取数据:  42%|████▏     | 3006270/7086503 [37:17<41:49, 1626.01it/s]读取数据:  42%|████▏     | 3006434/7086503 [37:17<41:51, 1624.49it/s]读取数据:  42%|████▏     | 3006597/7086503 [37:17<42:04, 1616.28it/s]读取数据:  42%|████▏     | 3006762/7086503 [37:17<41:52, 1623.72it/s]读取数据:  42%|████▏     | 3006939/7086503 [37:17<40:51, 1664.17it/s]读取数据:  42%|████▏     | 3007109/7086503 [37:17<40:36, 1674.49it/s]读取数据:  42%|████▏     | 3007294/7086503 [37:17<39:22, 1726.50it/s]读取数据:  42%|████▏     | 3007470/7086503 [37:17<39:11, 1734.43it/s]读取数据:  42%|████▏     | 3007644/7086503 [37:17<39:19, 1729.06it/s]读取数据:  42%|████▏     | 3007827/7086503 [37:17<38:40, 1757.83it/s]读取数据:  42%|████▏     | 3008008/7086503 [37:18<38:23, 1770.35it/s]读取数据:  42%|████▏     | 3008186/7086503 [37:18<38:42, 1756.33it/s]读取数据:  42%|████▏     | 3008362/7086503 [37:18<38:43, 1755.03it/s]读取数据:  42%|████▏     | 3008541/7086503 [37:18<38:33, 1762.67it/s]读取数据:  42%|████▏     | 3008728/7086503 [37:18<37:52, 1794.48it/s]读取数据:  42%|████▏     | 3008908/7086503 [37:18<38:42, 1755.81it/s]读取数据:  42%|████▏     | 3009084/7086503 [37:18<38:46, 1752.32it/s]读取数据:  42%|████▏     | 3009260/7086503 [37:18<38:53, 1747.08it/s]读取数据:  42%|████▏     | 3009435/7086503 [37:18<38:55, 1745.83it/s]读取数据:  42%|████▏     | 3009610/7086503 [37:19<38:53, 1746.77it/s]读取数据:  42%|████▏     | 3009787/7086503 [37:19<38:45, 1752.98it/s]读取数据:  42%|████▏     | 3009963/7086503 [37:19<38:58, 1743.19it/s]读取数据:  42%|████▏     | 3010139/7086503 [37:19<38:53, 1746.94it/s]读取数据:  42%|████▏     | 3010321/7086503 [37:19<38:27, 1766.42it/s]读取数据:  42%|████▏     | 3010498/7086503 [37:19<38:30, 1764.44it/s]读取数据:  42%|████▏     | 3010675/7086503 [37:19<38:40, 1756.55it/s]读取数据:  42%|████▏     | 3010851/7086503 [37:19<39:35, 1715.65it/s]读取数据:  42%|████▏     | 3011023/7086503 [37:19<40:38, 1671.55it/s]读取数据:  42%|████▏     | 3011191/7086503 [37:19<41:13, 1647.82it/s]读取数据:  42%|████▏     | 3011368/7086503 [37:20<40:23, 1681.28it/s]读取数据:  42%|████▏     | 3011547/7086503 [37:20<39:41, 1710.78it/s]读取数据:  42%|████▏     | 3011728/7086503 [37:20<39:04, 1738.02it/s]读取数据:  43%|████▎     | 3011912/7086503 [37:20<38:27, 1765.73it/s]读取数据:  43%|████▎     | 3012089/7086503 [37:20<38:31, 1762.52it/s]读取数据:  43%|████▎     | 3012267/7086503 [37:20<38:25, 1767.53it/s]读取数据:  43%|████▎     | 3012448/7086503 [37:20<38:11, 1777.76it/s]读取数据:  43%|████▎     | 3012626/7086503 [37:20<43:20, 1566.55it/s]读取数据:  43%|████▎     | 3012788/7086503 [37:20<43:01, 1578.23it/s]读取数据:  43%|████▎     | 3012958/7086503 [37:20<42:09, 1610.42it/s]读取数据:  43%|████▎     | 3013126/7086503 [37:21<41:42, 1627.42it/s]读取数据:  43%|████▎     | 3013291/7086503 [37:21<41:34, 1632.84it/s]读取数据:  43%|████▎     | 3013461/7086503 [37:21<41:08, 1650.29it/s]读取数据:  43%|████▎     | 3013627/7086503 [37:21<41:25, 1638.68it/s]读取数据:  43%|████▎     | 3013793/7086503 [37:21<41:19, 1642.68it/s]读取数据:  43%|████▎     | 3013962/7086503 [37:21<40:58, 1656.44it/s]读取数据:  43%|████▎     | 3014134/7086503 [37:21<40:35, 1672.33it/s]读取数据:  43%|████▎     | 3014302/7086503 [37:21<41:01, 1654.04it/s]读取数据:  43%|████▎     | 3014469/7086503 [37:21<40:56, 1657.44it/s]读取数据:  43%|████▎     | 3014635/7086503 [37:21<40:58, 1656.36it/s]读取数据:  43%|████▎     | 3014807/7086503 [37:22<40:34, 1672.19it/s]读取数据:  43%|████▎     | 3014975/7086503 [37:22<40:40, 1668.19it/s]读取数据:  43%|████▎     | 3015145/7086503 [37:22<40:31, 1674.72it/s]读取数据:  43%|████▎     | 3015315/7086503 [37:22<40:24, 1679.51it/s]读取数据:  43%|████▎     | 3015487/7086503 [37:22<40:09, 1689.80it/s]读取数据:  43%|████▎     | 3015657/7086503 [37:22<40:11, 1688.16it/s]读取数据:  43%|████▎     | 3015826/7086503 [37:22<40:28, 1676.03it/s]读取数据:  43%|████▎     | 3015994/7086503 [37:22<41:49, 1621.93it/s]读取数据:  43%|████▎     | 3016157/7086503 [37:22<42:37, 1591.65it/s]读取数据:  43%|████▎     | 3016319/7086503 [37:23<42:24, 1599.49it/s]读取数据:  43%|████▎     | 3016493/7086503 [37:23<41:22, 1639.62it/s]读取数据:  43%|████▎     | 3016667/7086503 [37:23<40:42, 1666.41it/s]读取数据:  43%|████▎     | 3016838/7086503 [37:23<40:27, 1676.44it/s]读取数据:  43%|████▎     | 3017006/7086503 [37:23<41:06, 1649.98it/s]读取数据:  43%|████▎     | 3017172/7086503 [37:23<41:45, 1623.87it/s]读取数据:  43%|████▎     | 3017339/7086503 [37:23<41:26, 1636.19it/s]读取数据:  43%|████▎     | 3017519/7086503 [37:23<40:17, 1683.31it/s]读取数据:  43%|████▎     | 3017702/7086503 [37:23<39:19, 1724.45it/s]读取数据:  43%|████▎     | 3017877/7086503 [37:23<39:11, 1730.19it/s]读取数据:  43%|████▎     | 3018056/7086503 [37:24<38:49, 1746.43it/s]读取数据:  43%|████▎     | 3018235/7086503 [37:24<38:32, 1758.98it/s]读取数据:  43%|████▎     | 3018411/7086503 [37:24<38:33, 1758.62it/s]读取数据:  43%|████▎     | 3018587/7086503 [37:24<40:03, 1692.61it/s]读取数据:  43%|████▎     | 3018757/7086503 [37:24<41:02, 1652.12it/s]读取数据:  43%|████▎     | 3018923/7086503 [37:24<41:04, 1650.48it/s]读取数据:  43%|████▎     | 3019098/7086503 [37:24<40:22, 1678.86it/s]读取数据:  43%|████▎     | 3019271/7086503 [37:24<40:05, 1691.11it/s]读取数据:  43%|████▎     | 3019448/7086503 [37:24<39:33, 1713.75it/s]读取数据:  43%|████▎     | 3019620/7086503 [37:24<40:17, 1682.30it/s]读取数据:  43%|████▎     | 3019789/7086503 [37:25<41:20, 1639.37it/s]读取数据:  43%|████▎     | 3019954/7086503 [37:25<41:20, 1639.61it/s]读取数据:  43%|████▎     | 3020130/7086503 [37:25<40:28, 1674.57it/s]读取数据:  43%|████▎     | 3020303/7086503 [37:25<40:06, 1690.00it/s]读取数据:  43%|████▎     | 3020483/7086503 [37:25<39:24, 1719.63it/s]读取数据:  43%|████▎     | 3020661/7086503 [37:25<39:01, 1736.69it/s]读取数据:  43%|████▎     | 3020839/7086503 [37:25<38:45, 1748.44it/s]读取数据:  43%|████▎     | 3021017/7086503 [37:25<38:34, 1756.84it/s]读取数据:  43%|████▎     | 3021193/7086503 [37:25<38:52, 1743.17it/s]读取数据:  43%|████▎     | 3021368/7086503 [37:25<40:08, 1687.88it/s]读取数据:  43%|████▎     | 3021538/7086503 [37:26<40:44, 1662.79it/s]读取数据:  43%|████▎     | 3021712/7086503 [37:26<40:14, 1683.30it/s]读取数据:  43%|████▎     | 3021890/7086503 [37:26<39:40, 1707.66it/s]读取数据:  43%|████▎     | 3022070/7086503 [37:26<39:03, 1734.02it/s]读取数据:  43%|████▎     | 3022248/7086503 [37:26<38:49, 1744.82it/s]读取数据:  43%|████▎     | 3022432/7086503 [37:26<38:13, 1771.86it/s]读取数据:  43%|████▎     | 3022617/7086503 [37:26<37:47, 1791.97it/s]读取数据:  43%|████▎     | 3022801/7086503 [37:26<37:33, 1803.36it/s]读取数据:  43%|████▎     | 3022991/7086503 [37:26<36:59, 1830.68it/s]读取数据:  43%|████▎     | 3023175/7086503 [37:27<37:00, 1829.58it/s]读取数据:  43%|████▎     | 3023364/7086503 [37:27<36:40, 1846.11it/s]读取数据:  43%|████▎     | 3023553/7086503 [37:27<36:27, 1857.04it/s]读取数据:  43%|████▎     | 3023739/7086503 [37:27<36:29, 1855.87it/s]读取数据:  43%|████▎     | 3023926/7086503 [37:27<36:24, 1859.87it/s]读取数据:  43%|████▎     | 3024116/7086503 [37:27<36:17, 1865.20it/s]读取数据:  43%|████▎     | 3024305/7086503 [37:27<36:09, 1872.26it/s]读取数据:  43%|████▎     | 3024536/7086503 [37:27<33:50, 2000.91it/s]读取数据:  43%|████▎     | 3024834/7086503 [37:27<29:31, 2293.42it/s]读取数据:  43%|████▎     | 3025135/7086503 [37:27<26:59, 2507.19it/s]读取数据:  43%|████▎     | 3025445/7086503 [37:28<25:13, 2682.81it/s]读取数据:  43%|████▎     | 3025772/7086503 [37:28<23:42, 2854.45it/s]读取数据:  43%|████▎     | 3026078/7086503 [37:28<23:13, 2913.04it/s]读取数据:  43%|████▎     | 3026421/7086503 [37:28<22:07, 3058.69it/s]读取数据:  43%|████▎     | 3026732/7086503 [37:28<22:02, 3070.65it/s]读取数据:  43%|████▎     | 3027051/7086503 [37:28<21:48, 3103.17it/s]读取数据:  43%|████▎     | 3027377/7086503 [37:28<21:30, 3146.41it/s]读取数据:  43%|████▎     | 3027710/7086503 [37:28<21:07, 3200.95it/s]读取数据:  43%|████▎     | 3028062/7086503 [37:28<20:32, 3292.93it/s]读取数据:  43%|████▎     | 3028392/7086503 [37:28<20:50, 3246.47it/s]读取数据:  43%|████▎     | 3028717/7086503 [37:29<20:49, 3247.11it/s]读取数据:  43%|████▎     | 3029050/7086503 [37:29<20:41, 3268.57it/s]读取数据:  43%|████▎     | 3029400/7086503 [37:29<20:17, 3333.17it/s]读取数据:  43%|████▎     | 3029750/7086503 [37:29<19:59, 3381.31it/s]读取数据:  43%|████▎     | 3030103/7086503 [37:29<19:44, 3423.18it/s]读取数据:  43%|████▎     | 3030446/7086503 [37:29<20:03, 3369.14it/s]读取数据:  43%|████▎     | 3030784/7086503 [37:29<20:11, 3347.71it/s]读取数据:  43%|████▎     | 3031130/7086503 [37:29<19:59, 3380.06it/s]读取数据:  43%|████▎     | 3031469/7086503 [37:29<20:03, 3369.62it/s]读取数据:  43%|████▎     | 3031859/7086503 [37:29<19:10, 3525.33it/s]读取数据:  43%|████▎     | 3032218/7086503 [37:30<19:04, 3541.91it/s]读取数据:  43%|████▎     | 3032577/7086503 [37:30<18:59, 3556.16it/s]读取数据:  43%|████▎     | 3032949/7086503 [37:30<18:46, 3599.24it/s]读取数据:  43%|████▎     | 3033310/7086503 [37:30<18:52, 3577.51it/s]读取数据:  43%|████▎     | 3033676/7086503 [37:30<18:45, 3599.62it/s]读取数据:  43%|████▎     | 3034061/7086503 [37:30<18:24, 3670.11it/s]读取数据:  43%|████▎     | 3034445/7086503 [37:30<18:09, 3720.51it/s]读取数据:  43%|████▎     | 3034842/7086503 [37:30<17:47, 3793.75it/s]读取数据:  43%|████▎     | 3035222/7086503 [37:30<17:58, 3755.97it/s]读取数据:  43%|████▎     | 3035598/7086503 [37:30<18:41, 3612.43it/s]读取数据:  43%|████▎     | 3035976/7086503 [37:31<18:27, 3658.31it/s]读取数据:  43%|████▎     | 3036372/7086503 [37:31<18:01, 3743.49it/s]读取数据:  43%|████▎     | 3036778/7086503 [37:31<17:35, 3835.87it/s]读取数据:  43%|████▎     | 3037163/7086503 [37:31<17:51, 3780.09it/s]读取数据:  43%|████▎     | 3037550/7086503 [37:31<17:43, 3806.20it/s]读取数据:  43%|████▎     | 3037957/7086503 [37:31<17:22, 3881.65it/s]读取数据:  43%|████▎     | 3038363/7086503 [37:31<17:09, 3931.76it/s]读取数据:  43%|████▎     | 3038777/7086503 [37:31<16:53, 3992.68it/s]读取数据:  43%|████▎     | 3039177/7086503 [37:31<17:07, 3940.15it/s]读取数据:  43%|████▎     | 3039603/7086503 [37:31<16:44, 4030.48it/s]读取数据:  43%|████▎     | 3040025/7086503 [37:32<16:31, 4082.82it/s]读取数据:  43%|████▎     | 3040454/7086503 [37:32<16:16, 4141.91it/s]读取数据:  43%|████▎     | 3040872/7086503 [37:32<16:14, 4151.83it/s]读取数据:  43%|████▎     | 3041298/7086503 [37:32<16:06, 4183.59it/s]读取数据:  43%|████▎     | 3041717/7086503 [37:32<16:06, 4184.81it/s]读取数据:  43%|████▎     | 3042179/7086503 [37:32<15:37, 4314.79it/s]读取数据:  43%|████▎     | 3042628/7086503 [37:32<15:26, 4366.69it/s]读取数据:  43%|████▎     | 3043079/7086503 [37:32<15:17, 4408.08it/s]读取数据:  43%|████▎     | 3043520/7086503 [37:32<15:19, 4399.03it/s]读取数据:  43%|████▎     | 3043971/7086503 [37:32<15:12, 4432.03it/s]读取数据:  43%|████▎     | 3044440/7086503 [37:33<14:56, 4509.02it/s]读取数据:  43%|████▎     | 3044898/7086503 [37:33<14:52, 4528.66it/s]读取数据:  43%|████▎     | 3045351/7086503 [37:33<14:52, 4528.16it/s]读取数据:  43%|████▎     | 3045804/7086503 [37:33<15:01, 4481.88it/s]读取数据:  43%|████▎     | 3046287/7086503 [37:33<14:41, 4584.67it/s]读取数据:  43%|████▎     | 3046755/7086503 [37:33<14:35, 4612.83it/s]读取数据:  43%|████▎     | 3047217/7086503 [37:33<14:45, 4562.55it/s]读取数据:  43%|████▎     | 3047676/7086503 [37:33<14:44, 4567.71it/s]读取数据:  43%|████▎     | 3048152/7086503 [37:33<14:33, 4621.62it/s]读取数据:  43%|████▎     | 3048651/7086503 [37:33<14:13, 4730.84it/s]读取数据:  43%|████▎     | 3049132/7086503 [37:34<14:09, 4754.20it/s]读取数据:  43%|████▎     | 3049608/7086503 [37:34<14:13, 4731.21it/s]读取数据:  43%|████▎     | 3050082/7086503 [37:35<1:11:44, 937.67it/s]读取数据:  43%|████▎     | 3050424/7086503 [37:35<1:01:01, 1102.31it/s]读取数据:  43%|████▎     | 3050740/7086503 [37:35<53:03, 1267.62it/s]  读取数据:  43%|████▎     | 3051035/7086503 [37:36<46:33, 1444.51it/s]读取数据:  43%|████▎     | 3051319/7086503 [37:36<41:06, 1635.92it/s]读取数据:  43%|████▎     | 3051600/7086503 [37:36<37:25, 1797.26it/s]读取数据:  43%|████▎     | 3051872/7086503 [37:36<34:43, 1936.73it/s]读取数据:  43%|████▎     | 3052148/7086503 [37:36<31:51, 2111.09it/s]读取数据:  43%|████▎     | 3052425/7086503 [37:36<29:42, 2263.26it/s]读取数据:  43%|████▎     | 3052701/7086503 [37:36<28:11, 2384.06it/s]读取数据:  43%|████▎     | 3052973/7086503 [37:36<27:29, 2445.45it/s]读取数据:  43%|████▎     | 3053267/7086503 [37:36<26:06, 2574.88it/s]读取数据:  43%|████▎     | 3053543/7086503 [37:36<25:49, 2602.95it/s]读取数据:  43%|████▎     | 3053817/7086503 [37:37<26:14, 2561.36it/s]读取数据:  43%|████▎     | 3054098/7086503 [37:37<25:33, 2630.39it/s]读取数据:  43%|████▎     | 3054393/7086503 [37:37<24:43, 2717.30it/s]读取数据:  43%|████▎     | 3054690/7086503 [37:37<24:05, 2789.14it/s]读取数据:  43%|████▎     | 3054980/7086503 [37:37<23:50, 2818.02it/s]读取数据:  43%|████▎     | 3055285/7086503 [37:37<23:18, 2882.08it/s]读取数据:  43%|████▎     | 3055576/7086503 [37:37<23:28, 2861.81it/s]读取数据:  43%|████▎     | 3055882/7086503 [37:37<23:00, 2918.74it/s]读取数据:  43%|████▎     | 3056175/7086503 [37:37<23:09, 2901.28it/s]读取数据:  43%|████▎     | 3056480/7086503 [37:37<22:49, 2943.05it/s]读取数据:  43%|████▎     | 3056789/7086503 [37:38<22:29, 2985.79it/s]读取数据:  43%|████▎     | 3057114/7086503 [37:38<21:55, 3062.92it/s]读取数据:  43%|████▎     | 3057421/7086503 [37:38<22:18, 3009.39it/s]读取数据:  43%|████▎     | 3057723/7086503 [37:38<22:24, 2996.31it/s]读取数据:  43%|████▎     | 3058039/7086503 [37:38<22:03, 3043.52it/s]读取数据:  43%|████▎     | 3058351/7086503 [37:38<21:56, 3060.86it/s]读取数据:  43%|████▎     | 3058684/7086503 [37:38<21:24, 3136.55it/s]读取数据:  43%|████▎     | 3058998/7086503 [37:38<21:35, 3109.63it/s]读取数据:  43%|████▎     | 3059326/7086503 [37:38<21:14, 3160.12it/s]读取数据:  43%|████▎     | 3059643/7086503 [37:38<21:32, 3115.58it/s]读取数据:  43%|████▎     | 3059980/7086503 [37:39<21:02, 3189.65it/s]读取数据:  43%|████▎     | 3060307/7086503 [37:39<20:53, 3211.92it/s]读取数据:  43%|████▎     | 3060651/7086503 [37:39<20:29, 3273.88it/s]读取数据:  43%|████▎     | 3060979/7086503 [37:39<20:57, 3201.03it/s]读取数据:  43%|████▎     | 3061326/7086503 [37:39<20:27, 3277.85it/s]读取数据:  43%|████▎     | 3061664/7086503 [37:39<20:16, 3307.87it/s]读取数据:  43%|████▎     | 3061996/7086503 [37:39<20:23, 3288.79it/s]读取数据:  43%|████▎     | 3062335/7086503 [37:39<20:13, 3316.56it/s]读取数据:  43%|████▎     | 3062690/7086503 [37:39<19:48, 3384.35it/s]读取数据:  43%|████▎     | 3063039/7086503 [37:39<19:38, 3414.44it/s]读取数据:  43%|████▎     | 3063381/7086503 [37:40<19:46, 3389.46it/s]读取数据:  43%|████▎     | 3063721/7086503 [37:40<21:00, 3190.86it/s]读取数据:  43%|████▎     | 3064053/7086503 [37:40<20:46, 3225.71it/s]读取数据:  43%|████▎     | 3064389/7086503 [37:40<20:33, 3259.45it/s]读取数据:  43%|████▎     | 3064719/7086503 [37:40<20:30, 3268.66it/s]读取数据:  43%|████▎     | 3065058/7086503 [37:40<20:17, 3303.89it/s]读取数据:  43%|████▎     | 3065424/7086503 [37:40<19:40, 3405.84it/s]读取数据:  43%|████▎     | 3065766/7086503 [37:40<20:11, 3319.94it/s]读取数据:  43%|████▎     | 3066106/7086503 [37:40<20:02, 3343.31it/s]读取数据:  43%|████▎     | 3066445/7086503 [37:41<19:57, 3356.09it/s]读取数据:  43%|████▎     | 3066805/7086503 [37:41<19:32, 3428.19it/s]读取数据:  43%|████▎     | 3067160/7086503 [37:41<19:21, 3460.89it/s]读取数据:  43%|████▎     | 3067529/7086503 [37:41<18:59, 3525.72it/s]读取数据:  43%|████▎     | 3067882/7086503 [37:41<19:36, 3416.10it/s]读取数据:  43%|████▎     | 3068229/7086503 [37:41<19:32, 3427.14it/s]读取数据:  43%|████▎     | 3068573/7086503 [37:41<19:49, 3378.20it/s]读取数据:  43%|████▎     | 3068942/7086503 [37:41<19:19, 3464.85it/s]读取数据:  43%|████▎     | 3069290/7086503 [37:41<19:47, 3382.27it/s]读取数据:  43%|████▎     | 3069639/7086503 [37:41<19:37, 3410.86it/s]读取数据:  43%|████▎     | 3069986/7086503 [37:42<19:32, 3427.01it/s]读取数据:  43%|████▎     | 3070334/7086503 [37:42<19:28, 3438.48it/s]读取数据:  43%|████▎     | 3070717/7086503 [37:42<18:50, 3551.28it/s]读取数据:  43%|████▎     | 3071086/7086503 [37:42<18:38, 3590.20it/s]读取数据:  43%|████▎     | 3071446/7086503 [37:42<18:45, 3568.62it/s]读取数据:  43%|████▎     | 3071814/7086503 [37:42<18:35, 3600.20it/s]读取数据:  43%|████▎     | 3072175/7086503 [37:42<19:05, 3505.16it/s]读取数据:  43%|████▎     | 3072527/7086503 [37:42<19:06, 3501.06it/s]读取数据:  43%|████▎     | 3072911/7086503 [37:42<18:35, 3599.16it/s]读取数据:  43%|████▎     | 3073289/7086503 [37:42<18:19, 3650.13it/s]读取数据:  43%|████▎     | 3073658/7086503 [37:43<18:16, 3661.18it/s]读取数据:  43%|████▎     | 3074028/7086503 [37:43<18:13, 3670.28it/s]读取数据:  43%|████▎     | 3074396/7086503 [37:43<18:22, 3637.67it/s]读取数据:  43%|████▎     | 3074796/7086503 [37:43<17:51, 3743.84it/s]读取数据:  43%|████▎     | 3075175/7086503 [37:43<17:49, 3751.56it/s]读取数据:  43%|████▎     | 3075586/7086503 [37:43<17:19, 3857.95it/s]读取数据:  43%|████▎     | 3075979/7086503 [37:43<17:13, 3879.07it/s]读取数据:  43%|████▎     | 3076368/7086503 [37:43<17:19, 3856.77it/s]读取数据:  43%|████▎     | 3076754/7086503 [37:43<17:24, 3839.14it/s]读取数据:  43%|████▎     | 3077145/7086503 [37:43<17:19, 3857.55it/s]读取数据:  43%|████▎     | 3077557/7086503 [37:44<16:59, 3932.07it/s]读取数据:  43%|████▎     | 3077951/7086503 [37:44<17:15, 3872.78it/s]读取数据:  43%|████▎     | 3078358/7086503 [37:44<17:00, 3925.92it/s]读取数据:  43%|████▎     | 3078757/7086503 [37:44<16:56, 3944.48it/s]读取数据:  43%|████▎     | 3079185/7086503 [37:44<16:32, 4038.81it/s]读取数据:  43%|████▎     | 3079591/7086503 [37:44<16:30, 4044.25it/s]读取数据:  43%|████▎     | 3080017/7086503 [37:44<16:15, 4107.91it/s]读取数据:  43%|████▎     | 3080428/7086503 [37:44<17:27, 3823.79it/s]读取数据:  43%|████▎     | 3080871/7086503 [37:44<16:43, 3992.53it/s]读取数据:  43%|████▎     | 3081332/7086503 [37:45<16:00, 4168.26it/s]读取数据:  43%|████▎     | 3081778/7086503 [37:45<15:41, 4253.34it/s]读取数据:  43%|████▎     | 3082215/7086503 [37:45<15:34, 4283.46it/s]读取数据:  44%|████▎     | 3082667/7086503 [37:45<15:20, 4350.81it/s]读取数据:  44%|████▎     | 3083154/7086503 [37:45<14:49, 4502.20it/s]读取数据:  44%|████▎     | 3083640/7086503 [37:45<14:28, 4607.18it/s]读取数据:  44%|████▎     | 3084111/7086503 [37:45<14:24, 4631.56it/s]读取数据:  44%|████▎     | 3084590/7086503 [37:45<14:15, 4675.94it/s]读取数据:  44%|████▎     | 3085108/7086503 [37:45<13:49, 4822.59it/s]读取数据:  44%|████▎     | 3085608/7086503 [37:45<13:40, 4874.78it/s]读取数据:  44%|████▎     | 3086110/7086503 [37:46<13:33, 4915.18it/s]读取数据:  44%|████▎     | 3086620/7086503 [37:46<13:24, 4969.70it/s]读取数据:  44%|████▎     | 3087167/7086503 [37:46<13:01, 5118.87it/s]读取数据:  44%|████▎     | 3087715/7086503 [37:46<12:45, 5226.86it/s]读取数据:  44%|████▎     | 3088247/7086503 [37:46<12:41, 5252.36it/s]读取数据:  44%|████▎     | 3088779/7086503 [37:46<12:38, 5269.82it/s]读取数据:  44%|████▎     | 3089355/7086503 [37:46<12:18, 5412.97it/s]读取数据:  44%|████▎     | 3089915/7086503 [37:46<12:11, 5466.28it/s]读取数据:  44%|████▎     | 3090491/7086503 [37:46<11:59, 5553.28it/s]读取数据:  44%|████▎     | 3091089/7086503 [37:46<11:43, 5681.06it/s]读取数据:  44%|████▎     | 3091666/7086503 [37:47<11:40, 5703.10it/s]读取数据:  44%|████▎     | 3092263/7086503 [37:47<11:30, 5782.44it/s]读取数据:  44%|████▎     | 3092859/7086503 [37:47<11:24, 5834.13it/s]读取数据:  44%|████▎     | 3093510/7086503 [37:47<11:01, 6036.18it/s]读取数据:  44%|████▎     | 3094154/7086503 [37:47<10:48, 6156.95it/s]读取数据:  44%|████▎     | 3094801/7086503 [37:47<10:38, 6247.90it/s]读取数据:  44%|████▎     | 3095474/7086503 [37:47<10:24, 6389.79it/s]读取数据:  44%|████▎     | 3096127/7086503 [37:47<10:20, 6429.69it/s]读取数据:  44%|████▎     | 3096798/7086503 [37:47<10:12, 6512.80it/s]读取数据:  44%|████▎     | 3097471/7086503 [37:47<10:06, 6574.74it/s]读取数据:  44%|████▎     | 3098184/7086503 [37:48<09:51, 6739.78it/s]读取数据:  44%|████▎     | 3098864/7086503 [37:48<09:50, 6753.88it/s]读取数据:  44%|████▎     | 3099573/7086503 [37:48<09:41, 6854.50it/s]读取数据:  44%|████▎     | 3100259/7086503 [37:49<54:40, 1215.30it/s]读取数据:  44%|████▍     | 3100752/7086503 [37:50<48:08, 1380.06it/s]读取数据:  44%|████▍     | 3101171/7086503 [37:50<43:03, 1542.89it/s]读取数据:  44%|████▍     | 3101543/7086503 [37:50<38:54, 1707.18it/s]读取数据:  44%|████▍     | 3101886/7086503 [37:50<35:59, 1845.00it/s]读取数据:  44%|████▍     | 3102203/7086503 [37:50<33:16, 1995.99it/s]读取数据:  44%|████▍     | 3102508/7086503 [37:50<31:11, 2129.25it/s]读取数据:  44%|████▍     | 3102803/7086503 [37:50<29:33, 2245.72it/s]读取数据:  44%|████▍     | 3103090/7086503 [37:50<28:17, 2346.70it/s]读取数据:  44%|████▍     | 3103372/7086503 [37:51<27:03, 2453.28it/s]读取数据:  44%|████▍     | 3103659/7086503 [37:51<26:00, 2552.67it/s]读取数据:  44%|████▍     | 3103942/7086503 [37:51<25:31, 2600.89it/s]读取数据:  44%|████▍     | 3104225/7086503 [37:51<24:55, 2662.53it/s]读取数据:  44%|████▍     | 3104516/7086503 [37:51<24:19, 2727.62it/s]读取数据:  44%|████▍     | 3104818/7086503 [37:51<23:37, 2809.12it/s]读取数据:  44%|████▍     | 3105107/7086503 [37:51<23:28, 2826.51it/s]读取数据:  44%|████▍     | 3105431/7086503 [37:51<22:31, 2946.54it/s]读取数据:  44%|████▍     | 3105733/7086503 [37:51<22:21, 2966.66it/s]读取数据:  44%|████▍     | 3106056/7086503 [37:51<21:47, 3043.16it/s]读取数据:  44%|████▍     | 3106371/7086503 [37:52<21:35, 3073.09it/s]读取数据:  44%|████▍     | 3106680/7086503 [37:52<21:34, 3074.32it/s]读取数据:  44%|████▍     | 3106992/7086503 [37:52<21:28, 3087.53it/s]读取数据:  44%|████▍     | 3107302/7086503 [37:52<21:35, 3071.20it/s]读取数据:  44%|████▍     | 3107645/7086503 [37:52<20:52, 3176.04it/s]读取数据:  44%|████▍     | 3107975/7086503 [37:52<20:39, 3210.72it/s]读取数据:  44%|████▍     | 3108330/7086503 [37:52<20:01, 3309.75it/s]读取数据:  44%|████▍     | 3108662/7086503 [37:52<20:02, 3306.72it/s]读取数据:  44%|████▍     | 3109002/7086503 [37:52<19:53, 3332.52it/s]读取数据:  44%|████▍     | 3109341/7086503 [37:52<19:47, 3349.24it/s]读取数据:  44%|████▍     | 3109704/7086503 [37:53<19:18, 3431.99it/s]读取数据:  44%|████▍     | 3110048/7086503 [37:53<19:24, 3416.06it/s]读取数据:  44%|████▍     | 3110390/7086503 [37:53<19:33, 3387.22it/s]读取数据:  44%|████▍     | 3110752/7086503 [37:53<19:11, 3453.02it/s]读取数据:  44%|████▍     | 3111098/7086503 [37:53<19:13, 3446.12it/s]读取数据:  44%|████▍     | 3111472/7086503 [37:53<18:45, 3530.73it/s]读取数据:  44%|████▍     | 3111851/7086503 [37:53<18:21, 3607.31it/s]读取数据:  44%|████▍     | 3112212/7086503 [37:53<18:38, 3554.07it/s]读取数据:  44%|████▍     | 3112578/7086503 [37:53<18:29, 3581.16it/s]读取数据:  44%|████▍     | 3112943/7086503 [37:53<18:24, 3597.00it/s]读取数据:  44%|████▍     | 3113303/7086503 [37:54<18:36, 3558.52it/s]读取数据:  44%|████▍     | 3113691/7086503 [37:54<18:07, 3652.79it/s]读取数据:  44%|████▍     | 3114057/7086503 [37:54<18:07, 3651.26it/s]读取数据:  44%|████▍     | 3114423/7086503 [37:54<18:07, 3651.33it/s]读取数据:  44%|████▍     | 3114810/7086503 [37:54<17:48, 3716.28it/s]读取数据:  44%|████▍     | 3115182/7086503 [37:54<17:58, 3681.11it/s]读取数据:  44%|████▍     | 3115561/7086503 [37:54<17:49, 3712.37it/s]读取数据:  44%|████▍     | 3115965/7086503 [37:54<17:22, 3809.65it/s]读取数据:  44%|████▍     | 3116349/7086503 [37:54<17:20, 3817.13it/s]读取数据:  44%|████▍     | 3116748/7086503 [37:54<17:06, 3867.16it/s]读取数据:  44%|████▍     | 3117135/7086503 [37:55<17:20, 3815.20it/s]读取数据:  44%|████▍     | 3117539/7086503 [37:55<17:02, 3881.17it/s]读取数据:  44%|████▍     | 3117956/7086503 [37:55<16:40, 3966.08it/s]读取数据:  44%|████▍     | 3118353/7086503 [37:55<16:41, 3963.05it/s]读取数据:  44%|████▍     | 3118765/7086503 [37:55<16:30, 4006.42it/s]读取数据:  44%|████▍     | 3119166/7086503 [37:55<16:53, 3915.01it/s]读取数据:  44%|████▍     | 3119559/7086503 [37:55<16:52, 3917.44it/s]读取数据:  44%|████▍     | 3119963/7086503 [37:55<16:43, 3950.98it/s]读取数据:  44%|████▍     | 3120372/7086503 [37:55<16:34, 3987.17it/s]读取数据:  44%|████▍     | 3120782/7086503 [37:55<16:26, 4020.53it/s]读取数据:  44%|████▍     | 3121185/7086503 [37:56<16:31, 4000.92it/s]读取数据:  44%|████▍     | 3121586/7086503 [37:56<16:30, 4001.04it/s]读取数据:  44%|████▍     | 3121987/7086503 [37:56<16:57, 3896.42it/s]读取数据:  44%|████▍     | 3122378/7086503 [37:56<17:06, 3863.23it/s]读取数据:  44%|████▍     | 3122777/7086503 [37:56<16:57, 3897.05it/s]读取数据:  44%|████▍     | 3123169/7086503 [37:56<16:55, 3901.50it/s]读取数据:  44%|████▍     | 3123560/7086503 [37:56<16:56, 3897.70it/s]读取数据:  44%|████▍     | 3124005/7086503 [37:56<16:16, 4056.35it/s]读取数据:  44%|████▍     | 3124419/7086503 [37:56<16:12, 4076.19it/s]读取数据:  44%|████▍     | 3124845/7086503 [37:56<15:59, 4127.88it/s]读取数据:  44%|████▍     | 3125265/7086503 [37:57<15:54, 4148.97it/s]读取数据:  44%|████▍     | 3125681/7086503 [37:57<15:54, 4149.16it/s]读取数据:  44%|████▍     | 3126127/7086503 [37:57<15:33, 4241.91it/s]读取数据:  44%|████▍     | 3126577/7086503 [37:57<15:16, 4318.96it/s]读取数据:  44%|████▍     | 3127042/7086503 [37:57<14:56, 4417.72it/s]读取数据:  44%|████▍     | 3127488/7086503 [37:57<14:53, 4429.78it/s]读取数据:  44%|████▍     | 3127954/7086503 [37:57<14:40, 4497.36it/s]读取数据:  44%|████▍     | 3128428/7086503 [37:57<14:26, 4568.12it/s]读取数据:  44%|████▍     | 3128924/7086503 [37:57<14:05, 4682.92it/s]读取数据:  44%|████▍     | 3129394/7086503 [37:57<14:04, 4686.82it/s]读取数据:  44%|████▍     | 3129876/7086503 [37:58<13:57, 4725.79it/s]读取数据:  44%|████▍     | 3130397/7086503 [37:58<13:32, 4868.13it/s]读取数据:  44%|████▍     | 3130884/7086503 [37:58<13:34, 4858.15it/s]读取数据:  44%|████▍     | 3131376/7086503 [37:58<13:31, 4874.87it/s]读取数据:  44%|████▍     | 3131900/7086503 [37:58<13:14, 4979.52it/s]读取数据:  44%|████▍     | 3132442/7086503 [37:58<12:53, 5111.20it/s]读取数据:  44%|████▍     | 3132972/7086503 [37:58<12:45, 5166.62it/s]读取数据:  44%|████▍     | 3133489/7086503 [37:58<12:45, 5160.94it/s]读取数据:  44%|████▍     | 3134014/7086503 [37:58<12:42, 5183.32it/s]读取数据:  44%|████▍     | 3134575/7086503 [37:58<12:24, 5310.60it/s]读取数据:  44%|████▍     | 3135107/7086503 [37:59<12:25, 5299.82it/s]读取数据:  44%|████▍     | 3135638/7086503 [37:59<12:52, 5113.97it/s]读取数据:  44%|████▍     | 3136227/7086503 [37:59<12:20, 5337.17it/s]读取数据:  44%|████▍     | 3136797/7086503 [37:59<12:05, 5440.78it/s]读取数据:  44%|████▍     | 3137378/7086503 [37:59<11:52, 5545.99it/s]读取数据:  44%|████▍     | 3137948/7086503 [37:59<11:46, 5590.74it/s]读取数据:  44%|████▍     | 3138519/7086503 [37:59<11:41, 5624.50it/s]读取数据:  44%|████▍     | 3139126/7086503 [37:59<11:25, 5756.61it/s]读取数据:  44%|████▍     | 3139703/7086503 [37:59<11:26, 5745.98it/s]读取数据:  44%|████▍     | 3140310/7086503 [38:00<11:15, 5842.37it/s]读取数据:  44%|████▍     | 3140914/7086503 [38:00<11:08, 5900.62it/s]读取数据:  44%|████▍     | 3141511/7086503 [38:00<11:06, 5917.63it/s]读取数据:  44%|████▍     | 3142150/7086503 [38:00<10:51, 6058.20it/s]读取数据:  44%|████▍     | 3142771/7086503 [38:00<10:46, 6101.45it/s]读取数据:  44%|████▍     | 3143415/7086503 [38:00<10:35, 6200.30it/s]读取数据:  44%|████▍     | 3144036/7086503 [38:00<10:40, 6155.35it/s]读取数据:  44%|████▍     | 3144688/7086503 [38:00<10:29, 6260.82it/s]读取数据:  44%|████▍     | 3145315/7086503 [38:00<10:32, 6235.62it/s]读取数据:  44%|████▍     | 3145982/7086503 [38:00<10:19, 6362.59it/s]读取数据:  44%|████▍     | 3146702/7086503 [38:01<09:56, 6609.61it/s]读取数据:  44%|████▍     | 3147431/7086503 [38:01<09:38, 6812.57it/s]读取数据:  44%|████▍     | 3148121/7086503 [38:01<09:36, 6834.52it/s]读取数据:  44%|████▍     | 3148833/7086503 [38:01<09:29, 6915.84it/s]读取数据:  44%|████▍     | 3149546/7086503 [38:01<09:24, 6979.31it/s]读取数据:  44%|████▍     | 3150245/7086503 [38:02<43:07, 1521.33it/s]读取数据:  44%|████▍     | 3150750/7086503 [38:02<38:56, 1684.61it/s]读取数据:  44%|████▍     | 3151181/7086503 [38:03<36:07, 1815.46it/s]读取数据:  44%|████▍     | 3151558/7086503 [38:03<34:29, 1901.35it/s]读取数据:  44%|████▍     | 3151890/7086503 [38:03<32:32, 2014.98it/s]读取数据:  44%|████▍     | 3152200/7086503 [38:03<30:24, 2156.51it/s]读取数据:  44%|████▍     | 3152503/7086503 [38:03<28:35, 2292.61it/s]读取数据:  44%|████▍     | 3152801/7086503 [38:03<26:59, 2429.00it/s]读取数据:  44%|████▍     | 3153099/7086503 [38:03<26:08, 2508.09it/s]读取数据:  44%|████▍     | 3153393/7086503 [38:03<25:08, 2607.38it/s]读取数据:  45%|████▍     | 3153685/7086503 [38:04<24:42, 2651.95it/s]读取数据:  45%|████▍     | 3153973/7086503 [38:04<24:22, 2689.24it/s]读取数据:  45%|████▍     | 3154258/7086503 [38:04<23:59, 2732.41it/s]读取数据:  45%|████▍     | 3154577/7086503 [38:04<22:56, 2855.79it/s]读取数据:  45%|████▍     | 3154875/7086503 [38:04<22:39, 2891.11it/s]读取数据:  45%|████▍     | 3155190/7086503 [38:04<22:06, 2964.49it/s]读取数据:  45%|████▍     | 3155492/7086503 [38:04<22:21, 2929.65it/s]读取数据:  45%|████▍     | 3155801/7086503 [38:04<22:00, 2975.81it/s]读取数据:  45%|████▍     | 3156108/7086503 [38:04<21:49, 3001.09it/s]读取数据:  45%|████▍     | 3156432/7086503 [38:04<21:20, 3068.49it/s]读取数据:  45%|████▍     | 3156756/7086503 [38:05<21:00, 3116.97it/s]读取数据:  45%|████▍     | 3157069/7086503 [38:05<21:03, 3110.72it/s]读取数据:  45%|████▍     | 3157404/7086503 [38:05<20:37, 3175.36it/s]读取数据:  45%|████▍     | 3157723/7086503 [38:05<20:38, 3171.04it/s]读取数据:  45%|████▍     | 3158055/7086503 [38:05<20:22, 3213.56it/s]读取数据:  45%|████▍     | 3158392/7086503 [38:05<20:05, 3259.44it/s]读取数据:  45%|████▍     | 3158729/7086503 [38:05<19:53, 3292.31it/s]读取数据:  45%|████▍     | 3159071/7086503 [38:05<19:41, 3324.41it/s]读取数据:  45%|████▍     | 3159431/7086503 [38:05<19:12, 3405.99it/s]读取数据:  45%|████▍     | 3159772/7086503 [38:05<19:16, 3395.81it/s]读取数据:  45%|████▍     | 3160112/7086503 [38:06<19:23, 3375.92it/s]读取数据:  45%|████▍     | 3160450/7086503 [38:06<19:27, 3363.25it/s]读取数据:  45%|████▍     | 3160829/7086503 [38:06<18:45, 3486.97it/s]读取数据:  45%|████▍     | 3161195/7086503 [38:06<18:30, 3534.95it/s]读取数据:  45%|████▍     | 3161550/7086503 [38:06<18:29, 3536.70it/s]读取数据:  45%|████▍     | 3161904/7086503 [38:06<18:40, 3501.97it/s]读取数据:  45%|████▍     | 3162263/7086503 [38:06<18:32, 3527.66it/s]读取数据:  45%|████▍     | 3162642/7086503 [38:06<18:09, 3601.07it/s]读取数据:  45%|████▍     | 3163019/7086503 [38:06<17:54, 3651.09it/s]读取数据:  45%|████▍     | 3163396/7086503 [38:06<17:44, 3685.24it/s]读取数据:  45%|████▍     | 3163786/7086503 [38:07<17:26, 3747.09it/s]读取数据:  45%|████▍     | 3164163/7086503 [38:07<17:24, 3753.54it/s]读取数据:  45%|████▍     | 3164539/7086503 [38:07<17:41, 3695.71it/s]读取数据:  45%|████▍     | 3164958/7086503 [38:07<17:01, 3839.45it/s]读取数据:  45%|████▍     | 3165355/7086503 [38:07<16:51, 3876.91it/s]读取数据:  45%|████▍     | 3165744/7086503 [38:07<16:51, 3876.81it/s]读取数据:  45%|████▍     | 3166145/7086503 [38:07<16:41, 3913.24it/s]读取数据:  45%|████▍     | 3166537/7086503 [38:07<16:46, 3894.66it/s]读取数据:  45%|████▍     | 3166950/7086503 [38:07<16:29, 3961.59it/s]读取数据:  45%|████▍     | 3167359/7086503 [38:07<16:20, 3998.86it/s]读取数据:  45%|████▍     | 3167793/7086503 [38:08<15:56, 4095.57it/s]读取数据:  45%|████▍     | 3168203/7086503 [38:08<16:08, 4045.14it/s]读取数据:  45%|████▍     | 3168608/7086503 [38:08<16:10, 4036.17it/s]读取数据:  45%|████▍     | 3169012/7086503 [38:08<16:13, 4024.98it/s]读取数据:  45%|████▍     | 3169434/7086503 [38:08<15:59, 4082.43it/s]读取数据:  45%|████▍     | 3169845/7086503 [38:08<15:59, 4083.76it/s]读取数据:  45%|████▍     | 3170254/7086503 [38:08<16:14, 4018.24it/s]读取数据:  45%|████▍     | 3170667/7086503 [38:08<16:07, 4048.75it/s]读取数据:  45%|████▍     | 3171087/7086503 [38:08<15:56, 4092.92it/s]读取数据:  45%|████▍     | 3171521/7086503 [38:08<15:40, 4162.68it/s]读取数据:  45%|████▍     | 3171938/7086503 [38:09<15:40, 4161.31it/s]读取数据:  45%|████▍     | 3172358/7086503 [38:09<15:39, 4168.22it/s]读取数据:  45%|████▍     | 3172799/7086503 [38:09<15:23, 4239.98it/s]读取数据:  45%|████▍     | 3173244/7086503 [38:09<15:09, 4301.89it/s]读取数据:  45%|████▍     | 3173675/7086503 [38:09<15:13, 4281.33it/s]读取数据:  45%|████▍     | 3174108/7086503 [38:09<15:10, 4295.79it/s]读取数据:  45%|████▍     | 3174538/7086503 [38:09<15:10, 4295.75it/s]读取数据:  45%|████▍     | 3174989/7086503 [38:09<14:57, 4356.41it/s]读取数据:  45%|████▍     | 3175465/7086503 [38:09<14:33, 4476.15it/s]读取数据:  45%|████▍     | 3175913/7086503 [38:09<14:33, 4475.31it/s]读取数据:  45%|████▍     | 3176388/7086503 [38:10<14:18, 4556.52it/s]读取数据:  45%|████▍     | 3176844/7086503 [38:10<14:25, 4514.77it/s]读取数据:  45%|████▍     | 3177332/7086503 [38:10<14:05, 4621.23it/s]读取数据:  45%|████▍     | 3177795/7086503 [38:10<14:52, 4381.54it/s]读取数据:  45%|████▍     | 3178263/7086503 [38:10<14:35, 4465.22it/s]读取数据:  45%|████▍     | 3178729/7086503 [38:10<14:24, 4520.45it/s]读取数据:  45%|████▍     | 3179199/7086503 [38:10<14:14, 4572.83it/s]读取数据:  45%|████▍     | 3179696/7086503 [38:10<13:53, 4687.53it/s]读取数据:  45%|████▍     | 3180166/7086503 [38:10<13:54, 4681.99it/s]读取数据:  45%|████▍     | 3180642/7086503 [38:10<13:51, 4698.31it/s]读取数据:  45%|████▍     | 3181123/7086503 [38:11<13:45, 4730.92it/s]读取数据:  45%|████▍     | 3181614/7086503 [38:11<13:36, 4781.80it/s]读取数据:  45%|████▍     | 3182106/7086503 [38:11<13:29, 4820.77it/s]读取数据:  45%|████▍     | 3182603/7086503 [38:11<13:22, 4864.30it/s]读取数据:  45%|████▍     | 3183138/7086503 [38:11<12:59, 5008.19it/s]读取数据:  45%|████▍     | 3183651/7086503 [38:11<12:53, 5043.89it/s]读取数据:  45%|████▍     | 3184160/7086503 [38:11<12:51, 5057.01it/s]读取数据:  45%|████▍     | 3184682/7086503 [38:11<12:44, 5104.88it/s]读取数据:  45%|████▍     | 3185211/7086503 [38:11<12:36, 5158.60it/s]读取数据:  45%|████▍     | 3185765/7086503 [38:11<12:20, 5270.37it/s]读取数据:  45%|████▍     | 3186320/7086503 [38:12<12:08, 5353.40it/s]读取数据:  45%|████▍     | 3186863/7086503 [38:12<12:05, 5375.63it/s]读取数据:  45%|████▍     | 3187435/7086503 [38:12<11:51, 5477.86it/s]读取数据:  45%|████▍     | 3188008/7086503 [38:12<11:42, 5552.72it/s]读取数据:  45%|████▍     | 3188587/7086503 [38:12<11:33, 5623.44it/s]读取数据:  45%|████▌     | 3189154/7086503 [38:12<11:31, 5635.60it/s]读取数据:  45%|████▌     | 3189754/7086503 [38:12<11:18, 5743.62it/s]读取数据:  45%|████▌     | 3190362/7086503 [38:12<11:06, 5843.20it/s]读取数据:  45%|████▌     | 3190955/7086503 [38:12<11:03, 5867.48it/s]读取数据:  45%|████▌     | 3191565/7086503 [38:12<10:56, 5935.91it/s]读取数据:  45%|████▌     | 3192159/7086503 [38:13<10:56, 5931.03it/s]读取数据:  45%|████▌     | 3192798/7086503 [38:13<10:41, 6066.85it/s]读取数据:  45%|████▌     | 3193446/7086503 [38:13<10:28, 6190.26it/s]读取数据:  45%|████▌     | 3194088/7086503 [38:13<10:21, 6258.97it/s]读取数据:  45%|████▌     | 3194768/7086503 [38:13<10:06, 6417.84it/s]读取数据:  45%|████▌     | 3195450/7086503 [38:13<09:55, 6536.28it/s]读取数据:  45%|████▌     | 3196140/7086503 [38:13<09:45, 6644.77it/s]读取数据:  45%|████▌     | 3196842/7086503 [38:13<09:35, 6755.74it/s]读取数据:  45%|████▌     | 3197539/7086503 [38:13<09:30, 6817.57it/s]读取数据:  45%|████▌     | 3198257/7086503 [38:13<09:21, 6920.30it/s]读取数据:  45%|████▌     | 3198986/7086503 [38:14<09:12, 7030.45it/s]读取数据:  45%|████▌     | 3199690/7086503 [38:14<09:13, 7022.62it/s]读取数据:  45%|████▌     | 3200393/7086503 [38:15<50:00, 1295.18it/s]读取数据:  45%|████▌     | 3200898/7086503 [38:15<44:38, 1450.70it/s]读取数据:  45%|████▌     | 3201323/7086503 [38:16<40:47, 1587.64it/s]读取数据:  45%|████▌     | 3201692/7086503 [38:16<37:37, 1720.71it/s]读取数据:  45%|████▌     | 3202025/7086503 [38:16<34:51, 1857.04it/s]读取数据:  45%|████▌     | 3202336/7086503 [38:16<32:45, 1975.78it/s]读取数据:  45%|████▌     | 3202630/7086503 [38:16<31:14, 2072.26it/s]读取数据:  45%|████▌     | 3202910/7086503 [38:16<30:01, 2156.27it/s]读取数据:  45%|████▌     | 3203181/7086503 [38:16<28:38, 2259.56it/s]读取数据:  45%|████▌     | 3203464/7086503 [38:16<27:05, 2389.55it/s]读取数据:  45%|████▌     | 3203741/7086503 [38:17<26:04, 2481.81it/s]读取数据:  45%|████▌     | 3204021/7086503 [38:17<25:16, 2560.67it/s]读取数据:  45%|████▌     | 3204297/7086503 [38:17<25:05, 2578.40it/s]读取数据:  45%|████▌     | 3204591/7086503 [38:17<24:10, 2677.14it/s]读取数据:  45%|████▌     | 3204869/7086503 [38:17<24:13, 2669.91it/s]读取数据:  45%|████▌     | 3205149/7086503 [38:17<23:54, 2705.74it/s]读取数据:  45%|████▌     | 3205425/7086503 [38:17<24:01, 2691.70it/s]读取数据:  45%|████▌     | 3205729/7086503 [38:17<23:10, 2791.51it/s]读取数据:  45%|████▌     | 3206030/7086503 [38:17<22:39, 2853.44it/s]读取数据:  45%|████▌     | 3206321/7086503 [38:17<22:33, 2866.14it/s]读取数据:  45%|████▌     | 3206619/7086503 [38:18<22:18, 2899.44it/s]读取数据:  45%|████▌     | 3206932/7086503 [38:18<21:47, 2967.91it/s]读取数据:  45%|████▌     | 3207230/7086503 [38:18<22:05, 2925.94it/s]读取数据:  45%|████▌     | 3207533/7086503 [38:18<21:51, 2956.58it/s]读取数据:  45%|████▌     | 3207867/7086503 [38:18<21:03, 3069.66it/s]读取数据:  45%|████▌     | 3208175/7086503 [38:18<21:02, 3071.40it/s]读取数据:  45%|████▌     | 3208507/7086503 [38:18<20:33, 3143.62it/s]读取数据:  45%|████▌     | 3208832/7086503 [38:18<20:21, 3175.25it/s]读取数据:  45%|████▌     | 3209150/7086503 [38:18<20:40, 3125.24it/s]读取数据:  45%|████▌     | 3209463/7086503 [38:19<20:41, 3122.49it/s]读取数据:  45%|████▌     | 3209787/7086503 [38:19<20:28, 3156.70it/s]读取数据:  45%|████▌     | 3210132/7086503 [38:19<19:55, 3242.84it/s]读取数据:  45%|████▌     | 3210477/7086503 [38:19<19:34, 3300.83it/s]读取数据:  45%|████▌     | 3210814/7086503 [38:19<19:28, 3315.55it/s]读取数据:  45%|████▌     | 3211146/7086503 [38:19<19:44, 3271.69it/s]读取数据:  45%|████▌     | 3211488/7086503 [38:19<19:29, 3312.98it/s]读取数据:  45%|████▌     | 3211820/7086503 [38:19<20:18, 3181.01it/s]读取数据:  45%|████▌     | 3212221/7086503 [38:19<18:52, 3420.76it/s]读取数据:  45%|████▌     | 3212586/7086503 [38:19<18:30, 3487.16it/s]读取数据:  45%|████▌     | 3212953/7086503 [38:20<18:14, 3539.78it/s]读取数据:  45%|████▌     | 3213344/7086503 [38:20<17:42, 3644.32it/s]读取数据:  45%|████▌     | 3213746/7086503 [38:20<17:11, 3755.44it/s]读取数据:  45%|████▌     | 3214165/7086503 [38:20<16:37, 3883.09it/s]读取数据:  45%|████▌     | 3214554/7086503 [38:20<16:47, 3841.94it/s]读取数据:  45%|████▌     | 3214955/7086503 [38:20<16:35, 3890.55it/s]读取数据:  45%|████▌     | 3215345/7086503 [38:20<16:36, 3885.70it/s]读取数据:  45%|████▌     | 3215734/7086503 [38:20<16:47, 3843.06it/s]读取数据:  45%|████▌     | 3216158/7086503 [38:20<16:18, 3957.35it/s]读取数据:  45%|████▌     | 3216564/7086503 [38:20<16:11, 3983.85it/s]读取数据:  45%|████▌     | 3216995/7086503 [38:21<15:48, 4080.00it/s]读取数据:  45%|████▌     | 3217404/7086503 [38:21<15:53, 4056.39it/s]读取数据:  45%|████▌     | 3217822/7086503 [38:21<15:46, 4089.42it/s]读取数据:  45%|████▌     | 3218232/7086503 [38:21<15:48, 4078.28it/s]读取数据:  45%|████▌     | 3218657/7086503 [38:21<15:37, 4125.99it/s]读取数据:  45%|████▌     | 3219086/7086503 [38:21<15:27, 4169.47it/s]读取数据:  45%|████▌     | 3219504/7086503 [38:21<15:43, 4097.22it/s]读取数据:  45%|████▌     | 3219915/7086503 [38:21<15:48, 4074.98it/s]读取数据:  45%|████▌     | 3220334/7086503 [38:21<15:41, 4108.25it/s]读取数据:  45%|████▌     | 3220777/7086503 [38:21<15:20, 4201.81it/s]读取数据:  45%|████▌     | 3221198/7086503 [38:22<15:28, 4162.55it/s]读取数据:  45%|████▌     | 3221615/7086503 [38:22<15:30, 4152.75it/s]读取数据:  45%|████▌     | 3222034/7086503 [38:22<15:28, 4161.23it/s]读取数据:  45%|████▌     | 3222485/7086503 [38:22<15:06, 4264.27it/s]读取数据:  45%|████▌     | 3222919/7086503 [38:22<15:01, 4284.26it/s]读取数据:  45%|████▌     | 3223364/7086503 [38:22<14:52, 4330.15it/s]读取数据:  45%|████▌     | 3223825/7086503 [38:22<14:35, 4413.48it/s]读取数据:  45%|████▌     | 3224267/7086503 [38:22<14:35, 4409.86it/s]读取数据:  46%|████▌     | 3224715/7086503 [38:22<14:32, 4428.23it/s]读取数据:  46%|████▌     | 3225180/7086503 [38:22<14:19, 4494.29it/s]读取数据:  46%|████▌     | 3225630/7086503 [38:23<14:25, 4462.79it/s]读取数据:  46%|████▌     | 3226086/7086503 [38:23<14:20, 4487.60it/s]读取数据:  46%|████▌     | 3226555/7086503 [38:23<14:08, 4547.26it/s]读取数据:  46%|████▌     | 3227040/7086503 [38:23<13:52, 4633.22it/s]读取数据:  46%|████▌     | 3227532/7086503 [38:23<13:38, 4714.28it/s]读取数据:  46%|████▌     | 3228017/7086503 [38:23<13:32, 4749.61it/s]读取数据:  46%|████▌     | 3228502/7086503 [38:23<13:27, 4778.78it/s]读取数据:  46%|████▌     | 3229022/7086503 [38:23<13:06, 4903.62it/s]读取数据:  46%|████▌     | 3229526/7086503 [38:23<13:00, 4939.57it/s]读取数据:  46%|████▌     | 3230022/7086503 [38:23<12:59, 4945.26it/s]读取数据:  46%|████▌     | 3230517/7086503 [38:24<12:59, 4946.48it/s]读取数据:  46%|████▌     | 3231058/7086503 [38:24<12:38, 5084.94it/s]读取数据:  46%|████▌     | 3231567/7086503 [38:24<12:40, 5069.08it/s]读取数据:  46%|████▌     | 3232091/7086503 [38:24<12:33, 5116.51it/s]读取数据:  46%|████▌     | 3232659/7086503 [38:24<12:09, 5284.74it/s]读取数据:  46%|████▌     | 3233188/7086503 [38:24<12:11, 5266.25it/s]读取数据:  46%|████▌     | 3233715/7086503 [38:24<12:16, 5232.84it/s]读取数据:  46%|████▌     | 3234239/7086503 [38:24<12:29, 5141.86it/s]读取数据:  46%|████▌     | 3234754/7086503 [38:24<12:33, 5109.13it/s]读取数据:  46%|████▌     | 3235266/7086503 [38:24<12:36, 5094.23it/s]读取数据:  46%|████▌     | 3235820/7086503 [38:25<12:16, 5225.05it/s]读取数据:  46%|████▌     | 3236382/7086503 [38:25<12:00, 5340.39it/s]读取数据:  46%|████▌     | 3236978/7086503 [38:25<11:36, 5523.03it/s]读取数据:  46%|████▌     | 3237582/7086503 [38:25<11:18, 5675.57it/s]读取数据:  46%|████▌     | 3238151/7086503 [38:25<11:17, 5679.73it/s]读取数据:  46%|████▌     | 3238762/7086503 [38:25<11:02, 5804.56it/s]读取数据:  46%|████▌     | 3239368/7086503 [38:25<10:54, 5879.45it/s]读取数据:  46%|████▌     | 3239973/7086503 [38:25<10:48, 5930.00it/s]读取数据:  46%|████▌     | 3240595/7086503 [38:25<10:39, 6016.16it/s]读取数据:  46%|████▌     | 3241253/7086503 [38:25<10:21, 6184.01it/s]读取数据:  46%|████▌     | 3241872/7086503 [38:26<10:22, 6179.34it/s]读取数据:  46%|████▌     | 3242510/7086503 [38:26<10:16, 6234.81it/s]读取数据:  46%|████▌     | 3243169/7086503 [38:26<10:06, 6339.87it/s]读取数据:  46%|████▌     | 3243827/7086503 [38:26<09:59, 6410.01it/s]读取数据:  46%|████▌     | 3244523/7086503 [38:26<09:44, 6572.53it/s]读取数据:  46%|████▌     | 3245221/7086503 [38:26<09:34, 6692.11it/s]读取数据:  46%|████▌     | 3245933/7086503 [38:26<09:23, 6818.58it/s]读取数据:  46%|████▌     | 3246672/7086503 [38:26<09:09, 6987.65it/s]读取数据:  46%|████▌     | 3247417/7086503 [38:26<08:58, 7125.17it/s]读取数据:  46%|████▌     | 3248182/7086503 [38:26<08:47, 7280.55it/s]读取数据:  46%|████▌     | 3248953/7086503 [38:27<08:38, 7408.06it/s]读取数据:  46%|████▌     | 3249711/7086503 [38:27<08:34, 7457.57it/s]读取数据:  46%|████▌     | 3250457/7086503 [38:28<39:42, 1610.27it/s]读取数据:  46%|████▌     | 3250997/7086503 [38:28<35:51, 1782.56it/s]读取数据:  46%|████▌     | 3251457/7086503 [38:28<32:56, 1940.29it/s]读取数据:  46%|████▌     | 3251863/7086503 [38:29<31:13, 2047.15it/s]读取数据:  46%|████▌     | 3252224/7086503 [38:29<29:42, 2151.14it/s]读取数据:  46%|████▌     | 3252555/7086503 [38:29<28:22, 2251.42it/s]读取数据:  46%|████▌     | 3252868/7086503 [38:29<27:01, 2364.36it/s]读取数据:  46%|████▌     | 3253172/7086503 [38:29<25:36, 2494.84it/s]读取数据:  46%|████▌     | 3253476/7086503 [38:29<25:08, 2540.80it/s]读取数据:  46%|████▌     | 3253773/7086503 [38:29<24:12, 2638.69it/s]读取数据:  46%|████▌     | 3254067/7086503 [38:29<23:58, 2665.02it/s]读取数据:  46%|████▌     | 3254355/7086503 [38:29<23:34, 2708.67it/s]读取数据:  46%|████▌     | 3254648/7086503 [38:30<23:04, 2767.13it/s]读取数据:  46%|████▌     | 3254944/7086503 [38:30<22:38, 2820.27it/s]读取数据:  46%|████▌     | 3255254/7086503 [38:30<22:02, 2897.63it/s]读取数据:  46%|████▌     | 3255551/7086503 [38:30<22:23, 2850.92it/s]读取数据:  46%|████▌     | 3255854/7086503 [38:30<22:00, 2901.59it/s]读取数据:  46%|████▌     | 3256151/7086503 [38:30<21:51, 2920.68it/s]读取数据:  46%|████▌     | 3256446/7086503 [38:30<22:16, 2866.06it/s]读取数据:  46%|████▌     | 3256735/7086503 [38:30<22:18, 2861.49it/s]读取数据:  46%|████▌     | 3257049/7086503 [38:30<21:43, 2938.24it/s]读取数据:  46%|████▌     | 3257384/7086503 [38:30<20:51, 3058.96it/s]读取数据:  46%|████▌     | 3257691/7086503 [38:31<20:59, 3040.90it/s]读取数据:  46%|████▌     | 3258029/7086503 [38:31<20:19, 3138.13it/s]读取数据:  46%|████▌     | 3258344/7086503 [38:31<20:23, 3128.22it/s]读取数据:  46%|████▌     | 3258658/7086503 [38:31<20:30, 3110.37it/s]读取数据:  46%|████▌     | 3259011/7086503 [38:31<19:44, 3229.96it/s]读取数据:  46%|████▌     | 3259343/7086503 [38:31<19:37, 3250.96it/s]读取数据:  46%|████▌     | 3259690/7086503 [38:31<19:14, 3315.77it/s]读取数据:  46%|████▌     | 3260034/7086503 [38:31<19:02, 3349.45it/s]读取数据:  46%|████▌     | 3260370/7086503 [38:31<19:22, 3292.46it/s]读取数据:  46%|████▌     | 3260700/7086503 [38:31<19:29, 3270.58it/s]读取数据:  46%|████▌     | 3261032/7086503 [38:32<19:24, 3285.13it/s]读取数据:  46%|████▌     | 3261404/7086503 [38:32<18:41, 3409.57it/s]读取数据:  46%|████▌     | 3261785/7086503 [38:32<18:04, 3526.75it/s]读取数据:  46%|████▌     | 3262138/7086503 [38:32<18:30, 3445.21it/s]读取数据:  46%|████▌     | 3262512/7086503 [38:32<18:03, 3528.89it/s]读取数据:  46%|████▌     | 3262875/7086503 [38:32<17:54, 3558.33it/s]读取数据:  46%|████▌     | 3263272/7086503 [38:32<17:19, 3677.66it/s]读取数据:  46%|████▌     | 3263648/7086503 [38:32<17:13, 3697.68it/s]读取数据:  46%|████▌     | 3264033/7086503 [38:32<17:03, 3734.43it/s]读取数据:  46%|████▌     | 3264407/7086503 [38:32<17:13, 3699.11it/s]读取数据:  46%|████▌     | 3264779/7086503 [38:33<17:11, 3703.71it/s]读取数据:  46%|████▌     | 3265199/7086503 [38:33<16:32, 3849.17it/s]读取数据:  46%|████▌     | 3265602/7086503 [38:33<16:19, 3902.56it/s]读取数据:  46%|████▌     | 3265997/7086503 [38:33<16:15, 3914.74it/s]读取数据:  46%|████▌     | 3266407/7086503 [38:33<16:02, 3969.25it/s]读取数据:  46%|████▌     | 3266805/7086503 [38:33<16:01, 3972.18it/s]读取数据:  46%|████▌     | 3267262/7086503 [38:33<15:20, 4148.50it/s]读取数据:  46%|████▌     | 3267714/7086503 [38:33<14:57, 4257.28it/s]读取数据:  46%|████▌     | 3268140/7086503 [38:33<15:01, 4236.57it/s]读取数据:  46%|████▌     | 3268565/7086503 [38:33<15:01, 4235.01it/s]读取数据:  46%|████▌     | 3268989/7086503 [38:34<15:45, 4036.36it/s]读取数据:  46%|████▌     | 3269405/7086503 [38:34<15:37, 4070.85it/s]读取数据:  46%|████▌     | 3269837/7086503 [38:34<15:21, 4140.21it/s]读取数据:  46%|████▌     | 3270253/7086503 [38:34<15:22, 4137.62it/s]读取数据:  46%|████▌     | 3270668/7086503 [38:34<15:24, 4128.01it/s]读取数据:  46%|████▌     | 3271082/7086503 [38:34<15:26, 4118.50it/s]读取数据:  46%|████▌     | 3271504/7086503 [38:34<15:20, 4145.26it/s]读取数据:  46%|████▌     | 3271933/7086503 [38:34<15:10, 4187.59it/s]读取数据:  46%|████▌     | 3272381/7086503 [38:34<14:52, 4272.25it/s]读取数据:  46%|████▌     | 3272809/7086503 [38:34<15:06, 4206.21it/s]读取数据:  46%|████▌     | 3273273/7086503 [38:35<14:40, 4331.91it/s]读取数据:  46%|████▌     | 3273750/7086503 [38:35<14:15, 4457.74it/s]读取数据:  46%|████▌     | 3274223/7086503 [38:35<13:59, 4538.69it/s]读取数据:  46%|████▌     | 3274678/7086503 [38:35<14:35, 4352.49it/s]读取数据:  46%|████▌     | 3275145/7086503 [38:35<14:18, 4440.88it/s]读取数据:  46%|████▌     | 3275623/7086503 [38:35<13:59, 4538.01it/s]读取数据:  46%|████▌     | 3276088/7086503 [38:35<13:54, 4568.33it/s]读取数据:  46%|████▌     | 3276565/7086503 [38:35<13:43, 4626.77it/s]读取数据:  46%|████▌     | 3277029/7086503 [38:35<13:50, 4585.10it/s]读取数据:  46%|████▋     | 3277510/7086503 [38:36<13:38, 4651.61it/s]读取数据:  46%|████▋     | 3277995/7086503 [38:36<13:28, 4708.65it/s]读取数据:  46%|████▋     | 3278481/7086503 [38:36<13:21, 4753.06it/s]读取数据:  46%|████▋     | 3278957/7086503 [38:36<13:25, 4728.87it/s]读取数据:  46%|████▋     | 3279469/7086503 [38:36<13:05, 4844.22it/s]读取数据:  46%|████▋     | 3279971/7086503 [38:36<12:58, 4891.20it/s]读取数据:  46%|████▋     | 3280487/7086503 [38:36<12:45, 4970.81it/s]读取数据:  46%|████▋     | 3280992/7086503 [38:36<12:41, 4994.13it/s]读取数据:  46%|████▋     | 3281492/7086503 [38:36<12:42, 4987.49it/s]读取数据:  46%|████▋     | 3282009/7086503 [38:36<12:35, 5038.43it/s]读取数据:  46%|████▋     | 3282553/7086503 [38:37<12:17, 5154.62it/s]读取数据:  46%|████▋     | 3283069/7086503 [38:37<12:18, 5149.66it/s]读取数据:  46%|████▋     | 3283600/7086503 [38:37<12:11, 5197.19it/s]读取数据:  46%|████▋     | 3284173/7086503 [38:37<11:49, 5356.69it/s]读取数据:  46%|████▋     | 3284709/7086503 [38:37<11:54, 5322.06it/s]读取数据:  46%|████▋     | 3285258/7086503 [38:37<11:47, 5370.16it/s]读取数据:  46%|████▋     | 3285818/7086503 [38:37<11:39, 5436.78it/s]读取数据:  46%|████▋     | 3286369/7086503 [38:37<11:36, 5458.01it/s]读取数据:  46%|████▋     | 3286942/7086503 [38:37<11:26, 5536.86it/s]读取数据:  46%|████▋     | 3287503/7086503 [38:37<11:23, 5556.64it/s]读取数据:  46%|████▋     | 3288105/7086503 [38:38<11:07, 5692.46it/s]读取数据:  46%|████▋     | 3288710/7086503 [38:38<10:55, 5794.87it/s]读取数据:  46%|████▋     | 3289292/7086503 [38:38<10:54, 5802.22it/s]读取数据:  46%|████▋     | 3289929/7086503 [38:38<10:35, 5969.67it/s]读取数据:  46%|████▋     | 3290564/7086503 [38:38<10:23, 6083.54it/s]读取数据:  46%|████▋     | 3291194/7086503 [38:38<10:17, 6148.26it/s]读取数据:  46%|████▋     | 3291813/7086503 [38:38<10:16, 6159.68it/s]读取数据:  46%|████▋     | 3292486/7086503 [38:38<09:59, 6330.09it/s]读取数据:  46%|████▋     | 3293135/7086503 [38:38<09:54, 6377.46it/s]读取数据:  46%|████▋     | 3293773/7086503 [38:38<09:57, 6352.52it/s]读取数据:  46%|████▋     | 3294424/7086503 [38:39<09:52, 6399.06it/s]读取数据:  46%|████▋     | 3295118/7086503 [38:39<09:38, 6558.81it/s]读取数据:  47%|████▋     | 3295857/7086503 [38:39<09:17, 6804.66it/s]读取数据:  47%|████▋     | 3296586/7086503 [38:39<09:05, 6947.45it/s]读取数据:  47%|████▋     | 3297325/7086503 [38:39<08:55, 7078.51it/s]读取数据:  47%|████▋     | 3298095/7086503 [38:39<08:41, 7263.64it/s]读取数据:  47%|████▋     | 3298822/7086503 [38:39<08:42, 7252.08it/s]读取数据:  47%|████▋     | 3299548/7086503 [38:39<08:50, 7143.78it/s]读取数据:  47%|████▋     | 3300263/7086503 [38:40<39:07, 1612.91it/s]读取数据:  47%|████▋     | 3300781/7086503 [38:41<35:28, 1778.65it/s]读取数据:  47%|████▋     | 3301224/7086503 [38:41<32:44, 1926.66it/s]读取数据:  47%|████▋     | 3301616/7086503 [38:41<30:45, 2051.22it/s]读取数据:  47%|████▋     | 3301970/7086503 [38:41<29:26, 2141.91it/s]读取数据:  47%|████▋     | 3302294/7086503 [38:41<27:48, 2267.46it/s]读取数据:  47%|████▋     | 3302606/7086503 [38:41<26:22, 2390.74it/s]读取数据:  47%|████▋     | 3302912/7086503 [38:41<25:35, 2464.78it/s]读取数据:  47%|████▋     | 3303208/7086503 [38:42<25:13, 2499.74it/s]读取数据:  47%|████▋     | 3303493/7086503 [38:42<24:37, 2560.90it/s]读取数据:  47%|████▋     | 3303776/7086503 [38:42<24:11, 2606.11it/s]读取数据:  47%|████▋     | 3304064/7086503 [38:42<23:33, 2675.68it/s]读取数据:  47%|████▋     | 3304392/7086503 [38:42<22:13, 2836.82it/s]读取数据:  47%|████▋     | 3304688/7086503 [38:42<22:13, 2835.72it/s]读取数据:  47%|████▋     | 3304980/7086503 [38:42<22:20, 2821.95it/s]读取数据:  47%|████▋     | 3305280/7086503 [38:42<21:58, 2868.17it/s]读取数据:  47%|████▋     | 3305571/7086503 [38:42<21:57, 2869.74it/s]读取数据:  47%|████▋     | 3305890/7086503 [38:42<21:16, 2961.78it/s]读取数据:  47%|████▋     | 3306220/7086503 [38:43<20:36, 3057.56it/s]读取数据:  47%|████▋     | 3306534/7086503 [38:43<20:26, 3081.76it/s]读取数据:  47%|████▋     | 3306844/7086503 [38:43<20:44, 3037.15it/s]读取数据:  47%|████▋     | 3307161/7086503 [38:43<20:30, 3072.53it/s]读取数据:  47%|████▋     | 3307470/7086503 [38:43<20:29, 3074.52it/s]读取数据:  47%|████▋     | 3307778/7086503 [38:43<20:44, 3035.43it/s]读取数据:  47%|████▋     | 3308113/7086503 [38:43<20:08, 3125.24it/s]读取数据:  47%|████▋     | 3308435/7086503 [38:43<19:58, 3153.22it/s]读取数据:  47%|████▋     | 3308774/7086503 [38:43<19:32, 3222.29it/s]读取数据:  47%|████▋     | 3309107/7086503 [38:43<19:21, 3253.07it/s]读取数据:  47%|████▋     | 3309437/7086503 [38:44<19:17, 3264.07it/s]读取数据:  47%|████▋     | 3309764/7086503 [38:44<19:39, 3203.26it/s]读取数据:  47%|████▋     | 3310100/7086503 [38:44<19:22, 3248.58it/s]读取数据:  47%|████▋     | 3310426/7086503 [38:44<19:35, 3213.12it/s]读取数据:  47%|████▋     | 3310767/7086503 [38:44<19:14, 3270.92it/s]读取数据:  47%|████▋     | 3311121/7086503 [38:44<18:47, 3347.34it/s]读取数据:  47%|████▋     | 3311457/7086503 [38:44<18:56, 3322.39it/s]读取数据:  47%|████▋     | 3311812/7086503 [38:44<18:33, 3389.73it/s]读取数据:  47%|████▋     | 3312152/7086503 [38:44<18:35, 3382.15it/s]读取数据:  47%|████▋     | 3312512/7086503 [38:45<18:15, 3444.78it/s]读取数据:  47%|████▋     | 3312893/7086503 [38:45<17:43, 3549.42it/s]读取数据:  47%|████▋     | 3313266/7086503 [38:45<17:27, 3601.74it/s]读取数据:  47%|████▋     | 3313627/7086503 [38:45<17:39, 3561.23it/s]读取数据:  47%|████▋     | 3313984/7086503 [38:45<18:09, 3462.33it/s]读取数据:  47%|████▋     | 3314337/7086503 [38:45<18:04, 3478.44it/s]读取数据:  47%|████▋     | 3314713/7086503 [38:45<17:40, 3558.08it/s]读取数据:  47%|████▋     | 3315084/7086503 [38:45<17:26, 3602.23it/s]读取数据:  47%|████▋     | 3315482/7086503 [38:45<16:55, 3712.35it/s]读取数据:  47%|████▋     | 3315863/7086503 [38:45<16:48, 3737.24it/s]读取数据:  47%|████▋     | 3316268/7086503 [38:46<16:24, 3829.36it/s]读取数据:  47%|████▋     | 3316667/7086503 [38:46<16:12, 3876.33it/s]读取数据:  47%|████▋     | 3317056/7086503 [38:46<16:11, 3878.45it/s]读取数据:  47%|████▋     | 3317467/7086503 [38:46<15:55, 3944.16it/s]读取数据:  47%|████▋     | 3317867/7086503 [38:46<15:52, 3957.39it/s]读取数据:  47%|████▋     | 3318263/7086503 [38:46<15:53, 3950.50it/s]读取数据:  47%|████▋     | 3318687/7086503 [38:46<15:33, 4034.88it/s]读取数据:  47%|████▋     | 3319091/7086503 [38:46<15:50, 3964.69it/s]读取数据:  47%|████▋     | 3319491/7086503 [38:46<15:47, 3973.73it/s]读取数据:  47%|████▋     | 3319896/7086503 [38:46<15:42, 3995.87it/s]读取数据:  47%|████▋     | 3320298/7086503 [38:47<15:40, 4002.35it/s]读取数据:  47%|████▋     | 3320742/7086503 [38:47<15:11, 4132.47it/s]读取数据:  47%|████▋     | 3321162/7086503 [38:47<15:07, 4150.04it/s]读取数据:  47%|████▋     | 3321582/7086503 [38:47<15:04, 4160.82it/s]读取数据:  47%|████▋     | 3321999/7086503 [38:47<15:19, 4093.17it/s]读取数据:  47%|████▋     | 3322416/7086503 [38:47<15:14, 4115.24it/s]读取数据:  47%|████▋     | 3322852/7086503 [38:47<14:58, 4186.89it/s]读取数据:  47%|████▋     | 3323310/7086503 [38:47<14:34, 4302.97it/s]读取数据:  47%|████▋     | 3323744/7086503 [38:47<14:33, 4309.12it/s]读取数据:  47%|████▋     | 3324182/7086503 [38:47<14:29, 4324.81it/s]读取数据:  47%|████▋     | 3324618/7086503 [38:48<14:27, 4334.19it/s]读取数据:  47%|████▋     | 3325089/7086503 [38:48<14:06, 4444.69it/s]读取数据:  47%|████▋     | 3325567/7086503 [38:48<13:48, 4542.02it/s]读取数据:  47%|████▋     | 3326022/7086503 [38:48<13:53, 4510.92it/s]读取数据:  47%|████▋     | 3326481/7086503 [38:48<13:49, 4532.70it/s]读取数据:  47%|████▋     | 3326975/7086503 [38:48<13:28, 4649.43it/s]读取数据:  47%|████▋     | 3327441/7086503 [38:48<13:31, 4633.14it/s]读取数据:  47%|████▋     | 3327929/7086503 [38:48<13:18, 4705.42it/s]读取数据:  47%|████▋     | 3328400/7086503 [38:48<13:30, 4634.82it/s]读取数据:  47%|████▋     | 3328904/7086503 [38:48<13:10, 4754.60it/s]读取数据:  47%|████▋     | 3329387/7086503 [38:49<13:06, 4774.13it/s]读取数据:  47%|████▋     | 3329876/7086503 [38:49<13:01, 4804.46it/s]读取数据:  47%|████▋     | 3330357/7086503 [38:49<13:12, 4739.05it/s]读取数据:  47%|████▋     | 3330877/7086503 [38:49<12:50, 4873.28it/s]读取数据:  47%|████▋     | 3331372/7086503 [38:49<12:47, 4894.38it/s]读取数据:  47%|████▋     | 3331874/7086503 [38:49<12:41, 4930.57it/s]读取数据:  47%|████▋     | 3332369/7086503 [38:49<12:41, 4932.48it/s]读取数据:  47%|████▋     | 3332873/7086503 [38:49<12:36, 4964.10it/s]读取数据:  47%|████▋     | 3333411/7086503 [38:49<12:17, 5088.26it/s]读取数据:  47%|████▋     | 3333920/7086503 [38:49<13:15, 4714.65it/s]读取数据:  47%|████▋     | 3334423/7086503 [38:50<13:01, 4803.34it/s]读取数据:  47%|████▋     | 3334955/7086503 [38:50<12:37, 4951.58it/s]读取数据:  47%|████▋     | 3335479/7086503 [38:50<12:24, 5035.33it/s]读取数据:  47%|████▋     | 3336003/7086503 [38:50<12:16, 5094.73it/s]读取数据:  47%|████▋     | 3336522/7086503 [38:50<12:12, 5121.39it/s]读取数据:  47%|████▋     | 3337091/7086503 [38:50<11:49, 5287.20it/s]读取数据:  47%|████▋     | 3337644/7086503 [38:50<11:39, 5358.51it/s]读取数据:  47%|████▋     | 3338214/7086503 [38:50<11:26, 5457.58it/s]读取数据:  47%|████▋     | 3338761/7086503 [38:50<11:28, 5441.01it/s]读取数据:  47%|████▋     | 3339358/7086503 [38:50<11:09, 5598.58it/s]读取数据:  47%|████▋     | 3339933/7086503 [38:51<11:04, 5641.53it/s]读取数据:  47%|████▋     | 3340510/7086503 [38:51<10:59, 5679.84it/s]读取数据:  47%|████▋     | 3341126/7086503 [38:51<10:43, 5822.77it/s]读取数据:  47%|████▋     | 3341745/7086503 [38:51<10:31, 5930.19it/s]读取数据:  47%|████▋     | 3342375/7086503 [38:51<10:20, 6037.07it/s]读取数据:  47%|████▋     | 3342989/7086503 [38:51<10:17, 6065.72it/s]读取数据:  47%|████▋     | 3343652/7086503 [38:51<10:00, 6229.88it/s]读取数据:  47%|████▋     | 3344276/7086503 [38:51<10:01, 6218.51it/s]读取数据:  47%|████▋     | 3344914/7086503 [38:51<09:57, 6262.51it/s]读取数据:  47%|████▋     | 3345618/7086503 [38:51<09:36, 6489.85it/s]读取数据:  47%|████▋     | 3346293/7086503 [38:52<09:29, 6562.97it/s]读取数据:  47%|████▋     | 3346994/7086503 [38:52<09:18, 6691.32it/s]读取数据:  47%|████▋     | 3347698/7086503 [38:52<09:10, 6795.14it/s]读取数据:  47%|████▋     | 3348448/7086503 [38:52<08:53, 7006.10it/s]读取数据:  47%|████▋     | 3349186/7086503 [38:52<08:45, 7117.99it/s]读取数据:  47%|████▋     | 3349929/7086503 [38:52<08:38, 7209.47it/s]读取数据:  47%|████▋     | 3350650/7086503 [38:53<42:13, 1474.72it/s]读取数据:  47%|████▋     | 3351171/7086503 [38:54<38:17, 1625.50it/s]读取数据:  47%|████▋     | 3351608/7086503 [38:54<35:11, 1769.22it/s]读取数据:  47%|████▋     | 3351992/7086503 [38:54<32:41, 1904.21it/s]读取数据:  47%|████▋     | 3352339/7086503 [38:54<31:03, 2004.24it/s]读取数据:  47%|████▋     | 3352656/7086503 [38:54<29:21, 2119.17it/s]读取数据:  47%|████▋     | 3352958/7086503 [38:54<28:37, 2173.74it/s]读取数据:  47%|████▋     | 3353241/7086503 [38:55<27:36, 2253.07it/s]读取数据:  47%|████▋     | 3353516/7086503 [38:55<26:44, 2326.94it/s]读取数据:  47%|████▋     | 3353786/7086503 [38:55<25:54, 2401.67it/s]读取数据:  47%|████▋     | 3354064/7086503 [38:55<24:57, 2492.05it/s]读取数据:  47%|████▋     | 3354335/7086503 [38:55<24:26, 2545.48it/s]读取数据:  47%|████▋     | 3354606/7086503 [38:55<24:15, 2564.63it/s]读取数据:  47%|████▋     | 3354874/7086503 [38:55<23:59, 2591.66it/s]读取数据:  47%|████▋     | 3355142/7086503 [38:55<24:11, 2571.20it/s]读取数据:  47%|████▋     | 3355419/7086503 [38:55<23:40, 2626.71it/s]读取数据:  47%|████▋     | 3355716/7086503 [38:55<22:51, 2721.16it/s]读取数据:  47%|████▋     | 3355992/7086503 [38:56<23:01, 2701.20it/s]读取数据:  47%|████▋     | 3356271/7086503 [38:56<22:50, 2722.51it/s]读取数据:  47%|████▋     | 3356545/7086503 [38:56<23:15, 2672.03it/s]读取数据:  47%|████▋     | 3356828/7086503 [38:56<22:53, 2716.05it/s]读取数据:  47%|████▋     | 3357130/7086503 [38:56<22:10, 2802.26it/s]读取数据:  47%|████▋     | 3357427/7086503 [38:56<21:48, 2849.99it/s]读取数据:  47%|████▋     | 3357713/7086503 [38:56<21:58, 2828.73it/s]读取数据:  47%|████▋     | 3357997/7086503 [38:56<22:06, 2811.77it/s]读取数据:  47%|████▋     | 3358287/7086503 [38:56<21:54, 2836.76it/s]读取数据:  47%|████▋     | 3358571/7086503 [38:56<22:00, 2823.76it/s]读取数据:  47%|████▋     | 3358854/7086503 [38:57<22:00, 2823.02it/s]读取数据:  47%|████▋     | 3359137/7086503 [38:57<22:10, 2800.90it/s]读取数据:  47%|████▋     | 3359460/7086503 [38:57<21:13, 2925.62it/s]读取数据:  47%|████▋     | 3359768/7086503 [38:57<20:54, 2970.76it/s]读取数据:  47%|████▋     | 3360092/7086503 [38:57<20:22, 3047.29it/s]读取数据:  47%|████▋     | 3360397/7086503 [38:57<20:24, 3042.46it/s]读取数据:  47%|████▋     | 3360720/7086503 [38:57<20:03, 3095.57it/s]读取数据:  47%|████▋     | 3361030/7086503 [38:57<20:15, 3063.77it/s]读取数据:  47%|████▋     | 3361349/7086503 [38:57<20:02, 3097.80it/s]读取数据:  47%|████▋     | 3361680/7086503 [38:57<19:40, 3156.04it/s]读取数据:  47%|████▋     | 3362021/7086503 [38:58<19:12, 3230.87it/s]读取数据:  47%|████▋     | 3362355/7086503 [38:58<19:01, 3262.97it/s]读取数据:  47%|████▋     | 3362687/7086503 [38:58<18:56, 3276.60it/s]读取数据:  47%|████▋     | 3363015/7086503 [38:58<19:02, 3258.41it/s]读取数据:  47%|████▋     | 3363356/7086503 [38:58<18:47, 3300.81it/s]读取数据:  47%|████▋     | 3363710/7086503 [38:58<18:24, 3369.79it/s]读取数据:  47%|████▋     | 3364055/7086503 [38:58<18:17, 3392.21it/s]读取数据:  47%|████▋     | 3364432/7086503 [38:58<17:42, 3502.11it/s]读取数据:  47%|████▋     | 3364783/7086503 [38:58<17:46, 3489.49it/s]读取数据:  47%|████▋     | 3365137/7086503 [38:58<17:42, 3501.71it/s]读取数据:  47%|████▋     | 3365507/7086503 [38:59<17:26, 3556.38it/s]读取数据:  47%|████▋     | 3365879/7086503 [38:59<17:12, 3604.36it/s]读取数据:  48%|████▊     | 3366240/7086503 [38:59<17:20, 3576.10it/s]读取数据:  48%|████▊     | 3366598/7086503 [38:59<17:19, 3576.93it/s]读取数据:  48%|████▊     | 3366956/7086503 [38:59<17:26, 3553.42it/s]读取数据:  48%|████▊     | 3367350/7086503 [38:59<16:54, 3666.39it/s]读取数据:  48%|████▊     | 3367730/7086503 [38:59<16:43, 3705.76it/s]读取数据:  48%|████▊     | 3368115/7086503 [38:59<16:31, 3748.78it/s]读取数据:  48%|████▊     | 3368490/7086503 [38:59<16:47, 3688.57it/s]读取数据:  48%|████▊     | 3368884/7086503 [38:59<16:28, 3761.34it/s]读取数据:  48%|████▊     | 3369266/7086503 [39:00<16:25, 3773.12it/s]读取数据:  48%|████▊     | 3369654/7086503 [39:00<16:17, 3803.73it/s]读取数据:  48%|████▊     | 3370063/7086503 [39:00<15:55, 3888.51it/s]读取数据:  48%|████▊     | 3370471/7086503 [39:00<15:41, 3944.96it/s]读取数据:  48%|████▊     | 3370880/7086503 [39:00<15:32, 3985.61it/s]读取数据:  48%|████▊     | 3371279/7086503 [39:00<15:42, 3943.79it/s]读取数据:  48%|████▊     | 3371697/7086503 [39:00<15:26, 4009.82it/s]读取数据:  48%|████▊     | 3372106/7086503 [39:00<15:20, 4033.55it/s]读取数据:  48%|████▊     | 3372527/7086503 [39:00<15:09, 4083.43it/s]读取数据:  48%|████▊     | 3372936/7086503 [39:00<15:17, 4048.90it/s]读取数据:  48%|████▊     | 3373343/7086503 [39:01<15:16, 4049.72it/s]读取数据:  48%|████▊     | 3373749/7086503 [39:01<15:31, 3985.40it/s]读取数据:  48%|████▊     | 3374169/7086503 [39:01<15:17, 4045.27it/s]读取数据:  48%|████▊     | 3374615/7086503 [39:01<14:50, 4166.83it/s]读取数据:  48%|████▊     | 3375033/7086503 [39:01<14:54, 4150.88it/s]读取数据:  48%|████▊     | 3375468/7086503 [39:01<14:42, 4205.79it/s]读取数据:  48%|████▊     | 3375926/7086503 [39:01<14:19, 4315.95it/s]读取数据:  48%|████▊     | 3376372/7086503 [39:01<14:11, 4358.64it/s]读取数据:  48%|████▊     | 3376814/7086503 [39:01<14:07, 4375.83it/s]读取数据:  48%|████▊     | 3377266/7086503 [39:02<13:59, 4417.87it/s]读取数据:  48%|████▊     | 3377730/7086503 [39:02<13:47, 4484.25it/s]读取数据:  48%|████▊     | 3378187/7086503 [39:02<13:42, 4509.29it/s]读取数据:  48%|████▊     | 3378640/7086503 [39:02<13:41, 4514.12it/s]读取数据:  48%|████▊     | 3379098/7086503 [39:02<13:37, 4532.80it/s]读取数据:  48%|████▊     | 3379554/7086503 [39:02<13:36, 4538.01it/s]读取数据:  48%|████▊     | 3380018/7086503 [39:02<13:31, 4565.22it/s]读取数据:  48%|████▊     | 3380482/7086503 [39:02<13:27, 4587.49it/s]读取数据:  48%|████▊     | 3380968/7086503 [39:02<13:14, 4665.91it/s]读取数据:  48%|████▊     | 3381437/7086503 [39:02<13:12, 4673.03it/s]读取数据:  48%|████▊     | 3381934/7086503 [39:03<12:58, 4759.45it/s]读取数据:  48%|████▊     | 3382417/7086503 [39:03<12:55, 4777.99it/s]读取数据:  48%|████▊     | 3382952/7086503 [39:03<12:28, 4947.81it/s]读取数据:  48%|████▊     | 3383447/7086503 [39:03<12:29, 4940.23it/s]读取数据:  48%|████▊     | 3383942/7086503 [39:03<12:29, 4942.19it/s]读取数据:  48%|████▊     | 3384462/7086503 [39:03<12:17, 5017.45it/s]读取数据:  48%|████▊     | 3384987/7086503 [39:03<12:08, 5083.11it/s]读取数据:  48%|████▊     | 3385498/7086503 [39:03<12:06, 5090.92it/s]读取数据:  48%|████▊     | 3386028/7086503 [39:03<11:58, 5150.17it/s]读取数据:  48%|████▊     | 3386585/7086503 [39:03<11:41, 5274.45it/s]读取数据:  48%|████▊     | 3387127/7086503 [39:04<11:35, 5316.67it/s]读取数据:  48%|████▊     | 3387671/7086503 [39:04<11:31, 5350.62it/s]读取数据:  48%|████▊     | 3388236/7086503 [39:04<11:20, 5438.22it/s]读取数据:  48%|████▊     | 3388788/7086503 [39:04<11:17, 5460.89it/s]读取数据:  48%|████▊     | 3389342/7086503 [39:04<11:14, 5483.41it/s]读取数据:  48%|████▊     | 3389923/7086503 [39:04<11:02, 5579.04it/s]读取数据:  48%|████▊     | 3390546/7086503 [39:04<10:40, 5771.80it/s]读取数据:  48%|████▊     | 3391168/7086503 [39:04<10:26, 5902.26it/s]读取数据:  48%|████▊     | 3391759/7086503 [39:04<10:25, 5904.19it/s]读取数据:  48%|████▊     | 3392398/7086503 [39:04<10:10, 6047.77it/s]读取数据:  48%|████▊     | 3393044/7086503 [39:05<09:58, 6170.80it/s]读取数据:  48%|████▊     | 3393690/7086503 [39:05<09:50, 6256.23it/s]读取数据:  48%|████▊     | 3394337/7086503 [39:05<09:44, 6319.25it/s]读取数据:  48%|████▊     | 3395042/7086503 [39:05<09:24, 6537.50it/s]读取数据:  48%|████▊     | 3395725/7086503 [39:05<09:17, 6623.10it/s]读取数据:  48%|████▊     | 3396404/7086503 [39:05<09:14, 6659.95it/s]读取数据:  48%|████▊     | 3397124/7086503 [39:05<09:00, 6820.47it/s]读取数据:  48%|████▊     | 3397846/7086503 [39:05<08:51, 6939.30it/s]读取数据:  48%|████▊     | 3398630/7086503 [39:05<08:31, 7207.95it/s]读取数据:  48%|████▊     | 3399351/7086503 [39:05<08:34, 7166.70it/s]读取数据:  48%|████▊     | 3400068/7086503 [39:07<37:03, 1657.80it/s]读取数据:  48%|████▊     | 3400588/7086503 [39:07<33:59, 1807.58it/s]读取数据:  48%|████▊     | 3401029/7086503 [39:07<31:51, 1927.73it/s]读取数据:  48%|████▊     | 3401413/7086503 [39:07<30:12, 2033.61it/s]读取数据:  48%|████▊     | 3401758/7086503 [39:07<29:43, 2066.31it/s]读取数据:  48%|████▊     | 3402065/7086503 [39:07<29:12, 2101.82it/s]读取数据:  48%|████▊     | 3402348/7086503 [39:08<27:59, 2193.07it/s]读取数据:  48%|████▊     | 3402624/7086503 [39:08<26:52, 2285.20it/s]读取数据:  48%|████▊     | 3402896/7086503 [39:08<26:14, 2339.95it/s]读取数据:  48%|████▊     | 3403162/7086503 [39:08<26:57, 2276.63it/s]读取数据:  48%|████▊     | 3403412/7086503 [39:08<27:14, 2253.68it/s]读取数据:  48%|████▊     | 3403674/7086503 [39:08<26:11, 2343.33it/s]读取数据:  48%|████▊     | 3403958/7086503 [39:08<24:49, 2473.06it/s]读取数据:  48%|████▊     | 3404217/7086503 [39:08<24:30, 2504.51it/s]读取数据:  48%|████▊     | 3404499/7086503 [39:08<23:42, 2588.99it/s]读取数据:  48%|████▊     | 3404794/7086503 [39:09<22:48, 2690.73it/s]读取数据:  48%|████▊     | 3405074/7086503 [39:09<22:32, 2722.28it/s]读取数据:  48%|████▊     | 3405366/7086503 [39:09<22:06, 2774.69it/s]读取数据:  48%|████▊     | 3405646/7086503 [39:09<22:07, 2771.84it/s]读取数据:  48%|████▊     | 3405925/7086503 [39:09<22:09, 2768.21it/s]读取数据:  48%|████▊     | 3406219/7086503 [39:09<21:45, 2818.98it/s]读取数据:  48%|████▊     | 3406502/7086503 [39:09<21:50, 2808.80it/s]读取数据:  48%|████▊     | 3406833/7086503 [39:09<20:45, 2954.09it/s]读取数据:  48%|████▊     | 3407129/7086503 [39:09<20:50, 2941.22it/s]读取数据:  48%|████▊     | 3407433/7086503 [39:09<20:38, 2970.52it/s]读取数据:  48%|████▊     | 3407731/7086503 [39:10<20:42, 2959.93it/s]读取数据:  48%|████▊     | 3408039/7086503 [39:10<20:28, 2995.08it/s]读取数据:  48%|████▊     | 3408360/7086503 [39:10<20:03, 3056.74it/s]读取数据:  48%|████▊     | 3408674/7086503 [39:10<19:54, 3079.38it/s]读取数据:  48%|████▊     | 3409012/7086503 [39:10<19:20, 3168.13it/s]读取数据:  48%|████▊     | 3409329/7086503 [39:10<19:40, 3114.52it/s]读取数据:  48%|████▊     | 3409641/7086503 [39:10<19:41, 3111.76it/s]读取数据:  48%|████▊     | 3409962/7086503 [39:10<19:31, 3138.85it/s]读取数据:  48%|████▊     | 3410284/7086503 [39:10<19:23, 3158.84it/s]读取数据:  48%|████▊     | 3410642/7086503 [39:10<18:41, 3279.06it/s]读取数据:  48%|████▊     | 3410986/7086503 [39:11<18:25, 3324.43it/s]读取数据:  48%|████▊     | 3411327/7086503 [39:11<18:18, 3345.48it/s]读取数据:  48%|████▊     | 3411681/7086503 [39:11<17:59, 3403.23it/s]读取数据:  48%|████▊     | 3412022/7086503 [39:11<18:02, 3393.27it/s]读取数据:  48%|████▊     | 3412362/7086503 [39:11<18:16, 3350.56it/s]读取数据:  48%|████▊     | 3412737/7086503 [39:11<17:40, 3463.79it/s]读取数据:  48%|████▊     | 3413087/7086503 [39:11<17:37, 3474.41it/s]读取数据:  48%|████▊     | 3413462/7086503 [39:11<17:14, 3552.12it/s]读取数据:  48%|████▊     | 3413828/7086503 [39:11<17:04, 3584.17it/s]读取数据:  48%|████▊     | 3414195/7086503 [39:11<16:57, 3608.94it/s]读取数据:  48%|████▊     | 3414556/7086503 [39:12<17:03, 3588.44it/s]读取数据:  48%|████▊     | 3414931/7086503 [39:12<16:50, 3633.82it/s]读取数据:  48%|████▊     | 3415310/7086503 [39:12<16:38, 3677.56it/s]读取数据:  48%|████▊     | 3415702/7086503 [39:12<16:19, 3748.71it/s]读取数据:  48%|████▊     | 3416077/7086503 [39:12<16:42, 3662.16it/s]读取数据:  48%|████▊     | 3416454/7086503 [39:12<16:33, 3693.84it/s]读取数据:  48%|████▊     | 3416825/7086503 [39:12<16:33, 3694.99it/s]读取数据:  48%|████▊     | 3417231/7086503 [39:12<16:05, 3802.32it/s]读取数据:  48%|████▊     | 3417622/7086503 [39:12<15:58, 3828.42it/s]读取数据:  48%|████▊     | 3418006/7086503 [39:12<16:14, 3763.96it/s]读取数据:  48%|████▊     | 3418421/7086503 [39:13<15:46, 3874.18it/s]读取数据:  48%|████▊     | 3418822/7086503 [39:13<15:37, 3913.99it/s]读取数据:  48%|████▊     | 3419224/7086503 [39:13<15:29, 3944.39it/s]读取数据:  48%|████▊     | 3419619/7086503 [39:13<15:55, 3836.38it/s]读取数据:  48%|████▊     | 3420022/7086503 [39:13<15:42, 3891.66it/s]读取数据:  48%|████▊     | 3420412/7086503 [39:13<15:54, 3840.24it/s]读取数据:  48%|████▊     | 3420821/7086503 [39:13<15:37, 3909.56it/s]读取数据:  48%|████▊     | 3421235/7086503 [39:13<15:21, 3976.80it/s]读取数据:  48%|████▊     | 3421654/7086503 [39:13<15:07, 4037.89it/s]读取数据:  48%|████▊     | 3422083/7086503 [39:13<14:51, 4112.42it/s]读取数据:  48%|████▊     | 3422495/7086503 [39:14<14:54, 4094.54it/s]读取数据:  48%|████▊     | 3422914/7086503 [39:14<14:48, 4122.11it/s]读取数据:  48%|████▊     | 3423358/7086503 [39:14<14:29, 4213.99it/s]读取数据:  48%|████▊     | 3423792/7086503 [39:14<14:21, 4251.29it/s]读取数据:  48%|████▊     | 3424225/7086503 [39:14<14:16, 4273.81it/s]读取数据:  48%|████▊     | 3424668/7086503 [39:14<14:08, 4316.82it/s]读取数据:  48%|████▊     | 3425110/7086503 [39:14<14:02, 4346.04it/s]读取数据:  48%|████▊     | 3425561/7086503 [39:14<13:53, 4393.53it/s]读取数据:  48%|████▊     | 3426023/7086503 [39:14<13:40, 4460.70it/s]读取数据:  48%|████▊     | 3426470/7086503 [39:14<13:40, 4462.89it/s]读取数据:  48%|████▊     | 3426935/7086503 [39:15<13:29, 4518.62it/s]读取数据:  48%|████▊     | 3427429/7086503 [39:15<13:07, 4644.15it/s]读取数据:  48%|████▊     | 3427904/7086503 [39:15<13:03, 4671.91it/s]读取数据:  48%|████▊     | 3428372/7086503 [39:15<13:10, 4625.80it/s]读取数据:  48%|████▊     | 3428862/7086503 [39:15<12:57, 4706.77it/s]读取数据:  48%|████▊     | 3429350/7086503 [39:15<12:48, 4756.78it/s]读取数据:  48%|████▊     | 3429826/7086503 [39:15<12:53, 4729.96it/s]读取数据:  48%|████▊     | 3430326/7086503 [39:15<12:40, 4809.71it/s]读取数据:  48%|████▊     | 3430808/7086503 [39:15<13:00, 4680.95it/s]读取数据:  48%|████▊     | 3431324/7086503 [39:15<12:38, 4819.53it/s]读取数据:  48%|████▊     | 3431815/7086503 [39:16<12:34, 4845.96it/s]读取数据:  48%|████▊     | 3432325/7086503 [39:16<12:23, 4918.12it/s]读取数据:  48%|████▊     | 3432818/7086503 [39:16<12:30, 4865.11it/s]读取数据:  48%|████▊     | 3433358/7086503 [39:16<12:07, 5023.19it/s]读取数据:  48%|████▊     | 3433902/7086503 [39:16<11:50, 5143.02it/s]读取数据:  48%|████▊     | 3435979/7086503 [39:16<06:12, 9795.54it/s]读取数据:  49%|████▊     | 3438807/7086503 [39:16<03:58, 15310.29it/s]读取数据:  49%|████▊     | 3441463/7086503 [39:16<03:15, 18668.56it/s]读取数据:  49%|████▊     | 3444571/7086503 [39:16<02:42, 22379.78it/s]读取数据:  49%|████▊     | 3447767/7086503 [39:16<02:24, 25247.30it/s]读取数据:  49%|████▊     | 3450296/7086503 [39:18<11:00, 5504.46it/s] 读取数据:  49%|████▊     | 3452816/7086503 [39:18<08:25, 7184.46it/s]读取数据:  49%|████▉     | 3455701/7086503 [39:18<06:20, 9537.76it/s]读取数据:  49%|████▉     | 3458761/7086503 [39:18<04:53, 12366.74it/s]读取数据:  49%|████▉     | 3461903/7086503 [39:18<03:54, 15433.49it/s]读取数据:  49%|████▉     | 3464823/7086503 [39:18<03:21, 18007.12it/s]读取数据:  49%|████▉     | 3467761/7086503 [39:18<02:57, 20404.20it/s]读取数据:  49%|████▉     | 3470851/7086503 [39:18<02:38, 22831.79it/s]读取数据:  49%|████▉     | 3473982/7086503 [39:19<02:24, 24937.67it/s]读取数据:  49%|████▉     | 3477119/7086503 [39:19<02:15, 26621.22it/s]读取数据:  49%|████▉     | 3480377/7086503 [39:19<02:07, 28243.49it/s]读取数据:  49%|████▉     | 3483660/7086503 [39:19<02:02, 29527.51it/s]读取数据:  49%|████▉     | 3487014/7086503 [39:19<01:57, 30672.90it/s]读取数据:  49%|████▉     | 3490225/7086503 [39:19<01:59, 30079.54it/s]读取数据:  49%|████▉     | 3493336/7086503 [39:19<02:00, 29932.25it/s]读取数据:  49%|████▉     | 3496401/7086503 [39:19<02:00, 29835.36it/s]读取数据:  49%|████▉     | 3499450/7086503 [39:19<01:59, 30021.70it/s]读取数据:  49%|████▉     | 3499450/7086503 [39:35<01:59, 30021.70it/s]读取数据:  49%|████▉     | 3500000/7086503 [45:40<48:31:21, 20.53it/s]读取数据:  49%|████▉     | 3503079/7086503 [45:41<31:03:06, 32.06it/s]读取数据:  49%|████▉     | 3506226/7086503 [45:41<20:21:04, 48.87it/s]读取数据:  50%|████▉     | 3509382/7086503 [45:41<13:37:33, 72.92it/s]读取数据:  50%|████▉     | 3512572/7086503 [45:41<9:13:37, 107.59it/s]读取数据:  50%|████▉     | 3515822/7086503 [45:41<6:16:50, 157.92it/s]读取数据:  50%|████▉     | 3519114/7086503 [45:41<4:17:57, 230.48it/s]读取数据:  50%|████▉     | 3522403/7086503 [45:41<2:58:07, 333.49it/s]读取数据:  50%|████▉     | 3525717/7086503 [45:41<2:03:28, 480.64it/s]读取数据:  50%|████▉     | 3529026/7086503 [45:41<1:26:08, 688.27it/s]读取数据:  50%|████▉     | 3532366/7086503 [45:41<1:00:15, 983.12it/s]读取数据:  50%|████▉     | 3535700/7086503 [45:42<42:26, 1394.47it/s] 读取数据:  50%|████▉     | 3539012/7086503 [45:42<30:09, 1960.37it/s]读取数据:  50%|████▉     | 3542351/7086503 [45:42<21:32, 2741.32it/s]读取数据:  50%|█████     | 3545667/7086503 [45:42<15:38, 3773.28it/s]读取数据:  50%|█████     | 3548906/7086503 [45:42<11:33, 5097.53it/s]读取数据:  50%|█████     | 3552113/7086503 [45:42<11:00, 5349.90it/s]读取数据:  50%|█████     | 3555358/7086503 [45:43<08:15, 7128.08it/s]读取数据:  50%|█████     | 3558545/7086503 [45:43<06:21, 9248.04it/s]读取数据:  50%|█████     | 3561799/7086503 [45:43<04:58, 11788.42it/s]读取数据:  50%|█████     | 3565071/7086503 [45:43<04:01, 14609.65it/s]读取数据:  50%|█████     | 3568353/7086503 [45:43<03:20, 17549.11it/s]读取数据:  50%|█████     | 3571628/7086503 [45:43<02:52, 20396.91it/s]读取数据:  50%|█████     | 3574873/7086503 [45:43<02:33, 22941.14it/s]读取数据:  50%|█████     | 3578202/7086503 [45:43<02:18, 25336.68it/s]读取数据:  51%|█████     | 3581586/7086503 [45:43<02:07, 27451.33it/s]读取数据:  51%|█████     | 3584915/7086503 [45:43<02:00, 28980.24it/s]读取数据:  51%|█████     | 3588423/7086503 [45:44<01:54, 30640.99it/s]读取数据:  51%|█████     | 3591870/7086503 [45:44<01:50, 31712.79it/s]读取数据:  51%|█████     | 3595289/7086503 [45:44<01:47, 32419.80it/s]读取数据:  51%|█████     | 3598824/7086503 [45:44<01:44, 33268.68it/s]读取数据:  51%|█████     | 3602261/7086503 [45:44<04:01, 14426.95it/s]读取数据:  51%|█████     | 3605650/7086503 [45:45<03:20, 17391.45it/s]读取数据:  51%|█████     | 3609184/7086503 [45:45<02:48, 20598.61it/s]读取数据:  51%|█████     | 3612741/7086503 [45:45<02:26, 23643.14it/s]读取数据:  51%|█████     | 3616280/7086503 [45:45<02:12, 26287.12it/s]读取数据:  51%|█████     | 3619700/7086503 [45:45<02:02, 28210.73it/s]读取数据:  51%|█████     | 3623184/7086503 [45:45<01:55, 29919.75it/s]读取数据:  51%|█████     | 3626646/7086503 [45:45<01:50, 31184.74it/s]读取数据:  51%|█████     | 3630089/7086503 [45:45<01:47, 32084.88it/s]读取数据:  51%|█████▏    | 3633607/7086503 [45:45<01:44, 32962.08it/s]读取数据:  51%|█████▏    | 3637054/7086503 [45:45<01:43, 33381.40it/s]读取数据:  51%|█████▏    | 3640519/7086503 [45:46<01:42, 33750.94it/s]读取数据:  51%|█████▏    | 3643970/7086503 [45:46<01:41, 33816.04it/s]读取数据:  51%|█████▏    | 3647405/7086503 [45:46<01:41, 33911.65it/s]读取数据:  52%|█████▏    | 3650834/7086503 [45:46<03:52, 14800.60it/s]读取数据:  52%|█████▏    | 3654227/7086503 [45:46<03:13, 17773.34it/s]读取数据:  52%|█████▏    | 3657654/7086503 [45:46<02:45, 20769.82it/s]读取数据:  52%|█████▏    | 3661046/7086503 [45:47<02:25, 23478.69it/s]读取数据:  52%|█████▏    | 3664401/7086503 [45:47<02:12, 25766.56it/s]读取数据:  52%|█████▏    | 3667742/7086503 [45:47<02:03, 27640.35it/s]读取数据:  52%|█████▏    | 3671103/7086503 [45:47<01:57, 29188.40it/s]读取数据:  52%|█████▏    | 3674398/7086503 [45:47<01:52, 30203.99it/s]读取数据:  52%|█████▏    | 3677736/7086503 [45:47<01:49, 31086.93it/s]读取数据:  52%|█████▏    | 3681034/7086503 [45:47<01:47, 31591.17it/s]读取数据:  52%|█████▏    | 3684328/7086503 [45:47<01:48, 31476.20it/s]读取数据:  52%|█████▏    | 3687570/7086503 [45:47<01:48, 31390.87it/s]读取数据:  52%|█████▏    | 3690776/7086503 [45:47<01:48, 31296.58it/s]读取数据:  52%|█████▏    | 3693952/7086503 [45:48<01:48, 31247.55it/s]读取数据:  52%|█████▏    | 3697109/7086503 [45:48<01:48, 31180.18it/s]读取数据:  52%|█████▏    | 3700250/7086503 [45:48<04:04, 13875.62it/s]读取数据:  52%|█████▏    | 3703409/7086503 [45:48<03:23, 16655.70it/s]读取数据:  52%|█████▏    | 3706483/7086503 [45:48<02:55, 19234.44it/s]读取数据:  52%|█████▏    | 3709539/7086503 [45:49<02:36, 21582.90it/s]读取数据:  52%|█████▏    | 3712680/7086503 [45:49<02:21, 23826.32it/s]读取数据:  52%|█████▏    | 3715795/7086503 [45:49<02:11, 25627.51it/s]读取数据:  52%|█████▏    | 3718868/7086503 [45:49<02:04, 26954.33it/s]读取数据:  53%|█████▎    | 3721881/7086503 [45:49<02:04, 26953.71it/s]读取数据:  53%|█████▎    | 3724835/7086503 [45:49<02:01, 27656.75it/s]读取数据:  53%|█████▎    | 3727873/7086503 [45:49<01:58, 28419.75it/s]读取数据:  53%|█████▎    | 3730883/7086503 [45:49<01:56, 28895.61it/s]读取数据:  53%|█████▎    | 3734008/7086503 [45:49<01:53, 29577.45it/s]读取数据:  53%|█████▎    | 3737046/7086503 [45:49<01:52, 29806.16it/s]读取数据:  53%|█████▎    | 3740200/7086503 [45:50<01:50, 30316.35it/s]读取数据:  53%|█████▎    | 3743313/7086503 [45:50<01:49, 30557.29it/s]读取数据:  53%|█████▎    | 3746465/7086503 [45:50<01:48, 30841.39it/s]读取数据:  53%|█████▎    | 3749566/7086503 [45:50<01:48, 30692.02it/s]读取数据:  53%|█████▎    | 3752647/7086503 [45:50<04:17, 12954.40it/s]读取数据:  53%|█████▎    | 3755757/7086503 [45:51<03:32, 15710.09it/s]读取数据:  53%|█████▎    | 3758882/7086503 [45:51<03:00, 18480.18it/s]读取数据:  53%|█████▎    | 3762004/7086503 [45:51<02:37, 21065.91it/s]读取数据:  53%|█████▎    | 3765135/7086503 [45:51<02:22, 23367.07it/s]读取数据:  53%|█████▎    | 3768066/7086503 [45:51<02:20, 23562.28it/s]读取数据:  53%|█████▎    | 3771131/7086503 [45:51<02:10, 25318.87it/s]读取数据:  53%|█████▎    | 3774165/7086503 [45:51<02:04, 26627.41it/s]读取数据:  53%|█████▎    | 3777248/7086503 [45:51<01:59, 27769.34it/s]读取数据:  53%|█████▎    | 3780296/7086503 [45:51<01:55, 28526.55it/s]读取数据:  53%|█████▎    | 3783333/7086503 [45:51<01:53, 29049.11it/s]读取数据:  53%|█████▎    | 3786464/7086503 [45:52<01:51, 29703.75it/s]读取数据:  53%|█████▎    | 3789506/7086503 [45:52<01:58, 27845.13it/s]读取数据:  54%|█████▎    | 3792521/7086503 [45:52<01:55, 28490.16it/s]读取数据:  54%|█████▎    | 3795533/7086503 [45:52<01:53, 28955.54it/s]读取数据:  54%|█████▎    | 3798548/7086503 [45:52<01:52, 29301.38it/s]读取数据:  54%|█████▎    | 3801508/7086503 [45:52<04:19, 12673.10it/s]读取数据:  54%|█████▎    | 3804531/7086503 [45:53<03:33, 15356.51it/s]读取数据:  54%|█████▎    | 3807526/7086503 [45:53<03:02, 17970.92it/s]读取数据:  54%|█████▍    | 3810465/7086503 [45:53<02:41, 20297.38it/s]读取数据:  54%|█████▍    | 3813439/7086503 [45:53<02:25, 22425.56it/s]读取数据:  54%|█████▍    | 3816468/7086503 [45:53<02:14, 24340.68it/s]读取数据:  54%|█████▍    | 3819395/7086503 [45:53<02:07, 25612.56it/s]读取数据:  54%|█████▍    | 3822366/7086503 [45:53<02:02, 26714.70it/s]读取数据:  54%|█████▍    | 3825276/7086503 [45:53<01:59, 27353.56it/s]读取数据:  54%|█████▍    | 3828184/7086503 [45:53<01:57, 27689.92it/s]读取数据:  54%|█████▍    | 3831075/7086503 [45:54<01:56, 27916.18it/s]读取数据:  54%|█████▍    | 3833962/7086503 [45:54<01:55, 28190.55it/s]读取数据:  54%|█████▍    | 3836843/7086503 [45:54<01:54, 28324.48it/s]读取数据:  54%|█████▍    | 3839719/7086503 [45:54<01:54, 28237.67it/s]读取数据:  54%|█████▍    | 3842573/7086503 [45:54<02:03, 26209.56it/s]读取数据:  54%|█████▍    | 3845382/7086503 [45:54<02:01, 26733.72it/s]读取数据:  54%|█████▍    | 3848134/7086503 [45:54<02:00, 26956.88it/s]读取数据:  54%|█████▍    | 3850858/7086503 [45:55<04:45, 11353.06it/s]读取数据:  54%|█████▍    | 3853442/7086503 [45:55<03:59, 13498.79it/s]读取数据:  54%|█████▍    | 3856030/7086503 [45:55<03:26, 15661.17it/s]读取数据:  54%|█████▍    | 3858614/7086503 [45:55<03:02, 17693.44it/s]读取数据:  54%|█████▍    | 3861177/7086503 [45:55<02:45, 19452.73it/s]读取数据:  55%|█████▍    | 3863763/7086503 [45:55<02:33, 20993.66it/s]读取数据:  55%|█████▍    | 3866370/7086503 [45:55<02:24, 22289.87it/s]读取数据:  55%|█████▍    | 3868895/7086503 [45:55<02:20, 22958.53it/s]读取数据:  55%|█████▍    | 3871449/7086503 [45:56<02:15, 23667.87it/s]读取数据:  55%|█████▍    | 3873972/7086503 [45:56<02:13, 24019.70it/s]读取数据:  55%|█████▍    | 3876486/7086503 [45:56<02:14, 23854.39it/s]读取数据:  55%|█████▍    | 3878950/7086503 [45:56<02:15, 23703.64it/s]读取数据:  55%|█████▍    | 3881375/7086503 [45:56<02:16, 23418.77it/s]读取数据:  55%|█████▍    | 3883755/7086503 [45:56<02:18, 23081.88it/s]读取数据:  55%|█████▍    | 3886090/7086503 [45:56<02:19, 22906.31it/s]读取数据:  55%|█████▍    | 3888400/7086503 [45:56<02:22, 22453.71it/s]读取数据:  55%|█████▍    | 3890659/7086503 [45:56<02:23, 22310.74it/s]读取数据:  55%|█████▍    | 3892900/7086503 [45:56<02:25, 21972.69it/s]读取数据:  55%|█████▍    | 3895104/7086503 [45:57<02:28, 21535.27it/s]读取数据:  55%|█████▍    | 3897263/7086503 [45:57<02:30, 21233.14it/s]读取数据:  55%|█████▌    | 3899390/7086503 [45:57<02:32, 20844.31it/s]读取数据:  55%|█████▌    | 3901478/7086503 [45:58<09:24, 5637.52it/s] 读取数据:  55%|█████▌    | 3903716/7086503 [45:58<07:15, 7312.04it/s]读取数据:  55%|█████▌    | 3905891/7086503 [45:58<05:48, 9116.52it/s]读取数据:  55%|█████▌    | 3907998/7086503 [45:58<04:50, 10927.89it/s]读取数据:  55%|█████▌    | 3910263/7086503 [45:58<04:04, 13013.68it/s]读取数据:  55%|█████▌    | 3912367/7086503 [45:58<03:36, 14638.76it/s]读取数据:  55%|█████▌    | 3914626/7086503 [45:58<03:13, 16423.78it/s]读取数据:  55%|█████▌    | 3916801/7086503 [45:59<02:58, 17712.71it/s]读取数据:  55%|█████▌    | 3919044/7086503 [45:59<02:47, 18921.39it/s]读取数据:  55%|█████▌    | 3921216/7086503 [45:59<02:40, 19669.18it/s]读取数据:  55%|█████▌    | 3923384/7086503 [45:59<02:36, 20190.65it/s]读取数据:  55%|█████▌    | 3925557/7086503 [45:59<02:33, 20626.29it/s]读取数据:  55%|█████▌    | 3927757/7086503 [45:59<02:30, 21021.72it/s]读取数据:  55%|█████▌    | 3929934/7086503 [45:59<02:30, 21023.31it/s]读取数据:  55%|█████▌    | 3932203/7086503 [45:59<02:26, 21507.61it/s]读取数据:  56%|█████▌    | 3934392/7086503 [45:59<02:26, 21562.93it/s]读取数据:  56%|█████▌    | 3936590/7086503 [45:59<02:25, 21684.06it/s]读取数据:  56%|█████▌    | 3938794/7086503 [46:00<02:24, 21787.19it/s]读取数据:  56%|█████▌    | 3940986/7086503 [46:00<02:24, 21719.56it/s]读取数据:  56%|█████▌    | 3943227/7086503 [46:00<02:23, 21922.87it/s]读取数据:  56%|█████▌    | 3945426/7086503 [46:00<02:24, 21758.28it/s]读取数据:  56%|█████▌    | 3947635/7086503 [46:00<02:23, 21855.65it/s]读取数据:  56%|█████▌    | 3949825/7086503 [46:00<02:23, 21823.96it/s]读取数据:  56%|█████▌    | 3952010/7086503 [46:01<05:34, 9364.37it/s] 读取数据:  56%|█████▌    | 3954128/7086503 [46:01<04:39, 11188.74it/s]读取数据:  56%|█████▌    | 3956356/7086503 [46:01<03:57, 13191.03it/s]读取数据:  56%|█████▌    | 3958556/7086503 [46:01<03:28, 14997.07it/s]读取数据:  56%|█████▌    | 3960759/7086503 [46:01<03:08, 16590.64it/s]读取数据:  56%|█████▌    | 3962823/7086503 [46:01<02:58, 17523.65it/s]读取数据:  56%|█████▌    | 3965123/7086503 [46:01<02:44, 18933.86it/s]读取数据:  56%|█████▌    | 3967281/7086503 [46:01<02:38, 19646.37it/s]读取数据:  56%|█████▌    | 3969474/7086503 [46:01<02:33, 20279.68it/s]读取数据:  56%|█████▌    | 3971981/7086503 [46:01<02:23, 21640.27it/s]读取数据:  56%|█████▌    | 3974722/7086503 [46:02<02:13, 23302.92it/s]读取数据:  56%|█████▌    | 3977248/7086503 [46:02<02:10, 23873.30it/s]读取数据:  56%|█████▌    | 3979853/7086503 [46:02<02:06, 24511.77it/s]读取数据:  56%|█████▌    | 3982594/7086503 [46:02<02:02, 25368.30it/s]读取数据:  56%|█████▌    | 3985160/7086503 [46:02<02:01, 25453.23it/s]读取数据:  56%|█████▋    | 3987838/7086503 [46:02<01:59, 25847.41it/s]读取数据:  56%|█████▋    | 3990591/7086503 [46:02<01:57, 26341.41it/s]读取数据:  56%|█████▋    | 3993270/7086503 [46:02<01:56, 26472.45it/s]读取数据:  56%|█████▋    | 3995925/7086503 [46:02<01:57, 26207.70it/s]读取数据:  56%|█████▋    | 3998552/7086503 [46:02<01:59, 25789.00it/s]读取数据:  56%|█████▋    | 3998552/7086503 [46:15<01:59, 25789.00it/s]读取数据:  56%|█████▋    | 4000000/7086503 [53:18<48:57:15, 17.51it/s]读取数据:  56%|█████▋    | 4001213/7086503 [53:18<39:53:13, 21.49it/s]读取数据:  56%|█████▋    | 4003654/7086503 [53:18<26:01:19, 32.91it/s]读取数据:  57%|█████▋    | 4006919/7086503 [53:18<15:38:02, 54.72it/s]读取数据:  57%|█████▋    | 4010496/7086503 [53:18<9:37:20, 88.80it/s] 读取数据:  57%|█████▋    | 4013358/7086503 [53:18<6:41:20, 127.62it/s]读取数据:  57%|█████▋    | 4016146/7086503 [53:18<4:41:59, 181.47it/s]读取数据:  57%|█████▋    | 4018909/7086503 [53:18<3:18:41, 257.31it/s]读取数据:  57%|█████▋    | 4021623/7086503 [53:18<2:20:44, 362.96it/s]读取数据:  57%|█████▋    | 4024287/7086503 [53:19<1:40:07, 509.70it/s]读取数据:  57%|█████▋    | 4026939/7086503 [53:19<1:11:23, 714.22it/s]读取数据:  57%|█████▋    | 4029644/7086503 [53:19<50:32, 1008.15it/s] 读取数据:  57%|█████▋    | 4032226/7086503 [53:19<36:25, 1397.55it/s]读取数据:  57%|█████▋    | 4034963/7086503 [53:19<25:51, 1967.08it/s]读取数据:  57%|█████▋    | 4037579/7086503 [53:19<18:50, 2697.02it/s]读取数据:  57%|█████▋    | 4040204/7086503 [53:19<13:48, 3674.78it/s]读取数据:  57%|█████▋    | 4042792/7086503 [53:19<10:19, 4913.09it/s]读取数据:  57%|█████▋    | 4045387/7086503 [53:19<07:50, 6469.50it/s]读取数据:  57%|█████▋    | 4047968/7086503 [53:20<06:13, 8125.49it/s]读取数据:  57%|█████▋    | 4050395/7086503 [53:20<08:30, 5947.70it/s]读取数据:  57%|█████▋    | 4052201/7086503 [53:20<07:16, 6951.47it/s]读取数据:  57%|█████▋    | 4053936/7086503 [53:20<06:15, 8075.85it/s]读取数据:  57%|█████▋    | 4055642/7086503 [53:21<05:27, 9240.53it/s]读取数据:  57%|█████▋    | 4057373/7086503 [53:21<04:46, 10563.68it/s]读取数据:  57%|█████▋    | 4060044/7086503 [53:21<03:42, 13627.56it/s]读取数据:  57%|█████▋    | 4062811/7086503 [53:21<03:01, 16620.03it/s]读取数据:  57%|█████▋    | 4065031/7086503 [53:21<02:52, 17560.76it/s]读取数据:  57%|█████▋    | 4067496/7086503 [53:21<02:36, 19306.24it/s]读取数据:  57%|█████▋    | 4070185/7086503 [53:21<02:21, 21279.84it/s]读取数据:  57%|█████▋    | 4073424/7086503 [53:21<02:04, 24290.31it/s]读取数据:  58%|█████▊    | 4076834/7086503 [53:21<01:51, 27024.14it/s]读取数据:  58%|█████▊    | 4079706/7086503 [53:21<01:52, 26816.95it/s]读取数据:  58%|█████▊    | 4082507/7086503 [53:22<01:52, 26721.23it/s]读取数据:  58%|█████▊    | 4085268/7086503 [53:22<01:51, 26974.42it/s]读取数据:  58%|█████▊    | 4088086/7086503 [53:22<01:49, 27319.70it/s]读取数据:  58%|█████▊    | 4090861/7086503 [53:22<01:50, 27109.94it/s]读取数据:  58%|█████▊    | 4093687/7086503 [53:22<01:49, 27444.52it/s]读取数据:  58%|█████▊    | 4096454/7086503 [53:22<01:50, 27131.31it/s]读取数据:  58%|█████▊    | 4099183/7086503 [53:22<01:52, 26444.11it/s]读取数据:  58%|█████▊    | 4101842/7086503 [53:23<06:12, 8010.83it/s] 读取数据:  58%|█████▊    | 4103792/7086503 [53:23<05:30, 9015.69it/s]读取数据:  58%|█████▊    | 4105617/7086503 [53:23<04:58, 9985.66it/s]读取数据:  58%|█████▊    | 4107352/7086503 [53:23<04:29, 11062.84it/s]读取数据:  58%|█████▊    | 4109101/7086503 [53:24<04:03, 12231.36it/s]读取数据:  58%|█████▊    | 4111062/7086503 [53:24<03:36, 13751.85it/s]读取数据:  58%|█████▊    | 4113037/7086503 [53:24<03:16, 15111.88it/s]读取数据:  58%|█████▊    | 4115284/7086503 [53:24<02:55, 16916.37it/s]读取数据:  58%|█████▊    | 4117677/7086503 [53:24<02:38, 18735.29it/s]读取数据:  58%|█████▊    | 4120291/7086503 [53:24<02:23, 20736.94it/s]读取数据:  58%|█████▊    | 4123082/7086503 [53:24<02:10, 22734.61it/s]读取数据:  58%|█████▊    | 4126005/7086503 [53:24<02:00, 24582.90it/s]读取数据:  58%|█████▊    | 4128775/7086503 [53:24<01:56, 25483.33it/s]读取数据:  58%|█████▊    | 4131402/7086503 [53:25<02:22, 20775.16it/s]读取数据:  58%|█████▊    | 4133736/7086503 [53:25<02:17, 21420.92it/s]读取数据:  58%|█████▊    | 4136032/7086503 [53:25<02:15, 21824.91it/s]读取数据:  58%|█████▊    | 4138325/7086503 [53:25<02:31, 19397.45it/s]读取数据:  58%|█████▊    | 4140391/7086503 [53:25<02:29, 19717.49it/s]读取数据:  58%|█████▊    | 4142452/7086503 [53:25<02:52, 17045.26it/s]读取数据:  58%|█████▊    | 4144273/7086503 [53:25<03:08, 15631.12it/s]读取数据:  59%|█████▊    | 4145926/7086503 [53:25<03:19, 14753.22it/s]读取数据:  59%|█████▊    | 4147463/7086503 [53:26<03:28, 14126.61it/s]读取数据:  59%|█████▊    | 4148915/7086503 [53:26<03:33, 13754.06it/s]读取数据:  59%|█████▊    | 4150314/7086503 [53:26<09:16, 5271.45it/s] 读取数据:  59%|█████▊    | 4151350/7086503 [53:27<08:56, 5473.79it/s]读取数据:  59%|█████▊    | 4152267/7086503 [53:27<08:52, 5513.74it/s]读取数据:  59%|█████▊    | 4153079/7086503 [53:27<08:30, 5746.73it/s]读取数据:  59%|█████▊    | 4153852/7086503 [53:27<08:07, 6020.86it/s]读取数据:  59%|█████▊    | 4154610/7086503 [53:27<07:45, 6300.62it/s]读取数据:  59%|█████▊    | 4155362/7086503 [53:27<07:26, 6565.08it/s]读取数据:  59%|█████▊    | 4156167/7086503 [53:27<07:03, 6920.68it/s]读取数据:  59%|█████▊    | 4156997/7086503 [53:27<06:42, 7271.98it/s]读取数据:  59%|█████▊    | 4157867/7086503 [53:27<06:22, 7648.46it/s]读取数据:  59%|█████▊    | 4158780/7086503 [53:28<06:03, 8055.47it/s]读取数据:  59%|█████▊    | 4159722/7086503 [53:28<05:46, 8440.55it/s]读取数据:  59%|█████▊    | 4160698/7086503 [53:28<05:31, 8819.97it/s]读取数据:  59%|█████▊    | 4161725/7086503 [53:28<05:16, 9241.42it/s]读取数据:  59%|█████▊    | 4162831/7086503 [53:28<04:59, 9773.33it/s]读取数据:  59%|█████▉    | 4163968/7086503 [53:28<04:45, 10244.14it/s]读取数据:  59%|█████▉    | 4165092/7086503 [53:28<04:37, 10537.82it/s]读取数据:  59%|█████▉    | 4166225/7086503 [53:28<04:31, 10772.18it/s]读取数据:  59%|█████▉    | 4167387/7086503 [53:28<04:24, 11024.92it/s]读取数据:  59%|█████▉    | 4168576/7086503 [53:28<04:18, 11281.23it/s]读取数据:  59%|█████▉    | 4169757/7086503 [53:29<04:15, 11436.23it/s]读取数据:  59%|█████▉    | 4170933/7086503 [53:29<04:12, 11531.88it/s]读取数据:  59%|█████▉    | 4172134/7086503 [53:29<04:09, 11671.13it/s]读取数据:  59%|█████▉    | 4173303/7086503 [53:29<04:44, 10242.42it/s]读取数据:  59%|█████▉    | 4174461/7086503 [53:29<04:34, 10601.51it/s]读取数据:  59%|█████▉    | 4175659/7086503 [53:29<04:24, 10985.06it/s]读取数据:  59%|█████▉    | 4176846/7086503 [53:29<04:18, 11236.55it/s]读取数据:  59%|█████▉    | 4178027/7086503 [53:29<04:15, 11401.55it/s]读取数据:  59%|█████▉    | 4179209/7086503 [53:29<04:12, 11522.75it/s]读取数据:  59%|█████▉    | 4180371/7086503 [53:29<04:11, 11549.13it/s]读取数据:  59%|█████▉    | 4181536/7086503 [53:30<04:10, 11578.39it/s]读取数据:  59%|█████▉    | 4182721/7086503 [53:30<04:09, 11659.04it/s]读取数据:  59%|█████▉    | 4183890/7086503 [53:30<04:10, 11605.93it/s]读取数据:  59%|█████▉    | 4185110/7086503 [53:30<04:06, 11781.30it/s]读取数据:  59%|█████▉    | 4186302/7086503 [53:30<04:05, 11821.11it/s]读取数据:  59%|█████▉    | 4187486/7086503 [53:30<04:07, 11734.68it/s]读取数据:  59%|█████▉    | 4188679/7086503 [53:30<04:05, 11788.97it/s]读取数据:  59%|█████▉    | 4189892/7086503 [53:30<04:03, 11890.54it/s]读取数据:  59%|█████▉    | 4191082/7086503 [53:30<04:03, 11868.63it/s]读取数据:  59%|█████▉    | 4192285/7086503 [53:30<04:02, 11915.92it/s]读取数据:  59%|█████▉    | 4193487/7086503 [53:31<04:02, 11942.01it/s]读取数据:  59%|█████▉    | 4194682/7086503 [53:31<04:02, 11911.50it/s]读取数据:  59%|█████▉    | 4195875/7086503 [53:31<04:02, 11916.71it/s]读取数据:  59%|█████▉    | 4197067/7086503 [53:31<04:04, 11837.96it/s]读取数据:  59%|█████▉    | 4198251/7086503 [53:31<04:05, 11748.53it/s]读取数据:  59%|█████▉    | 4199458/7086503 [53:31<04:03, 11841.90it/s]读取数据:  59%|█████▉    | 4200643/7086503 [53:32<10:36, 4535.99it/s] 读取数据:  59%|█████▉    | 4201528/7086503 [53:32<09:32, 5038.21it/s]读取数据:  59%|█████▉    | 4202380/7086503 [53:32<09:02, 5318.25it/s]读取数据:  59%|█████▉    | 4203226/7086503 [53:32<08:09, 5887.30it/s]读取数据:  59%|█████▉    | 4204129/7086503 [53:32<07:21, 6534.63it/s]读取数据:  59%|█████▉    | 4205164/7086503 [53:32<06:29, 7402.10it/s]读取数据:  59%|█████▉    | 4206318/7086503 [53:32<05:42, 8414.40it/s]读取数据:  59%|█████▉    | 4207580/7086503 [53:32<05:02, 9504.06it/s]读取数据:  59%|█████▉    | 4208784/7086503 [53:33<04:42, 10188.30it/s]读取数据:  59%|█████▉    | 4209965/7086503 [53:33<04:30, 10637.12it/s]读取数据:  59%|█████▉    | 4211154/7086503 [53:33<04:21, 10988.64it/s]读取数据:  59%|█████▉    | 4212347/7086503 [53:33<04:15, 11257.20it/s]读取数据:  59%|█████▉    | 4213521/7086503 [53:33<04:12, 11397.59it/s]读取数据:  59%|█████▉    | 4214696/7086503 [53:33<04:09, 11500.76it/s]读取数据:  59%|█████▉    | 4215863/7086503 [53:33<04:09, 11495.02it/s]读取数据:  60%|█████▉    | 4217024/7086503 [53:33<04:10, 11436.81it/s]读取数据:  60%|█████▉    | 4218200/7086503 [53:33<04:08, 11528.58it/s]读取数据:  60%|█████▉    | 4219363/7086503 [53:33<04:08, 11557.48it/s]读取数据:  60%|█████▉    | 4220575/7086503 [53:34<04:04, 11722.72it/s]读取数据:  60%|█████▉    | 4221751/7086503 [53:34<04:04, 11693.43it/s]读取数据:  60%|█████▉    | 4222945/7086503 [53:34<04:03, 11765.29it/s]读取数据:  60%|█████▉    | 4224126/7086503 [53:34<04:03, 11778.20it/s]读取数据:  60%|█████▉    | 4225325/7086503 [53:34<04:01, 11836.28it/s]读取数据:  60%|█████▉    | 4226510/7086503 [53:34<04:02, 11795.00it/s]读取数据:  60%|█████▉    | 4227718/7086503 [53:34<04:00, 11879.93it/s]读取数据:  60%|█████▉    | 4228907/7086503 [53:34<04:02, 11778.52it/s]读取数据:  60%|█████▉    | 4230111/7086503 [53:34<04:00, 11854.96it/s]读取数据:  60%|█████▉    | 4231297/7086503 [53:34<04:00, 11849.69it/s]读取数据:  60%|█████▉    | 4232486/7086503 [53:35<04:00, 11860.13it/s]读取数据:  60%|█████▉    | 4233691/7086503 [53:35<03:59, 11913.57it/s]读取数据:  60%|█████▉    | 4234883/7086503 [53:35<03:59, 11898.58it/s]读取数据:  60%|█████▉    | 4236095/7086503 [53:35<03:58, 11963.27it/s]读取数据:  60%|█████▉    | 4237292/7086503 [53:35<03:59, 11893.79it/s]读取数据:  60%|█████▉    | 4238482/7086503 [53:35<03:59, 11890.70it/s]读取数据:  60%|█████▉    | 4239682/7086503 [53:35<03:58, 11920.55it/s]读取数据:  60%|█████▉    | 4240875/7086503 [53:35<04:00, 11846.24it/s]读取数据:  60%|█████▉    | 4242100/7086503 [53:35<03:57, 11963.35it/s]读取数据:  60%|█████▉    | 4243325/7086503 [53:36<03:55, 12048.54it/s]读取数据:  60%|█████▉    | 4244531/7086503 [53:36<03:58, 11935.82it/s]读取数据:  60%|█████▉    | 4245748/7086503 [53:36<03:56, 12003.36it/s]读取数据:  60%|█████▉    | 4246966/7086503 [53:36<03:55, 12052.94it/s]读取数据:  60%|█████▉    | 4248189/7086503 [53:36<03:54, 12103.77it/s]读取数据:  60%|█████▉    | 4249400/7086503 [53:36<03:54, 12081.56it/s]读取数据:  60%|█████▉    | 4250609/7086503 [53:37<10:49, 4368.86it/s] 读取数据:  60%|█████▉    | 4251508/7086503 [53:37<10:01, 4714.21it/s]读取数据:  60%|██████    | 4252326/7086503 [53:37<09:29, 4974.50it/s]读取数据:  60%|██████    | 4253080/7086503 [53:37<08:55, 5293.42it/s]读取数据:  60%|██████    | 4253807/7086503 [53:37<08:31, 5540.38it/s]读取数据:  60%|██████    | 4254510/7086503 [53:37<08:10, 5769.33it/s]读取数据:  60%|██████    | 4255234/7086503 [53:37<07:43, 6106.97it/s]读取数据:  60%|██████    | 4255942/7086503 [53:38<07:26, 6346.08it/s]读取数据:  60%|██████    | 4256684/7086503 [53:38<07:07, 6625.69it/s]读取数据:  60%|██████    | 4257443/7086503 [53:38<06:50, 6886.88it/s]读取数据:  60%|██████    | 4258216/7086503 [53:38<06:37, 7121.95it/s]读取数据:  60%|██████    | 4259050/7086503 [53:38<06:18, 7468.41it/s]读取数据:  60%|██████    | 4259908/7086503 [53:38<06:02, 7789.45it/s]读取数据:  60%|██████    | 4260792/7086503 [53:38<05:49, 8092.61it/s]读取数据:  60%|██████    | 4261728/7086503 [53:38<05:33, 8465.76it/s]读取数据:  60%|██████    | 4262658/7086503 [53:38<05:24, 8707.48it/s]读取数据:  60%|██████    | 4263758/7086503 [53:38<05:00, 9385.56it/s]读取数据:  60%|██████    | 4264937/7086503 [53:39<04:39, 10099.65it/s]读取数据:  60%|██████    | 4266166/7086503 [53:39<04:22, 10751.02it/s]读取数据:  60%|██████    | 4267302/7086503 [53:39<04:17, 10931.65it/s]读取数据:  60%|██████    | 4268407/7086503 [53:39<04:16, 10966.05it/s]读取数据:  60%|██████    | 4269600/7086503 [53:39<04:10, 11248.66it/s]读取数据:  60%|██████    | 4270792/7086503 [53:39<04:05, 11446.92it/s]读取数据:  60%|██████    | 4271988/7086503 [53:39<04:02, 11600.42it/s]读取数据:  60%|██████    | 4273199/7086503 [53:39<03:59, 11751.83it/s]读取数据:  60%|██████    | 4274375/7086503 [53:39<04:00, 11714.58it/s]读取数据:  60%|██████    | 4275565/7086503 [53:39<03:58, 11769.25it/s]读取数据:  60%|██████    | 4276789/7086503 [53:40<03:55, 11905.98it/s]读取数据:  60%|██████    | 4277989/7086503 [53:40<03:55, 11931.06it/s]读取数据:  60%|██████    | 4279191/7086503 [53:40<03:54, 11957.32it/s]读取数据:  60%|██████    | 4280387/7086503 [53:40<03:55, 11938.47it/s]读取数据:  60%|██████    | 4281581/7086503 [53:40<03:55, 11919.55it/s]读取数据:  60%|██████    | 4282774/7086503 [53:40<03:55, 11895.38it/s]读取数据:  60%|██████    | 4283973/7086503 [53:40<03:55, 11923.04it/s]读取数据:  60%|██████    | 4285197/7086503 [53:40<03:53, 12017.22it/s]读取数据:  60%|██████    | 4286399/7086503 [53:40<03:53, 11989.67it/s]读取数据:  61%|██████    | 4287599/7086503 [53:40<03:53, 11974.45it/s]读取数据:  61%|██████    | 4288797/7086503 [53:41<03:54, 11932.28it/s]读取数据:  61%|██████    | 4289991/7086503 [53:41<03:54, 11927.16it/s]读取数据:  61%|██████    | 4291184/7086503 [53:41<04:12, 11062.39it/s]读取数据:  61%|██████    | 4292384/7086503 [53:41<04:06, 11327.71it/s]读取数据:  61%|██████    | 4293563/7086503 [53:41<04:03, 11459.48it/s]读取数据:  61%|██████    | 4294773/7086503 [53:41<03:59, 11643.10it/s]读取数据:  61%|██████    | 4295977/7086503 [53:41<03:57, 11758.49it/s]读取数据:  61%|██████    | 4297168/7086503 [53:41<03:56, 11801.11it/s]读取数据:  61%|██████    | 4298391/7086503 [53:41<03:53, 11927.95it/s]读取数据:  61%|██████    | 4299587/7086503 [53:41<03:54, 11908.26it/s]读取数据:  61%|██████    | 4300780/7086503 [53:42<12:21, 3759.11it/s] 读取数据:  61%|██████    | 4301658/7086503 [53:42<11:25, 4059.56it/s]读取数据:  61%|██████    | 4302436/7086503 [53:43<10:41, 4341.78it/s]读取数据:  61%|██████    | 4303150/7086503 [53:43<10:02, 4621.76it/s]读取数据:  61%|██████    | 4303826/7086503 [53:43<09:33, 4855.76it/s]读取数据:  61%|██████    | 4304473/7086503 [53:43<09:08, 5070.65it/s]读取数据:  61%|██████    | 4305102/7086503 [53:43<08:43, 5313.61it/s]读取数据:  61%|██████    | 4305753/7086503 [53:43<08:17, 5590.11it/s]读取数据:  61%|██████    | 4306412/7086503 [53:43<07:55, 5840.71it/s]读取数据:  61%|██████    | 4307053/7086503 [53:43<07:46, 5962.24it/s]读取数据:  61%|██████    | 4307690/7086503 [53:43<07:38, 6055.65it/s]读取数据:  61%|██████    | 4308367/7086503 [53:44<07:24, 6253.06it/s]读取数据:  61%|██████    | 4309025/7086503 [53:44<07:17, 6346.13it/s]读取数据:  61%|██████    | 4309676/7086503 [53:44<07:16, 6368.82it/s]读取数据:  61%|██████    | 4310378/7086503 [53:44<07:03, 6556.15it/s]读取数据:  61%|██████    | 4311129/7086503 [53:44<06:46, 6828.94it/s]读取数据:  61%|██████    | 4311874/7086503 [53:44<06:35, 7010.64it/s]读取数据:  61%|██████    | 4312614/7086503 [53:44<06:29, 7123.32it/s]读取数据:  61%|██████    | 4313393/7086503 [53:44<06:19, 7316.57it/s]读取数据:  61%|██████    | 4314197/7086503 [53:44<06:08, 7526.57it/s]读取数据:  61%|██████    | 4315000/7086503 [53:44<06:01, 7674.37it/s]读取数据:  61%|██████    | 4315870/7086503 [53:45<05:47, 7975.54it/s]读取数据:  61%|██████    | 4316792/7086503 [53:45<05:31, 8345.05it/s]读取数据:  61%|██████    | 4317780/7086503 [53:45<05:14, 8800.10it/s]读取数据:  61%|██████    | 4318831/7086503 [53:45<04:57, 9307.96it/s]读取数据:  61%|██████    | 4319943/7086503 [53:45<04:40, 9847.91it/s]读取数据:  61%|██████    | 4321116/7086503 [53:45<04:25, 10411.47it/s]读取数据:  61%|██████    | 4322354/7086503 [53:45<04:11, 10999.73it/s]读取数据:  61%|██████    | 4323602/7086503 [53:45<04:01, 11442.91it/s]读取数据:  61%|██████    | 4324771/7086503 [53:45<03:59, 11510.90it/s]读取数据:  61%|██████    | 4325933/7086503 [53:45<03:59, 11542.66it/s]读取数据:  61%|██████    | 4327123/7086503 [53:46<03:56, 11649.30it/s]读取数据:  61%|██████    | 4328318/7086503 [53:46<03:54, 11738.92it/s]读取数据:  61%|██████    | 4329519/7086503 [53:46<03:53, 11817.87it/s]读取数据:  61%|██████    | 4330701/7086503 [53:46<03:54, 11742.31it/s]读取数据:  61%|██████    | 4331876/7086503 [53:46<03:55, 11680.39it/s]读取数据:  61%|██████    | 4333062/7086503 [53:46<03:54, 11732.22it/s]读取数据:  61%|██████    | 4334242/7086503 [53:46<03:54, 11750.90it/s]读取数据:  61%|██████    | 4335418/7086503 [53:46<03:55, 11696.81it/s]读取数据:  61%|██████    | 4336622/7086503 [53:46<03:53, 11798.10it/s]读取数据:  61%|██████    | 4337835/7086503 [53:46<03:51, 11895.87it/s]读取数据:  61%|██████    | 4339025/7086503 [53:47<03:52, 11813.08it/s]读取数据:  61%|██████    | 4340216/7086503 [53:47<03:51, 11838.61it/s]读取数据:  61%|██████▏   | 4341414/7086503 [53:47<03:51, 11878.38it/s]读取数据:  61%|██████▏   | 4342602/7086503 [53:47<03:52, 11787.81it/s]读取数据:  61%|██████▏   | 4343781/7086503 [53:47<03:53, 11739.65it/s]读取数据:  61%|██████▏   | 4344990/7086503 [53:47<03:51, 11843.58it/s]读取数据:  61%|██████▏   | 4346175/7086503 [53:47<03:52, 11775.67it/s]读取数据:  61%|██████▏   | 4347384/7086503 [53:47<03:50, 11867.11it/s]读取数据:  61%|██████▏   | 4348587/7086503 [53:47<03:49, 11914.00it/s]读取数据:  61%|██████▏   | 4349779/7086503 [53:47<03:50, 11861.66it/s]读取数据:  61%|██████▏   | 4350966/7086503 [53:48<12:39, 3604.01it/s] 读取数据:  61%|██████▏   | 4351838/7086503 [53:48<11:38, 3915.06it/s]读取数据:  61%|██████▏   | 4352611/7086503 [53:49<10:50, 4201.64it/s]读取数据:  61%|██████▏   | 4353318/7086503 [53:49<10:23, 4384.73it/s]读取数据:  61%|██████▏   | 4353967/7086503 [53:49<09:55, 4591.03it/s]读取数据:  61%|██████▏   | 4354584/7086503 [53:49<09:27, 4817.24it/s]读取数据:  61%|██████▏   | 4355187/7086503 [53:49<09:01, 5044.66it/s]读取数据:  61%|██████▏   | 4355786/7086503 [53:49<08:45, 5199.00it/s]读取数据:  61%|██████▏   | 4356376/7086503 [53:49<08:37, 5279.23it/s]读取数据:  61%|██████▏   | 4356954/7086503 [53:49<08:33, 5312.71it/s]读取数据:  61%|██████▏   | 4357544/7086503 [53:50<08:19, 5464.51it/s]读取数据:  61%|██████▏   | 4358127/7086503 [53:50<08:10, 5563.94it/s]读取数据:  62%|██████▏   | 4358733/7086503 [53:50<07:58, 5696.97it/s]读取数据:  62%|██████▏   | 4359327/7086503 [53:50<07:53, 5764.79it/s]读取数据:  62%|██████▏   | 4359914/7086503 [53:50<07:51, 5785.70it/s]读取数据:  62%|██████▏   | 4360506/7086503 [53:50<07:48, 5823.97it/s]读取数据:  62%|██████▏   | 4361147/7086503 [53:50<07:34, 5995.90it/s]读取数据:  62%|██████▏   | 4361751/7086503 [53:50<07:35, 5984.08it/s]读取数据:  62%|██████▏   | 4362424/7086503 [53:50<07:19, 6203.20it/s]读取数据:  62%|██████▏   | 4363092/7086503 [53:50<07:09, 6338.49it/s]读取数据:  62%|██████▏   | 4363807/7086503 [53:51<06:53, 6578.88it/s]读取数据:  62%|██████▏   | 4364505/7086503 [53:51<06:46, 6697.26it/s]读取数据:  62%|██████▏   | 4365236/7086503 [53:51<06:35, 6879.04it/s]读取数据:  62%|██████▏   | 4365988/7086503 [53:51<06:24, 7069.72it/s]读取数据:  62%|██████▏   | 4366757/7086503 [53:51<06:14, 7254.20it/s]读取数据:  62%|██████▏   | 4367511/7086503 [53:51<06:10, 7335.65it/s]读取数据:  62%|██████▏   | 4368361/7086503 [53:51<05:53, 7682.85it/s]读取数据:  62%|██████▏   | 4369224/7086503 [53:51<05:41, 7966.18it/s]读取数据:  62%|██████▏   | 4370113/7086503 [53:51<05:29, 8240.60it/s]读取数据:  62%|██████▏   | 4371049/7086503 [53:51<05:16, 8575.40it/s]读取数据:  62%|██████▏   | 4372034/7086503 [53:52<05:03, 8955.73it/s]读取数据:  62%|██████▏   | 4373065/7086503 [53:52<04:49, 9357.11it/s]读取数据:  62%|██████▏   | 4374183/7086503 [53:52<04:33, 9902.71it/s]读取数据:  62%|██████▏   | 4375356/7086503 [53:52<04:19, 10447.20it/s]读取数据:  62%|██████▏   | 4376553/7086503 [53:52<04:08, 10903.15it/s]读取数据:  62%|██████▏   | 4377795/7086503 [53:52<03:58, 11355.44it/s]读取数据:  62%|██████▏   | 4379073/7086503 [53:52<03:49, 11781.08it/s]读取数据:  62%|██████▏   | 4380309/7086503 [53:52<03:46, 11953.47it/s]读取数据:  62%|██████▏   | 4381505/7086503 [53:52<03:48, 11837.98it/s]读取数据:  62%|██████▏   | 4382690/7086503 [53:52<03:48, 11824.57it/s]读取数据:  62%|██████▏   | 4383882/7086503 [53:53<03:48, 11851.92it/s]读取数据:  62%|██████▏   | 4385125/7086503 [53:53<03:44, 12021.33it/s]读取数据:  62%|██████▏   | 4386360/7086503 [53:53<03:42, 12118.76it/s]读取数据:  62%|██████▏   | 4387573/7086503 [53:53<03:43, 12066.35it/s]读取数据:  62%|██████▏   | 4388781/7086503 [53:53<03:43, 12068.68it/s]读取数据:  62%|██████▏   | 4390022/7086503 [53:53<03:41, 12164.43it/s]读取数据:  62%|██████▏   | 4391239/7086503 [53:53<03:43, 12047.99it/s]读取数据:  62%|██████▏   | 4392445/7086503 [53:53<03:57, 11321.63it/s]读取数据:  62%|██████▏   | 4393629/7086503 [53:53<03:54, 11464.43it/s]读取数据:  62%|██████▏   | 4394831/7086503 [53:53<03:51, 11622.72it/s]读取数据:  62%|██████▏   | 4396040/7086503 [53:54<03:48, 11757.85it/s]读取数据:  62%|██████▏   | 4397245/7086503 [53:54<03:47, 11841.45it/s]读取数据:  62%|██████▏   | 4398565/7086503 [53:54<03:39, 12241.71it/s]读取数据:  62%|██████▏   | 4399805/7086503 [53:54<03:38, 12286.42it/s]读取数据:  62%|██████▏   | 4401036/7086503 [53:55<12:37, 3546.31it/s] 读取数据:  62%|██████▏   | 4401938/7086503 [53:55<11:29, 3892.73it/s]读取数据:  62%|██████▏   | 4402739/7086503 [53:55<10:38, 4204.34it/s]读取数据:  62%|██████▏   | 4403472/7086503 [53:55<10:03, 4443.33it/s]读取数据:  62%|██████▏   | 4404149/7086503 [53:55<09:35, 4658.43it/s]读取数据:  62%|██████▏   | 4404789/7086503 [53:55<09:11, 4866.61it/s]读取数据:  62%|██████▏   | 4405407/7086503 [53:56<08:55, 5004.71it/s]读取数据:  62%|██████▏   | 4406004/7086503 [53:56<08:39, 5155.52it/s]读取数据:  62%|██████▏   | 4406592/7086503 [53:56<08:32, 5231.70it/s]读取数据:  62%|██████▏   | 4407167/7086503 [53:56<08:21, 5346.87it/s]读取数据:  62%|██████▏   | 4407740/7086503 [53:56<08:13, 5429.27it/s]读取数据:  62%|██████▏   | 4408346/7086503 [53:56<07:58, 5600.28it/s]读取数据:  62%|██████▏   | 4408928/7086503 [53:56<07:53, 5651.62it/s]读取数据:  62%|██████▏   | 4409509/7086503 [53:56<07:51, 5681.62it/s]读取数据:  62%|██████▏   | 4410124/7086503 [53:56<07:40, 5816.44it/s]读取数据:  62%|██████▏   | 4410742/7086503 [53:56<07:32, 5918.70it/s]读取数据:  62%|██████▏   | 4411348/7086503 [53:57<07:28, 5958.18it/s]读取数据:  62%|██████▏   | 4411948/7086503 [53:57<07:29, 5946.16it/s]读取数据:  62%|██████▏   | 4412598/7086503 [53:57<07:17, 6106.85it/s]读取数据:  62%|██████▏   | 4413261/7086503 [53:57<07:06, 6261.82it/s]读取数据:  62%|██████▏   | 4413901/7086503 [53:57<07:04, 6302.27it/s]读取数据:  62%|██████▏   | 4414536/7086503 [53:57<07:03, 6312.98it/s]读取数据:  62%|██████▏   | 4415229/7086503 [53:57<06:51, 6494.60it/s]读取数据:  62%|██████▏   | 4415880/7086503 [53:57<06:53, 6457.57it/s]读取数据:  62%|██████▏   | 4416585/7086503 [53:57<06:42, 6632.25it/s]读取数据:  62%|██████▏   | 4417272/7086503 [53:57<06:38, 6699.49it/s]读取数据:  62%|██████▏   | 4418016/7086503 [53:58<06:25, 6920.32it/s]读取数据:  62%|██████▏   | 4418832/7086503 [53:58<06:05, 7290.83it/s]读取数据:  62%|██████▏   | 4419562/7086503 [53:58<06:06, 7272.34it/s]读取数据:  62%|██████▏   | 4420401/7086503 [53:58<05:50, 7600.83it/s]读取数据:  62%|██████▏   | 4421229/7086503 [53:58<05:41, 7803.37it/s]读取数据:  62%|██████▏   | 4422043/7086503 [53:58<05:37, 7903.88it/s]读取数据:  62%|██████▏   | 4422900/7086503 [53:58<05:28, 8101.40it/s]读取数据:  62%|██████▏   | 4423803/7086503 [53:58<05:17, 8378.45it/s]读取数据:  62%|██████▏   | 4424724/7086503 [53:58<05:08, 8623.66it/s]读取数据:  62%|██████▏   | 4425743/7086503 [53:58<04:52, 9091.08it/s]读取数据:  62%|██████▏   | 4426798/7086503 [53:59<04:39, 9526.42it/s]读取数据:  62%|██████▏   | 4427935/7086503 [53:59<04:23, 10076.15it/s]读取数据:  63%|██████▎   | 4429152/7086503 [53:59<04:08, 10703.75it/s]读取数据:  63%|██████▎   | 4430414/7086503 [53:59<03:55, 11276.76it/s]读取数据:  63%|██████▎   | 4431725/7086503 [53:59<03:44, 11824.60it/s]读取数据:  63%|██████▎   | 4433038/7086503 [53:59<03:37, 12215.00it/s]读取数据:  63%|██████▎   | 4434260/7086503 [53:59<03:37, 12170.94it/s]读取数据:  63%|██████▎   | 4435478/7086503 [53:59<03:38, 12112.28it/s]读取数据:  63%|██████▎   | 4436690/7086503 [53:59<03:40, 12020.41it/s]读取数据:  63%|██████▎   | 4437893/7086503 [53:59<03:42, 11880.83it/s]读取数据:  63%|██████▎   | 4439084/7086503 [54:00<03:42, 11884.23it/s]读取数据:  63%|██████▎   | 4440273/7086503 [54:00<03:42, 11885.28it/s]读取数据:  63%|██████▎   | 4441468/7086503 [54:00<03:42, 11902.53it/s]读取数据:  63%|██████▎   | 4442665/7086503 [54:00<03:41, 11921.91it/s]读取数据:  63%|██████▎   | 4443858/7086503 [54:00<03:42, 11881.38it/s]读取数据:  63%|██████▎   | 4445047/7086503 [54:00<03:45, 11729.96it/s]读取数据:  63%|██████▎   | 4446221/7086503 [54:00<03:48, 11569.45it/s]读取数据:  63%|██████▎   | 4447379/7086503 [54:00<03:51, 11416.20it/s]读取数据:  63%|██████▎   | 4448553/7086503 [54:00<03:49, 11510.06it/s]读取数据:  63%|██████▎   | 4449705/7086503 [54:01<03:50, 11425.85it/s]读取数据:  63%|██████▎   | 4450849/7086503 [54:01<13:48, 3181.10it/s] 读取数据:  63%|██████▎   | 4451685/7086503 [54:02<12:30, 3510.40it/s]读取数据:  63%|██████▎   | 4452429/7086503 [54:02<11:32, 3801.72it/s]读取数据:  63%|██████▎   | 4453107/7086503 [54:02<10:42, 4099.06it/s]读取数据:  63%|██████▎   | 4453748/7086503 [54:02<10:05, 4351.57it/s]读取数据:  63%|██████▎   | 4454360/7086503 [54:02<09:36, 4565.54it/s]读取数据:  63%|██████▎   | 4454950/7086503 [54:02<09:11, 4775.22it/s]读取数据:  63%|██████▎   | 4455529/7086503 [54:02<08:50, 4961.66it/s]读取数据:  63%|██████▎   | 4456102/7086503 [54:02<08:32, 5129.32it/s]读取数据:  63%|██████▎   | 4456676/7086503 [54:03<08:17, 5281.88it/s]读取数据:  63%|██████▎   | 4457247/7086503 [54:03<08:07, 5389.82it/s]读取数据:  63%|██████▎   | 4457822/7086503 [54:03<07:59, 5483.45it/s]读取数据:  63%|██████▎   | 4458393/7086503 [54:03<07:54, 5537.67it/s]读取数据:  63%|██████▎   | 4458974/7086503 [54:03<07:48, 5614.37it/s]读取数据:  63%|██████▎   | 4459565/7086503 [54:03<07:40, 5700.34it/s]读取数据:  63%|██████▎   | 4460163/7086503 [54:03<07:34, 5778.42it/s]读取数据:  63%|██████▎   | 4460749/7086503 [54:03<07:32, 5800.07it/s]读取数据:  63%|██████▎   | 4461355/7086503 [54:03<07:26, 5875.20it/s]读取数据:  63%|██████▎   | 4461947/7086503 [54:03<07:25, 5887.96it/s]读取数据:  63%|██████▎   | 4462538/7086503 [54:04<07:51, 5562.69it/s]读取数据:  63%|██████▎   | 4463170/7086503 [54:04<07:33, 5778.72it/s]读取数据:  63%|██████▎   | 4463794/7086503 [54:04<07:23, 5910.72it/s]读取数据:  63%|██████▎   | 4464389/7086503 [54:04<07:43, 5653.40it/s]读取数据:  63%|██████▎   | 4465015/7086503 [54:04<07:29, 5825.98it/s]读取数据:  63%|██████▎   | 4465713/7086503 [54:04<07:05, 6158.20it/s]读取数据:  63%|██████▎   | 4466389/7086503 [54:04<06:53, 6331.97it/s]读取数据:  63%|██████▎   | 4467092/7086503 [54:04<06:40, 6536.98it/s]读取数据:  63%|██████▎   | 4467780/7086503 [54:04<06:34, 6633.94it/s]读取数据:  63%|██████▎   | 4468467/7086503 [54:04<06:30, 6700.98it/s]读取数据:  63%|██████▎   | 4469170/7086503 [54:05<06:25, 6797.28it/s]读取数据:  63%|██████▎   | 4469871/7086503 [54:05<06:21, 6860.47it/s]读取数据:  63%|██████▎   | 4470625/7086503 [54:05<06:10, 7060.63it/s]读取数据:  63%|██████▎   | 4471437/7086503 [54:05<05:54, 7375.38it/s]读取数据:  63%|██████▎   | 4472216/7086503 [54:05<05:48, 7497.14it/s]读取数据:  63%|██████▎   | 4472994/7086503 [54:05<05:44, 7580.23it/s]读取数据:  63%|██████▎   | 4473855/7086503 [54:05<05:31, 7885.15it/s]读取数据:  63%|██████▎   | 4474733/7086503 [54:05<05:20, 8151.89it/s]读取数据:  63%|██████▎   | 4475629/7086503 [54:05<05:11, 8393.40it/s]读取数据:  63%|██████▎   | 4476603/7086503 [54:05<04:56, 8794.33it/s]读取数据:  63%|██████▎   | 4477599/7086503 [54:06<04:45, 9142.81it/s]读取数据:  63%|██████▎   | 4478638/7086503 [54:06<04:34, 9512.45it/s]读取数据:  63%|██████▎   | 4479688/7086503 [54:06<04:25, 9808.22it/s]读取数据:  63%|██████▎   | 4480805/7086503 [54:06<04:15, 10216.33it/s]读取数据:  63%|██████▎   | 4482023/7086503 [54:06<04:01, 10802.76it/s]读取数据:  63%|██████▎   | 4483276/7086503 [54:06<03:49, 11319.48it/s]读取数据:  63%|██████▎   | 4484572/7086503 [54:06<03:40, 11807.87it/s]读取数据:  63%|██████▎   | 4485861/7086503 [54:06<03:34, 12130.35it/s]读取数据:  63%|██████▎   | 4487094/7086503 [54:06<03:33, 12187.16it/s]读取数据:  63%|██████▎   | 4488313/7086503 [54:06<03:38, 11914.51it/s]读取数据:  63%|██████▎   | 4489506/7086503 [54:07<03:39, 11813.25it/s]读取数据:  63%|██████▎   | 4490689/7086503 [54:07<03:41, 11694.84it/s]读取数据:  63%|██████▎   | 4491860/7086503 [54:07<03:41, 11697.23it/s]读取数据:  63%|██████▎   | 4493031/7086503 [54:07<03:41, 11684.00it/s]读取数据:  63%|██████▎   | 4494235/7086503 [54:07<03:39, 11788.27it/s]读取数据:  63%|██████▎   | 4495422/7086503 [54:07<03:39, 11810.85it/s]读取数据:  63%|██████▎   | 4496604/7086503 [54:07<03:39, 11780.44it/s]读取数据:  63%|██████▎   | 4497783/7086503 [54:07<03:41, 11693.68it/s]读取数据:  63%|██████▎   | 4498953/7086503 [54:07<03:46, 11446.48it/s]读取数据:  63%|██████▎   | 4498953/7086503 [54:25<03:46, 11446.48it/s]读取数据:  64%|██████▎   | 4500000/7086503 [1:02:54<99:37:41,  7.21it/s]读取数据:  64%|██████▎   | 4500241/7086503 [1:02:54<91:22:18,  7.86it/s]读取数据:  64%|██████▎   | 4501116/7086503 [1:02:55<63:53:20, 11.24it/s]读取数据:  64%|██████▎   | 4501872/7086503 [1:02:55<46:36:21, 15.40it/s]读取数据:  64%|██████▎   | 4502552/7086503 [1:02:55<34:35:54, 20.75it/s]读取数据:  64%|██████▎   | 4503182/7086503 [1:02:55<25:48:58, 27.80it/s]读取数据:  64%|██████▎   | 4503773/7086503 [1:02:55<19:16:37, 37.22it/s]读取数据:  64%|██████▎   | 4504343/7086503 [1:02:55<14:18:26, 50.13it/s]读取数据:  64%|██████▎   | 4504899/7086503 [1:02:55<10:32:18, 68.05it/s]读取数据:  64%|██████▎   | 4505449/7086503 [1:02:55<7:41:48, 93.15it/s] 读取数据:  64%|██████▎   | 4505997/7086503 [1:02:56<5:34:51, 128.44it/s]读取数据:  64%|██████▎   | 4506535/7086503 [1:02:56<4:02:46, 177.12it/s]读取数据:  64%|██████▎   | 4507080/7086503 [1:02:56<2:54:42, 246.07it/s]读取数据:  64%|██████▎   | 4507615/7086503 [1:02:56<2:06:33, 339.60it/s]读取数据:  64%|██████▎   | 4508150/7086503 [1:02:56<1:31:55, 467.49it/s]读取数据:  64%|██████▎   | 4508684/7086503 [1:02:56<1:07:19, 638.08it/s]读取数据:  64%|██████▎   | 4509212/7086503 [1:02:56<49:59, 859.17it/s]  读取数据:  64%|██████▎   | 4509752/7086503 [1:02:56<37:22, 1149.13it/s]读取数据:  64%|██████▎   | 4510313/7086503 [1:02:56<28:12, 1522.04it/s]读取数据:  64%|██████▎   | 4510891/7086503 [1:02:57<21:43, 1976.06it/s]读取数据:  64%|██████▎   | 4511474/7086503 [1:02:57<17:16, 2484.83it/s]读取数据:  64%|██████▎   | 4512062/7086503 [1:02:57<14:11, 3023.85it/s]读取数据:  64%|██████▎   | 4512636/7086503 [1:02:57<12:10, 3525.08it/s]读取数据:  64%|██████▎   | 4513206/7086503 [1:02:57<10:48, 3968.98it/s]读取数据:  64%|██████▎   | 4513797/7086503 [1:02:57<09:43, 4412.38it/s]读取数据:  64%|██████▎   | 4514381/7086503 [1:02:57<09:00, 4762.46it/s]读取数据:  64%|██████▎   | 4514991/7086503 [1:02:57<08:23, 5105.90it/s]读取数据:  64%|██████▎   | 4515625/7086503 [1:02:57<07:52, 5439.59it/s]读取数据:  64%|██████▎   | 4516238/7086503 [1:02:57<07:36, 5631.93it/s]读取数据:  64%|██████▎   | 4516853/7086503 [1:02:58<07:24, 5777.68it/s]读取数据:  64%|██████▎   | 4517508/7086503 [1:02:58<07:08, 6000.54it/s]读取数据:  64%|██████▍   | 4518130/7086503 [1:02:58<07:03, 6058.75it/s]读取数据:  64%|██████▍   | 4518768/7086503 [1:02:58<06:57, 6152.59it/s]读取数据:  64%|██████▍   | 4519406/7086503 [1:02:58<06:52, 6218.01it/s]读取数据:  64%|██████▍   | 4520068/7086503 [1:02:58<06:45, 6335.83it/s]读取数据:  64%|██████▍   | 4520736/7086503 [1:02:58<06:38, 6436.81it/s]读取数据:  64%|██████▍   | 4521429/7086503 [1:02:58<06:29, 6581.64it/s]读取数据:  64%|██████▍   | 4522145/7086503 [1:02:58<06:19, 6753.24it/s]读取数据:  64%|██████▍   | 4522864/7086503 [1:02:58<06:12, 6883.37it/s]读取数据:  64%|██████▍   | 4523587/7086503 [1:02:59<06:06, 6985.97it/s]读取数据:  64%|██████▍   | 4524338/7086503 [1:02:59<05:58, 7139.34it/s]读取数据:  64%|██████▍   | 4525114/7086503 [1:02:59<05:49, 7324.67it/s]读取数据:  64%|██████▍   | 4525881/7086503 [1:02:59<05:45, 7421.70it/s]读取数据:  64%|██████▍   | 4526658/7086503 [1:02:59<05:40, 7525.53it/s]读取数据:  64%|██████▍   | 4527511/7086503 [1:02:59<05:27, 7824.91it/s]读取数据:  64%|██████▍   | 4528404/7086503 [1:02:59<05:13, 8153.83it/s]读取数据:  64%|██████▍   | 4529321/7086503 [1:02:59<05:02, 8457.46it/s]读取数据:  64%|██████▍   | 4530250/7086503 [1:02:59<04:53, 8705.36it/s]读取数据:  64%|██████▍   | 4531274/7086503 [1:02:59<04:38, 9162.01it/s]读取数据:  64%|██████▍   | 4532259/7086503 [1:03:00<04:32, 9367.07it/s]读取数据:  64%|██████▍   | 4533343/7086503 [1:03:00<04:20, 9805.66it/s]读取数据:  64%|██████▍   | 4534496/7086503 [1:03:00<04:07, 10317.69it/s]读取数据:  64%|██████▍   | 4535646/7086503 [1:03:00<03:59, 10669.36it/s]读取数据:  64%|██████▍   | 4536835/7086503 [1:03:00<03:51, 11035.03it/s]读取数据:  64%|██████▍   | 4537956/7086503 [1:03:00<03:49, 11084.34it/s]读取数据:  64%|██████▍   | 4539147/7086503 [1:03:00<03:44, 11328.00it/s]读取数据:  64%|██████▍   | 4540280/7086503 [1:03:00<03:44, 11317.22it/s]读取数据:  64%|██████▍   | 4541412/7086503 [1:03:00<03:50, 11030.13it/s]读取数据:  64%|██████▍   | 4542517/7086503 [1:03:00<03:50, 11030.23it/s]读取数据:  64%|██████▍   | 4543622/7086503 [1:03:01<03:54, 10829.97it/s]读取数据:  64%|██████▍   | 4544707/7086503 [1:03:01<03:57, 10699.07it/s]读取数据:  64%|██████▍   | 4545806/7086503 [1:03:01<03:55, 10782.81it/s]读取数据:  64%|██████▍   | 4546903/7086503 [1:03:01<03:54, 10837.63it/s]读取数据:  64%|██████▍   | 4548006/7086503 [1:03:01<03:53, 10891.88it/s]读取数据:  64%|██████▍   | 4549096/7086503 [1:03:01<03:53, 10888.73it/s]读取数据:  64%|██████▍   | 4550186/7086503 [1:03:02<13:52, 3045.78it/s] 读取数据:  64%|██████▍   | 4550983/7086503 [1:03:02<12:37, 3349.21it/s]读取数据:  64%|██████▍   | 4551689/7086503 [1:03:02<11:31, 3663.87it/s]读取数据:  64%|██████▍   | 4552343/7086503 [1:03:02<10:50, 3894.76it/s]读取数据:  64%|██████▍   | 4552948/7086503 [1:03:03<10:11, 4140.54it/s]读取数据:  64%|██████▍   | 4553528/7086503 [1:03:03<09:41, 4354.18it/s]读取数据:  64%|██████▍   | 4554089/7086503 [1:03:03<09:21, 4513.34it/s]读取数据:  64%|██████▍   | 4554634/7086503 [1:03:03<09:08, 4618.43it/s]读取数据:  64%|██████▍   | 4555164/7086503 [1:03:03<08:56, 4720.63it/s]读取数据:  64%|██████▍   | 4555700/7086503 [1:03:03<08:38, 4879.29it/s]读取数据:  64%|██████▍   | 4556226/7086503 [1:03:03<08:29, 4963.61it/s]读取数据:  64%|██████▍   | 4556750/7086503 [1:03:03<08:24, 5016.20it/s]读取数据:  64%|██████▍   | 4557272/7086503 [1:03:03<08:23, 5020.80it/s]读取数据:  64%|██████▍   | 4557795/7086503 [1:03:03<08:18, 5073.12it/s]读取数据:  64%|██████▍   | 4558321/7086503 [1:03:04<08:13, 5125.00it/s]读取数据:  64%|██████▍   | 4558865/7086503 [1:03:04<08:04, 5215.35it/s]读取数据:  64%|██████▍   | 4559392/7086503 [1:03:04<08:06, 5196.05it/s]读取数据:  64%|██████▍   | 4559916/7086503 [1:03:04<08:06, 5190.02it/s]读取数据:  64%|██████▍   | 4560443/7086503 [1:03:04<08:04, 5211.84it/s]读取数据:  64%|██████▍   | 4560967/7086503 [1:03:04<08:07, 5183.74it/s]读取数据:  64%|██████▍   | 4561509/7086503 [1:03:04<08:00, 5253.58it/s]读取数据:  64%|██████▍   | 4562036/7086503 [1:03:04<08:06, 5184.96it/s]读取数据:  64%|██████▍   | 4562604/7086503 [1:03:04<07:53, 5330.01it/s]读取数据:  64%|██████▍   | 4563150/7086503 [1:03:04<07:50, 5367.01it/s]读取数据:  64%|██████▍   | 4563730/7086503 [1:03:05<07:39, 5493.34it/s]读取数据:  64%|██████▍   | 4564283/7086503 [1:03:05<07:38, 5498.16it/s]读取数据:  64%|██████▍   | 4564862/7086503 [1:03:05<07:31, 5583.47it/s]读取数据:  64%|██████▍   | 4565434/7086503 [1:03:05<07:28, 5621.32it/s]读取数据:  64%|██████▍   | 4566012/7086503 [1:03:05<07:25, 5663.21it/s]读取数据:  64%|██████▍   | 4566613/7086503 [1:03:05<07:17, 5763.97it/s]读取数据:  64%|██████▍   | 4567206/7086503 [1:03:05<07:13, 5810.60it/s]读取数据:  64%|██████▍   | 4567833/7086503 [1:03:05<07:03, 5947.92it/s]读取数据:  64%|██████▍   | 4568459/7086503 [1:03:05<06:56, 6038.67it/s]读取数据:  64%|██████▍   | 4569072/7086503 [1:03:05<06:55, 6065.89it/s]读取数据:  64%|██████▍   | 4569748/7086503 [1:03:06<06:41, 6270.81it/s]读取数据:  64%|██████▍   | 4570383/7086503 [1:03:06<06:39, 6291.84it/s]读取数据:  65%|██████▍   | 4571013/7086503 [1:03:06<06:40, 6288.41it/s]读取数据:  65%|██████▍   | 4571695/7086503 [1:03:06<06:30, 6446.58it/s]读取数据:  65%|██████▍   | 4572360/7086503 [1:03:06<06:26, 6506.80it/s]读取数据:  65%|██████▍   | 4573034/7086503 [1:03:06<06:22, 6573.77it/s]读取数据:  65%|██████▍   | 4573702/7086503 [1:03:06<06:20, 6604.13it/s]读取数据:  65%|██████▍   | 4574363/7086503 [1:03:06<06:24, 6538.56it/s]读取数据:  65%|██████▍   | 4575094/7086503 [1:03:06<06:11, 6766.67it/s]读取数据:  65%|██████▍   | 4575850/7086503 [1:03:07<05:58, 7002.03it/s]读取数据:  65%|██████▍   | 4576582/7086503 [1:03:07<05:53, 7095.85it/s]读取数据:  65%|██████▍   | 4577391/7086503 [1:03:07<05:39, 7392.62it/s]读取数据:  65%|██████▍   | 4578166/7086503 [1:03:07<05:34, 7499.00it/s]读取数据:  65%|██████▍   | 4579001/7086503 [1:03:07<05:23, 7752.31it/s]读取数据:  65%|██████▍   | 4579833/7086503 [1:03:07<05:16, 7920.81it/s]读取数据:  65%|██████▍   | 4580701/7086503 [1:03:07<05:07, 8145.13it/s]读取数据:  65%|██████▍   | 4581614/7086503 [1:03:07<04:56, 8438.51it/s]读取数据:  65%|██████▍   | 4582573/7086503 [1:03:07<04:45, 8781.89it/s]读取数据:  65%|██████▍   | 4583580/7086503 [1:03:07<04:33, 9165.90it/s]读取数据:  65%|██████▍   | 4584631/7086503 [1:03:08<04:21, 9566.72it/s]读取数据:  65%|██████▍   | 4585740/7086503 [1:03:08<04:09, 10019.21it/s]读取数据:  65%|██████▍   | 4586853/7086503 [1:03:08<04:01, 10351.86it/s]读取数据:  65%|██████▍   | 4588020/7086503 [1:03:08<03:52, 10745.82it/s]读取数据:  65%|██████▍   | 4589176/7086503 [1:03:08<03:47, 10989.58it/s]读取数据:  65%|██████▍   | 4590352/7086503 [1:03:08<03:42, 11212.92it/s]读取数据:  65%|██████▍   | 4591487/7086503 [1:03:08<03:41, 11252.55it/s]读取数据:  65%|██████▍   | 4592613/7086503 [1:03:08<03:42, 11221.74it/s]读取数据:  65%|██████▍   | 4593757/7086503 [1:03:08<03:40, 11286.48it/s]读取数据:  65%|██████▍   | 4594909/7086503 [1:03:08<03:39, 11354.93it/s]读取数据:  65%|██████▍   | 4596054/7086503 [1:03:09<03:38, 11380.07it/s]读取数据:  65%|██████▍   | 4597193/7086503 [1:03:09<03:39, 11365.79it/s]读取数据:  65%|██████▍   | 4598350/7086503 [1:03:09<03:37, 11420.69it/s]读取数据:  65%|██████▍   | 4599493/7086503 [1:03:09<03:38, 11393.65it/s]读取数据:  65%|██████▍   | 4600633/7086503 [1:03:10<18:27, 2245.12it/s] 读取数据:  65%|██████▍   | 4601454/7086503 [1:03:10<15:55, 2602.08it/s]读取数据:  65%|██████▍   | 4602191/7086503 [1:03:11<14:15, 2902.45it/s]读取数据:  65%|██████▍   | 4602848/7086503 [1:03:11<12:49, 3227.73it/s]读取数据:  65%|██████▍   | 4603464/7086503 [1:03:11<11:37, 3558.90it/s]读取数据:  65%|██████▍   | 4604056/7086503 [1:03:11<10:38, 3888.36it/s]读取数据:  65%|██████▍   | 4604635/7086503 [1:03:11<09:49, 4210.75it/s]读取数据:  65%|██████▍   | 4605207/7086503 [1:03:11<09:17, 4447.11it/s]读取数据:  65%|██████▍   | 4605766/7086503 [1:03:11<08:54, 4645.22it/s]读取数据:  65%|██████▌   | 4606316/7086503 [1:03:11<08:38, 4781.34it/s]读取数据:  65%|██████▌   | 4606859/7086503 [1:03:11<08:21, 4942.72it/s]读取数据:  65%|██████▌   | 4607400/7086503 [1:03:12<08:13, 5027.30it/s]读取数据:  65%|██████▌   | 4607936/7086503 [1:03:12<08:11, 5044.09it/s]读取数据:  65%|██████▌   | 4608464/7086503 [1:03:12<08:05, 5099.69it/s]读取数据:  65%|██████▌   | 4608995/7086503 [1:03:12<08:00, 5157.88it/s]读取数据:  65%|██████▌   | 4609524/7086503 [1:03:12<07:56, 5195.60it/s]读取数据:  65%|██████▌   | 4610053/7086503 [1:03:12<07:55, 5210.70it/s]读取数据:  65%|██████▌   | 4610583/7086503 [1:03:12<07:52, 5235.58it/s]读取数据:  65%|██████▌   | 4611123/7086503 [1:03:12<07:48, 5283.61it/s]读取数据:  65%|██████▌   | 4611684/7086503 [1:03:12<07:40, 5376.76it/s]读取数据:  65%|██████▌   | 4612278/7086503 [1:03:12<07:26, 5539.95it/s]读取数据:  65%|██████▌   | 4612839/7086503 [1:03:13<07:24, 5559.97it/s]读取数据:  65%|██████▌   | 4613403/7086503 [1:03:13<07:23, 5577.88it/s]读取数据:  65%|██████▌   | 4613962/7086503 [1:03:13<07:24, 5565.50it/s]读取数据:  65%|██████▌   | 4614543/7086503 [1:03:13<07:18, 5636.26it/s]读取数据:  65%|██████▌   | 4615108/7086503 [1:03:13<07:20, 5604.83it/s]读取数据:  65%|██████▌   | 4615669/7086503 [1:03:13<07:26, 5531.65it/s]读取数据:  65%|██████▌   | 4616284/7086503 [1:03:13<07:12, 5706.66it/s]读取数据:  65%|██████▌   | 4616856/7086503 [1:03:13<07:12, 5706.19it/s]读取数据:  65%|██████▌   | 4617435/7086503 [1:03:13<07:10, 5729.45it/s]读取数据:  65%|██████▌   | 4618032/7086503 [1:03:13<07:05, 5800.39it/s]读取数据:  65%|██████▌   | 4618682/7086503 [1:03:14<06:50, 6007.47it/s]读取数据:  65%|██████▌   | 4619314/7086503 [1:03:14<06:44, 6097.84it/s]读取数据:  65%|██████▌   | 4619928/7086503 [1:03:14<06:43, 6109.34it/s]读取数据:  65%|██████▌   | 4620562/7086503 [1:03:14<06:39, 6177.46it/s]读取数据:  65%|██████▌   | 4621219/7086503 [1:03:14<06:31, 6292.64it/s]读取数据:  65%|██████▌   | 4621909/7086503 [1:03:14<06:20, 6473.42it/s]读取数据:  65%|██████▌   | 4622572/7086503 [1:03:14<06:17, 6519.64it/s]读取数据:  65%|██████▌   | 4623291/7086503 [1:03:14<06:06, 6717.80it/s]读取数据:  65%|██████▌   | 4623963/7086503 [1:03:14<06:07, 6696.41it/s]读取数据:  65%|██████▌   | 4624633/7086503 [1:03:14<06:18, 6510.70it/s]读取数据:  65%|██████▌   | 4625313/7086503 [1:03:15<06:13, 6594.15it/s]读取数据:  65%|██████▌   | 4626016/7086503 [1:03:15<06:06, 6722.26it/s]读取数据:  65%|██████▌   | 4626778/7086503 [1:03:15<05:51, 6987.98it/s]读取数据:  65%|██████▌   | 4627528/7086503 [1:03:15<05:44, 7139.85it/s]读取数据:  65%|██████▌   | 4628301/7086503 [1:03:15<05:36, 7315.34it/s]读取数据:  65%|██████▌   | 4629103/7086503 [1:03:15<05:26, 7524.56it/s]读取数据:  65%|██████▌   | 4629923/7086503 [1:03:15<05:17, 7726.49it/s]读取数据:  65%|██████▌   | 4630745/7086503 [1:03:15<05:12, 7869.94it/s]读取数据:  65%|██████▌   | 4631654/7086503 [1:03:15<04:58, 8235.12it/s]读取数据:  65%|██████▌   | 4632508/7086503 [1:03:15<04:54, 8322.88it/s]读取数据:  65%|██████▌   | 4633476/7086503 [1:03:16<04:41, 8725.15it/s]读取数据:  65%|██████▌   | 4634461/7086503 [1:03:16<04:30, 9061.28it/s]读取数据:  65%|██████▌   | 4635508/7086503 [1:03:16<04:18, 9481.86it/s]读取数据:  65%|██████▌   | 4636588/7086503 [1:03:16<04:08, 9873.92it/s]读取数据:  65%|██████▌   | 4637726/7086503 [1:03:16<03:57, 10323.58it/s]读取数据:  65%|██████▌   | 4638933/7086503 [1:03:16<03:45, 10845.26it/s]读取数据:  65%|██████▌   | 4640099/7086503 [1:03:16<03:40, 11087.85it/s]读取数据:  65%|██████▌   | 4641259/7086503 [1:03:16<03:37, 11240.48it/s]读取数据:  66%|██████▌   | 4642464/7086503 [1:03:16<03:32, 11479.61it/s]读取数据:  66%|██████▌   | 4643612/7086503 [1:03:16<03:32, 11470.70it/s]读取数据:  66%|██████▌   | 4644778/7086503 [1:03:17<03:31, 11526.46it/s]读取数据:  66%|██████▌   | 4645931/7086503 [1:03:17<03:31, 11526.09it/s]读取数据:  66%|██████▌   | 4647103/7086503 [1:03:17<03:30, 11583.34it/s]读取数据:  66%|██████▌   | 4648262/7086503 [1:03:17<03:30, 11573.45it/s]读取数据:  66%|██████▌   | 4649420/7086503 [1:03:17<03:31, 11542.31it/s]读取数据:  66%|██████▌   | 4650575/7086503 [1:03:18<12:50, 3159.74it/s] 读取数据:  66%|██████▌   | 4651419/7086503 [1:03:18<11:51, 3422.53it/s]读取数据:  66%|██████▌   | 4652150/7086503 [1:03:18<10:55, 3712.69it/s]读取数据:  66%|██████▌   | 4652818/7086503 [1:03:18<10:15, 3952.50it/s]读取数据:  66%|██████▌   | 4653437/7086503 [1:03:19<09:47, 4141.68it/s]读取数据:  66%|██████▌   | 4654018/7086503 [1:03:19<09:17, 4364.88it/s]读取数据:  66%|██████▌   | 4654583/7086503 [1:03:19<08:52, 4563.21it/s]读取数据:  66%|██████▌   | 4655138/7086503 [1:03:19<08:36, 4703.31it/s]读取数据:  66%|██████▌   | 4655688/7086503 [1:03:19<08:16, 4891.17it/s]读取数据:  66%|██████▌   | 4656233/7086503 [1:03:19<08:07, 4982.14it/s]读取数据:  66%|██████▌   | 4656772/7086503 [1:03:19<08:02, 5031.47it/s]读取数据:  66%|██████▌   | 4657342/7086503 [1:03:19<07:46, 5209.95it/s]读取数据:  66%|██████▌   | 4657885/7086503 [1:03:19<07:50, 5160.80it/s]读取数据:  66%|██████▌   | 4658417/7086503 [1:03:20<08:06, 4994.64it/s]读取数据:  66%|██████▌   | 4658942/7086503 [1:03:20<07:59, 5060.93it/s]读取数据:  66%|██████▌   | 4659499/7086503 [1:03:20<07:46, 5199.09it/s]读取数据:  66%|██████▌   | 4660039/7086503 [1:03:20<07:41, 5255.68it/s]读取数据:  66%|██████▌   | 4660603/7086503 [1:03:20<07:32, 5364.88it/s]读取数据:  66%|██████▌   | 4661144/7086503 [1:03:20<07:34, 5338.79it/s]读取数据:  66%|██████▌   | 4661718/7086503 [1:03:20<07:24, 5452.22it/s]读取数据:  66%|██████▌   | 4662266/7086503 [1:03:20<07:29, 5388.99it/s]读取数据:  66%|██████▌   | 4662808/7086503 [1:03:20<07:29, 5397.62it/s]读取数据:  66%|██████▌   | 4663386/7086503 [1:03:20<07:19, 5508.68it/s]读取数据:  66%|██████▌   | 4663945/7086503 [1:03:21<07:18, 5526.40it/s]读取数据:  66%|██████▌   | 4664514/7086503 [1:03:21<07:14, 5568.12it/s]读取数据:  66%|██████▌   | 4665113/7086503 [1:03:21<07:05, 5693.56it/s]读取数据:  66%|██████▌   | 4665706/7086503 [1:03:21<07:00, 5763.58it/s]读取数据:  66%|██████▌   | 4666290/7086503 [1:03:21<06:58, 5784.63it/s]读取数据:  66%|██████▌   | 4666889/7086503 [1:03:21<06:54, 5839.24it/s]读取数据:  66%|██████▌   | 4667494/7086503 [1:03:21<06:49, 5900.57it/s]读取数据:  66%|██████▌   | 4668136/7086503 [1:03:21<06:39, 6054.43it/s]读取数据:  66%|██████▌   | 4668742/7086503 [1:03:21<06:41, 6021.87it/s]读取数据:  66%|██████▌   | 4669382/7086503 [1:03:21<06:34, 6134.28it/s]读取数据:  66%|██████▌   | 4670013/7086503 [1:03:22<06:30, 6186.72it/s]读取数据:  66%|██████▌   | 4670650/7086503 [1:03:22<06:27, 6238.51it/s]读取数据:  66%|██████▌   | 4671319/7086503 [1:03:22<06:19, 6371.52it/s]读取数据:  66%|██████▌   | 4671987/7086503 [1:03:22<06:13, 6463.30it/s]读取数据:  66%|██████▌   | 4672634/7086503 [1:03:22<06:18, 6376.28it/s]读取数据:  66%|██████▌   | 4673272/7086503 [1:03:22<06:54, 5825.26it/s]读取数据:  66%|██████▌   | 4673933/7086503 [1:03:22<06:39, 6042.88it/s]读取数据:  66%|██████▌   | 4674611/7086503 [1:03:22<06:25, 6251.78it/s]读取数据:  66%|██████▌   | 4675323/7086503 [1:03:22<06:10, 6499.81it/s]读取数据:  66%|██████▌   | 4676012/7086503 [1:03:22<06:04, 6612.15it/s]读取数据:  66%|██████▌   | 4676706/7086503 [1:03:23<05:59, 6707.67it/s]读取数据:  66%|██████▌   | 4677452/7086503 [1:03:23<05:47, 6930.06it/s]读取数据:  66%|██████▌   | 4678148/7086503 [1:03:23<05:47, 6930.13it/s]读取数据:  66%|██████▌   | 4678857/7086503 [1:03:23<05:45, 6976.08it/s]读取数据:  66%|██████▌   | 4679628/7086503 [1:03:23<05:34, 7194.25it/s]读取数据:  66%|██████▌   | 4680462/7086503 [1:03:23<05:19, 7536.46it/s]读取数据:  66%|██████▌   | 4681297/7086503 [1:03:23<05:09, 7778.96it/s]读取数据:  66%|██████▌   | 4682199/7086503 [1:03:23<04:55, 8143.56it/s]读取数据:  66%|██████▌   | 4683116/7086503 [1:03:23<04:44, 8450.35it/s]读取数据:  66%|██████▌   | 4684031/7086503 [1:03:23<04:37, 8655.23it/s]读取数据:  66%|██████▌   | 4684989/7086503 [1:03:24<04:28, 8931.77it/s]读取数据:  66%|██████▌   | 4685912/7086503 [1:03:24<04:26, 9015.17it/s]读取数据:  66%|██████▌   | 4686964/7086503 [1:03:24<04:13, 9464.01it/s]读取数据:  66%|██████▌   | 4688092/7086503 [1:03:24<03:59, 10006.72it/s]读取数据:  66%|██████▌   | 4689257/7086503 [1:03:24<03:48, 10498.26it/s]读取数据:  66%|██████▌   | 4690470/7086503 [1:03:24<03:38, 10984.73it/s]读取数据:  66%|██████▌   | 4691667/7086503 [1:03:24<03:32, 11277.42it/s]读取数据:  66%|██████▌   | 4692853/7086503 [1:03:24<03:29, 11449.33it/s]读取数据:  66%|██████▌   | 4694055/7086503 [1:03:24<03:25, 11618.12it/s]读取数据:  66%|██████▋   | 4695217/7086503 [1:03:24<03:28, 11482.30it/s]读取数据:  66%|██████▋   | 4696366/7086503 [1:03:25<03:29, 11421.11it/s]读取数据:  66%|██████▋   | 4697509/7086503 [1:03:25<03:29, 11415.39it/s]读取数据:  66%|██████▋   | 4698651/7086503 [1:03:25<03:30, 11355.43it/s]读取数据:  66%|██████▋   | 4699798/7086503 [1:03:25<03:29, 11384.40it/s]读取数据:  66%|██████▋   | 4700937/7086503 [1:03:26<13:13, 3006.34it/s] 读取数据:  66%|██████▋   | 4701768/7086503 [1:03:26<11:55, 3333.67it/s]读取数据:  66%|██████▋   | 4702503/7086503 [1:03:26<10:58, 3618.79it/s]读取数据:  66%|██████▋   | 4703170/7086503 [1:03:26<10:14, 3875.66it/s]读取数据:  66%|██████▋   | 4703789/7086503 [1:03:26<09:34, 4148.60it/s]读取数据:  66%|██████▋   | 4704385/7086503 [1:03:27<09:13, 4306.21it/s]读取数据:  66%|██████▋   | 4704949/7086503 [1:03:27<08:48, 4504.93it/s]读取数据:  66%|██████▋   | 4705501/7086503 [1:03:27<08:30, 4662.46it/s]读取数据:  66%|██████▋   | 4706043/7086503 [1:03:27<08:13, 4820.32it/s]读取数据:  66%|██████▋   | 4706582/7086503 [1:03:27<08:02, 4928.82it/s]读取数据:  66%|██████▋   | 4707132/7086503 [1:03:27<07:48, 5075.74it/s]读取数据:  66%|██████▋   | 4707671/7086503 [1:03:27<07:45, 5107.34it/s]读取数据:  66%|██████▋   | 4708204/7086503 [1:03:27<07:42, 5137.41it/s]读取数据:  66%|██████▋   | 4708734/7086503 [1:03:27<07:43, 5134.48it/s]读取数据:  66%|██████▋   | 4709299/7086503 [1:03:28<07:30, 5281.92it/s]读取数据:  66%|██████▋   | 4709836/7086503 [1:03:28<07:31, 5264.52it/s]读取数据:  66%|██████▋   | 4710418/7086503 [1:03:28<07:18, 5423.34it/s]读取数据:  66%|██████▋   | 4710975/7086503 [1:03:28<07:14, 5464.38it/s]读取数据:  66%|██████▋   | 4711525/7086503 [1:03:28<07:15, 5450.93it/s]读取数据:  66%|██████▋   | 4712075/7086503 [1:03:28<07:15, 5452.65it/s]读取数据:  67%|██████▋   | 4712625/7086503 [1:03:28<07:14, 5459.14it/s]读取数据:  67%|██████▋   | 4713180/7086503 [1:03:28<07:12, 5485.91it/s]读取数据:  67%|██████▋   | 4713747/7086503 [1:03:28<07:08, 5538.74it/s]读取数据:  67%|██████▋   | 4714305/7086503 [1:03:28<07:07, 5550.26it/s]读取数据:  67%|██████▋   | 4714867/7086503 [1:03:29<07:05, 5570.82it/s]读取数据:  67%|██████▋   | 4715455/7086503 [1:03:29<06:58, 5662.62it/s]读取数据:  67%|██████▋   | 4716039/7086503 [1:03:29<06:54, 5715.67it/s]读取数据:  67%|██████▋   | 4716640/7086503 [1:03:29<06:48, 5802.98it/s]读取数据:  67%|██████▋   | 4717245/7086503 [1:03:29<06:43, 5876.87it/s]读取数据:  67%|██████▋   | 4717833/7086503 [1:03:29<06:47, 5812.86it/s]读取数据:  67%|██████▋   | 4718425/7086503 [1:03:29<06:45, 5841.94it/s]读取数据:  67%|██████▋   | 4719040/7086503 [1:03:29<06:39, 5933.45it/s]读取数据:  67%|██████▋   | 4719646/7086503 [1:03:29<06:36, 5967.14it/s]读取数据:  67%|██████▋   | 4720263/7086503 [1:03:29<06:32, 6026.98it/s]读取数据:  67%|██████▋   | 4720903/7086503 [1:03:30<06:25, 6136.48it/s]读取数据:  67%|██████▋   | 4721548/7086503 [1:03:30<06:19, 6229.75it/s]读取数据:  67%|██████▋   | 4722189/7086503 [1:03:30<06:16, 6282.83it/s]读取数据:  67%|██████▋   | 4722888/7086503 [1:03:30<06:03, 6494.20it/s]读取数据:  67%|██████▋   | 4723567/7086503 [1:03:30<05:59, 6575.66it/s]读取数据:  67%|██████▋   | 4724225/7086503 [1:03:30<06:01, 6540.00it/s]读取数据:  67%|██████▋   | 4724898/7086503 [1:03:30<05:58, 6595.77it/s]读取数据:  67%|██████▋   | 4725595/7086503 [1:03:30<05:52, 6706.55it/s]读取数据:  67%|██████▋   | 4726304/7086503 [1:03:30<05:46, 6819.16it/s]读取数据:  67%|██████▋   | 4727051/7086503 [1:03:30<05:36, 7010.36it/s]读取数据:  67%|██████▋   | 4727775/7086503 [1:03:31<05:33, 7077.99it/s]读取数据:  67%|██████▋   | 4728534/7086503 [1:03:31<05:26, 7230.80it/s]读取数据:  67%|██████▋   | 4729299/7086503 [1:03:31<05:20, 7356.23it/s]读取数据:  67%|██████▋   | 4730093/7086503 [1:03:31<05:12, 7529.28it/s]读取数据:  67%|██████▋   | 4730969/7086503 [1:03:31<04:58, 7896.49it/s]读取数据:  67%|██████▋   | 4731808/7086503 [1:03:31<04:52, 8039.06it/s]读取数据:  67%|██████▋   | 4732651/7086503 [1:03:31<04:48, 8155.83it/s]读取数据:  67%|██████▋   | 4733533/7086503 [1:03:31<04:41, 8352.37it/s]读取数据:  67%|██████▋   | 4734451/7086503 [1:03:31<04:33, 8596.62it/s]读取数据:  67%|██████▋   | 4735473/7086503 [1:03:31<04:19, 9074.70it/s]读取数据:  67%|██████▋   | 4736461/7086503 [1:03:32<04:12, 9315.71it/s]读取数据:  67%|██████▋   | 4737511/7086503 [1:03:32<04:02, 9667.59it/s]读取数据:  67%|██████▋   | 4738604/7086503 [1:03:32<03:53, 10045.65it/s]读取数据:  67%|██████▋   | 4739769/7086503 [1:03:32<03:42, 10525.45it/s]读取数据:  67%|██████▋   | 4740972/7086503 [1:03:32<03:33, 10976.20it/s]读取数据:  67%|██████▋   | 4742173/7086503 [1:03:32<03:27, 11285.61it/s]读取数据:  67%|██████▋   | 4743377/7086503 [1:03:32<03:23, 11511.62it/s]读取数据:  67%|██████▋   | 4744622/7086503 [1:03:32<03:18, 11790.71it/s]读取数据:  67%|██████▋   | 4745806/7086503 [1:03:32<03:18, 11803.73it/s]读取数据:  67%|██████▋   | 4746987/7086503 [1:03:32<03:20, 11685.52it/s]读取数据:  67%|██████▋   | 4748156/7086503 [1:03:33<03:22, 11570.84it/s]读取数据:  67%|██████▋   | 4749335/7086503 [1:03:33<03:20, 11631.66it/s]读取数据:  67%|██████▋   | 4750499/7086503 [1:03:34<12:15, 3175.33it/s] 读取数据:  67%|██████▋   | 4751349/7086503 [1:03:34<11:12, 3471.46it/s]读取数据:  67%|██████▋   | 4752093/7086503 [1:03:34<10:25, 3729.86it/s]读取数据:  67%|██████▋   | 4752763/7086503 [1:03:34<09:49, 3959.02it/s]读取数据:  67%|██████▋   | 4753383/7086503 [1:03:34<09:21, 4155.32it/s]读取数据:  67%|██████▋   | 4753966/7086503 [1:03:34<09:01, 4304.43it/s]读取数据:  67%|██████▋   | 4754520/7086503 [1:03:34<08:36, 4511.59it/s]读取数据:  67%|██████▋   | 4755067/7086503 [1:03:35<08:19, 4668.95it/s]读取数据:  67%|██████▋   | 4755606/7086503 [1:03:35<08:05, 4801.29it/s]读取数据:  67%|██████▋   | 4756140/7086503 [1:03:35<07:53, 4926.59it/s]读取数据:  67%|██████▋   | 4756686/7086503 [1:03:35<07:39, 5066.79it/s]读取数据:  67%|██████▋   | 4757223/7086503 [1:03:35<07:41, 5042.94it/s]读取数据:  67%|██████▋   | 4757771/7086503 [1:03:35<07:31, 5157.32it/s]读取数据:  67%|██████▋   | 4758321/7086503 [1:03:35<07:23, 5253.39it/s]读取数据:  67%|██████▋   | 4758879/7086503 [1:03:35<07:15, 5346.78it/s]读取数据:  67%|██████▋   | 4759422/7086503 [1:03:35<07:22, 5258.54it/s]读取数据:  67%|██████▋   | 4759979/7086503 [1:03:35<07:15, 5347.84it/s]读取数据:  67%|██████▋   | 4760564/7086503 [1:03:36<07:03, 5493.09it/s]读取数据:  67%|██████▋   | 4761133/7086503 [1:03:36<06:59, 5548.53it/s]读取数据:  67%|██████▋   | 4761691/7086503 [1:03:36<07:09, 5411.12it/s]读取数据:  67%|██████▋   | 4762235/7086503 [1:03:36<07:08, 5419.14it/s]读取数据:  67%|██████▋   | 4762780/7086503 [1:03:36<07:08, 5425.23it/s]读取数据:  67%|██████▋   | 4763324/7086503 [1:03:36<07:14, 5350.23it/s]读取数据:  67%|██████▋   | 4763893/7086503 [1:03:36<07:06, 5446.28it/s]读取数据:  67%|██████▋   | 4764453/7086503 [1:03:36<07:02, 5490.72it/s]读取数据:  67%|██████▋   | 4765048/7086503 [1:03:36<06:52, 5626.14it/s]读取数据:  67%|██████▋   | 4765626/7086503 [1:03:36<06:49, 5670.92it/s]读取数据:  67%|██████▋   | 4766214/7086503 [1:03:37<06:44, 5731.01it/s]读取数据:  67%|██████▋   | 4766797/7086503 [1:03:37<06:42, 5759.69it/s]读取数据:  67%|██████▋   | 4767374/7086503 [1:03:37<06:46, 5698.46it/s]读取数据:  67%|██████▋   | 4767981/7086503 [1:03:37<06:39, 5808.46it/s]读取数据:  67%|██████▋   | 4768563/7086503 [1:03:37<06:41, 5771.06it/s]读取数据:  67%|██████▋   | 4769185/7086503 [1:03:37<06:32, 5904.08it/s]读取数据:  67%|██████▋   | 4769800/7086503 [1:03:37<06:28, 5968.37it/s]读取数据:  67%|██████▋   | 4770446/7086503 [1:03:37<06:18, 6114.66it/s]读取数据:  67%|██████▋   | 4771058/7086503 [1:03:37<06:20, 6088.61it/s]读取数据:  67%|██████▋   | 4771696/7086503 [1:03:37<06:15, 6172.58it/s]读取数据:  67%|██████▋   | 4772373/7086503 [1:03:38<06:04, 6349.63it/s]读取数据:  67%|██████▋   | 4773009/7086503 [1:03:38<06:07, 6291.29it/s]读取数据:  67%|██████▋   | 4773663/7086503 [1:03:38<06:03, 6361.05it/s]读取数据:  67%|██████▋   | 4774300/7086503 [1:03:38<06:05, 6322.74it/s]读取数据:  67%|██████▋   | 4775016/7086503 [1:03:38<05:51, 6571.46it/s]读取数据:  67%|██████▋   | 4775722/7086503 [1:03:38<05:44, 6716.68it/s]读取数据:  67%|██████▋   | 4776436/7086503 [1:03:38<05:37, 6841.01it/s]读取数据:  67%|██████▋   | 4777197/7086503 [1:03:38<05:26, 7070.31it/s]读取数据:  67%|██████▋   | 4777905/7086503 [1:03:38<05:26, 7070.02it/s]读取数据:  67%|██████▋   | 4778639/7086503 [1:03:38<05:22, 7150.21it/s]读取数据:  67%|██████▋   | 4779413/7086503 [1:03:39<05:14, 7325.58it/s]读取数据:  67%|██████▋   | 4780231/7086503 [1:03:39<05:04, 7578.87it/s]读取数据:  67%|██████▋   | 4781034/7086503 [1:03:39<04:58, 7713.57it/s]读取数据:  67%|██████▋   | 4781857/7086503 [1:03:39<04:53, 7865.62it/s]读取数据:  67%|██████▋   | 4782724/7086503 [1:03:39<04:44, 8106.28it/s]读取数据:  68%|██████▊   | 4783666/7086503 [1:03:39<04:30, 8499.23it/s]读取数据:  68%|██████▊   | 4784575/7086503 [1:03:39<04:25, 8674.46it/s]读取数据:  68%|██████▊   | 4785516/7086503 [1:03:39<04:18, 8894.79it/s]读取数据:  68%|██████▊   | 4786502/7086503 [1:03:39<04:10, 9181.82it/s]读取数据:  68%|██████▊   | 4787501/7086503 [1:03:39<04:03, 9422.26it/s]读取数据:  68%|██████▊   | 4788617/7086503 [1:03:40<03:51, 9942.58it/s]读取数据:  68%|██████▊   | 4789776/7086503 [1:03:40<03:40, 10433.75it/s]读取数据:  68%|██████▊   | 4791011/7086503 [1:03:40<03:28, 10999.96it/s]读取数据:  68%|██████▊   | 4792221/7086503 [1:03:40<03:22, 11328.12it/s]读取数据:  68%|██████▊   | 4793495/7086503 [1:03:40<03:15, 11745.66it/s]读取数据:  68%|██████▊   | 4794738/7086503 [1:03:40<03:11, 11950.69it/s]读取数据:  68%|██████▊   | 4795934/7086503 [1:03:40<03:11, 11942.55it/s]读取数据:  68%|██████▊   | 4797129/7086503 [1:03:40<03:14, 11765.17it/s]读取数据:  68%|██████▊   | 4798307/7086503 [1:03:40<03:19, 11472.08it/s]读取数据:  68%|██████▊   | 4799456/7086503 [1:03:40<03:21, 11371.31it/s]读取数据:  68%|██████▊   | 4800595/7086503 [1:03:42<12:31, 3040.62it/s] 读取数据:  68%|██████▊   | 4801425/7086503 [1:03:42<11:23, 3341.46it/s]读取数据:  68%|██████▊   | 4802155/7086503 [1:03:42<10:28, 3632.50it/s]读取数据:  68%|██████▊   | 4802821/7086503 [1:03:42<09:50, 3870.14it/s]读取数据:  68%|██████▊   | 4803436/7086503 [1:03:42<09:13, 4122.21it/s]读取数据:  68%|██████▊   | 4804025/7086503 [1:03:42<08:48, 4321.36it/s]读取数据:  68%|██████▊   | 4804590/7086503 [1:03:42<08:27, 4499.81it/s]读取数据:  68%|██████▊   | 4805164/7086503 [1:03:42<07:58, 4771.18it/s]读取数据:  68%|██████▊   | 4805721/7086503 [1:03:43<07:47, 4875.71it/s]读取数据:  68%|██████▊   | 4806267/7086503 [1:03:43<07:49, 4851.74it/s]读取数据:  68%|██████▊   | 4806813/7086503 [1:03:43<07:35, 5004.34it/s]读取数据:  68%|██████▊   | 4807345/7086503 [1:03:43<07:28, 5078.63it/s]读取数据:  68%|██████▊   | 4807909/7086503 [1:03:43<07:15, 5232.55it/s]读取数据:  68%|██████▊   | 4808450/7086503 [1:03:43<07:11, 5280.12it/s]读取数据:  68%|██████▊   | 4809016/7086503 [1:03:43<07:02, 5388.77it/s]读取数据:  68%|██████▊   | 4809564/7086503 [1:03:43<07:00, 5412.06it/s]读取数据:  68%|██████▊   | 4810112/7086503 [1:03:43<07:03, 5371.76it/s]读取数据:  68%|██████▊   | 4810669/7086503 [1:03:43<06:59, 5424.23it/s]读取数据:  68%|██████▊   | 4811215/7086503 [1:03:44<07:05, 5342.40it/s]读取数据:  68%|██████▊   | 4811774/7086503 [1:03:44<07:00, 5413.81it/s]读取数据:  68%|██████▊   | 4812372/7086503 [1:03:44<06:47, 5580.30it/s]读取数据:  68%|██████▊   | 4812932/7086503 [1:03:44<06:53, 5504.31it/s]读取数据:  68%|██████▊   | 4813484/7086503 [1:03:44<06:56, 5463.16it/s]读取数据:  68%|██████▊   | 4814032/7086503 [1:03:44<06:55, 5467.97it/s]读取数据:  68%|██████▊   | 4814603/7086503 [1:03:44<06:50, 5537.75it/s]读取数据:  68%|██████▊   | 4815194/7086503 [1:03:44<06:42, 5647.78it/s]读取数据:  68%|██████▊   | 4815760/7086503 [1:03:44<06:48, 5555.86it/s]读取数据:  68%|██████▊   | 4816338/7086503 [1:03:44<06:43, 5620.50it/s]读取数据:  68%|██████▊   | 4816901/7086503 [1:03:45<06:50, 5532.23it/s]读取数据:  68%|██████▊   | 4817469/7086503 [1:03:45<06:46, 5575.62it/s]读取数据:  68%|██████▊   | 4818071/7086503 [1:03:45<06:37, 5706.56it/s]读取数据:  68%|██████▊   | 4818679/7086503 [1:03:45<06:30, 5812.60it/s]读取数据:  68%|██████▊   | 4819286/7086503 [1:03:45<06:25, 5883.86it/s]读取数据:  68%|██████▊   | 4819910/7086503 [1:03:45<06:18, 5987.58it/s]读取数据:  68%|██████▊   | 4820513/7086503 [1:03:45<06:17, 5999.96it/s]读取数据:  68%|██████▊   | 4821114/7086503 [1:03:45<06:17, 5997.95it/s]读取数据:  68%|██████▊   | 4821788/7086503 [1:03:45<06:04, 6216.12it/s]读取数据:  68%|██████▊   | 4822410/7086503 [1:03:45<06:06, 6180.79it/s]读取数据:  68%|██████▊   | 4823052/7086503 [1:03:46<06:02, 6251.58it/s]读取数据:  68%|██████▊   | 4823699/7086503 [1:03:46<05:58, 6316.50it/s]读取数据:  68%|██████▊   | 4824361/7086503 [1:03:46<05:53, 6403.46it/s]读取数据:  68%|██████▊   | 4825010/7086503 [1:03:46<05:51, 6427.84it/s]读取数据:  68%|██████▊   | 4825671/7086503 [1:03:46<05:48, 6480.73it/s]读取数据:  68%|██████▊   | 4826371/7086503 [1:03:46<05:40, 6633.28it/s]读取数据:  68%|██████▊   | 4827081/7086503 [1:03:46<05:33, 6771.57it/s]读取数据:  68%|██████▊   | 4827813/7086503 [1:03:46<05:25, 6934.29it/s]读取数据:  68%|██████▊   | 4828575/7086503 [1:03:46<05:16, 7135.58it/s]读取数据:  68%|██████▊   | 4829311/7086503 [1:03:46<05:13, 7201.08it/s]读取数据:  68%|██████▊   | 4830104/7086503 [1:03:47<05:04, 7416.38it/s]读取数据:  68%|██████▊   | 4830846/7086503 [1:03:47<05:04, 7412.86it/s]读取数据:  68%|██████▊   | 4831681/7086503 [1:03:47<04:53, 7691.62it/s]读取数据:  68%|██████▊   | 4832514/7086503 [1:03:47<04:46, 7881.04it/s]读取数据:  68%|██████▊   | 4833331/7086503 [1:03:47<04:42, 7963.68it/s]读取数据:  68%|██████▊   | 4834194/7086503 [1:03:47<04:35, 8160.55it/s]读取数据:  68%|██████▊   | 4835114/7086503 [1:03:47<04:25, 8470.97it/s]读取数据:  68%|██████▊   | 4836067/7086503 [1:03:47<04:16, 8785.62it/s]读取数据:  68%|██████▊   | 4837102/7086503 [1:03:47<04:03, 9252.90it/s]读取数据:  68%|██████▊   | 4838189/7086503 [1:03:47<03:50, 9736.19it/s]读取数据:  68%|██████▊   | 4839296/7086503 [1:03:48<03:41, 10134.59it/s]读取数据:  68%|██████▊   | 4840466/7086503 [1:03:48<03:31, 10599.26it/s]读取数据:  68%|██████▊   | 4841685/7086503 [1:03:48<03:22, 11072.93it/s]读取数据:  68%|██████▊   | 4842918/7086503 [1:03:48<03:15, 11449.17it/s]读取数据:  68%|██████▊   | 4844157/7086503 [1:03:48<03:11, 11727.71it/s]读取数据:  68%|██████▊   | 4845418/7086503 [1:03:48<03:06, 11991.44it/s]读取数据:  68%|██████▊   | 4846632/7086503 [1:03:48<03:06, 12034.79it/s]读取数据:  68%|██████▊   | 4847836/7086503 [1:03:48<03:09, 11822.21it/s]读取数据:  68%|██████▊   | 4849020/7086503 [1:03:48<03:11, 11714.41it/s]读取数据:  68%|██████▊   | 4850193/7086503 [1:03:49<11:50, 3147.93it/s] 读取数据:  68%|██████▊   | 4851048/7086503 [1:03:50<10:44, 3471.13it/s]读取数据:  68%|██████▊   | 4851803/7086503 [1:03:50<09:56, 3747.42it/s]读取数据:  68%|██████▊   | 4852485/7086503 [1:03:50<09:17, 4007.85it/s]读取数据:  68%|██████▊   | 4853120/7086503 [1:03:50<08:52, 4193.98it/s]读取数据:  68%|██████▊   | 4853713/7086503 [1:03:50<08:27, 4397.23it/s]读取数据:  69%|██████▊   | 4854285/7086503 [1:03:50<08:07, 4578.36it/s]读取数据:  69%|██████▊   | 4854843/7086503 [1:03:50<07:56, 4686.18it/s]读取数据:  69%|██████▊   | 4855384/7086503 [1:03:50<07:41, 4838.78it/s]读取数据:  69%|██████▊   | 4855923/7086503 [1:03:51<07:32, 4925.03it/s]读取数据:  69%|██████▊   | 4856456/7086503 [1:03:51<07:31, 4944.30it/s]读取数据:  69%|██████▊   | 4856979/7086503 [1:03:51<07:29, 4959.48it/s]读取数据:  69%|██████▊   | 4857498/7086503 [1:03:51<07:23, 5021.12it/s]读取数据:  69%|██████▊   | 4858024/7086503 [1:03:51<07:17, 5088.40it/s]读取数据:  69%|██████▊   | 4858544/7086503 [1:03:51<07:18, 5083.69it/s]读取数据:  69%|██████▊   | 4859088/7086503 [1:03:51<07:09, 5183.51it/s]读取数据:  69%|██████▊   | 4859627/7086503 [1:03:51<07:04, 5242.38it/s]读取数据:  69%|██████▊   | 4860197/7086503 [1:03:51<06:54, 5373.99it/s]读取数据:  69%|██████▊   | 4860738/7086503 [1:03:51<06:56, 5339.43it/s]读取数据:  69%|██████▊   | 4861297/7086503 [1:03:52<06:51, 5411.69it/s]读取数据:  69%|██████▊   | 4861871/7086503 [1:03:52<06:43, 5507.40it/s]读取数据:  69%|██████▊   | 4862423/7086503 [1:03:52<06:45, 5485.81it/s]读取数据:  69%|██████▊   | 4862988/7086503 [1:03:52<06:41, 5534.32it/s]读取数据:  69%|██████▊   | 4863543/7086503 [1:03:52<06:44, 5499.98it/s]读取数据:  69%|██████▊   | 4864109/7086503 [1:03:52<06:40, 5547.06it/s]读取数据:  69%|██████▊   | 4864695/7086503 [1:03:52<06:34, 5637.10it/s]读取数据:  69%|██████▊   | 4865283/7086503 [1:03:52<06:29, 5708.61it/s]读取数据:  69%|██████▊   | 4865875/7086503 [1:03:52<06:24, 5771.54it/s]读取数据:  69%|██████▊   | 4866470/7086503 [1:03:52<06:21, 5824.49it/s]读取数据:  69%|██████▊   | 4867053/7086503 [1:03:53<06:28, 5713.73it/s]读取数据:  69%|██████▊   | 4867651/7086503 [1:03:53<06:23, 5788.24it/s]读取数据:  69%|██████▊   | 4868263/7086503 [1:03:53<06:16, 5884.08it/s]读取数据:  69%|██████▊   | 4868852/7086503 [1:03:53<06:17, 5882.09it/s]读取数据:  69%|██████▊   | 4869441/7086503 [1:03:53<06:16, 5881.46it/s]读取数据:  69%|██████▊   | 4870030/7086503 [1:03:53<06:17, 5872.11it/s]读取数据:  69%|██████▊   | 4870643/7086503 [1:03:53<06:12, 5945.49it/s]读取数据:  69%|██████▊   | 4871270/7086503 [1:03:53<06:06, 6040.81it/s]读取数据:  69%|██████▊   | 4871900/7086503 [1:03:53<06:01, 6118.20it/s]读取数据:  69%|██████▉   | 4872522/7086503 [1:03:53<06:00, 6148.18it/s]读取数据:  69%|██████▉   | 4873164/7086503 [1:03:54<05:55, 6227.58it/s]读取数据:  69%|██████▉   | 4873825/7086503 [1:03:54<05:48, 6340.33it/s]读取数据:  69%|██████▉   | 4874460/7086503 [1:03:54<05:49, 6326.80it/s]读取数据:  69%|██████▉   | 4875133/7086503 [1:03:54<05:43, 6441.57it/s]读取数据:  69%|██████▉   | 4875807/7086503 [1:03:54<05:38, 6529.96it/s]读取数据:  69%|██████▉   | 4876485/7086503 [1:03:54<05:34, 6604.60it/s]读取数据:  69%|██████▉   | 4877185/7086503 [1:03:54<05:28, 6722.63it/s]读取数据:  69%|██████▉   | 4877888/7086503 [1:03:54<05:24, 6812.41it/s]读取数据:  69%|██████▉   | 4878587/7086503 [1:03:54<05:21, 6859.24it/s]读取数据:  69%|██████▉   | 4879356/7086503 [1:03:54<05:10, 7107.45it/s]读取数据:  69%|██████▉   | 4880107/7086503 [1:03:55<05:05, 7227.24it/s]读取数据:  69%|██████▉   | 4880883/7086503 [1:03:55<04:58, 7383.03it/s]读取数据:  69%|██████▉   | 4881671/7086503 [1:03:55<04:52, 7531.15it/s]读取数据:  69%|██████▉   | 4882500/7086503 [1:03:55<04:44, 7758.55it/s]读取数据:  69%|██████▉   | 4883330/7086503 [1:03:55<04:38, 7915.90it/s]读取数据:  69%|██████▉   | 4884122/7086503 [1:03:55<06:18, 5820.40it/s]读取数据:  69%|██████▉   | 4884785/7086503 [1:03:55<07:02, 5206.15it/s]读取数据:  69%|██████▉   | 4885547/7086503 [1:03:55<06:22, 5757.45it/s]读取数据:  69%|██████▉   | 4886435/7086503 [1:03:56<05:37, 6522.63it/s]读取数据:  69%|██████▉   | 4887315/7086503 [1:03:56<05:09, 7107.99it/s]读取数据:  69%|██████▉   | 4888077/7086503 [1:03:56<05:06, 7164.26it/s]读取数据:  69%|██████▉   | 4888994/7086503 [1:03:56<04:44, 7717.91it/s]读取数据:  69%|██████▉   | 4889925/7086503 [1:03:56<04:28, 8168.14it/s]读取数据:  69%|██████▉   | 4890873/7086503 [1:03:56<04:16, 8545.33it/s]读取数据:  69%|██████▉   | 4891804/7086503 [1:03:56<04:10, 8766.82it/s]读取数据:  69%|██████▉   | 4892745/7086503 [1:03:56<04:04, 8955.01it/s]读取数据:  69%|██████▉   | 4893651/7086503 [1:03:56<04:48, 7604.93it/s]读取数据:  69%|██████▉   | 4894632/7086503 [1:03:57<04:27, 8182.21it/s]读取数据:  69%|██████▉   | 4895639/7086503 [1:03:57<04:11, 8697.88it/s]读取数据:  69%|██████▉   | 4896620/7086503 [1:03:57<04:03, 9007.41it/s]读取数据:  69%|██████▉   | 4897652/7086503 [1:03:57<03:53, 9380.84it/s]读取数据:  69%|██████▉   | 4898630/7086503 [1:03:57<03:50, 9493.18it/s]读取数据:  69%|██████▉   | 4899593/7086503 [1:03:57<03:50, 9496.91it/s]读取数据:  69%|██████▉   | 4900552/7086503 [1:03:58<14:51, 2452.48it/s]读取数据:  69%|██████▉   | 4901250/7086503 [1:03:58<13:09, 2766.68it/s]读取数据:  69%|██████▉   | 4901881/7086503 [1:03:58<11:51, 3070.49it/s]读取数据:  69%|██████▉   | 4902467/7086503 [1:03:58<10:53, 3340.78it/s]读取数据:  69%|██████▉   | 4903018/7086503 [1:03:59<10:10, 3577.48it/s]读取数据:  69%|██████▉   | 4903542/7086503 [1:03:59<09:35, 3792.86it/s]读取数据:  69%|██████▉   | 4904048/7086503 [1:03:59<09:15, 3925.39it/s]读取数据:  69%|██████▉   | 4904534/7086503 [1:03:59<08:53, 4092.87it/s]读取数据:  69%|██████▉   | 4905037/7086503 [1:03:59<08:25, 4312.24it/s]读取数据:  69%|██████▉   | 4905562/7086503 [1:03:59<07:59, 4548.90it/s]读取数据:  69%|██████▉   | 4906088/7086503 [1:03:59<07:40, 4735.54it/s]读取数据:  69%|██████▉   | 4906594/7086503 [1:03:59<07:32, 4814.88it/s]读取数据:  69%|██████▉   | 4907103/7086503 [1:03:59<07:25, 4891.83it/s]读取数据:  69%|██████▉   | 4907610/7086503 [1:04:00<07:22, 4919.11it/s]读取数据:  69%|██████▉   | 4908114/7086503 [1:04:00<07:23, 4912.12it/s]读取数据:  69%|██████▉   | 4908623/7086503 [1:04:00<07:18, 4962.23it/s]读取数据:  69%|██████▉   | 4909126/7086503 [1:04:00<09:39, 3754.77it/s]读取数据:  69%|██████▉   | 4909662/7086503 [1:04:00<08:46, 4137.13it/s]读取数据:  69%|██████▉   | 4910139/7086503 [1:04:00<08:26, 4298.26it/s]读取数据:  69%|██████▉   | 4910643/7086503 [1:04:00<08:04, 4492.54it/s]读取数据:  69%|██████▉   | 4911140/7086503 [1:04:00<07:50, 4622.48it/s]读取数据:  69%|██████▉   | 4911621/7086503 [1:04:01<09:59, 3628.18it/s]读取数据:  69%|██████▉   | 4912158/7086503 [1:04:01<08:57, 4041.68it/s]读取数据:  69%|██████▉   | 4912690/7086503 [1:04:01<08:18, 4365.06it/s]读取数据:  69%|██████▉   | 4913213/7086503 [1:04:01<07:52, 4595.31it/s]读取数据:  69%|██████▉   | 4913701/7086503 [1:04:01<07:45, 4664.29it/s]读取数据:  69%|██████▉   | 4914215/7086503 [1:04:01<07:32, 4796.29it/s]读取数据:  69%|██████▉   | 4914718/7086503 [1:04:01<07:26, 4861.30it/s]读取数据:  69%|██████▉   | 4915261/7086503 [1:04:01<07:11, 5026.54it/s]读取数据:  69%|██████▉   | 4915774/7086503 [1:04:01<07:09, 5055.80it/s]读取数据:  69%|██████▉   | 4916318/7086503 [1:04:01<06:59, 5169.14it/s]读取数据:  69%|██████▉   | 4916875/7086503 [1:04:02<06:50, 5282.39it/s]读取数据:  69%|██████▉   | 4917446/7086503 [1:04:02<06:41, 5408.25it/s]读取数据:  69%|██████▉   | 4917990/7086503 [1:04:02<06:45, 5347.99it/s]读取数据:  69%|██████▉   | 4918529/7086503 [1:04:02<06:44, 5360.34it/s]读取数据:  69%|██████▉   | 4919067/7086503 [1:04:02<06:45, 5340.26it/s]读取数据:  69%|██████▉   | 4919629/7086503 [1:04:02<06:39, 5422.41it/s]读取数据:  69%|██████▉   | 4920196/7086503 [1:04:02<06:34, 5496.09it/s]读取数据:  69%|██████▉   | 4920747/7086503 [1:04:02<06:37, 5449.42it/s]读取数据:  69%|██████▉   | 4921296/7086503 [1:04:02<06:36, 5456.84it/s]读取数据:  69%|██████▉   | 4921872/7086503 [1:04:02<06:30, 5546.44it/s]读取数据:  69%|██████▉   | 4922436/7086503 [1:04:03<06:28, 5572.12it/s]读取数据:  69%|██████▉   | 4923029/7086503 [1:04:03<06:21, 5674.91it/s]读取数据:  69%|██████▉   | 4923597/7086503 [1:04:03<06:21, 5669.46it/s]读取数据:  69%|██████▉   | 4924209/7086503 [1:04:03<06:12, 5800.47it/s]读取数据:  69%|██████▉   | 4924822/7086503 [1:04:03<06:06, 5895.22it/s]读取数据:  70%|██████▉   | 4925412/7086503 [1:04:03<06:07, 5879.35it/s]读取数据:  70%|██████▉   | 4926030/7086503 [1:04:03<06:02, 5964.59it/s]读取数据:  70%|██████▉   | 4926639/7086503 [1:04:03<05:59, 6001.02it/s]读取数据:  70%|██████▉   | 4927282/7086503 [1:04:03<05:52, 6127.94it/s]读取数据:  70%|██████▉   | 4927910/7086503 [1:04:03<05:49, 6170.35it/s]读取数据:  70%|██████▉   | 4928549/7086503 [1:04:04<05:46, 6235.43it/s]读取数据:  70%|██████▉   | 4929217/7086503 [1:04:04<05:38, 6367.32it/s]读取数据:  70%|██████▉   | 4929884/7086503 [1:04:04<05:34, 6456.72it/s]读取数据:  70%|██████▉   | 4930558/7086503 [1:04:04<05:29, 6538.63it/s]读取数据:  70%|██████▉   | 4931246/7086503 [1:04:04<05:24, 6640.40it/s]读取数据:  70%|██████▉   | 4931959/7086503 [1:04:04<05:17, 6784.59it/s]读取数据:  70%|██████▉   | 4932654/7086503 [1:04:04<05:15, 6833.72it/s]读取数据:  70%|██████▉   | 4933420/7086503 [1:04:04<05:04, 7080.72it/s]读取数据:  70%|██████▉   | 4934159/7086503 [1:04:04<05:00, 7169.20it/s]读取数据:  70%|██████▉   | 4934924/7086503 [1:04:04<04:54, 7307.96it/s]读取数据:  70%|██████▉   | 4935762/7086503 [1:04:05<04:41, 7628.39it/s]读取数据:  70%|██████▉   | 4936628/7086503 [1:04:05<04:30, 7935.95it/s]读取数据:  70%|██████▉   | 4937476/7086503 [1:04:05<04:25, 8097.67it/s]读取数据:  70%|██████▉   | 4938362/7086503 [1:04:05<04:18, 8325.86it/s]读取数据:  70%|██████▉   | 4939248/7086503 [1:04:05<04:13, 8485.57it/s]读取数据:  70%|██████▉   | 4940097/7086503 [1:04:05<08:21, 4277.39it/s]读取数据:  70%|██████▉   | 4940751/7086503 [1:04:06<08:47, 4068.13it/s]读取数据:  70%|██████▉   | 4941662/7086503 [1:04:06<07:11, 4976.09it/s]读取数据:  70%|██████▉   | 4942562/7086503 [1:04:06<06:09, 5800.16it/s]读取数据:  70%|██████▉   | 4943540/7086503 [1:04:06<05:19, 6701.62it/s]读取数据:  70%|██████▉   | 4944564/7086503 [1:04:06<04:43, 7565.75it/s]读取数据:  70%|██████▉   | 4945596/7086503 [1:04:06<04:18, 8277.69it/s]读取数据:  70%|██████▉   | 4946648/7086503 [1:04:06<04:00, 8880.47it/s]读取数据:  70%|██████▉   | 4947651/7086503 [1:04:06<03:52, 9199.29it/s]读取数据:  70%|██████▉   | 4948648/7086503 [1:04:06<03:47, 9417.64it/s]读取数据:  70%|██████▉   | 4949628/7086503 [1:04:06<03:46, 9448.85it/s]读取数据:  70%|██████▉   | 4950600/7086503 [1:04:08<14:45, 2413.27it/s]读取数据:  70%|██████▉   | 4951307/7086503 [1:04:08<13:05, 2716.96it/s]读取数据:  70%|██████▉   | 4951940/7086503 [1:04:08<11:57, 2974.66it/s]读取数据:  70%|██████▉   | 4952513/7086503 [1:04:08<11:00, 3230.76it/s]读取数据:  70%|██████▉   | 4953051/7086503 [1:04:08<10:07, 3512.29it/s]读取数据:  70%|██████▉   | 4953574/7086503 [1:04:08<09:28, 3750.84it/s]读取数据:  70%|██████▉   | 4954082/7086503 [1:04:08<08:56, 3973.26it/s]读取数据:  70%|██████▉   | 4954582/7086503 [1:04:08<08:29, 4188.09it/s]读取数据:  70%|██████▉   | 4955080/7086503 [1:04:09<08:14, 4310.54it/s]读取数据:  70%|██████▉   | 4955569/7086503 [1:04:09<08:00, 4435.87it/s]读取数据:  70%|██████▉   | 4956056/7086503 [1:04:09<08:06, 4377.86it/s]读取数据:  70%|██████▉   | 4956531/7086503 [1:04:09<07:55, 4476.62it/s]读取数据:  70%|██████▉   | 4957001/7086503 [1:04:09<07:49, 4531.36it/s]读取数据:  70%|██████▉   | 4957492/7086503 [1:04:09<07:39, 4632.07it/s]读取数据:  70%|██████▉   | 4957967/7086503 [1:04:09<07:43, 4590.47it/s]读取数据:  70%|██████▉   | 4958461/7086503 [1:04:09<07:33, 4690.66it/s]读取数据:  70%|██████▉   | 4958937/7086503 [1:04:09<07:33, 4694.89it/s]读取数据:  70%|██████▉   | 4959460/7086503 [1:04:09<07:18, 4850.38it/s]读取数据:  70%|██████▉   | 4959949/7086503 [1:04:10<07:17, 4856.71it/s]读取数据:  70%|██████▉   | 4960438/7086503 [1:04:10<07:18, 4851.37it/s]读取数据:  70%|███████   | 4960941/7086503 [1:04:10<07:13, 4902.02it/s]读取数据:  70%|███████   | 4961433/7086503 [1:04:10<07:16, 4865.83it/s]读取数据:  70%|███████   | 4961937/7086503 [1:04:10<07:12, 4912.38it/s]读取数据:  70%|███████   | 4962429/7086503 [1:04:10<07:15, 4877.89it/s]读取数据:  70%|███████   | 4962918/7086503 [1:04:10<07:15, 4880.26it/s]读取数据:  70%|███████   | 4963475/7086503 [1:04:10<06:57, 5081.32it/s]读取数据:  70%|███████   | 4964013/7086503 [1:04:10<06:50, 5166.45it/s]读取数据:  70%|███████   | 4964530/7086503 [1:04:11<06:52, 5138.42it/s]读取数据:  70%|███████   | 4965045/7086503 [1:04:11<06:57, 5085.70it/s]读取数据:  70%|███████   | 4965554/7086503 [1:04:11<07:02, 5023.62it/s]读取数据:  70%|███████   | 4966105/7086503 [1:04:11<06:50, 5162.62it/s]读取数据:  70%|███████   | 4966630/7086503 [1:04:11<06:48, 5185.92it/s]读取数据:  70%|███████   | 4967163/7086503 [1:04:11<06:45, 5223.51it/s]读取数据:  70%|███████   | 4967690/7086503 [1:04:11<06:44, 5236.27it/s]读取数据:  70%|███████   | 4968222/7086503 [1:04:11<06:42, 5258.36it/s]读取数据:  70%|███████   | 4968756/7086503 [1:04:11<06:41, 5278.21it/s]读取数据:  70%|███████   | 4969294/7086503 [1:04:11<06:39, 5304.99it/s]读取数据:  70%|███████   | 4969825/7086503 [1:04:12<06:44, 5237.29it/s]读取数据:  70%|███████   | 4970365/7086503 [1:04:12<06:40, 5284.98it/s]读取数据:  70%|███████   | 4970898/7086503 [1:04:12<06:39, 5296.95it/s]读取数据:  70%|███████   | 4971467/7086503 [1:04:12<06:30, 5411.65it/s]读取数据:  70%|███████   | 4972009/7086503 [1:04:12<06:34, 5356.59it/s]读取数据:  70%|███████   | 4972580/7086503 [1:04:12<06:27, 5460.90it/s]读取数据:  70%|███████   | 4973157/7086503 [1:04:12<06:20, 5552.37it/s]读取数据:  70%|███████   | 4973729/7086503 [1:04:12<06:17, 5601.04it/s]读取数据:  70%|███████   | 4974326/7086503 [1:04:12<06:10, 5706.30it/s]读取数据:  70%|███████   | 4974897/7086503 [1:04:12<06:11, 5691.52it/s]读取数据:  70%|███████   | 4975486/7086503 [1:04:13<06:07, 5750.61it/s]读取数据:  70%|███████   | 4976097/7086503 [1:04:13<06:00, 5857.41it/s]读取数据:  70%|███████   | 4976695/7086503 [1:04:13<05:57, 5893.74it/s]读取数据:  70%|███████   | 4977314/7086503 [1:04:13<05:52, 5978.85it/s]读取数据:  70%|███████   | 4977912/7086503 [1:04:13<07:19, 4799.30it/s]读取数据:  70%|███████   | 4978482/7086503 [1:04:13<06:59, 5029.06it/s]读取数据:  70%|███████   | 4979101/7086503 [1:04:13<06:34, 5338.11it/s]读取数据:  70%|███████   | 4979710/7086503 [1:04:13<06:19, 5544.24it/s]读取数据:  70%|███████   | 4980369/7086503 [1:04:13<06:00, 5838.19it/s]读取数据:  70%|███████   | 4980991/7086503 [1:04:14<06:39, 5274.81it/s]读取数据:  70%|███████   | 4981550/7086503 [1:04:14<06:32, 5358.64it/s]读取数据:  70%|███████   | 4982270/7086503 [1:04:14<05:58, 5865.36it/s]读取数据:  70%|███████   | 4982925/7086503 [1:04:14<06:06, 5744.47it/s]读取数据:  70%|███████   | 4983511/7086503 [1:04:14<06:53, 5089.38it/s]读取数据:  70%|███████   | 4984236/7086503 [1:04:14<06:12, 5644.02it/s]读取数据:  70%|███████   | 4984859/7086503 [1:04:14<06:11, 5654.93it/s]读取数据:  70%|███████   | 4985441/7086503 [1:04:14<06:20, 5516.18it/s]读取数据:  70%|███████   | 4986258/7086503 [1:04:14<05:36, 6241.52it/s]读取数据:  70%|███████   | 4987107/7086503 [1:04:15<05:05, 6872.24it/s]读取数据:  70%|███████   | 4987809/7086503 [1:04:15<05:16, 6620.92it/s]读取数据:  70%|███████   | 4988483/7086503 [1:04:15<05:44, 6082.90it/s]读取数据:  70%|███████   | 4989149/7086503 [1:04:15<05:36, 6234.63it/s]读取数据:  70%|███████   | 4989876/7086503 [1:04:15<05:21, 6521.69it/s]读取数据:  70%|███████   | 4990539/7086503 [1:04:15<05:38, 6195.76it/s]读取数据:  70%|███████   | 4991169/7086503 [1:04:15<06:09, 5672.25it/s]读取数据:  70%|███████   | 4992090/7086503 [1:04:15<05:16, 6610.07it/s]读取数据:  70%|███████   | 4993042/7086503 [1:04:15<04:42, 7408.71it/s]读取数据:  70%|███████   | 4993966/7086503 [1:04:16<04:24, 7922.66it/s]读取数据:  70%|███████   | 4994923/7086503 [1:04:16<04:09, 8394.98it/s]读取数据:  70%|███████   | 4995951/7086503 [1:04:16<03:53, 8941.72it/s]读取数据:  71%|███████   | 4996922/7086503 [1:04:16<03:47, 9165.55it/s]读取数据:  71%|███████   | 4997954/7086503 [1:04:16<03:39, 9506.14it/s]读取数据:  71%|███████   | 4998957/7086503 [1:04:16<03:36, 9660.71it/s]读取数据:  71%|███████   | 4999929/7086503 [1:04:16<03:36, 9653.11it/s]读取数据:  71%|███████   | 4999929/7086503 [1:04:36<03:36, 9653.11it/s]读取数据:  71%|███████   | 5000000/7086503 [1:12:47<126:17:10,  4.59it/s]读取数据:  71%|███████   | 5000211/7086503 [1:12:47<111:55:58,  5.18it/s]读取数据:  71%|███████   | 5000953/7086503 [1:12:48<71:14:25,  8.13it/s] 读取数据:  71%|███████   | 5001595/7086503 [1:12:48<49:11:32, 11.77it/s]读取数据:  71%|███████   | 5002129/7086503 [1:12:48<35:58:21, 16.10it/s]读取数据:  71%|███████   | 5002635/7086503 [1:12:48<26:23:10, 21.94it/s]读取数据:  71%|███████   | 5003145/7086503 [1:12:48<19:04:58, 30.33it/s]读取数据:  71%|███████   | 5003649/7086503 [1:12:48<13:44:15, 42.12it/s]读取数据:  71%|███████   | 5004164/7086503 [1:12:48<9:45:54, 59.23it/s] 读取数据:  71%|███████   | 5004665/7086503 [1:12:48<6:58:55, 82.82it/s]读取数据:  71%|███████   | 5005166/7086503 [1:12:49<4:58:43, 116.12it/s]读取数据:  71%|███████   | 5005664/7086503 [1:12:49<3:33:35, 162.37it/s]读取数据:  71%|███████   | 5006139/7086503 [1:12:49<2:34:48, 223.97it/s]读取数据:  71%|███████   | 5006635/7086503 [1:12:49<1:50:39, 313.25it/s]读取数据:  71%|███████   | 5007120/7086503 [1:12:49<1:20:11, 432.19it/s]读取数据:  71%|███████   | 5007641/7086503 [1:12:49<57:17, 604.70it/s]  读取数据:  71%|███████   | 5008169/7086503 [1:12:49<41:32, 833.99it/s]读取数据:  71%|███████   | 5008672/7086503 [1:12:49<31:17, 1106.93it/s]读取数据:  71%|███████   | 5009197/7086503 [1:12:49<23:42, 1460.38it/s]读取数据:  71%|███████   | 5009704/7086503 [1:12:49<18:59, 1821.96it/s]读取数据:  71%|███████   | 5010239/7086503 [1:12:50<15:07, 2289.07it/s]读取数据:  71%|███████   | 5010740/7086503 [1:12:50<12:44, 2716.30it/s]读取数据:  71%|███████   | 5011263/7086503 [1:12:50<10:52, 3179.34it/s]读取数据:  71%|███████   | 5011769/7086503 [1:12:50<09:42, 3563.64it/s]读取数据:  71%|███████   | 5012316/7086503 [1:12:50<08:38, 3999.43it/s]读取数据:  71%|███████   | 5012833/7086503 [1:12:50<08:05, 4272.09it/s]读取数据:  71%|███████   | 5013348/7086503 [1:12:50<07:44, 4463.90it/s]读取数据:  71%|███████   | 5013858/7086503 [1:12:50<07:27, 4634.05it/s]读取数据:  71%|███████   | 5014368/7086503 [1:12:50<07:37, 4527.43it/s]读取数据:  71%|███████   | 5014904/7086503 [1:12:51<07:15, 4754.46it/s]读取数据:  71%|███████   | 5015427/7086503 [1:12:51<07:03, 4886.66it/s]读取数据:  71%|███████   | 5015994/7086503 [1:12:51<06:45, 5108.69it/s]读取数据:  71%|███████   | 5016523/7086503 [1:12:51<06:41, 5159.88it/s]读取数据:  71%|███████   | 5017049/7086503 [1:12:51<06:41, 5153.62it/s]读取数据:  71%|███████   | 5017586/7086503 [1:12:51<06:37, 5210.89it/s]读取数据:  71%|███████   | 5018120/7086503 [1:12:51<06:34, 5246.89it/s]读取数据:  71%|███████   | 5018671/7086503 [1:12:51<06:28, 5321.81it/s]读取数据:  71%|███████   | 5019206/7086503 [1:12:51<06:29, 5302.26it/s]读取数据:  71%|███████   | 5019757/7086503 [1:12:51<06:25, 5363.53it/s]读取数据:  71%|███████   | 5020324/7086503 [1:12:52<06:18, 5453.18it/s]读取数据:  71%|███████   | 5020914/7086503 [1:12:52<06:09, 5584.49it/s]读取数据:  71%|███████   | 5021474/7086503 [1:12:52<06:16, 5484.61it/s]读取数据:  71%|███████   | 5022042/7086503 [1:12:52<06:12, 5541.97it/s]读取数据:  71%|███████   | 5022664/7086503 [1:12:52<05:59, 5741.00it/s]读取数据:  71%|███████   | 5023269/7086503 [1:12:52<05:53, 5832.76it/s]读取数据:  71%|███████   | 5023853/7086503 [1:12:52<05:56, 5789.80it/s]读取数据:  71%|███████   | 5024465/7086503 [1:12:52<05:50, 5885.94it/s]读取数据:  71%|███████   | 5025084/7086503 [1:12:52<05:45, 5974.87it/s]读取数据:  71%|███████   | 5025698/7086503 [1:12:52<05:42, 6023.74it/s]读取数据:  71%|███████   | 5026362/7086503 [1:12:53<05:31, 6206.95it/s]读取数据:  71%|███████   | 5026983/7086503 [1:12:53<06:01, 5690.36it/s]读取数据:  71%|███████   | 5027618/7086503 [1:12:53<05:50, 5875.37it/s]读取数据:  71%|███████   | 5028268/7086503 [1:12:53<05:40, 6052.43it/s]读取数据:  71%|███████   | 5028932/7086503 [1:12:53<05:30, 6222.62it/s]读取数据:  71%|███████   | 5029591/7086503 [1:12:53<05:24, 6330.32it/s]读取数据:  71%|███████   | 5030311/7086503 [1:12:53<05:12, 6585.88it/s]读取数据:  71%|███████   | 5031011/7086503 [1:12:53<05:06, 6708.52it/s]读取数据:  71%|███████   | 5031708/7086503 [1:12:53<05:02, 6782.42it/s]读取数据:  71%|███████   | 5032418/7086503 [1:12:53<04:58, 6876.79it/s]读取数据:  71%|███████   | 5033171/7086503 [1:12:54<04:50, 7071.50it/s]读取数据:  71%|███████   | 5033896/7086503 [1:12:54<04:48, 7124.82it/s]读取数据:  71%|███████   | 5034650/7086503 [1:12:54<04:43, 7248.57it/s]读取数据:  71%|███████   | 5035437/7086503 [1:12:54<04:36, 7429.56it/s]读取数据:  71%|███████   | 5036269/7086503 [1:12:54<04:26, 7694.95it/s]读取数据:  71%|███████   | 5037098/7086503 [1:12:54<04:20, 7872.11it/s]读取数据:  71%|███████   | 5037964/7086503 [1:12:54<04:12, 8107.19it/s]读取数据:  71%|███████   | 5038800/7086503 [1:12:54<04:10, 8180.08it/s]读取数据:  71%|███████   | 5039675/7086503 [1:12:54<04:05, 8346.78it/s]读取数据:  71%|███████   | 5040619/7086503 [1:12:54<03:55, 8674.28it/s]读取数据:  71%|███████   | 5041574/7086503 [1:12:55<03:48, 8932.70it/s]读取数据:  71%|███████   | 5042556/7086503 [1:12:55<03:42, 9197.78it/s]读取数据:  71%|███████   | 5043487/7086503 [1:12:55<03:41, 9226.52it/s]读取数据:  71%|███████   | 5044495/7086503 [1:12:55<03:35, 9481.34it/s]读取数据:  71%|███████   | 5045530/7086503 [1:12:55<03:29, 9741.03it/s]读取数据:  71%|███████   | 5046535/7086503 [1:12:55<03:27, 9832.65it/s]读取数据:  71%|███████   | 5047552/7086503 [1:12:55<03:25, 9933.70it/s]读取数据:  71%|███████   | 5048546/7086503 [1:12:55<03:28, 9796.39it/s]读取数据:  71%|███████▏  | 5049541/7086503 [1:12:55<03:27, 9838.67it/s]读取数据:  71%|███████▏  | 5050526/7086503 [1:12:56<12:58, 2614.21it/s]读取数据:  71%|███████▏  | 5051244/7086503 [1:12:57<11:30, 2949.50it/s]读取数据:  71%|███████▏  | 5051898/7086503 [1:12:57<10:25, 3254.85it/s]读取数据:  71%|███████▏  | 5052503/7086503 [1:12:57<09:34, 3538.09it/s]读取数据:  71%|███████▏  | 5053074/7086503 [1:12:57<08:48, 3844.80it/s]读取数据:  71%|███████▏  | 5053632/7086503 [1:12:57<08:15, 4099.59it/s]读取数据:  71%|███████▏  | 5054176/7086503 [1:12:57<07:52, 4301.85it/s]读取数据:  71%|███████▏  | 5054707/7086503 [1:12:57<07:41, 4406.64it/s]读取数据:  71%|███████▏  | 5055220/7086503 [1:12:57<07:25, 4561.06it/s]读取数据:  71%|███████▏  | 5055732/7086503 [1:12:57<07:11, 4702.81it/s]读取数据:  71%|███████▏  | 5056265/7086503 [1:12:58<06:57, 4867.88it/s]读取数据:  71%|███████▏  | 5056789/7086503 [1:12:58<06:48, 4969.56it/s]读取数据:  71%|███████▏  | 5057309/7086503 [1:12:58<06:47, 4984.21it/s]读取数据:  71%|███████▏  | 5057842/7086503 [1:12:58<06:39, 5079.13it/s]读取数据:  71%|███████▏  | 5058362/7086503 [1:12:58<06:37, 5100.48it/s]读取数据:  71%|███████▏  | 5058881/7086503 [1:12:58<06:40, 5061.02it/s]读取数据:  71%|███████▏  | 5059393/7086503 [1:12:58<06:40, 5057.35it/s]读取数据:  71%|███████▏  | 5059941/7086503 [1:12:58<06:31, 5181.09it/s]读取数据:  71%|███████▏  | 5060470/7086503 [1:12:58<06:28, 5209.23it/s]读取数据:  71%|███████▏  | 5061000/7086503 [1:12:58<06:27, 5233.22it/s]读取数据:  71%|███████▏  | 5061552/7086503 [1:12:59<06:21, 5310.69it/s]读取数据:  71%|███████▏  | 5062094/7086503 [1:12:59<06:19, 5341.44it/s]读取数据:  71%|███████▏  | 5062650/7086503 [1:12:59<06:14, 5406.04it/s]读取数据:  71%|███████▏  | 5063192/7086503 [1:12:59<06:18, 5348.01it/s]读取数据:  71%|███████▏  | 5063739/7086503 [1:12:59<06:15, 5383.30it/s]读取数据:  71%|███████▏  | 5064278/7086503 [1:12:59<06:19, 5329.48it/s]读取数据:  71%|███████▏  | 5064861/7086503 [1:12:59<06:09, 5477.10it/s]读取数据:  71%|███████▏  | 5065421/7086503 [1:12:59<06:06, 5513.45it/s]读取数据:  71%|███████▏  | 5065973/7086503 [1:12:59<06:13, 5407.59it/s]读取数据:  71%|███████▏  | 5066515/7086503 [1:12:59<06:14, 5394.13it/s]读取数据:  72%|███████▏  | 5067081/7086503 [1:13:00<06:09, 5472.38it/s]读取数据:  72%|███████▏  | 5067647/7086503 [1:13:00<06:05, 5523.43it/s]读取数据:  72%|███████▏  | 5068248/7086503 [1:13:00<05:56, 5662.33it/s]读取数据:  72%|███████▏  | 5068815/7086503 [1:13:00<05:59, 5607.69it/s]读取数据:  72%|███████▏  | 5069377/7086503 [1:13:00<06:37, 5080.75it/s]读取数据:  72%|███████▏  | 5069929/7086503 [1:13:00<06:27, 5200.46it/s]读取数据:  72%|███████▏  | 5070496/7086503 [1:13:00<06:18, 5331.06it/s]读取数据:  72%|███████▏  | 5071036/7086503 [1:13:00<07:17, 4607.31it/s]读取数据:  72%|███████▏  | 5071605/7086503 [1:13:00<06:52, 4889.43it/s]读取数据:  72%|███████▏  | 5072215/7086503 [1:13:01<06:26, 5216.00it/s]读取数据:  72%|███████▏  | 5072818/7086503 [1:13:01<06:10, 5440.73it/s]读取数据:  72%|███████▏  | 5073437/7086503 [1:13:01<05:56, 5652.99it/s]读取数据:  72%|███████▏  | 5074066/7086503 [1:13:01<05:44, 5835.20it/s]读取数据:  72%|███████▏  | 5074695/7086503 [1:13:01<05:37, 5967.34it/s]读取数据:  72%|███████▏  | 5075314/7086503 [1:13:01<05:33, 6027.69it/s]读取数据:  72%|███████▏  | 5075921/7086503 [1:13:01<05:38, 5941.79it/s]读取数据:  72%|███████▏  | 5076539/7086503 [1:13:01<05:34, 6011.10it/s]读取数据:  72%|███████▏  | 5077143/7086503 [1:13:01<05:38, 5928.46it/s]读取数据:  72%|███████▏  | 5077738/7086503 [1:13:01<05:51, 5721.17it/s]读取数据:  72%|███████▏  | 5078390/7086503 [1:13:02<05:37, 5948.00it/s]读取数据:  72%|███████▏  | 5079116/7086503 [1:13:02<05:17, 6329.85it/s]读取数据:  72%|███████▏  | 5079789/7086503 [1:13:02<05:11, 6447.01it/s]读取数据:  72%|███████▏  | 5080437/7086503 [1:13:02<05:40, 5889.45it/s]读取数据:  72%|███████▏  | 5081158/7086503 [1:13:02<05:20, 6253.99it/s]读取数据:  72%|███████▏  | 5081884/7086503 [1:13:02<05:06, 6538.33it/s]读取数据:  72%|███████▏  | 5082624/7086503 [1:13:02<04:55, 6785.02it/s]读取数据:  72%|███████▏  | 5083370/7086503 [1:13:02<04:46, 6981.21it/s]读取数据:  72%|███████▏  | 5084165/7086503 [1:13:02<04:35, 7266.16it/s]读取数据:  72%|███████▏  | 5084917/7086503 [1:13:03<04:32, 7341.13it/s]读取数据:  72%|███████▏  | 5085655/7086503 [1:13:03<04:39, 7151.33it/s]读取数据:  72%|███████▏  | 5086448/7086503 [1:13:03<04:31, 7377.59it/s]读取数据:  72%|███████▏  | 5087189/7086503 [1:13:03<04:54, 6794.56it/s]读取数据:  72%|███████▏  | 5088057/7086503 [1:13:03<04:33, 7319.46it/s]读取数据:  72%|███████▏  | 5088932/7086503 [1:13:03<04:18, 7725.62it/s]读取数据:  72%|███████▏  | 5089845/7086503 [1:13:03<04:05, 8130.80it/s]读取数据:  72%|███████▏  | 5090775/7086503 [1:13:03<03:55, 8459.47it/s]读取数据:  72%|███████▏  | 5091685/7086503 [1:13:03<03:50, 8647.04it/s]读取数据:  72%|███████▏  | 5092650/7086503 [1:13:03<03:42, 8942.66it/s]读取数据:  72%|███████▏  | 5093645/7086503 [1:13:04<03:35, 9238.16it/s]读取数据:  72%|███████▏  | 5094661/7086503 [1:13:04<03:29, 9507.01it/s]读取数据:  72%|███████▏  | 5095614/7086503 [1:13:04<03:29, 9488.11it/s]读取数据:  72%|███████▏  | 5096626/7086503 [1:13:04<03:25, 9676.21it/s]读取数据:  72%|███████▏  | 5097627/7086503 [1:13:04<03:23, 9775.33it/s]读取数据:  72%|███████▏  | 5098646/7086503 [1:13:04<03:20, 9896.62it/s]读取数据:  72%|███████▏  | 5099637/7086503 [1:13:04<03:22, 9832.87it/s]读取数据:  72%|███████▏  | 5100621/7086503 [1:13:05<12:48, 2585.27it/s]读取数据:  72%|███████▏  | 5101339/7086503 [1:13:05<11:20, 2915.79it/s]读取数据:  72%|███████▏  | 5101990/7086503 [1:13:05<10:15, 3224.08it/s]读取数据:  72%|███████▏  | 5102593/7086503 [1:13:06<09:18, 3551.78it/s]读取数据:  72%|███████▏  | 5103174/7086503 [1:13:06<08:40, 3809.67it/s]读取数据:  72%|███████▏  | 5103728/7086503 [1:13:06<08:06, 4073.50it/s]读取数据:  72%|███████▏  | 5104270/7086503 [1:13:06<07:41, 4296.59it/s]读取数据:  72%|███████▏  | 5104802/7086503 [1:13:06<07:20, 4498.84it/s]读取数据:  72%|███████▏  | 5105341/7086503 [1:13:06<07:00, 4715.40it/s]读取数据:  72%|███████▏  | 5105872/7086503 [1:13:06<06:53, 4794.87it/s]读取数据:  72%|███████▏  | 5106406/7086503 [1:13:06<06:41, 4936.42it/s]读取数据:  72%|███████▏  | 5106931/7086503 [1:13:06<06:37, 4975.97it/s]读取数据:  72%|███████▏  | 5107461/7086503 [1:13:07<06:30, 5065.75it/s]读取数据:  72%|███████▏  | 5107985/7086503 [1:13:07<06:26, 5113.82it/s]读取数据:  72%|███████▏  | 5108508/7086503 [1:13:07<06:30, 5062.49it/s]读取数据:  72%|███████▏  | 5109030/7086503 [1:13:07<06:27, 5105.93it/s]读取数据:  72%|███████▏  | 5109574/7086503 [1:13:07<06:20, 5201.02it/s]读取数据:  72%|███████▏  | 5110118/7086503 [1:13:07<06:15, 5269.53it/s]读取数据:  72%|███████▏  | 5110649/7086503 [1:13:07<06:14, 5270.93it/s]读取数据:  72%|███████▏  | 5111205/7086503 [1:13:07<06:08, 5356.52it/s]读取数据:  72%|███████▏  | 5111743/7086503 [1:13:07<06:10, 5333.54it/s]读取数据:  72%|███████▏  | 5112278/7086503 [1:13:07<06:09, 5338.02it/s]读取数据:  72%|███████▏  | 5112813/7086503 [1:13:08<06:12, 5303.40it/s]读取数据:  72%|███████▏  | 5113382/7086503 [1:13:08<06:04, 5414.65it/s]读取数据:  72%|███████▏  | 5113940/7086503 [1:13:08<06:01, 5463.11it/s]读取数据:  72%|███████▏  | 5114487/7086503 [1:13:08<06:04, 5408.08it/s]读取数据:  72%|███████▏  | 5115029/7086503 [1:13:08<06:06, 5379.04it/s]读取数据:  72%|███████▏  | 5115605/7086503 [1:13:08<05:59, 5487.95it/s]读取数据:  72%|███████▏  | 5116184/7086503 [1:13:08<05:53, 5572.19it/s]读取数据:  72%|███████▏  | 5116742/7086503 [1:13:08<06:01, 5450.53it/s]读取数据:  72%|███████▏  | 5117320/7086503 [1:13:08<05:54, 5547.19it/s]读取数据:  72%|███████▏  | 5117876/7086503 [1:13:08<05:58, 5487.41it/s]读取数据:  72%|███████▏  | 5118426/7086503 [1:13:09<05:58, 5487.56it/s]读取数据:  72%|███████▏  | 5118999/7086503 [1:13:09<05:53, 5558.74it/s]读取数据:  72%|███████▏  | 5119582/7086503 [1:13:09<05:48, 5636.40it/s]读取数据:  72%|███████▏  | 5120167/7086503 [1:13:09<05:45, 5699.23it/s]读取数据:  72%|███████▏  | 5120761/7086503 [1:13:09<05:40, 5768.25it/s]读取数据:  72%|███████▏  | 5121339/7086503 [1:13:09<05:44, 5712.51it/s]读取数据:  72%|███████▏  | 5121911/7086503 [1:13:09<05:44, 5706.03it/s]读取数据:  72%|███████▏  | 5122493/7086503 [1:13:09<05:42, 5735.37it/s]读取数据:  72%|███████▏  | 5123097/7086503 [1:13:09<05:37, 5824.60it/s]读取数据:  72%|███████▏  | 5123693/7086503 [1:13:09<05:34, 5863.08it/s]读取数据:  72%|███████▏  | 5124371/7086503 [1:13:10<05:19, 6135.55it/s]读取数据:  72%|███████▏  | 5125010/7086503 [1:13:10<05:16, 6205.98it/s]读取数据:  72%|███████▏  | 5125634/7086503 [1:13:10<05:15, 6212.09it/s]读取数据:  72%|███████▏  | 5126276/7086503 [1:13:10<05:12, 6272.29it/s]读取数据:  72%|███████▏  | 5126953/7086503 [1:13:10<05:05, 6421.02it/s]读取数据:  72%|███████▏  | 5127625/7086503 [1:13:10<05:00, 6509.26it/s]读取数据:  72%|███████▏  | 5128281/7086503 [1:13:10<05:00, 6524.09it/s]读取数据:  72%|███████▏  | 5128966/7086503 [1:13:10<04:55, 6614.75it/s]读取数据:  72%|███████▏  | 5129632/7086503 [1:13:10<04:55, 6622.13it/s]读取数据:  72%|███████▏  | 5130310/7086503 [1:13:10<04:53, 6667.05it/s]读取数据:  72%|███████▏  | 5131000/7086503 [1:13:11<04:50, 6732.92it/s]读取数据:  72%|███████▏  | 5131739/7086503 [1:13:11<04:42, 6929.06it/s]读取数据:  72%|███████▏  | 5132493/7086503 [1:13:11<04:34, 7110.53it/s]读取数据:  72%|███████▏  | 5133242/7086503 [1:13:11<04:30, 7223.14it/s]读取数据:  72%|███████▏  | 5134007/7086503 [1:13:11<04:25, 7347.93it/s]读取数据:  72%|███████▏  | 5134781/7086503 [1:13:11<04:21, 7465.13it/s]读取数据:  72%|███████▏  | 5135528/7086503 [1:13:11<04:29, 7235.88it/s]读取数据:  72%|███████▏  | 5136356/7086503 [1:13:11<04:18, 7540.04it/s]读取数据:  72%|███████▏  | 5137174/7086503 [1:13:11<04:12, 7723.25it/s]读取数据:  73%|███████▎  | 5138009/7086503 [1:13:11<04:06, 7900.12it/s]读取数据:  73%|███████▎  | 5138926/7086503 [1:13:12<03:55, 8277.16it/s]读取数据:  73%|███████▎  | 5139812/7086503 [1:13:12<03:50, 8448.55it/s]读取数据:  73%|███████▎  | 5140774/7086503 [1:13:12<03:41, 8798.11it/s]读取数据:  73%|███████▎  | 5141762/7086503 [1:13:12<03:33, 9120.99it/s]读取数据:  73%|███████▎  | 5142675/7086503 [1:13:12<03:34, 9064.39it/s]读取数据:  73%|███████▎  | 5143704/7086503 [1:13:12<03:26, 9424.41it/s]读取数据:  73%|███████▎  | 5144776/7086503 [1:13:12<03:17, 9809.35it/s]读取数据:  73%|███████▎  | 5145828/7086503 [1:13:12<03:13, 10020.56it/s]读取数据:  73%|███████▎  | 5146889/7086503 [1:13:12<03:10, 10193.72it/s]读取数据:  73%|███████▎  | 5147969/7086503 [1:13:12<03:06, 10373.60it/s]读取数据:  73%|███████▎  | 5149007/7086503 [1:13:13<03:07, 10348.07it/s]读取数据:  73%|███████▎  | 5150043/7086503 [1:13:14<11:44, 2748.86it/s] 读取数据:  73%|███████▎  | 5150798/7086503 [1:13:14<10:30, 3069.58it/s]读取数据:  73%|███████▎  | 5151474/7086503 [1:13:14<09:29, 3397.34it/s]读取数据:  73%|███████▎  | 5152105/7086503 [1:13:14<08:43, 3692.42it/s]读取数据:  73%|███████▎  | 5152700/7086503 [1:13:14<08:09, 3950.10it/s]读取数据:  73%|███████▎  | 5153268/7086503 [1:13:14<07:46, 4143.80it/s]读取数据:  73%|███████▎  | 5153812/7086503 [1:13:14<07:25, 4340.23it/s]读取数据:  73%|███████▎  | 5154344/7086503 [1:13:14<07:07, 4523.55it/s]读取数据:  73%|███████▎  | 5154871/7086503 [1:13:15<06:53, 4675.51it/s]读取数据:  73%|███████▎  | 5155394/7086503 [1:13:15<06:41, 4807.28it/s]读取数据:  73%|███████▎  | 5155923/7086503 [1:13:15<06:31, 4935.14it/s]读取数据:  73%|███████▎  | 5156484/7086503 [1:13:15<06:17, 5117.38it/s]读取数据:  73%|███████▎  | 5157019/7086503 [1:13:15<06:17, 5113.20it/s]读取数据:  73%|███████▎  | 5157558/7086503 [1:13:15<06:11, 5187.76it/s]读取数据:  73%|███████▎  | 5158089/7086503 [1:13:15<06:11, 5184.57it/s]读取数据:  73%|███████▎  | 5158630/7086503 [1:13:15<06:07, 5249.05it/s]读取数据:  73%|███████▎  | 5159164/7086503 [1:13:15<06:05, 5273.66it/s]读取数据:  73%|███████▎  | 5159722/7086503 [1:13:15<05:59, 5359.55it/s]读取数据:  73%|███████▎  | 5160261/7086503 [1:13:16<06:07, 5241.78it/s]读取数据:  73%|███████▎  | 5160806/7086503 [1:13:16<06:03, 5301.32it/s]读取数据:  73%|███████▎  | 5161339/7086503 [1:13:16<06:07, 5244.01it/s]读取数据:  73%|███████▎  | 5161866/7086503 [1:13:16<06:06, 5247.80it/s]读取数据:  73%|███████▎  | 5162419/7086503 [1:13:16<06:01, 5326.91it/s]读取数据:  73%|███████▎  | 5162953/7086503 [1:13:16<06:08, 5224.44it/s]读取数据:  73%|███████▎  | 5163482/7086503 [1:13:16<06:06, 5242.45it/s]读取数据:  73%|███████▎  | 5164020/7086503 [1:13:16<06:04, 5279.73it/s]读取数据:  73%|███████▎  | 5164613/7086503 [1:13:16<05:51, 5472.35it/s]读取数据:  73%|███████▎  | 5165187/7086503 [1:13:16<05:46, 5549.91it/s]读取数据:  73%|███████▎  | 5165758/7086503 [1:13:17<05:43, 5594.31it/s]读取数据:  73%|███████▎  | 5166318/7086503 [1:13:17<05:44, 5577.30it/s]读取数据:  73%|███████▎  | 5166876/7086503 [1:13:17<05:44, 5565.15it/s]读取数据:  73%|███████▎  | 5167433/7086503 [1:13:17<05:44, 5566.46it/s]读取数据:  73%|███████▎  | 5168004/7086503 [1:13:17<05:42, 5607.80it/s]读取数据:  73%|███████▎  | 5168574/7086503 [1:13:17<05:40, 5635.31it/s]读取数据:  73%|███████▎  | 5169138/7086503 [1:13:17<05:41, 5618.11it/s]读取数据:  73%|███████▎  | 5169756/7086503 [1:13:17<05:31, 5784.25it/s]读取数据:  73%|███████▎  | 5170335/7086503 [1:13:17<05:32, 5755.60it/s]读取数据:  73%|███████▎  | 5170912/7086503 [1:13:17<05:32, 5756.21it/s]读取数据:  73%|███████▎  | 5171537/7086503 [1:13:18<05:24, 5902.92it/s]读取数据:  73%|███████▎  | 5172136/7086503 [1:13:18<05:22, 5928.45it/s]读取数据:  73%|███████▎  | 5172742/7086503 [1:13:18<05:20, 5967.42it/s]读取数据:  73%|███████▎  | 5173341/7086503 [1:13:18<05:20, 5971.46it/s]读取数据:  73%|███████▎  | 5173939/7086503 [1:13:18<05:21, 5945.48it/s]读取数据:  73%|███████▎  | 5174565/7086503 [1:13:18<05:16, 6038.91it/s]读取数据:  73%|███████▎  | 5175202/7086503 [1:13:18<05:11, 6136.71it/s]读取数据:  73%|███████▎  | 5175833/7086503 [1:13:18<05:08, 6186.95it/s]读取数据:  73%|███████▎  | 5176476/7086503 [1:13:18<05:05, 6258.95it/s]读取数据:  73%|███████▎  | 5177116/7086503 [1:13:18<05:03, 6300.71it/s]读取数据:  73%|███████▎  | 5177786/7086503 [1:13:19<04:57, 6420.13it/s]读取数据:  73%|███████▎  | 5178474/7086503 [1:13:19<04:51, 6556.21it/s]读取数据:  73%|███████▎  | 5179141/7086503 [1:13:19<04:49, 6587.41it/s]读取数据:  73%|███████▎  | 5179833/7086503 [1:13:19<04:45, 6684.61it/s]读取数据:  73%|███████▎  | 5180526/7086503 [1:13:19<04:42, 6757.61it/s]读取数据:  73%|███████▎  | 5181232/7086503 [1:13:19<04:38, 6846.69it/s]读取数据:  73%|███████▎  | 5181952/7086503 [1:13:19<04:33, 6951.33it/s]读取数据:  73%|███████▎  | 5182681/7086503 [1:13:19<04:29, 7052.27it/s]读取数据:  73%|███████▎  | 5183431/7086503 [1:13:19<04:24, 7186.15it/s]读取数据:  73%|███████▎  | 5184217/7086503 [1:13:19<04:17, 7387.63it/s]读取数据:  73%|███████▎  | 5185002/7086503 [1:13:20<04:12, 7525.47it/s]读取数据:  73%|███████▎  | 5185798/7086503 [1:13:20<04:08, 7655.54it/s]读取数据:  73%|███████▎  | 5186621/7086503 [1:13:20<04:02, 7820.04it/s]读取数据:  73%|███████▎  | 5187436/7086503 [1:13:20<03:59, 7915.92it/s]读取数据:  73%|███████▎  | 5188332/7086503 [1:13:20<03:50, 8227.80it/s]读取数据:  73%|███████▎  | 5189195/7086503 [1:13:20<03:47, 8346.90it/s]读取数据:  73%|███████▎  | 5190101/7086503 [1:13:20<03:41, 8557.45it/s]读取数据:  73%|███████▎  | 5191042/7086503 [1:13:20<03:35, 8811.73it/s]读取数据:  73%|███████▎  | 5192024/7086503 [1:13:20<03:27, 9113.89it/s]读取数据:  73%|███████▎  | 5192985/7086503 [1:13:20<03:24, 9261.20it/s]读取数据:  73%|███████▎  | 5193987/7086503 [1:13:21<03:19, 9484.73it/s]读取数据:  73%|███████▎  | 5194975/7086503 [1:13:21<03:17, 9598.44it/s]读取数据:  73%|███████▎  | 5196010/7086503 [1:13:21<03:12, 9823.19it/s]读取数据:  73%|███████▎  | 5197073/7086503 [1:13:21<03:08, 10042.55it/s]读取数据:  73%|███████▎  | 5198078/7086503 [1:13:21<03:08, 10027.90it/s]读取数据:  73%|███████▎  | 5199081/7086503 [1:13:21<03:08, 9997.89it/s] 读取数据:  73%|███████▎  | 5200081/7086503 [1:13:22<12:05, 2600.48it/s]读取数据:  73%|███████▎  | 5200810/7086503 [1:13:22<10:43, 2930.18it/s]读取数据:  73%|███████▎  | 5201469/7086503 [1:13:22<09:40, 3245.63it/s]读取数据:  73%|███████▎  | 5202080/7086503 [1:13:23<08:54, 3523.40it/s]读取数据:  73%|███████▎  | 5202654/7086503 [1:13:23<08:19, 3771.99it/s]读取数据:  73%|███████▎  | 5203201/7086503 [1:13:23<07:56, 3956.09it/s]读取数据:  73%|███████▎  | 5203724/7086503 [1:13:23<07:26, 4212.28it/s]读取数据:  73%|███████▎  | 5204246/7086503 [1:13:23<07:14, 4330.92it/s]读取数据:  73%|███████▎  | 5204757/7086503 [1:13:23<06:56, 4516.03it/s]读取数据:  73%|███████▎  | 5205265/7086503 [1:13:23<06:51, 4567.95it/s]读取数据:  73%|███████▎  | 5205772/7086503 [1:13:23<06:40, 4698.20it/s]读取数据:  73%|███████▎  | 5206284/7086503 [1:13:23<06:30, 4812.34it/s]读取数据:  73%|███████▎  | 5206788/7086503 [1:13:24<06:26, 4862.62it/s]读取数据:  73%|███████▎  | 5207290/7086503 [1:13:24<06:25, 4871.73it/s]读取数据:  73%|███████▎  | 5207833/7086503 [1:13:24<06:13, 5029.24it/s]读取数据:  73%|███████▎  | 5208356/7086503 [1:13:24<06:09, 5082.54it/s]读取数据:  74%|███████▎  | 5208871/7086503 [1:13:24<06:13, 5021.64it/s]读取数据:  74%|███████▎  | 5209378/7086503 [1:13:24<06:12, 5035.72it/s]读取数据:  74%|███████▎  | 5209902/7086503 [1:13:24<06:08, 5094.64it/s]读取数据:  74%|███████▎  | 5210423/7086503 [1:13:24<06:05, 5126.89it/s]读取数据:  74%|███████▎  | 5210942/7086503 [1:13:24<06:04, 5143.66it/s]读取数据:  74%|███████▎  | 5211466/7086503 [1:13:24<06:02, 5170.71it/s]读取数据:  74%|███████▎  | 5211989/7086503 [1:13:25<06:01, 5187.73it/s]读取数据:  74%|███████▎  | 5212509/7086503 [1:13:25<06:02, 5176.56it/s]读取数据:  74%|███████▎  | 5213028/7086503 [1:13:25<06:06, 5106.23it/s]读取数据:  74%|███████▎  | 5213545/7086503 [1:13:25<06:05, 5124.78it/s]读取数据:  74%|███████▎  | 5214058/7086503 [1:13:25<06:06, 5109.87it/s]读取数据:  74%|███████▎  | 5214587/7086503 [1:13:25<06:02, 5162.80it/s]读取数据:  74%|███████▎  | 5215133/7086503 [1:13:25<05:56, 5243.86it/s]读取数据:  74%|███████▎  | 5215658/7086503 [1:13:25<06:01, 5178.01it/s]读取数据:  74%|███████▎  | 5216200/7086503 [1:13:25<05:56, 5246.23it/s]读取数据:  74%|███████▎  | 5216753/7086503 [1:13:25<05:51, 5324.33it/s]读取数据:  74%|███████▎  | 5217295/7086503 [1:13:26<05:49, 5352.16it/s]读取数据:  74%|███████▎  | 5217831/7086503 [1:13:26<05:56, 5246.97it/s]读取数据:  74%|███████▎  | 5218362/7086503 [1:13:26<05:54, 5265.28it/s]读取数据:  74%|███████▎  | 5218889/7086503 [1:13:26<10:44, 2898.99it/s]读取数据:  74%|███████▎  | 5219450/7086503 [1:13:26<09:07, 3411.08it/s]读取数据:  74%|███████▎  | 5220049/7086503 [1:13:26<07:51, 3958.47it/s]读取数据:  74%|███████▎  | 5220659/7086503 [1:13:26<06:58, 4455.28it/s]读取数据:  74%|███████▎  | 5221265/7086503 [1:13:27<06:24, 4854.20it/s]读取数据:  74%|███████▎  | 5221898/7086503 [1:13:27<05:55, 5240.58it/s]读取数据:  74%|███████▎  | 5222528/7086503 [1:13:27<05:37, 5528.74it/s]读取数据:  74%|███████▎  | 5223174/7086503 [1:13:27<05:21, 5788.52it/s]读取数据:  74%|███████▎  | 5223795/7086503 [1:13:27<05:15, 5902.75it/s]读取数据:  74%|███████▎  | 5224407/7086503 [1:13:27<05:12, 5952.28it/s]读取数据:  74%|███████▎  | 5225060/7086503 [1:13:27<05:04, 6115.84it/s]读取数据:  74%|███████▎  | 5225733/7086503 [1:13:27<04:55, 6293.75it/s]读取数据:  74%|███████▍  | 5226372/7086503 [1:13:27<04:54, 6320.54it/s]读取数据:  74%|███████▍  | 5227078/7086503 [1:13:27<04:44, 6536.74it/s]读取数据:  74%|███████▍  | 5227774/7086503 [1:13:28<04:39, 6661.95it/s]读取数据:  74%|███████▍  | 5228485/7086503 [1:13:28<04:33, 6794.70it/s]读取数据:  74%|███████▍  | 5229168/7086503 [1:13:28<04:33, 6802.48it/s]读取数据:  74%|███████▍  | 5229886/7086503 [1:13:28<04:28, 6914.20it/s]读取数据:  74%|███████▍  | 5230579/7086503 [1:13:28<06:06, 5066.31it/s]读取数据:  74%|███████▍  | 5231361/7086503 [1:13:28<05:24, 5719.27it/s]读取数据:  74%|███████▍  | 5232120/7086503 [1:13:28<04:59, 6194.17it/s]读取数据:  74%|███████▍  | 5232882/7086503 [1:13:28<04:42, 6573.10it/s]读取数据:  74%|███████▍  | 5233607/7086503 [1:13:28<04:34, 6757.22it/s]读取数据:  74%|███████▍  | 5234412/7086503 [1:13:29<04:20, 7118.02it/s]读取数据:  74%|███████▍  | 5235255/7086503 [1:13:29<04:07, 7492.45it/s]读取数据:  74%|███████▍  | 5236082/7086503 [1:13:29<03:59, 7711.90it/s]读取数据:  74%|███████▍  | 5237011/7086503 [1:13:29<03:46, 8173.13it/s]读取数据:  74%|███████▍  | 5237880/7086503 [1:13:29<03:42, 8324.41it/s]读取数据:  74%|███████▍  | 5238814/7086503 [1:13:29<03:34, 8623.18it/s]读取数据:  74%|███████▍  | 5239809/7086503 [1:13:29<03:24, 9016.02it/s]读取数据:  74%|███████▍  | 5240828/7086503 [1:13:29<03:17, 9364.09it/s]读取数据:  74%|███████▍  | 5241957/7086503 [1:13:29<03:05, 9936.00it/s]读取数据:  74%|███████▍  | 5243093/7086503 [1:13:29<02:57, 10359.96it/s]读取数据:  74%|███████▍  | 5244301/7086503 [1:13:30<02:49, 10874.27it/s]读取数据:  74%|███████▍  | 5245515/7086503 [1:13:30<02:43, 11251.39it/s]读取数据:  74%|███████▍  | 5246642/7086503 [1:13:30<02:48, 10899.32it/s]读取数据:  74%|███████▍  | 5247883/7086503 [1:13:30<02:42, 11341.68it/s]读取数据:  74%|███████▍  | 5249045/7086503 [1:13:30<02:40, 11421.79it/s]读取数据:  74%|███████▍  | 5250190/7086503 [1:13:31<10:01, 3054.19it/s] 读取数据:  74%|███████▍  | 5251025/7086503 [1:13:31<09:03, 3379.40it/s]读取数据:  74%|███████▍  | 5251764/7086503 [1:13:31<08:23, 3645.95it/s]读取数据:  74%|███████▍  | 5252430/7086503 [1:13:31<07:51, 3889.91it/s]读取数据:  74%|███████▍  | 5253047/7086503 [1:13:32<08:22, 3650.66it/s]读取数据:  74%|███████▍  | 5253570/7086503 [1:13:32<07:54, 3862.38it/s]读取数据:  74%|███████▍  | 5254082/7086503 [1:13:32<07:34, 4033.11it/s]读取数据:  74%|███████▍  | 5254585/7086503 [1:13:32<07:12, 4239.41it/s]读取数据:  74%|███████▍  | 5255102/7086503 [1:13:32<06:51, 4449.03it/s]读取数据:  74%|███████▍  | 5255670/7086503 [1:13:32<06:25, 4747.97it/s]读取数据:  74%|███████▍  | 5256220/7086503 [1:13:32<06:10, 4941.42it/s]读取数据:  74%|███████▍  | 5256751/7086503 [1:13:32<06:05, 5004.01it/s]读取数据:  74%|███████▍  | 5257310/7086503 [1:13:32<05:54, 5166.24it/s]读取数据:  74%|███████▍  | 5257847/7086503 [1:13:33<05:55, 5136.97it/s]读取数据:  74%|███████▍  | 5258375/7086503 [1:13:33<05:58, 5100.88it/s]读取数据:  74%|███████▍  | 5258918/7086503 [1:13:33<05:52, 5191.59it/s]读取数据:  74%|███████▍  | 5259445/7086503 [1:13:33<05:57, 5107.86it/s]读取数据:  74%|███████▍  | 5259961/7086503 [1:13:33<05:58, 5097.49it/s]读取数据:  74%|███████▍  | 5260533/7086503 [1:13:33<05:46, 5277.34it/s]读取数据:  74%|███████▍  | 5261064/7086503 [1:13:33<05:47, 5247.58it/s]读取数据:  74%|███████▍  | 5261622/7086503 [1:13:33<05:41, 5345.06it/s]读取数据:  74%|███████▍  | 5262161/7086503 [1:13:33<05:40, 5357.83it/s]读取数据:  74%|███████▍  | 5262702/7086503 [1:13:33<05:39, 5370.57it/s]读取数据:  74%|███████▍  | 5263240/7086503 [1:13:34<05:39, 5363.29it/s]读取数据:  74%|███████▍  | 5263814/7086503 [1:13:34<05:32, 5474.14it/s]读取数据:  74%|███████▍  | 5264362/7086503 [1:13:34<05:34, 5451.96it/s]读取数据:  74%|███████▍  | 5264908/7086503 [1:13:34<05:37, 5404.38it/s]读取数据:  74%|███████▍  | 5265454/7086503 [1:13:34<05:36, 5419.06it/s]读取数据:  74%|███████▍  | 5266013/7086503 [1:13:34<05:32, 5468.17it/s]读取数据:  74%|███████▍  | 5266561/7086503 [1:13:34<05:36, 5412.68it/s]读取数据:  74%|███████▍  | 5267113/7086503 [1:13:34<05:34, 5435.76it/s]读取数据:  74%|███████▍  | 5267657/7086503 [1:13:34<05:36, 5397.97it/s]读取数据:  74%|███████▍  | 5268197/7086503 [1:13:34<05:44, 5270.50it/s]读取数据:  74%|███████▍  | 5268743/7086503 [1:13:35<05:41, 5325.32it/s]读取数据:  74%|███████▍  | 5269311/7086503 [1:13:35<05:34, 5426.57it/s]读取数据:  74%|███████▍  | 5269855/7086503 [1:13:35<05:36, 5403.85it/s]读取数据:  74%|███████▍  | 5270439/7086503 [1:13:35<05:28, 5531.67it/s]读取数据:  74%|███████▍  | 5270995/7086503 [1:13:35<05:27, 5537.73it/s]读取数据:  74%|███████▍  | 5271596/7086503 [1:13:35<05:19, 5673.26it/s]读取数据:  74%|███████▍  | 5272189/7086503 [1:13:35<05:15, 5744.88it/s]读取数据:  74%|███████▍  | 5272779/7086503 [1:13:35<05:13, 5787.20it/s]读取数据:  74%|███████▍  | 5273393/7086503 [1:13:35<05:07, 5887.13it/s]读取数据:  74%|███████▍  | 5273987/7086503 [1:13:35<05:07, 5900.78it/s]读取数据:  74%|███████▍  | 5274578/7086503 [1:13:36<05:08, 5865.61it/s]读取数据:  74%|███████▍  | 5275209/7086503 [1:13:36<05:02, 5996.79it/s]读取数据:  74%|███████▍  | 5275850/7086503 [1:13:36<04:55, 6117.49it/s]读取数据:  74%|███████▍  | 5276463/7086503 [1:13:36<04:55, 6118.67it/s]读取数据:  74%|███████▍  | 5277131/7086503 [1:13:36<04:48, 6279.14it/s]读取数据:  74%|███████▍  | 5277773/7086503 [1:13:36<04:46, 6319.19it/s]读取数据:  74%|███████▍  | 5278432/7086503 [1:13:36<04:42, 6397.42it/s]读取数据:  74%|███████▍  | 5279124/7086503 [1:13:36<04:36, 6542.16it/s]读取数据:  75%|███████▍  | 5279780/7086503 [1:13:36<04:36, 6543.48it/s]读取数据:  75%|███████▍  | 5280476/7086503 [1:13:36<04:30, 6664.63it/s]读取数据:  75%|███████▍  | 5281219/7086503 [1:13:37<04:21, 6891.02it/s]读取数据:  75%|███████▍  | 5281909/7086503 [1:13:37<04:22, 6864.87it/s]读取数据:  75%|███████▍  | 5282630/7086503 [1:13:37<04:18, 6967.36it/s]读取数据:  75%|███████▍  | 5283372/7086503 [1:13:37<04:14, 7097.65it/s]读取数据:  75%|███████▍  | 5284169/7086503 [1:13:37<04:05, 7355.25it/s]读取数据:  75%|███████▍  | 5284968/7086503 [1:13:37<03:58, 7543.45it/s]读取数据:  75%|███████▍  | 5285805/7086503 [1:13:37<03:51, 7790.54it/s]读取数据:  75%|███████▍  | 5286639/7086503 [1:13:37<03:46, 7954.71it/s]读取数据:  75%|███████▍  | 5287515/7086503 [1:13:37<03:39, 8195.65it/s]读取数据:  75%|███████▍  | 5288402/7086503 [1:13:38<03:34, 8395.21it/s]读取数据:  75%|███████▍  | 5289312/7086503 [1:13:38<03:28, 8601.55it/s]读取数据:  75%|███████▍  | 5290279/7086503 [1:13:38<03:21, 8920.81it/s]读取数据:  75%|███████▍  | 5291332/7086503 [1:13:38<03:10, 9402.37it/s]读取数据:  75%|███████▍  | 5292379/7086503 [1:13:38<03:04, 9719.23it/s]读取数据:  75%|███████▍  | 5293466/7086503 [1:13:38<02:58, 10062.87it/s]读取数据:  75%|███████▍  | 5294602/7086503 [1:13:38<02:51, 10447.33it/s]读取数据:  75%|███████▍  | 5295769/7086503 [1:13:38<02:45, 10812.74it/s]读取数据:  75%|███████▍  | 5296903/7086503 [1:13:38<02:43, 10970.51it/s]读取数据:  75%|███████▍  | 5298001/7086503 [1:13:39<03:36, 8275.55it/s] 读取数据:  75%|███████▍  | 5298927/7086503 [1:13:39<03:49, 7785.13it/s]读取数据:  75%|███████▍  | 5299776/7086503 [1:13:39<04:38, 6413.24it/s]读取数据:  75%|███████▍  | 5300498/7086503 [1:13:40<17:55, 1661.17it/s]读取数据:  75%|███████▍  | 5301019/7086503 [1:13:40<15:32, 1913.89it/s]读取数据:  75%|███████▍  | 5301534/7086503 [1:13:41<13:31, 2200.29it/s]读取数据:  75%|███████▍  | 5302039/7086503 [1:13:41<11:44, 2534.56it/s]读取数据:  75%|███████▍  | 5302562/7086503 [1:13:41<10:10, 2921.60it/s]读取数据:  75%|███████▍  | 5303087/7086503 [1:13:41<08:57, 3316.74it/s]读取数据:  75%|███████▍  | 5303601/7086503 [1:13:41<08:07, 3654.32it/s]读取数据:  75%|███████▍  | 5304111/7086503 [1:13:41<07:31, 3950.85it/s]读取数据:  75%|███████▍  | 5304618/7086503 [1:13:41<07:09, 4148.40it/s]读取数据:  75%|███████▍  | 5305135/7086503 [1:13:41<06:44, 4401.69it/s]读取数据:  75%|███████▍  | 5305659/7086503 [1:13:41<06:25, 4620.48it/s]读取数据:  75%|███████▍  | 5306186/7086503 [1:13:41<06:11, 4794.73it/s]读取数据:  75%|███████▍  | 5306701/7086503 [1:13:42<06:04, 4886.48it/s]读取数据:  75%|███████▍  | 5307247/7086503 [1:13:42<05:52, 5049.85it/s]读取数据:  75%|███████▍  | 5307772/7086503 [1:13:42<05:48, 5102.05it/s]读取数据:  75%|███████▍  | 5308307/7086503 [1:13:42<05:44, 5168.63it/s]读取数据:  75%|███████▍  | 5308834/7086503 [1:13:42<05:45, 5147.12it/s]读取数据:  75%|███████▍  | 5309377/7086503 [1:13:42<05:40, 5224.32it/s]读取数据:  75%|███████▍  | 5309944/7086503 [1:13:42<05:31, 5351.16it/s]读取数据:  75%|███████▍  | 5310483/7086503 [1:13:42<05:31, 5358.24it/s]读取数据:  75%|███████▍  | 5311022/7086503 [1:13:42<05:31, 5360.15it/s]读取数据:  75%|███████▍  | 5311561/7086503 [1:13:42<05:30, 5367.45it/s]读取数据:  75%|███████▍  | 5312113/7086503 [1:13:43<05:27, 5410.71it/s]读取数据:  75%|███████▍  | 5312678/7086503 [1:13:43<05:23, 5479.91it/s]读取数据:  75%|███████▍  | 5313254/7086503 [1:13:43<05:18, 5560.09it/s]读取数据:  75%|███████▍  | 5313811/7086503 [1:13:43<05:20, 5531.89it/s]读取数据:  75%|███████▍  | 5314377/7086503 [1:13:43<05:18, 5569.81it/s]读取数据:  75%|███████▌  | 5314935/7086503 [1:13:43<05:18, 5569.56it/s]读取数据:  75%|███████▌  | 5315493/7086503 [1:13:43<05:20, 5521.07it/s]读取数据:  75%|███████▌  | 5316063/7086503 [1:13:43<05:17, 5571.51it/s]读取数据:  75%|███████▌  | 5316685/7086503 [1:13:43<05:07, 5755.83it/s]读取数据:  75%|███████▌  | 5317272/7086503 [1:13:43<05:05, 5788.42it/s]读取数据:  75%|███████▌  | 5317851/7086503 [1:13:44<05:12, 5665.22it/s]读取数据:  75%|███████▌  | 5318448/7086503 [1:13:44<05:07, 5745.90it/s]读取数据:  75%|███████▌  | 5319042/7086503 [1:13:44<05:04, 5799.71it/s]读取数据:  75%|███████▌  | 5319637/7086503 [1:13:44<05:02, 5841.75it/s]读取数据:  75%|███████▌  | 5320222/7086503 [1:13:44<05:04, 5796.00it/s]读取数据:  75%|███████▌  | 5320822/7086503 [1:13:44<05:01, 5855.65it/s]读取数据:  75%|███████▌  | 5321410/7086503 [1:13:44<05:01, 5861.71it/s]读取数据:  75%|███████▌  | 5322004/7086503 [1:13:44<04:59, 5884.98it/s]读取数据:  75%|███████▌  | 5322613/7086503 [1:13:44<04:56, 5944.75it/s]读取数据:  75%|███████▌  | 5323208/7086503 [1:13:44<05:01, 5845.09it/s]读取数据:  75%|███████▌  | 5323860/7086503 [1:13:45<04:51, 6043.38it/s]读取数据:  75%|███████▌  | 5324465/7086503 [1:13:45<07:18, 4019.51it/s]读取数据:  75%|███████▌  | 5324956/7086503 [1:13:45<07:46, 3772.77it/s]读取数据:  75%|███████▌  | 5325547/7086503 [1:13:45<06:55, 4241.92it/s]读取数据:  75%|███████▌  | 5326032/7086503 [1:13:46<13:26, 2183.66it/s]读取数据:  75%|███████▌  | 5326621/7086503 [1:13:46<10:46, 2720.90it/s]读取数据:  75%|███████▌  | 5327184/7086503 [1:13:46<09:06, 3220.11it/s]读取数据:  75%|███████▌  | 5327657/7086503 [1:13:46<08:55, 3281.71it/s]读取数据:  75%|███████▌  | 5328251/7086503 [1:13:46<07:38, 3833.05it/s]读取数据:  75%|███████▌  | 5328865/7086503 [1:13:46<06:43, 4360.54it/s]读取数据:  75%|███████▌  | 5329519/7086503 [1:13:46<05:58, 4896.38it/s]读取数据:  75%|███████▌  | 5330182/7086503 [1:13:46<05:28, 5343.06it/s]读取数据:  75%|███████▌  | 5330773/7086503 [1:13:46<05:32, 5279.94it/s]读取数据:  75%|███████▌  | 5331426/7086503 [1:13:47<05:12, 5617.50it/s]读取数据:  75%|███████▌  | 5332096/7086503 [1:13:47<04:56, 5919.31it/s]读取数据:  75%|███████▌  | 5332815/7086503 [1:13:47<04:39, 6278.76it/s]读取数据:  75%|███████▌  | 5333489/7086503 [1:13:47<04:33, 6409.74it/s]读取数据:  75%|███████▌  | 5334144/7086503 [1:13:47<04:43, 6187.30it/s]读取数据:  75%|███████▌  | 5334828/7086503 [1:13:47<04:35, 6361.20it/s]读取数据:  75%|███████▌  | 5335572/7086503 [1:13:47<04:22, 6672.29it/s]读取数据:  75%|███████▌  | 5336326/7086503 [1:13:47<04:12, 6925.55it/s]读取数据:  75%|███████▌  | 5337062/7086503 [1:13:47<04:08, 7047.60it/s]读取数据:  75%|███████▌  | 5337866/7086503 [1:13:47<03:58, 7340.99it/s]读取数据:  75%|███████▌  | 5338788/7086503 [1:13:48<03:41, 7899.50it/s]读取数据:  75%|███████▌  | 5339744/7086503 [1:13:48<03:28, 8394.07it/s]读取数据:  75%|███████▌  | 5340734/7086503 [1:13:48<03:17, 8840.76it/s]读取数据:  75%|███████▌  | 5341753/7086503 [1:13:48<03:08, 9240.57it/s]读取数据:  75%|███████▌  | 5342801/7086503 [1:13:48<03:01, 9611.14it/s]读取数据:  75%|███████▌  | 5343930/7086503 [1:13:48<02:52, 10112.25it/s]读取数据:  75%|███████▌  | 5345109/7086503 [1:13:48<02:44, 10614.27it/s]读取数据:  75%|███████▌  | 5346302/7086503 [1:13:48<02:38, 11005.93it/s]读取数据:  75%|███████▌  | 5347487/7086503 [1:13:48<02:34, 11257.96it/s]读取数据:  75%|███████▌  | 5348669/7086503 [1:13:48<02:32, 11422.36it/s]读取数据:  75%|███████▌  | 5349812/7086503 [1:13:49<02:33, 11285.14it/s]读取数据:  76%|███████▌  | 5350942/7086503 [1:13:50<10:17, 2811.73it/s] 读取数据:  76%|███████▌  | 5351763/7086503 [1:13:50<09:09, 3159.53it/s]读取数据:  76%|███████▌  | 5352496/7086503 [1:13:50<08:21, 3454.93it/s]读取数据:  76%|███████▌  | 5353160/7086503 [1:13:50<07:44, 3729.74it/s]读取数据:  76%|███████▌  | 5353777/7086503 [1:13:50<07:07, 4056.49it/s]读取数据:  76%|███████▌  | 5354380/7086503 [1:13:50<06:38, 4349.54it/s]读取数据:  76%|███████▌  | 5354970/7086503 [1:13:50<06:20, 4554.54it/s]读取数据:  76%|███████▌  | 5355541/7086503 [1:13:51<06:08, 4701.33it/s]读取数据:  76%|███████▌  | 5356096/7086503 [1:13:51<05:56, 4848.93it/s]读取数据:  76%|███████▌  | 5356644/7086503 [1:13:51<05:53, 4889.16it/s]读取数据:  76%|███████▌  | 5357178/7086503 [1:13:51<05:49, 4945.24it/s]读取数据:  76%|███████▌  | 5357705/7086503 [1:13:51<05:44, 5023.54it/s]读取数据:  76%|███████▌  | 5358231/7086503 [1:13:51<05:40, 5074.04it/s]读取数据:  76%|███████▌  | 5358755/7086503 [1:13:51<05:40, 5074.04it/s]读取数据:  76%|███████▌  | 5359275/7086503 [1:13:51<05:38, 5102.82it/s]读取数据:  76%|███████▌  | 5359794/7086503 [1:13:52<08:06, 3546.81it/s]读取数据:  76%|███████▌  | 5360296/7086503 [1:13:52<07:25, 3873.61it/s]读取数据:  76%|███████▌  | 5360795/7086503 [1:13:52<06:57, 4136.15it/s]读取数据:  76%|███████▌  | 5361257/7086503 [1:13:52<07:19, 3924.64it/s]读取数据:  76%|███████▌  | 5361767/7086503 [1:13:52<06:48, 4217.40it/s]读取数据:  76%|███████▌  | 5362269/7086503 [1:13:52<06:29, 4429.56it/s]读取数据:  76%|███████▌  | 5362736/7086503 [1:13:52<06:47, 4234.90it/s]读取数据:  76%|███████▌  | 5363178/7086503 [1:13:52<06:48, 4222.93it/s]读取数据:  76%|███████▌  | 5363703/7086503 [1:13:52<06:22, 4504.17it/s]读取数据:  76%|███████▌  | 5364168/7086503 [1:13:53<06:19, 4539.59it/s]读取数据:  76%|███████▌  | 5364700/7086503 [1:13:53<06:02, 4755.08it/s]读取数据:  76%|███████▌  | 5365182/7086503 [1:13:53<06:17, 4564.40it/s]读取数据:  76%|███████▌  | 5365685/7086503 [1:13:53<06:06, 4695.26it/s]读取数据:  76%|███████▌  | 5366193/7086503 [1:13:53<05:58, 4802.26it/s]读取数据:  76%|███████▌  | 5366677/7086503 [1:13:53<06:35, 4346.09it/s]读取数据:  76%|███████▌  | 5367173/7086503 [1:13:53<06:20, 4513.20it/s]读取数据:  76%|███████▌  | 5367722/7086503 [1:13:53<05:59, 4783.07it/s]读取数据:  76%|███████▌  | 5368209/7086503 [1:13:53<06:02, 4734.84it/s]读取数据:  76%|███████▌  | 5368731/7086503 [1:13:53<05:52, 4872.17it/s]读取数据:  76%|███████▌  | 5369275/7086503 [1:13:54<05:41, 5032.23it/s]读取数据:  76%|███████▌  | 5369813/7086503 [1:13:54<05:34, 5133.82it/s]读取数据:  76%|███████▌  | 5370347/7086503 [1:13:54<05:30, 5191.03it/s]读取数据:  76%|███████▌  | 5370899/7086503 [1:13:54<05:24, 5287.60it/s]读取数据:  76%|███████▌  | 5371470/7086503 [1:13:54<05:16, 5412.89it/s]读取数据:  76%|███████▌  | 5372017/7086503 [1:13:54<05:15, 5429.78it/s]读取数据:  76%|███████▌  | 5372584/7086503 [1:13:54<05:11, 5497.58it/s]读取数据:  76%|███████▌  | 5373181/7086503 [1:13:54<05:04, 5633.83it/s]读取数据:  76%|███████▌  | 5373745/7086503 [1:13:54<05:04, 5628.69it/s]读取数据:  76%|███████▌  | 5374341/7086503 [1:13:54<04:58, 5727.52it/s]读取数据:  76%|███████▌  | 5374929/7086503 [1:13:55<04:56, 5770.01it/s]读取数据:  76%|███████▌  | 5375507/7086503 [1:13:55<04:59, 5722.36it/s]读取数据:  76%|███████▌  | 5376080/7086503 [1:13:55<05:02, 5653.24it/s]读取数据:  76%|███████▌  | 5376698/7086503 [1:13:55<04:54, 5807.89it/s]读取数据:  76%|███████▌  | 5377339/7086503 [1:13:55<04:45, 5984.05it/s]读取数据:  76%|███████▌  | 5377964/7086503 [1:13:55<04:41, 6063.18it/s]读取数据:  76%|███████▌  | 5378622/7086503 [1:13:55<04:34, 6215.65it/s]读取数据:  76%|███████▌  | 5379244/7086503 [1:13:55<04:42, 6043.30it/s]读取数据:  76%|███████▌  | 5379850/7086503 [1:13:55<04:44, 5992.95it/s]读取数据:  76%|███████▌  | 5380475/7086503 [1:13:55<04:41, 6067.53it/s]读取数据:  76%|███████▌  | 5381114/7086503 [1:13:56<04:36, 6157.82it/s]读取数据:  76%|███████▌  | 5381766/7086503 [1:13:56<04:32, 6262.50it/s]读取数据:  76%|███████▌  | 5382416/7086503 [1:13:56<04:29, 6331.87it/s]读取数据:  76%|███████▌  | 5383130/7086503 [1:13:56<04:19, 6571.24it/s]读取数据:  76%|███████▌  | 5383844/7086503 [1:13:56<04:12, 6734.75it/s]读取数据:  76%|███████▌  | 5384557/7086503 [1:13:56<04:08, 6850.35it/s]读取数据:  76%|███████▌  | 5385289/7086503 [1:13:56<04:03, 6986.39it/s]读取数据:  76%|███████▌  | 5386074/7086503 [1:13:56<03:54, 7242.37it/s]读取数据:  76%|███████▌  | 5386812/7086503 [1:13:56<03:53, 7281.85it/s]读取数据:  76%|███████▌  | 5387541/7086503 [1:13:57<04:23, 6441.05it/s]读取数据:  76%|███████▌  | 5388322/7086503 [1:13:57<04:09, 6815.03it/s]读取数据:  76%|███████▌  | 5389123/7086503 [1:13:57<03:57, 7150.77it/s]读取数据:  76%|███████▌  | 5389937/7086503 [1:13:57<03:48, 7433.51it/s]读取数据:  76%|███████▌  | 5390738/7086503 [1:13:57<03:43, 7599.13it/s]读取数据:  76%|███████▌  | 5391548/7086503 [1:13:57<03:38, 7745.32it/s]读取数据:  76%|███████▌  | 5392350/7086503 [1:13:57<03:36, 7825.70it/s]读取数据:  76%|███████▌  | 5393188/7086503 [1:13:57<03:31, 7989.02it/s]读取数据:  76%|███████▌  | 5394028/7086503 [1:13:57<03:28, 8110.40it/s]读取数据:  76%|███████▌  | 5394842/7086503 [1:13:58<06:05, 4629.62it/s]读取数据:  76%|███████▌  | 5395594/7086503 [1:13:58<05:25, 5193.91it/s]读取数据:  76%|███████▌  | 5396432/7086503 [1:13:58<04:47, 5887.00it/s]读取数据:  76%|███████▌  | 5397154/7086503 [1:13:58<08:30, 3309.81it/s]读取数据:  76%|███████▌  | 5398021/7086503 [1:13:58<06:48, 4130.75it/s]读取数据:  76%|███████▌  | 5398882/7086503 [1:13:59<05:43, 4916.62it/s]读取数据:  76%|███████▌  | 5399638/7086503 [1:13:59<05:16, 5335.93it/s]读取数据:  76%|███████▌  | 5400336/7086503 [1:14:00<14:59, 1873.77it/s]读取数据:  76%|███████▌  | 5400845/7086503 [1:14:00<13:00, 2159.01it/s]读取数据:  76%|███████▌  | 5401355/7086503 [1:14:00<11:12, 2504.93it/s]读取数据:  76%|███████▌  | 5401870/7086503 [1:14:00<09:44, 2884.33it/s]读取数据:  76%|███████▌  | 5402375/7086503 [1:14:00<08:41, 3230.55it/s]读取数据:  76%|███████▌  | 5402874/7086503 [1:14:00<07:57, 3526.58it/s]读取数据:  76%|███████▌  | 5403374/7086503 [1:14:00<07:18, 3841.81it/s]读取数据:  76%|███████▋  | 5403866/7086503 [1:14:00<06:55, 4050.78it/s]读取数据:  76%|███████▋  | 5404409/7086503 [1:14:01<06:22, 4392.84it/s]读取数据:  76%|███████▋  | 5404916/7086503 [1:14:01<06:08, 4569.10it/s]读取数据:  76%|███████▋  | 5405424/7086503 [1:14:01<05:57, 4702.84it/s]读取数据:  76%|███████▋  | 5405929/7086503 [1:14:01<05:51, 4780.02it/s]读取数据:  76%|███████▋  | 5406471/7086503 [1:14:01<05:38, 4958.52it/s]读取数据:  76%|███████▋  | 5406985/7086503 [1:14:01<05:35, 5008.04it/s]读取数据:  76%|███████▋  | 5407501/7086503 [1:14:01<05:32, 5048.74it/s]读取数据:  76%|███████▋  | 5408015/7086503 [1:14:01<05:34, 5016.62it/s]读取数据:  76%|███████▋  | 5408526/7086503 [1:14:01<05:32, 5043.05it/s]读取数据:  76%|███████▋  | 5409035/7086503 [1:14:01<05:34, 5008.49it/s]读取数据:  76%|███████▋  | 5409560/7086503 [1:14:02<05:30, 5074.68it/s]读取数据:  76%|███████▋  | 5410070/7086503 [1:14:02<05:29, 5081.49it/s]读取数据:  76%|███████▋  | 5410586/7086503 [1:14:02<05:28, 5103.11it/s]读取数据:  76%|███████▋  | 5411103/7086503 [1:14:02<05:27, 5121.70it/s]读取数据:  76%|███████▋  | 5411616/7086503 [1:14:02<05:29, 5087.71it/s]读取数据:  76%|███████▋  | 5412126/7086503 [1:14:02<05:31, 5054.58it/s]读取数据:  76%|███████▋  | 5412632/7086503 [1:14:02<05:32, 5027.50it/s]读取数据:  76%|███████▋  | 5413147/7086503 [1:14:02<05:30, 5059.40it/s]读取数据:  76%|███████▋  | 5413666/7086503 [1:14:02<05:28, 5096.32it/s]读取数据:  76%|███████▋  | 5414180/7086503 [1:14:02<05:27, 5108.40it/s]读取数据:  76%|███████▋  | 5414709/7086503 [1:14:03<05:23, 5161.76it/s]读取数据:  76%|███████▋  | 5415226/7086503 [1:14:03<05:28, 5082.86it/s]读取数据:  76%|███████▋  | 5415772/7086503 [1:14:03<05:21, 5193.81it/s]读取数据:  76%|███████▋  | 5416318/7086503 [1:14:03<05:16, 5272.05it/s]读取数据:  76%|███████▋  | 5416880/7086503 [1:14:03<05:10, 5375.10it/s]读取数据:  76%|███████▋  | 5417418/7086503 [1:14:03<05:10, 5373.67it/s]读取数据:  76%|███████▋  | 5417981/7086503 [1:14:03<05:06, 5449.16it/s]读取数据:  76%|███████▋  | 5418548/7086503 [1:14:03<05:02, 5511.79it/s]读取数据:  76%|███████▋  | 5419100/7086503 [1:14:03<05:06, 5444.71it/s]读取数据:  76%|███████▋  | 5419663/7086503 [1:14:03<05:03, 5499.15it/s]读取数据:  76%|███████▋  | 5420235/7086503 [1:14:04<04:59, 5561.16it/s]读取数据:  76%|███████▋  | 5420809/7086503 [1:14:04<04:56, 5613.40it/s]读取数据:  77%|███████▋  | 5421389/7086503 [1:14:04<04:53, 5668.83it/s]读取数据:  77%|███████▋  | 5421957/7086503 [1:14:04<04:54, 5660.93it/s]读取数据:  77%|███████▋  | 5422538/7086503 [1:14:04<04:51, 5705.41it/s]读取数据:  77%|███████▋  | 5423114/7086503 [1:14:04<04:50, 5717.61it/s]读取数据:  77%|███████▋  | 5423714/7086503 [1:14:04<04:46, 5797.68it/s]读取数据:  77%|███████▋  | 5424294/7086503 [1:14:04<04:48, 5760.71it/s]读取数据:  77%|███████▋  | 5424911/7086503 [1:14:04<04:42, 5880.11it/s]读取数据:  77%|███████▋  | 5425500/7086503 [1:14:04<04:43, 5862.50it/s]读取数据:  77%|███████▋  | 5426087/7086503 [1:14:05<04:43, 5851.83it/s]读取数据:  77%|███████▋  | 5426688/7086503 [1:14:05<04:41, 5897.46it/s]读取数据:  77%|███████▋  | 5427278/7086503 [1:14:05<04:43, 5862.87it/s]读取数据:  77%|███████▋  | 5427874/7086503 [1:14:05<04:41, 5890.82it/s]读取数据:  77%|███████▋  | 5428495/7086503 [1:14:05<04:37, 5979.68it/s]读取数据:  77%|███████▋  | 5429129/7086503 [1:14:05<04:32, 6081.33it/s]读取数据:  77%|███████▋  | 5429779/7086503 [1:14:05<04:26, 6206.36it/s]读取数据:  77%|███████▋  | 5430430/7086503 [1:14:05<04:23, 6295.70it/s]读取数据:  77%|███████▋  | 5431070/7086503 [1:14:05<04:21, 6323.72it/s]读取数据:  77%|███████▋  | 5431744/7086503 [1:14:05<04:16, 6447.45it/s]读取数据:  77%|███████▋  | 5432396/7086503 [1:14:06<04:15, 6467.23it/s]读取数据:  77%|███████▋  | 5433112/7086503 [1:14:06<04:07, 6674.18it/s]读取数据:  77%|███████▋  | 5433814/7086503 [1:14:06<04:03, 6776.18it/s]读取数据:  77%|███████▋  | 5434492/7086503 [1:14:06<04:06, 6713.69it/s]读取数据:  77%|███████▋  | 5435212/7086503 [1:14:06<04:00, 6856.88it/s]读取数据:  77%|███████▋  | 5435921/7086503 [1:14:06<03:58, 6925.12it/s]读取数据:  77%|███████▋  | 5436664/7086503 [1:14:06<03:53, 7073.55it/s]读取数据:  77%|███████▋  | 5437407/7086503 [1:14:06<03:49, 7173.54it/s]读取数据:  77%|███████▋  | 5438179/7086503 [1:14:06<03:44, 7336.75it/s]读取数据:  77%|███████▋  | 5438989/7086503 [1:14:06<03:37, 7564.49it/s]读取数据:  77%|███████▋  | 5439746/7086503 [1:14:07<03:40, 7466.30it/s]读取数据:  77%|███████▋  | 5440635/7086503 [1:14:07<03:28, 7888.39it/s]读取数据:  77%|███████▋  | 5441451/7086503 [1:14:07<03:26, 7966.48it/s]读取数据:  77%|███████▋  | 5442272/7086503 [1:14:07<03:24, 8033.64it/s]读取数据:  77%|███████▋  | 5443101/7086503 [1:14:07<03:22, 8109.78it/s]读取数据:  77%|███████▋  | 5443954/7086503 [1:14:07<03:19, 8233.77it/s]读取数据:  77%|███████▋  | 5444802/7086503 [1:14:07<03:17, 8304.29it/s]读取数据:  77%|███████▋  | 5445785/7086503 [1:14:07<03:07, 8759.77it/s]读取数据:  77%|███████▋  | 5446781/7086503 [1:14:07<02:59, 9117.78it/s]读取数据:  77%|███████▋  | 5447693/7086503 [1:14:07<03:01, 9027.15it/s]读取数据:  77%|███████▋  | 5448597/7086503 [1:14:08<03:01, 9026.57it/s]读取数据:  77%|███████▋  | 5449500/7086503 [1:14:08<03:05, 8824.13it/s]读取数据:  77%|███████▋  | 5450384/7086503 [1:14:09<11:36, 2348.67it/s]读取数据:  77%|███████▋  | 5451028/7086503 [1:14:09<10:15, 2656.76it/s]读取数据:  77%|███████▋  | 5451619/7086503 [1:14:09<09:11, 2966.11it/s]读取数据:  77%|███████▋  | 5452176/7086503 [1:14:09<08:23, 3247.20it/s]读取数据:  77%|███████▋  | 5452705/7086503 [1:14:09<07:42, 3533.94it/s]读取数据:  77%|███████▋  | 5453221/7086503 [1:14:09<07:09, 3801.08it/s]读取数据:  77%|███████▋  | 5453728/7086503 [1:14:09<06:44, 4034.96it/s]读取数据:  77%|███████▋  | 5454249/7086503 [1:14:10<06:19, 4304.39it/s]读取数据:  77%|███████▋  | 5454756/7086503 [1:14:10<06:09, 4410.30it/s]读取数据:  77%|███████▋  | 5455271/7086503 [1:14:10<05:54, 4600.83it/s]读取数据:  77%|███████▋  | 5455773/7086503 [1:14:10<05:47, 4691.06it/s]读取数据:  77%|███████▋  | 5456290/7086503 [1:14:10<05:38, 4822.45it/s]读取数据:  77%|███████▋  | 5456795/7086503 [1:14:10<05:34, 4876.43it/s]读取数据:  77%|███████▋  | 5457330/7086503 [1:14:10<05:25, 5011.91it/s]读取数据:  77%|███████▋  | 5457843/7086503 [1:14:10<05:26, 4983.21it/s]读取数据:  77%|███████▋  | 5458350/7086503 [1:14:10<05:27, 4975.71it/s]读取数据:  77%|███████▋  | 5458854/7086503 [1:14:10<05:27, 4967.56it/s]读取数据:  77%|███████▋  | 5459355/7086503 [1:14:11<05:27, 4961.87it/s]读取数据:  77%|███████▋  | 5459863/7086503 [1:14:11<05:26, 4989.54it/s]读取数据:  77%|███████▋  | 5460370/7086503 [1:14:11<05:24, 5013.15it/s]读取数据:  77%|███████▋  | 5460875/7086503 [1:14:11<05:23, 5022.85it/s]读取数据:  77%|███████▋  | 5461379/7086503 [1:14:11<05:26, 4981.60it/s]读取数据:  77%|███████▋  | 5461878/7086503 [1:14:11<05:27, 4967.61it/s]读取数据:  77%|███████▋  | 5462417/7086503 [1:14:11<05:18, 5091.74it/s]读取数据:  77%|███████▋  | 5462936/7086503 [1:14:11<05:17, 5119.47it/s]读取数据:  77%|███████▋  | 5463457/7086503 [1:14:11<05:15, 5145.46it/s]读取数据:  77%|███████▋  | 5463977/7086503 [1:14:11<05:14, 5158.47it/s]读取数据:  77%|███████▋  | 5464494/7086503 [1:14:12<05:16, 5120.24it/s]读取数据:  77%|███████▋  | 5465030/7086503 [1:14:12<05:12, 5188.30it/s]读取数据:  77%|███████▋  | 5465551/7086503 [1:14:12<05:12, 5191.27it/s]读取数据:  77%|███████▋  | 5466071/7086503 [1:14:12<05:12, 5187.65it/s]读取数据:  77%|███████▋  | 5466594/7086503 [1:14:12<05:11, 5194.42it/s]读取数据:  77%|███████▋  | 5467146/7086503 [1:14:12<05:06, 5287.19it/s]读取数据:  77%|███████▋  | 5467698/7086503 [1:14:12<05:02, 5355.91it/s]读取数据:  77%|███████▋  | 5468234/7086503 [1:14:12<05:08, 5251.38it/s]读取数据:  77%|███████▋  | 5468760/7086503 [1:14:12<05:11, 5191.55it/s]读取数据:  77%|███████▋  | 5469312/7086503 [1:14:12<05:06, 5281.85it/s]读取数据:  77%|███████▋  | 5469867/7086503 [1:14:13<05:01, 5360.03it/s]读取数据:  77%|███████▋  | 5470454/7086503 [1:14:13<04:53, 5509.52it/s]读取数据:  77%|███████▋  | 5471010/7086503 [1:14:13<04:52, 5520.44it/s]读取数据:  77%|███████▋  | 5471563/7086503 [1:14:13<04:52, 5512.46it/s]读取数据:  77%|███████▋  | 5472144/7086503 [1:14:13<04:48, 5600.79it/s]读取数据:  77%|███████▋  | 5472705/7086503 [1:14:13<04:48, 5601.76it/s]读取数据:  77%|███████▋  | 5473308/7086503 [1:14:13<04:41, 5728.41it/s]读取数据:  77%|███████▋  | 5473920/7086503 [1:14:13<04:36, 5835.73it/s]读取数据:  77%|███████▋  | 5474504/7086503 [1:14:13<04:37, 5802.65it/s]读取数据:  77%|███████▋  | 5475113/7086503 [1:14:13<04:33, 5885.85it/s]读取数据:  77%|███████▋  | 5475719/7086503 [1:14:14<04:31, 5932.83it/s]读取数据:  77%|███████▋  | 5476347/7086503 [1:14:14<04:26, 6036.36it/s]读取数据:  77%|███████▋  | 5476958/7086503 [1:14:14<04:25, 6051.05it/s]读取数据:  77%|███████▋  | 5477597/7086503 [1:14:14<04:21, 6150.14it/s]读取数据:  77%|███████▋  | 5478223/7086503 [1:14:14<04:20, 6179.84it/s]读取数据:  77%|███████▋  | 5478888/7086503 [1:14:14<04:14, 6316.67it/s]读取数据:  77%|███████▋  | 5479530/7086503 [1:14:14<04:13, 6342.41it/s]读取数据:  77%|███████▋  | 5480170/7086503 [1:14:14<04:12, 6355.89it/s]读取数据:  77%|███████▋  | 5480820/7086503 [1:14:14<04:11, 6395.88it/s]读取数据:  77%|███████▋  | 5481460/7086503 [1:14:14<04:14, 6300.83it/s]读取数据:  77%|███████▋  | 5482154/7086503 [1:14:15<04:07, 6489.86it/s]读取数据:  77%|███████▋  | 5482812/7086503 [1:14:15<04:06, 6514.89it/s]读取数据:  77%|███████▋  | 5483509/7086503 [1:14:15<04:01, 6645.65it/s]读取数据:  77%|███████▋  | 5484240/7086503 [1:14:15<03:54, 6842.52it/s]读取数据:  77%|███████▋  | 5485009/7086503 [1:14:15<03:45, 7092.19it/s]读取数据:  77%|███████▋  | 5485767/7086503 [1:14:15<03:41, 7236.30it/s]读取数据:  77%|███████▋  | 5486584/7086503 [1:14:15<03:32, 7513.48it/s]读取数据:  77%|███████▋  | 5487451/7086503 [1:14:15<03:23, 7859.55it/s]读取数据:  77%|███████▋  | 5488348/7086503 [1:14:15<03:15, 8191.23it/s]读取数据:  77%|███████▋  | 5489246/7086503 [1:14:15<03:09, 8424.95it/s]读取数据:  77%|███████▋  | 5490229/7086503 [1:14:16<03:00, 8843.22it/s]读取数据:  77%|███████▋  | 5491255/7086503 [1:14:16<02:52, 9267.23it/s]读取数据:  78%|███████▊  | 5492326/7086503 [1:14:16<02:44, 9698.88it/s]读取数据:  78%|███████▊  | 5493458/7086503 [1:14:16<02:36, 10184.84it/s]读取数据:  78%|███████▊  | 5494580/7086503 [1:14:16<02:31, 10494.89it/s]读取数据:  78%|███████▊  | 5495783/7086503 [1:14:16<02:25, 10953.44it/s]读取数据:  78%|███████▊  | 5497021/7086503 [1:14:16<02:19, 11377.48it/s]读取数据:  78%|███████▊  | 5498237/7086503 [1:14:16<02:16, 11610.58it/s]读取数据:  78%|███████▊  | 5499439/7086503 [1:14:16<02:15, 11731.15it/s]读取数据:  78%|███████▊  | 5499439/7086503 [1:14:27<02:15, 11731.15it/s]读取数据:  78%|███████▊  | 5500000/7086503 [1:23:16<72:04:04,  6.11it/s]读取数据:  78%|███████▊  | 5500212/7086503 [1:23:16<66:01:06,  6.67it/s]读取数据:  78%|███████▊  | 5501097/7086503 [1:23:16<43:58:45, 10.01it/s]读取数据:  78%|███████▊  | 5501863/7086503 [1:23:16<31:08:16, 14.14it/s]读取数据:  78%|███████▊  | 5502550/7086503 [1:23:16<22:40:11, 19.41it/s]读取数据:  78%|███████▊  | 5503180/7086503 [1:23:16<16:43:23, 26.30it/s]读取数据:  78%|███████▊  | 5503775/7086503 [1:23:17<12:21:36, 35.57it/s]读取数据:  78%|███████▊  | 5504350/7086503 [1:23:17<9:05:50, 48.31it/s] 读取数据:  78%|███████▊  | 5504906/7086503 [1:23:17<6:40:38, 65.80it/s]读取数据:  78%|███████▊  | 5505444/7086503 [1:23:17<4:53:27, 89.80it/s]读取数据:  78%|███████▊  | 5505981/7086503 [1:23:17<3:33:10, 123.57it/s]读取数据:  78%|███████▊  | 5506516/7086503 [1:23:17<2:34:01, 170.97it/s]读取数据:  78%|███████▊  | 5507043/7086503 [1:23:17<1:51:30, 236.08it/s]读取数据:  78%|███████▊  | 5507571/7086503 [1:23:17<1:20:35, 326.52it/s]读取数据:  78%|███████▊  | 5508094/7086503 [1:23:17<58:35, 448.98it/s]  读取数据:  78%|███████▊  | 5508642/7086503 [1:23:18<42:15, 622.28it/s]读取数据:  78%|███████▊  | 5509202/7086503 [1:23:18<30:43, 855.76it/s]读取数据:  78%|███████▊  | 5509772/7086503 [1:23:18<22:39, 1159.94it/s]读取数据:  78%|███████▊  | 5510347/7086503 [1:23:18<17:04, 1537.83it/s]读取数据:  78%|███████▊  | 5510903/7086503 [1:23:18<13:26, 1954.70it/s]读取数据:  78%|███████▊  | 5511463/7086503 [1:23:18<10:48, 2429.16it/s]读取数据:  78%|███████▊  | 5512017/7086503 [1:23:18<09:05, 2883.72it/s]读取数据:  78%|███████▊  | 5512560/7086503 [1:23:18<07:53, 3327.39it/s]读取数据:  78%|███████▊  | 5513120/7086503 [1:23:18<06:54, 3792.56it/s]读取数据:  78%|███████▊  | 5513665/7086503 [1:23:18<06:18, 4157.64it/s]读取数据:  78%|███████▊  | 5514215/7086503 [1:23:19<05:50, 4484.01it/s]读取数据:  78%|███████▊  | 5514778/7086503 [1:23:19<05:29, 4775.19it/s]读取数据:  78%|███████▊  | 5515351/7086503 [1:23:19<05:12, 5026.48it/s]读取数据:  78%|███████▊  | 5515921/7086503 [1:23:19<05:01, 5211.05it/s]读取数据:  78%|███████▊  | 5516483/7086503 [1:23:19<04:54, 5323.11it/s]读取数据:  78%|███████▊  | 5517048/7086503 [1:23:19<04:50, 5411.22it/s]读取数据:  78%|███████▊  | 5517627/7086503 [1:23:19<04:44, 5520.55it/s]读取数据:  78%|███████▊  | 5518194/7086503 [1:23:19<04:42, 5551.20it/s]读取数据:  78%|███████▊  | 5518782/7086503 [1:23:19<04:37, 5647.08it/s]读取数据:  78%|███████▊  | 5519399/7086503 [1:23:19<04:30, 5797.82it/s]读取数据:  78%|███████▊  | 5520000/7086503 [1:23:20<04:27, 5860.81it/s]读取数据:  78%|███████▊  | 5520605/7086503 [1:23:20<04:24, 5916.08it/s]读取数据:  78%|███████▊  | 5521235/7086503 [1:23:20<04:19, 6029.73it/s]读取数据:  78%|███████▊  | 5521840/7086503 [1:23:20<04:20, 5996.31it/s]读取数据:  78%|███████▊  | 5522447/7086503 [1:23:20<04:19, 6018.14it/s]读取数据:  78%|███████▊  | 5523099/7086503 [1:23:20<04:13, 6163.30it/s]读取数据:  78%|███████▊  | 5523717/7086503 [1:23:20<05:29, 4745.43it/s]读取数据:  78%|███████▊  | 5524242/7086503 [1:23:20<06:39, 3909.02it/s]读取数据:  78%|███████▊  | 5524838/7086503 [1:23:21<05:58, 4360.36it/s]读取数据:  78%|███████▊  | 5525329/7086503 [1:23:21<07:04, 3674.39it/s]读取数据:  78%|███████▊  | 5525920/7086503 [1:23:21<06:14, 4163.18it/s]读取数据:  78%|███████▊  | 5526516/7086503 [1:23:21<05:39, 4589.72it/s]读取数据:  78%|███████▊  | 5527136/7086503 [1:23:21<05:12, 4997.86it/s]读取数据:  78%|███████▊  | 5527775/7086503 [1:23:21<04:50, 5366.28it/s]读取数据:  78%|███████▊  | 5528451/7086503 [1:23:21<04:31, 5745.51it/s]读取数据:  78%|███████▊  | 5529152/7086503 [1:23:21<04:15, 6101.15it/s]读取数据:  78%|███████▊  | 5529832/7086503 [1:23:21<04:07, 6300.03it/s]读取数据:  78%|███████▊  | 5530524/7086503 [1:23:22<04:00, 6473.83it/s]读取数据:  78%|███████▊  | 5531197/7086503 [1:23:22<03:57, 6548.89it/s]读取数据:  78%|███████▊  | 5531946/7086503 [1:23:22<03:47, 6825.97it/s]读取数据:  78%|███████▊  | 5532684/7086503 [1:23:22<03:42, 6989.95it/s]读取数据:  78%|███████▊  | 5533442/7086503 [1:23:22<03:36, 7165.14it/s]读取数据:  78%|███████▊  | 5534231/7086503 [1:23:22<03:30, 7380.35it/s]读取数据:  78%|███████▊  | 5534972/7086503 [1:23:22<03:30, 7377.03it/s]读取数据:  78%|███████▊  | 5535779/7086503 [1:23:22<03:24, 7582.90it/s]读取数据:  78%|███████▊  | 5536614/7086503 [1:23:22<03:18, 7810.06it/s]读取数据:  78%|███████▊  | 5537445/7086503 [1:23:22<03:14, 7958.95it/s]读取数据:  78%|███████▊  | 5538315/7086503 [1:23:23<03:09, 8180.28it/s]读取数据:  78%|███████▊  | 5539197/7086503 [1:23:23<03:04, 8370.47it/s]读取数据:  78%|███████▊  | 5540130/7086503 [1:23:23<02:58, 8655.86it/s]读取数据:  78%|███████▊  | 5541114/7086503 [1:23:23<02:51, 9010.49it/s]读取数据:  78%|███████▊  | 5542156/7086503 [1:23:23<02:43, 9432.75it/s]读取数据:  78%|███████▊  | 5543193/7086503 [1:23:23<02:38, 9711.29it/s]读取数据:  78%|███████▊  | 5544315/7086503 [1:23:23<02:31, 10162.37it/s]读取数据:  78%|███████▊  | 5545468/7086503 [1:23:23<02:25, 10571.27it/s]读取数据:  78%|███████▊  | 5546646/7086503 [1:23:23<02:20, 10932.80it/s]读取数据:  78%|███████▊  | 5547780/7086503 [1:23:23<02:19, 11054.25it/s]读取数据:  78%|███████▊  | 5548975/7086503 [1:23:24<02:15, 11319.75it/s]读取数据:  78%|███████▊  | 5550107/7086503 [1:23:25<09:22, 2731.62it/s] 读取数据:  78%|███████▊  | 5550929/7086503 [1:23:25<08:31, 3000.71it/s]读取数据:  78%|███████▊  | 5551637/7086503 [1:23:25<07:47, 3282.03it/s]读取数据:  78%|███████▊  | 5552278/7086503 [1:23:25<07:11, 3559.45it/s]读取数据:  78%|███████▊  | 5552877/7086503 [1:23:25<06:41, 3822.37it/s]读取数据:  78%|███████▊  | 5553448/7086503 [1:23:25<06:16, 4068.49it/s]读取数据:  78%|███████▊  | 5554001/7086503 [1:23:25<05:55, 4312.71it/s]读取数据:  78%|███████▊  | 5554546/7086503 [1:23:26<05:41, 4486.02it/s]读取数据:  78%|███████▊  | 5555080/7086503 [1:23:26<05:32, 4607.06it/s]读取数据:  78%|███████▊  | 5555603/7086503 [1:23:26<05:26, 4688.28it/s]读取数据:  78%|███████▊  | 5556117/7086503 [1:23:26<05:21, 4754.39it/s]读取数据:  78%|███████▊  | 5556625/7086503 [1:23:26<05:16, 4827.24it/s]读取数据:  78%|███████▊  | 5557132/7086503 [1:23:26<05:13, 4881.64it/s]读取数据:  78%|███████▊  | 5557652/7086503 [1:23:26<05:07, 4969.02it/s]读取数据:  78%|███████▊  | 5558167/7086503 [1:23:26<05:04, 5019.40it/s]读取数据:  78%|███████▊  | 5558717/7086503 [1:23:26<04:56, 5151.06it/s]读取数据:  78%|███████▊  | 5559253/7086503 [1:23:27<04:53, 5209.59it/s]读取数据:  78%|███████▊  | 5559832/7086503 [1:23:27<04:43, 5378.82it/s]读取数据:  78%|███████▊  | 5560374/7086503 [1:23:27<04:47, 5313.26it/s]读取数据:  78%|███████▊  | 5560920/7086503 [1:23:27<04:44, 5355.44it/s]读取数据:  78%|███████▊  | 5561464/7086503 [1:23:27<04:43, 5378.87it/s]读取数据:  78%|███████▊  | 5562004/7086503 [1:23:27<04:43, 5376.01it/s]读取数据:  78%|███████▊  | 5562543/7086503 [1:23:27<04:46, 5313.68it/s]读取数据:  79%|███████▊  | 5563084/7086503 [1:23:27<04:45, 5341.08it/s]读取数据:  79%|███████▊  | 5563619/7086503 [1:23:27<04:52, 5206.43it/s]读取数据:  79%|███████▊  | 5564185/7086503 [1:23:27<04:45, 5337.41it/s]读取数据:  79%|███████▊  | 5564787/7086503 [1:23:28<04:34, 5537.41it/s]读取数据:  79%|███████▊  | 5565403/7086503 [1:23:28<04:25, 5721.47it/s]读取数据:  79%|███████▊  | 5565985/7086503 [1:23:28<04:24, 5748.39it/s]读取数据:  79%|███████▊  | 5566577/7086503 [1:23:28<04:22, 5796.03it/s]读取数据:  79%|███████▊  | 5567205/7086503 [1:23:28<04:15, 5938.17it/s]读取数据:  79%|███████▊  | 5567808/7086503 [1:23:28<04:14, 5960.73it/s]读取数据:  79%|███████▊  | 5568405/7086503 [1:23:28<04:16, 5908.39it/s]读取数据:  79%|███████▊  | 5568997/7086503 [1:23:28<04:17, 5904.01it/s]读取数据:  79%|███████▊  | 5569630/7086503 [1:23:28<04:11, 6029.68it/s]读取数据:  79%|███████▊  | 5570234/7086503 [1:23:28<04:12, 5995.35it/s]读取数据:  79%|███████▊  | 5570863/7086503 [1:23:29<04:09, 6082.28it/s]读取数据:  79%|███████▊  | 5571506/7086503 [1:23:29<04:04, 6183.91it/s]读取数据:  79%|███████▊  | 5572177/7086503 [1:23:29<03:59, 6332.65it/s]读取数据:  79%|███████▊  | 5572823/7086503 [1:23:29<03:57, 6369.05it/s]读取数据:  79%|███████▊  | 5573461/7086503 [1:23:29<03:58, 6344.76it/s]读取数据:  79%|███████▊  | 5574100/7086503 [1:23:29<03:57, 6357.93it/s]读取数据:  79%|███████▊  | 5574746/7086503 [1:23:29<03:56, 6386.03it/s]读取数据:  79%|███████▊  | 5575406/7086503 [1:23:29<03:54, 6444.83it/s]读取数据:  79%|███████▊  | 5576100/7086503 [1:23:29<03:49, 6590.57it/s]读取数据:  79%|███████▊  | 5576760/7086503 [1:23:29<03:51, 6523.61it/s]读取数据:  79%|███████▊  | 5577485/7086503 [1:23:30<03:43, 6737.46it/s]读取数据:  79%|███████▊  | 5578173/7086503 [1:23:30<03:42, 6773.62it/s]读取数据:  79%|███████▊  | 5578886/7086503 [1:23:30<03:39, 6876.62it/s]读取数据:  79%|███████▊  | 5579590/7086503 [1:23:30<03:37, 6925.35it/s]读取数据:  79%|███████▊  | 5580306/7086503 [1:23:30<03:35, 6991.79it/s]读取数据:  79%|███████▉  | 5581045/7086503 [1:23:30<03:31, 7108.48it/s]读取数据:  79%|███████▉  | 5581756/7086503 [1:23:30<03:31, 7107.74it/s]读取数据:  79%|███████▉  | 5582518/7086503 [1:23:30<03:27, 7259.76it/s]读取数据:  79%|███████▉  | 5583287/7086503 [1:23:30<03:23, 7387.26it/s]读取数据:  79%|███████▉  | 5584111/7086503 [1:23:30<03:16, 7640.03it/s]读取数据:  79%|███████▉  | 5584943/7086503 [1:23:31<03:11, 7842.12it/s]读取数据:  79%|███████▉  | 5585784/7086503 [1:23:31<03:07, 8011.95it/s]读取数据:  79%|███████▉  | 5586661/7086503 [1:23:31<03:27, 7215.15it/s]读取数据:  79%|███████▉  | 5587401/7086503 [1:23:31<05:49, 4284.77it/s]读取数据:  79%|███████▉  | 5587987/7086503 [1:23:31<05:27, 4578.19it/s]读取数据:  79%|███████▉  | 5588569/7086503 [1:23:31<06:03, 4123.23it/s]读取数据:  79%|███████▉  | 5589072/7086503 [1:23:32<06:15, 3985.18it/s]读取数据:  79%|███████▉  | 5589649/7086503 [1:23:32<05:57, 4183.67it/s]读取数据:  79%|███████▉  | 5590325/7086503 [1:23:32<05:16, 4731.48it/s]读取数据:  79%|███████▉  | 5591059/7086503 [1:23:32<04:46, 5214.77it/s]读取数据:  79%|███████▉  | 5591970/7086503 [1:23:32<04:01, 6194.51it/s]读取数据:  79%|███████▉  | 5592959/7086503 [1:23:32<03:28, 7168.54it/s]读取数据:  79%|███████▉  | 5593892/7086503 [1:23:32<03:12, 7760.29it/s]读取数据:  79%|███████▉  | 5594836/7086503 [1:23:32<03:01, 8231.39it/s]读取数据:  79%|███████▉  | 5595689/7086503 [1:23:32<03:19, 7489.61it/s]读取数据:  79%|███████▉  | 5596655/7086503 [1:23:33<03:26, 7222.87it/s]读取数据:  79%|███████▉  | 5597404/7086503 [1:23:33<03:25, 7261.19it/s]读取数据:  79%|███████▉  | 5598382/7086503 [1:23:33<03:07, 7932.31it/s]读取数据:  79%|███████▉  | 5599268/7086503 [1:23:33<03:01, 8186.74it/s]读取数据:  79%|███████▉  | 5600105/7086503 [1:23:34<10:34, 2343.69it/s]读取数据:  79%|███████▉  | 5600716/7086503 [1:23:34<09:21, 2646.47it/s]读取数据:  79%|███████▉  | 5601283/7086503 [1:23:34<08:17, 2986.85it/s]读取数据:  79%|███████▉  | 5601835/7086503 [1:23:34<08:07, 3044.92it/s]读取数据:  79%|███████▉  | 5602319/7086503 [1:23:34<07:26, 3320.74it/s]读取数据:  79%|███████▉  | 5602799/7086503 [1:23:34<06:53, 3589.33it/s]读取数据:  79%|███████▉  | 5603301/7086503 [1:23:35<06:21, 3890.16it/s]读取数据:  79%|███████▉  | 5603793/7086503 [1:23:35<05:59, 4128.38it/s]读取数据:  79%|███████▉  | 5604299/7086503 [1:23:35<05:40, 4356.87it/s]读取数据:  79%|███████▉  | 5604792/7086503 [1:23:35<05:29, 4503.51it/s]读取数据:  79%|███████▉  | 5605292/7086503 [1:23:35<05:19, 4637.08it/s]读取数据:  79%|███████▉  | 5605828/7086503 [1:23:35<05:06, 4835.48it/s]读取数据:  79%|███████▉  | 5606356/7086503 [1:23:35<04:58, 4957.73it/s]读取数据:  79%|███████▉  | 5606922/7086503 [1:23:35<04:46, 5160.76it/s]读取数据:  79%|███████▉  | 5607451/7086503 [1:23:35<05:05, 4840.83it/s]读取数据:  79%|███████▉  | 5607948/7086503 [1:23:36<05:05, 4842.39it/s]读取数据:  79%|███████▉  | 5608441/7086503 [1:23:36<05:19, 4632.50it/s]读取数据:  79%|███████▉  | 5608929/7086503 [1:23:36<05:14, 4700.65it/s]读取数据:  79%|███████▉  | 5609453/7086503 [1:23:36<05:04, 4852.66it/s]读取数据:  79%|███████▉  | 5609944/7086503 [1:23:36<05:14, 4695.22it/s]读取数据:  79%|███████▉  | 5610463/7086503 [1:23:36<05:05, 4830.76it/s]读取数据:  79%|███████▉  | 5611002/7086503 [1:23:36<04:55, 4991.68it/s]读取数据:  79%|███████▉  | 5611525/7086503 [1:23:36<04:51, 5058.56it/s]读取数据:  79%|███████▉  | 5612054/7086503 [1:23:36<04:47, 5119.68it/s]读取数据:  79%|███████▉  | 5612585/7086503 [1:23:36<04:44, 5173.64it/s]读取数据:  79%|███████▉  | 5613104/7086503 [1:23:37<04:45, 5166.60it/s]读取数据:  79%|███████▉  | 5613629/7086503 [1:23:37<04:43, 5190.01it/s]读取数据:  79%|███████▉  | 5614157/7086503 [1:23:37<04:42, 5216.30it/s]读取数据:  79%|███████▉  | 5614691/7086503 [1:23:37<04:40, 5252.42it/s]读取数据:  79%|███████▉  | 5615235/7086503 [1:23:37<04:37, 5307.60it/s]读取数据:  79%|███████▉  | 5615769/7086503 [1:23:37<04:36, 5314.72it/s]读取数据:  79%|███████▉  | 5616348/7086503 [1:23:37<04:29, 5456.39it/s]读取数据:  79%|███████▉  | 5616917/7086503 [1:23:37<04:25, 5524.97it/s]读取数据:  79%|███████▉  | 5617470/7086503 [1:23:37<04:54, 4991.22it/s]读取数据:  79%|███████▉  | 5617979/7086503 [1:23:38<04:58, 4923.76it/s]读取数据:  79%|███████▉  | 5618567/7086503 [1:23:38<04:42, 5188.92it/s]读取数据:  79%|███████▉  | 5619103/7086503 [1:23:38<04:40, 5235.54it/s]读取数据:  79%|███████▉  | 5619632/7086503 [1:23:38<04:44, 5162.17it/s]读取数据:  79%|███████▉  | 5620224/7086503 [1:23:38<04:32, 5380.38it/s]读取数据:  79%|███████▉  | 5620804/7086503 [1:23:38<04:26, 5502.03it/s]读取数据:  79%|███████▉  | 5621383/7086503 [1:23:38<04:22, 5585.78it/s]读取数据:  79%|███████▉  | 5621944/7086503 [1:23:38<04:38, 5262.81it/s]读取数据:  79%|███████▉  | 5622545/7086503 [1:23:38<04:27, 5474.59it/s]读取数据:  79%|███████▉  | 5623159/7086503 [1:23:38<04:18, 5665.67it/s]读取数据:  79%|███████▉  | 5623757/7086503 [1:23:39<04:14, 5755.90it/s]读取数据:  79%|███████▉  | 5624344/7086503 [1:23:39<04:12, 5785.27it/s]读取数据:  79%|███████▉  | 5624957/7086503 [1:23:39<04:08, 5886.01it/s]读取数据:  79%|███████▉  | 5625582/7086503 [1:23:39<04:03, 5992.92it/s]读取数据:  79%|███████▉  | 5626221/7086503 [1:23:39<03:59, 6109.13it/s]读取数据:  79%|███████▉  | 5626850/7086503 [1:23:39<03:57, 6156.48it/s]读取数据:  79%|███████▉  | 5627505/7086503 [1:23:39<03:52, 6270.02it/s]读取数据:  79%|███████▉  | 5628179/7086503 [1:23:39<03:47, 6409.04it/s]读取数据:  79%|███████▉  | 5628855/7086503 [1:23:39<03:43, 6513.87it/s]读取数据:  79%|███████▉  | 5629544/7086503 [1:23:39<03:39, 6622.70it/s]读取数据:  79%|███████▉  | 5630207/7086503 [1:23:40<03:41, 6584.75it/s]读取数据:  79%|███████▉  | 5630931/7086503 [1:23:40<03:34, 6778.51it/s]读取数据:  79%|███████▉  | 5631610/7086503 [1:23:40<03:37, 6699.91it/s]读取数据:  79%|███████▉  | 5632305/7086503 [1:23:40<03:34, 6773.60it/s]读取数据:  79%|███████▉  | 5633018/7086503 [1:23:40<03:31, 6879.10it/s]读取数据:  79%|███████▉  | 5633751/7086503 [1:23:40<03:27, 7009.53it/s]读取数据:  80%|███████▉  | 5634506/7086503 [1:23:40<03:22, 7169.13it/s]读取数据:  80%|███████▉  | 5635257/7086503 [1:23:40<03:19, 7269.39it/s]读取数据:  80%|███████▉  | 5636018/7086503 [1:23:40<03:16, 7366.55it/s]读取数据:  80%|███████▉  | 5636775/7086503 [1:23:40<03:15, 7424.44it/s]读取数据:  80%|███████▉  | 5637554/7086503 [1:23:41<03:12, 7531.38it/s]读取数据:  80%|███████▉  | 5638403/7086503 [1:23:41<03:05, 7817.03it/s]读取数据:  80%|███████▉  | 5639237/7086503 [1:23:41<03:01, 7972.75it/s]读取数据:  80%|███████▉  | 5640101/7086503 [1:23:41<02:57, 8170.57it/s]读取数据:  80%|███████▉  | 5640919/7086503 [1:23:41<03:09, 7645.40it/s]读取数据:  80%|███████▉  | 5641824/7086503 [1:23:41<02:59, 8045.09it/s]读取数据:  80%|███████▉  | 5642806/7086503 [1:23:41<02:48, 8558.35it/s]读取数据:  80%|███████▉  | 5643798/7086503 [1:23:41<02:41, 8956.28it/s]读取数据:  80%|███████▉  | 5644772/7086503 [1:23:41<02:36, 9184.53it/s]读取数据:  80%|███████▉  | 5645695/7086503 [1:23:41<02:51, 8414.32it/s]读取数据:  80%|███████▉  | 5646690/7086503 [1:23:42<02:42, 8839.49it/s]读取数据:  80%|███████▉  | 5647705/7086503 [1:23:42<02:36, 9204.87it/s]读取数据:  80%|███████▉  | 5648722/7086503 [1:23:42<02:31, 9482.17it/s]读取数据:  80%|███████▉  | 5649706/7086503 [1:23:42<02:29, 9585.75it/s]读取数据:  80%|███████▉  | 5650672/7086503 [1:23:43<09:42, 2464.69it/s]读取数据:  80%|███████▉  | 5651375/7086503 [1:23:43<08:31, 2805.77it/s]读取数据:  80%|███████▉  | 5652020/7086503 [1:23:43<07:36, 3139.87it/s]读取数据:  80%|███████▉  | 5652625/7086503 [1:23:43<06:53, 3466.43it/s]读取数据:  80%|███████▉  | 5653204/7086503 [1:23:43<06:21, 3758.84it/s]读取数据:  80%|███████▉  | 5653761/7086503 [1:23:44<05:54, 4043.42it/s]读取数据:  80%|███████▉  | 5654307/7086503 [1:23:44<05:34, 4277.86it/s]读取数据:  80%|███████▉  | 5654843/7086503 [1:23:44<05:23, 4422.01it/s]读取数据:  80%|███████▉  | 5655364/7086503 [1:23:44<05:13, 4564.41it/s]读取数据:  80%|███████▉  | 5655879/7086503 [1:23:44<05:09, 4629.68it/s]读取数据:  80%|███████▉  | 5656408/7086503 [1:23:44<04:57, 4800.08it/s]读取数据:  80%|███████▉  | 5656920/7086503 [1:23:44<04:53, 4877.96it/s]读取数据:  80%|███████▉  | 5657462/7086503 [1:23:44<04:44, 5027.44it/s]读取数据:  80%|███████▉  | 5658008/7086503 [1:23:44<04:37, 5150.55it/s]读取数据:  80%|███████▉  | 5658536/7086503 [1:23:45<04:35, 5184.77it/s]读取数据:  80%|███████▉  | 5659064/7086503 [1:23:45<04:34, 5205.65it/s]读取数据:  80%|███████▉  | 5659591/7086503 [1:23:45<04:34, 5197.47it/s]读取数据:  80%|███████▉  | 5660116/7086503 [1:23:45<04:33, 5207.25it/s]读取数据:  80%|███████▉  | 5660664/7086503 [1:23:45<04:29, 5286.46it/s]读取数据:  80%|███████▉  | 5661206/7086503 [1:23:45<04:27, 5325.43it/s]读取数据:  80%|███████▉  | 5661778/7086503 [1:23:45<04:21, 5441.63it/s]读取数据:  80%|███████▉  | 5662343/7086503 [1:23:45<04:18, 5500.78it/s]读取数据:  80%|███████▉  | 5662894/7086503 [1:23:45<04:19, 5493.08it/s]读取数据:  80%|███████▉  | 5663444/7086503 [1:23:45<04:21, 5443.11it/s]读取数据:  80%|███████▉  | 5664039/7086503 [1:23:46<04:14, 5591.94it/s]读取数据:  80%|███████▉  | 5664599/7086503 [1:23:46<04:14, 5578.33it/s]读取数据:  80%|███████▉  | 5665173/7086503 [1:23:46<04:12, 5624.16it/s]读取数据:  80%|███████▉  | 5665736/7086503 [1:23:46<04:16, 5530.58it/s]读取数据:  80%|███████▉  | 5666311/7086503 [1:23:46<04:14, 5587.55it/s]读取数据:  80%|███████▉  | 5666871/7086503 [1:23:46<04:17, 5511.83it/s]读取数据:  80%|███████▉  | 5667423/7086503 [1:23:46<04:25, 5350.09it/s]读取数据:  80%|███████▉  | 5668002/7086503 [1:23:46<04:19, 5476.10it/s]读取数据:  80%|███████▉  | 5668585/7086503 [1:23:46<04:14, 5578.80it/s]读取数据:  80%|███████▉  | 5669163/7086503 [1:23:46<04:11, 5637.92it/s]读取数据:  80%|████████  | 5669776/7086503 [1:23:47<04:04, 5782.90it/s]读取数据:  80%|████████  | 5670356/7086503 [1:23:47<04:09, 5683.18it/s]读取数据:  80%|████████  | 5670936/7086503 [1:23:47<04:07, 5716.48it/s]读取数据:  80%|████████  | 5671511/7086503 [1:23:47<04:07, 5726.20it/s]读取数据:  80%|████████  | 5672121/7086503 [1:23:47<04:02, 5836.06it/s]读取数据:  80%|████████  | 5672762/7086503 [1:23:47<03:55, 6005.63it/s]读取数据:  80%|████████  | 5673363/7086503 [1:23:47<03:57, 5945.53it/s]读取数据:  80%|████████  | 5673990/7086503 [1:23:47<03:53, 6040.19it/s]读取数据:  80%|████████  | 5674608/7086503 [1:23:47<03:52, 6081.47it/s]读取数据:  80%|████████  | 5675217/7086503 [1:23:47<03:56, 5956.51it/s]读取数据:  80%|████████  | 5675824/7086503 [1:23:48<03:55, 5989.09it/s]读取数据:  80%|████████  | 5676438/7086503 [1:23:48<03:53, 6032.05it/s]读取数据:  80%|████████  | 5677077/7086503 [1:23:48<03:49, 6133.30it/s]读取数据:  80%|████████  | 5677691/7086503 [1:23:48<03:50, 6107.04it/s]读取数据:  80%|████████  | 5678332/7086503 [1:23:48<03:47, 6195.86it/s]读取数据:  80%|████████  | 5678990/7086503 [1:23:48<03:43, 6306.93it/s]读取数据:  80%|████████  | 5679664/7086503 [1:23:48<03:38, 6431.04it/s]读取数据:  80%|████████  | 5680316/7086503 [1:23:48<03:37, 6456.44it/s]读取数据:  80%|████████  | 5680974/7086503 [1:23:48<03:36, 6491.84it/s]读取数据:  80%|████████  | 5681649/7086503 [1:23:48<03:33, 6569.00it/s]读取数据:  80%|████████  | 5682363/7086503 [1:23:49<03:28, 6738.61it/s]读取数据:  80%|████████  | 5683084/7086503 [1:23:49<03:23, 6879.54it/s]读取数据:  80%|████████  | 5683833/7086503 [1:23:49<03:18, 7062.20it/s]读取数据:  80%|████████  | 5684552/7086503 [1:23:49<03:17, 7098.64it/s]读取数据:  80%|████████  | 5685316/7086503 [1:23:49<03:13, 7259.99it/s]读取数据:  80%|████████  | 5686067/7086503 [1:23:49<03:10, 7334.36it/s]读取数据:  80%|████████  | 5686810/7086503 [1:23:49<03:10, 7361.31it/s]读取数据:  80%|████████  | 5687570/7086503 [1:23:49<03:08, 7430.64it/s]读取数据:  80%|████████  | 5688356/7086503 [1:23:49<03:04, 7558.98it/s]读取数据:  80%|████████  | 5689154/7086503 [1:23:49<03:01, 7678.20it/s]读取数据:  80%|████████  | 5689999/7086503 [1:23:50<02:56, 7906.88it/s]读取数据:  80%|████████  | 5690800/7086503 [1:23:50<02:55, 7936.96it/s]读取数据:  80%|████████  | 5691649/7086503 [1:23:50<02:52, 8101.65it/s]读取数据:  80%|████████  | 5692468/7086503 [1:23:50<02:51, 8126.59it/s]读取数据:  80%|████████  | 5693281/7086503 [1:23:50<02:55, 7935.91it/s]读取数据:  80%|████████  | 5694144/7086503 [1:23:50<02:51, 8140.45it/s]读取数据:  80%|████████  | 5695087/7086503 [1:23:50<02:43, 8522.43it/s]读取数据:  80%|████████  | 5695946/7086503 [1:23:50<02:42, 8534.13it/s]读取数据:  80%|████████  | 5696887/7086503 [1:23:50<02:38, 8794.80it/s]读取数据:  80%|████████  | 5697908/7086503 [1:23:50<02:30, 9214.43it/s]读取数据:  80%|████████  | 5698879/7086503 [1:23:51<02:28, 9357.30it/s]读取数据:  80%|████████  | 5699816/7086503 [1:23:51<02:34, 8955.34it/s]读取数据:  80%|████████  | 5700716/7086503 [1:23:52<10:13, 2260.17it/s]读取数据:  80%|████████  | 5701370/7086503 [1:23:52<08:53, 2595.28it/s]读取数据:  80%|████████  | 5701981/7086503 [1:23:52<07:50, 2941.53it/s]读取数据:  80%|████████  | 5702564/7086503 [1:23:52<07:06, 3247.79it/s]读取数据:  80%|████████  | 5703116/7086503 [1:23:52<06:40, 3458.17it/s]读取数据:  80%|████████  | 5703632/7086503 [1:23:52<06:13, 3705.96it/s]读取数据:  80%|████████  | 5704135/7086503 [1:23:53<05:48, 3963.52it/s]读取数据:  81%|████████  | 5704636/7086503 [1:23:53<05:33, 4141.52it/s]读取数据:  81%|████████  | 5705128/7086503 [1:23:53<05:19, 4319.02it/s]读取数据:  81%|████████  | 5705619/7086503 [1:23:53<05:15, 4371.38it/s]读取数据:  81%|████████  | 5706160/7086503 [1:23:53<04:57, 4643.33it/s]读取数据:  81%|████████  | 5706685/7086503 [1:23:53<04:47, 4803.44it/s]读取数据:  81%|████████  | 5707190/7086503 [1:23:53<08:18, 2769.48it/s]读取数据:  81%|████████  | 5707585/7086503 [1:23:54<13:29, 1703.24it/s]读取数据:  81%|████████  | 5707885/7086503 [1:23:54<16:20, 1405.49it/s]读取数据:  81%|████████  | 5708121/7086503 [1:23:55<18:51, 1218.11it/s]读取数据:  81%|████████  | 5708309/7086503 [1:23:55<18:15, 1258.03it/s]读取数据:  81%|████████  | 5708488/7086503 [1:23:55<17:40, 1299.77it/s]读取数据:  81%|████████  | 5708751/7086503 [1:23:55<15:16, 1503.81it/s]读取数据:  81%|████████  | 5708950/7086503 [1:23:55<15:09, 1514.79it/s]读取数据:  81%|████████  | 5709131/7086503 [1:23:55<15:08, 1515.57it/s]读取数据:  81%|████████  | 5709303/7086503 [1:23:55<20:21, 1127.19it/s]读取数据:  81%|████████  | 5709442/7086503 [1:23:56<21:25, 1070.97it/s]读取数据:  81%|████████  | 5709567/7086503 [1:23:56<21:12, 1082.16it/s]读取数据:  81%|████████  | 5709979/7086503 [1:23:56<13:15, 1731.23it/s]读取数据:  81%|████████  | 5710527/7086503 [1:23:56<08:47, 2607.68it/s]读取数据:  81%|████████  | 5711088/7086503 [1:23:56<06:49, 3359.51it/s]读取数据:  81%|████████  | 5711610/7086503 [1:23:56<05:57, 3849.46it/s]读取数据:  81%|████████  | 5712176/7086503 [1:23:56<05:16, 4343.89it/s]读取数据:  81%|████████  | 5712711/7086503 [1:23:56<04:57, 4625.28it/s]读取数据:  81%|████████  | 5713294/7086503 [1:23:56<04:36, 4969.92it/s]读取数据:  81%|████████  | 5713855/7086503 [1:23:57<04:26, 5154.75it/s]读取数据:  81%|████████  | 5714402/7086503 [1:23:57<04:21, 5242.97it/s]读取数据:  81%|████████  | 5714950/7086503 [1:23:57<04:18, 5311.21it/s]读取数据:  81%|████████  | 5715489/7086503 [1:23:57<04:17, 5314.62it/s]读取数据:  81%|████████  | 5716072/7086503 [1:23:57<04:10, 5466.87it/s]读取数据:  81%|████████  | 5716632/7086503 [1:23:57<04:09, 5499.46it/s]读取数据:  81%|████████  | 5717185/7086503 [1:23:57<04:09, 5486.21it/s]读取数据:  81%|████████  | 5717771/7086503 [1:23:57<04:04, 5591.43it/s]读取数据:  81%|████████  | 5718379/7086503 [1:23:57<03:58, 5735.03it/s]读取数据:  81%|████████  | 5718954/7086503 [1:23:57<03:59, 5717.73it/s]读取数据:  81%|████████  | 5719527/7086503 [1:23:58<03:59, 5715.08it/s]读取数据:  81%|████████  | 5720113/7086503 [1:23:58<03:57, 5757.47it/s]读取数据:  81%|████████  | 5720740/7086503 [1:23:58<03:51, 5907.62it/s]读取数据:  81%|████████  | 5721344/7086503 [1:23:58<03:49, 5946.91it/s]读取数据:  81%|████████  | 5721990/7086503 [1:23:58<03:43, 6094.39it/s]读取数据:  81%|████████  | 5722619/7086503 [1:23:58<03:41, 6151.60it/s]读取数据:  81%|████████  | 5723256/7086503 [1:23:58<03:39, 6215.90it/s]读取数据:  81%|████████  | 5723878/7086503 [1:23:58<03:39, 6202.67it/s]读取数据:  81%|████████  | 5724499/7086503 [1:23:58<03:41, 6149.58it/s]读取数据:  81%|████████  | 5725127/7086503 [1:23:58<03:40, 6184.02it/s]读取数据:  81%|████████  | 5725781/7086503 [1:23:59<03:36, 6289.52it/s]读取数据:  81%|████████  | 5726438/7086503 [1:23:59<03:33, 6372.13it/s]读取数据:  81%|████████  | 5727109/7086503 [1:23:59<03:30, 6472.13it/s]读取数据:  81%|████████  | 5727760/7086503 [1:23:59<03:29, 6482.56it/s]读取数据:  81%|████████  | 5728450/7086503 [1:23:59<03:25, 6607.29it/s]读取数据:  81%|████████  | 5729156/7086503 [1:23:59<03:21, 6742.69it/s]读取数据:  81%|████████  | 5729831/7086503 [1:23:59<05:01, 4499.25it/s]读取数据:  81%|████████  | 5730380/7086503 [1:23:59<05:07, 4404.45it/s]读取数据:  81%|████████  | 5730889/7086503 [1:24:00<04:57, 4553.93it/s]读取数据:  81%|████████  | 5731495/7086503 [1:24:00<04:35, 4923.01it/s]读取数据:  81%|████████  | 5732032/7086503 [1:24:00<05:05, 4435.22it/s]读取数据:  81%|████████  | 5732714/7086503 [1:24:00<04:29, 5021.91it/s]读取数据:  81%|████████  | 5733367/7086503 [1:24:00<04:09, 5412.75it/s]读取数据:  81%|████████  | 5734065/7086503 [1:24:00<03:51, 5836.72it/s]读取数据:  81%|████████  | 5734748/7086503 [1:24:00<03:41, 6110.99it/s]读取数据:  81%|████████  | 5735482/7086503 [1:24:00<03:29, 6460.18it/s]读取数据:  81%|████████  | 5736145/7086503 [1:24:01<04:55, 4564.93it/s]读取数据:  81%|████████  | 5736704/7086503 [1:24:01<04:41, 4794.80it/s]读取数据:  81%|████████  | 5737431/7086503 [1:24:01<04:10, 5395.60it/s]读取数据:  81%|████████  | 5738163/7086503 [1:24:01<03:49, 5886.76it/s]读取数据:  81%|████████  | 5738951/7086503 [1:24:01<03:29, 6421.57it/s]读取数据:  81%|████████  | 5739712/7086503 [1:24:01<03:19, 6749.09it/s]读取数据:  81%|████████  | 5740524/7086503 [1:24:01<03:08, 7136.53it/s]读取数据:  81%|████████  | 5741390/7086503 [1:24:01<02:57, 7573.56it/s]读取数据:  81%|████████  | 5742226/7086503 [1:24:01<02:52, 7791.78it/s]读取数据:  81%|████████  | 5743070/7086503 [1:24:01<02:48, 7982.14it/s]读取数据:  81%|████████  | 5743879/7086503 [1:24:02<02:48, 7974.51it/s]读取数据:  81%|████████  | 5744684/7086503 [1:24:02<03:13, 6938.77it/s]读取数据:  81%|████████  | 5745407/7086503 [1:24:02<03:13, 6930.76it/s]读取数据:  81%|████████  | 5746316/7086503 [1:24:02<02:59, 7473.74it/s]读取数据:  81%|████████  | 5747082/7086503 [1:24:02<03:23, 6569.41it/s]读取数据:  81%|████████  | 5747855/7086503 [1:24:02<03:14, 6867.52it/s]读取数据:  81%|████████  | 5748568/7086503 [1:24:02<03:15, 6829.74it/s]读取数据:  81%|████████  | 5749404/7086503 [1:24:02<03:04, 7244.22it/s]读取数据:  81%|████████  | 5750145/7086503 [1:24:03<11:27, 1943.15it/s]读取数据:  81%|████████  | 5750684/7086503 [1:24:04<09:54, 2248.63it/s]读取数据:  81%|████████  | 5751205/7086503 [1:24:04<08:39, 2572.40it/s]读取数据:  81%|████████  | 5751711/7086503 [1:24:04<07:39, 2904.77it/s]读取数据:  81%|████████  | 5752228/7086503 [1:24:04<06:45, 3290.29it/s]读取数据:  81%|████████  | 5752731/7086503 [1:24:04<06:08, 3618.09it/s]读取数据:  81%|████████  | 5753231/7086503 [1:24:04<05:43, 3880.30it/s]读取数据:  81%|████████  | 5753726/7086503 [1:24:04<05:22, 4130.77it/s]读取数据:  81%|████████  | 5754220/7086503 [1:24:04<05:11, 4281.91it/s]读取数据:  81%|████████  | 5754707/7086503 [1:24:04<05:01, 4411.76it/s]读取数据:  81%|████████  | 5755191/7086503 [1:24:04<05:15, 4213.08it/s]读取数据:  81%|████████  | 5755658/7086503 [1:24:05<05:07, 4332.82it/s]读取数据:  81%|████████  | 5756142/7086503 [1:24:05<04:57, 4471.89it/s]读取数据:  81%|████████  | 5756612/7086503 [1:24:05<04:53, 4532.50it/s]读取数据:  81%|████████  | 5757123/7086503 [1:24:05<04:43, 4697.28it/s]读取数据:  81%|████████  | 5757603/7086503 [1:24:05<04:43, 4688.53it/s]读取数据:  81%|████████▏ | 5758098/7086503 [1:24:05<04:39, 4761.20it/s]读取数据:  81%|████████▏ | 5758580/7086503 [1:24:05<04:39, 4753.82it/s]读取数据:  81%|████████▏ | 5759093/7086503 [1:24:05<04:32, 4864.08it/s]读取数据:  81%|████████▏ | 5759647/7086503 [1:24:05<04:22, 5064.12it/s]读取数据:  81%|████████▏ | 5760156/7086503 [1:24:05<04:24, 5020.98it/s]读取数据:  81%|████████▏ | 5760660/7086503 [1:24:06<04:30, 4893.26it/s]读取数据:  81%|████████▏ | 5761153/7086503 [1:24:06<04:30, 4896.84it/s]读取数据:  81%|████████▏ | 5761644/7086503 [1:24:06<04:31, 4877.96it/s]读取数据:  81%|████████▏ | 5762163/7086503 [1:24:06<04:26, 4966.01it/s]读取数据:  81%|████████▏ | 5762661/7086503 [1:24:06<04:29, 4908.61it/s]读取数据:  81%|████████▏ | 5763160/7086503 [1:24:06<04:28, 4926.51it/s]读取数据:  81%|████████▏ | 5763663/7086503 [1:24:06<04:27, 4954.16it/s]读取数据:  81%|████████▏ | 5764187/7086503 [1:24:06<04:22, 5037.33it/s]读取数据:  81%|████████▏ | 5764692/7086503 [1:24:06<04:26, 4962.75it/s]读取数据:  81%|████████▏ | 5765191/7086503 [1:24:07<04:25, 4969.74it/s]读取数据:  81%|████████▏ | 5765697/7086503 [1:24:07<04:24, 4993.94it/s]读取数据:  81%|████████▏ | 5766210/7086503 [1:24:07<04:22, 5034.05it/s]读取数据:  81%|████████▏ | 5766740/7086503 [1:24:07<04:18, 5112.15it/s]读取数据:  81%|████████▏ | 5767257/7086503 [1:24:07<04:17, 5126.96it/s]读取数据:  81%|████████▏ | 5767818/7086503 [1:24:07<04:10, 5265.22it/s]读取数据:  81%|████████▏ | 5768367/7086503 [1:24:07<04:07, 5331.30it/s]读取数据:  81%|████████▏ | 5768901/7086503 [1:24:07<04:07, 5318.79it/s]读取数据:  81%|████████▏ | 5769438/7086503 [1:24:07<04:06, 5332.95it/s]读取数据:  81%|████████▏ | 5770020/7086503 [1:24:07<04:00, 5477.03it/s]读取数据:  81%|████████▏ | 5770568/7086503 [1:24:08<04:02, 5416.59it/s]读取数据:  81%|████████▏ | 5771110/7086503 [1:24:08<04:04, 5373.75it/s]读取数据:  81%|████████▏ | 5771696/7086503 [1:24:08<03:58, 5517.75it/s]读取数据:  81%|████████▏ | 5772249/7086503 [1:24:08<04:02, 5428.63it/s]读取数据:  81%|████████▏ | 5772793/7086503 [1:24:08<04:02, 5421.74it/s]读取数据:  81%|████████▏ | 5773369/7086503 [1:24:08<03:57, 5520.12it/s]读取数据:  81%|████████▏ | 5773935/7086503 [1:24:08<03:56, 5557.14it/s]读取数据:  81%|████████▏ | 5774524/7086503 [1:24:08<03:51, 5655.35it/s]读取数据:  81%|████████▏ | 5775090/7086503 [1:24:08<03:52, 5640.02it/s]读取数据:  82%|████████▏ | 5775655/7086503 [1:24:08<03:53, 5619.22it/s]读取数据:  82%|████████▏ | 5776220/7086503 [1:24:09<03:52, 5627.74it/s]读取数据:  82%|████████▏ | 5776816/7086503 [1:24:09<03:48, 5723.96it/s]读取数据:  82%|████████▏ | 5777389/7086503 [1:24:09<03:50, 5673.80it/s]读取数据:  82%|████████▏ | 5777957/7086503 [1:24:09<05:51, 3719.51it/s]读取数据:  82%|████████▏ | 5778416/7086503 [1:24:09<06:03, 3594.42it/s]读取数据:  82%|████████▏ | 5778902/7086503 [1:24:09<05:37, 3875.00it/s]读取数据:  82%|████████▏ | 5779483/7086503 [1:24:09<05:01, 4339.78it/s]读取数据:  82%|████████▏ | 5780085/7086503 [1:24:09<04:34, 4766.68it/s]读取数据:  82%|████████▏ | 5780701/7086503 [1:24:10<04:14, 5139.09it/s]读取数据:  82%|████████▏ | 5781273/7086503 [1:24:10<04:15, 5101.30it/s]读取数据:  82%|████████▏ | 5781807/7086503 [1:24:10<04:32, 4784.51it/s]读取数据:  82%|████████▏ | 5782325/7086503 [1:24:10<04:26, 4889.28it/s]读取数据:  82%|████████▏ | 5782930/7086503 [1:24:10<04:10, 5206.00it/s]读取数据:  82%|████████▏ | 5783563/7086503 [1:24:10<03:55, 5521.78it/s]读取数据:  82%|████████▏ | 5784230/7086503 [1:24:10<03:42, 5851.27it/s]读取数据:  82%|████████▏ | 5784924/7086503 [1:24:10<03:31, 6167.96it/s]读取数据:  82%|████████▏ | 5785628/7086503 [1:24:10<03:22, 6423.45it/s]读取数据:  82%|████████▏ | 5786336/7086503 [1:24:10<03:16, 6617.04it/s]读取数据:  82%|████████▏ | 5787082/7086503 [1:24:11<03:09, 6865.39it/s]读取数据:  82%|████████▏ | 5787772/7086503 [1:24:11<03:12, 6760.76it/s]读取数据:  82%|████████▏ | 5788508/7086503 [1:24:11<03:07, 6933.26it/s]读取数据:  82%|████████▏ | 5789289/7086503 [1:24:11<03:00, 7191.07it/s]读取数据:  82%|████████▏ | 5790077/7086503 [1:24:11<02:55, 7395.63it/s]读取数据:  82%|████████▏ | 5790818/7086503 [1:24:11<02:55, 7385.41it/s]读取数据:  82%|████████▏ | 5791614/7086503 [1:24:11<02:51, 7555.66it/s]读取数据:  82%|████████▏ | 5792464/7086503 [1:24:11<02:45, 7834.16it/s]读取数据:  82%|████████▏ | 5793273/7086503 [1:24:11<02:43, 7904.27it/s]读取数据:  82%|████████▏ | 5794115/7086503 [1:24:12<02:40, 8048.72it/s]读取数据:  82%|████████▏ | 5794921/7086503 [1:24:12<03:19, 6485.91it/s]读取数据:  82%|████████▏ | 5795688/7086503 [1:24:12<03:10, 6782.68it/s]读取数据:  82%|████████▏ | 5796506/7086503 [1:24:12<03:00, 7155.64it/s]读取数据:  82%|████████▏ | 5797416/7086503 [1:24:12<02:47, 7692.65it/s]读取数据:  82%|████████▏ | 5798252/7086503 [1:24:12<02:43, 7878.67it/s]读取数据:  82%|████████▏ | 5799155/7086503 [1:24:12<02:36, 8208.78it/s]读取数据:  82%|████████▏ | 5800000/7086503 [1:24:13<11:12, 1912.81it/s]读取数据:  82%|████████▏ | 5800606/7086503 [1:24:14<11:38, 1841.79it/s]读取数据:  82%|████████▏ | 5801080/7086503 [1:24:14<10:10, 2105.52it/s]读取数据:  82%|████████▏ | 5801552/7086503 [1:24:14<08:56, 2396.55it/s]读取数据:  82%|████████▏ | 5802018/7086503 [1:24:14<07:54, 2706.05it/s]读取数据:  82%|████████▏ | 5802480/7086503 [1:24:14<07:04, 3021.82it/s]读取数据:  82%|████████▏ | 5802949/7086503 [1:24:14<06:23, 3343.44it/s]读取数据:  82%|████████▏ | 5803426/7086503 [1:24:14<05:51, 3647.75it/s]读取数据:  82%|████████▏ | 5803894/7086503 [1:24:15<05:29, 3888.82it/s]读取数据:  82%|████████▏ | 5804375/7086503 [1:24:15<05:11, 4119.90it/s]读取数据:  82%|████████▏ | 5804846/7086503 [1:24:15<05:53, 3622.30it/s]读取数据:  82%|████████▏ | 5805260/7086503 [1:24:15<11:34, 1844.92it/s]读取数据:  82%|████████▏ | 5805574/7086503 [1:24:16<14:43, 1450.49it/s]读取数据:  82%|████████▏ | 5805819/7086503 [1:24:16<16:19, 1307.00it/s]读取数据:  82%|████████▏ | 5806019/7086503 [1:24:16<18:38, 1144.92it/s]读取数据:  82%|████████▏ | 5806181/7086503 [1:24:16<20:58, 1017.67it/s]读取数据:  82%|████████▏ | 5806580/7086503 [1:24:17<14:54, 1430.42it/s]读取数据:  82%|████████▏ | 5807040/7086503 [1:24:17<10:54, 1954.42it/s]读取数据:  82%|████████▏ | 5807557/7086503 [1:24:17<08:17, 2569.13it/s]读取数据:  82%|████████▏ | 5808020/7086503 [1:24:17<07:04, 3010.18it/s]读取数据:  82%|████████▏ | 5808476/7086503 [1:24:17<06:18, 3372.32it/s]读取数据:  82%|████████▏ | 5808985/7086503 [1:24:17<05:36, 3800.66it/s]读取数据:  82%|████████▏ | 5809489/7086503 [1:24:17<05:09, 4126.66it/s]读取数据:  82%|████████▏ | 5809950/7086503 [1:24:17<04:59, 4257.42it/s]读取数据:  82%|████████▏ | 5810468/7086503 [1:24:17<04:42, 4514.57it/s]读取数据:  82%|████████▏ | 5810973/7086503 [1:24:17<04:33, 4664.83it/s]读取数据:  82%|████████▏ | 5811491/7086503 [1:24:18<04:24, 4813.61it/s]读取数据:  82%|████████▏ | 5811996/7086503 [1:24:18<04:21, 4880.42it/s]读取数据:  82%|████████▏ | 5812496/7086503 [1:24:18<04:19, 4910.00it/s]读取数据:  82%|████████▏ | 5812998/7086503 [1:24:18<04:17, 4939.47it/s]读取数据:  82%|████████▏ | 5813500/7086503 [1:24:18<04:16, 4961.18it/s]读取数据:  82%|████████▏ | 5814024/7086503 [1:24:18<04:12, 5042.46it/s]读取数据:  82%|████████▏ | 5814582/7086503 [1:24:18<04:04, 5202.57it/s]读取数据:  82%|████████▏ | 5815126/7086503 [1:24:18<04:01, 5272.37it/s]读取数据:  82%|████████▏ | 5815655/7086503 [1:24:18<04:02, 5234.49it/s]读取数据:  82%|████████▏ | 5816180/7086503 [1:24:18<04:05, 5169.80it/s]读取数据:  82%|████████▏ | 5816698/7086503 [1:24:19<04:07, 5136.05it/s]读取数据:  82%|████████▏ | 5817213/7086503 [1:24:19<04:08, 5108.00it/s]读取数据:  82%|████████▏ | 5817735/7086503 [1:24:19<04:06, 5140.52it/s]读取数据:  82%|████████▏ | 5818261/7086503 [1:24:19<04:05, 5174.21it/s]读取数据:  82%|████████▏ | 5818815/7086503 [1:24:19<04:00, 5281.22it/s]读取数据:  82%|████████▏ | 5819344/7086503 [1:24:19<04:00, 5272.62it/s]读取数据:  82%|████████▏ | 5819908/7086503 [1:24:19<03:55, 5381.38it/s]读取数据:  82%|████████▏ | 5820447/7086503 [1:24:19<03:55, 5364.68it/s]读取数据:  82%|████████▏ | 5820984/7086503 [1:24:19<04:23, 4804.15it/s]读取数据:  82%|████████▏ | 5821557/7086503 [1:24:20<04:10, 5058.13it/s]读取数据:  82%|████████▏ | 5822117/7086503 [1:24:20<04:02, 5211.16it/s]读取数据:  82%|████████▏ | 5822701/7086503 [1:24:20<03:54, 5390.56it/s]读取数据:  82%|████████▏ | 5823272/7086503 [1:24:20<03:50, 5483.22it/s]读取数据:  82%|████████▏ | 5823825/7086503 [1:24:20<05:26, 3862.92it/s]读取数据:  82%|████████▏ | 5824281/7086503 [1:24:20<06:09, 3419.61it/s]读取数据:  82%|████████▏ | 5824770/7086503 [1:24:20<06:09, 3414.03it/s]读取数据:  82%|████████▏ | 5825193/7086503 [1:24:20<05:50, 3593.51it/s]读取数据:  82%|████████▏ | 5825586/7086503 [1:24:21<07:32, 2785.97it/s]读取数据:  82%|████████▏ | 5826201/7086503 [1:24:21<06:02, 3478.20it/s]读取数据:  82%|████████▏ | 5826753/7086503 [1:24:21<05:19, 3941.26it/s]读取数据:  82%|████████▏ | 5827387/7086503 [1:24:21<04:38, 4528.92it/s]读取数据:  82%|████████▏ | 5828034/7086503 [1:24:21<04:10, 5031.47it/s]读取数据:  82%|████████▏ | 5828584/7086503 [1:24:21<04:04, 5154.21it/s]读取数据:  82%|████████▏ | 5829191/7086503 [1:24:21<03:52, 5409.07it/s]读取数据:  82%|████████▏ | 5829826/7086503 [1:24:21<03:41, 5675.30it/s]读取数据:  82%|████████▏ | 5830477/7086503 [1:24:22<03:32, 5913.00it/s]读取数据:  82%|████████▏ | 5831083/7086503 [1:24:22<03:57, 5290.85it/s]读取数据:  82%|████████▏ | 5831680/7086503 [1:24:22<03:49, 5473.81it/s]读取数据:  82%|████████▏ | 5832245/7086503 [1:24:22<04:02, 5171.79it/s]读取数据:  82%|████████▏ | 5832777/7086503 [1:24:22<04:03, 5158.99it/s]读取数据:  82%|████████▏ | 5833476/7086503 [1:24:22<03:41, 5662.75it/s]读取数据:  82%|████████▏ | 5834054/7086503 [1:24:22<04:20, 4808.19it/s]读取数据:  82%|████████▏ | 5834770/7086503 [1:24:22<03:51, 5406.72it/s]读取数据:  82%|████████▏ | 5835443/7086503 [1:24:22<03:37, 5758.08it/s]读取数据:  82%|████████▏ | 5836184/7086503 [1:24:23<03:21, 6212.24it/s]读取数据:  82%|████████▏ | 5836828/7086503 [1:24:23<03:33, 5839.81it/s]读取数据:  82%|████████▏ | 5837580/7086503 [1:24:23<03:18, 6298.17it/s]读取数据:  82%|████████▏ | 5838318/7086503 [1:24:23<03:09, 6601.58it/s]读取数据:  82%|████████▏ | 5839088/7086503 [1:24:23<03:00, 6915.05it/s]读取数据:  82%|████████▏ | 5839792/7086503 [1:24:23<03:08, 6616.95it/s]读取数据:  82%|████████▏ | 5840465/7086503 [1:24:23<03:20, 6201.38it/s]读取数据:  82%|████████▏ | 5841097/7086503 [1:24:23<04:10, 4965.31it/s]读取数据:  82%|████████▏ | 5841638/7086503 [1:24:24<04:22, 4737.83it/s]读取数据:  82%|████████▏ | 5842476/7086503 [1:24:24<03:41, 5613.10it/s]读取数据:  82%|████████▏ | 5843396/7086503 [1:24:24<03:10, 6530.05it/s]读取数据:  82%|████████▏ | 5844284/7086503 [1:24:24<02:53, 7158.25it/s]读取数据:  82%|████████▏ | 5845142/7086503 [1:24:24<02:44, 7546.15it/s]读取数据:  82%|████████▏ | 5846049/7086503 [1:24:24<02:35, 7971.52it/s]读取数据:  83%|████████▎ | 5846871/7086503 [1:24:24<02:47, 7406.95it/s]读取数据:  83%|████████▎ | 5847636/7086503 [1:24:24<03:21, 6162.75it/s]读取数据:  83%|████████▎ | 5848459/7086503 [1:24:24<03:05, 6665.25it/s]读取数据:  83%|████████▎ | 5849171/7086503 [1:24:25<03:34, 5766.79it/s]读取数据:  83%|████████▎ | 5849797/7086503 [1:24:25<04:15, 4837.64it/s]读取数据:  83%|████████▎ | 5850334/7086503 [1:24:26<13:25, 1534.90it/s]读取数据:  83%|████████▎ | 5850834/7086503 [1:24:26<11:11, 1841.19it/s]读取数据:  83%|████████▎ | 5851313/7086503 [1:24:26<09:29, 2170.51it/s]读取数据:  83%|████████▎ | 5851767/7086503 [1:24:26<08:14, 2496.76it/s]读取数据:  83%|████████▎ | 5852251/7086503 [1:24:26<07:08, 2882.24it/s]读取数据:  83%|████████▎ | 5852715/7086503 [1:24:26<06:23, 3214.58it/s]读取数据:  83%|████████▎ | 5853217/7086503 [1:24:27<05:42, 3599.22it/s]读取数据:  83%|████████▎ | 5853723/7086503 [1:24:27<05:13, 3936.04it/s]读取数据:  83%|████████▎ | 5854223/7086503 [1:24:27<04:53, 4199.09it/s]读取数据:  83%|████████▎ | 5854713/7086503 [1:24:27<04:41, 4382.73it/s]读取数据:  83%|████████▎ | 5855216/7086503 [1:24:27<04:30, 4559.44it/s]读取数据:  83%|████████▎ | 5855710/7086503 [1:24:27<04:23, 4662.68it/s]读取数据:  83%|████████▎ | 5856203/7086503 [1:24:27<04:19, 4736.05it/s]读取数据:  83%|████████▎ | 5856730/7086503 [1:24:27<04:11, 4887.62it/s]读取数据:  83%|████████▎ | 5857240/7086503 [1:24:27<04:08, 4949.24it/s]读取数据:  83%|████████▎ | 5857752/7086503 [1:24:27<04:06, 4993.49it/s]读取数据:  83%|████████▎ | 5858263/7086503 [1:24:28<04:04, 5023.04it/s]读取数据:  83%|████████▎ | 5858771/7086503 [1:24:28<04:04, 5022.43it/s]读取数据:  83%|████████▎ | 5859309/7086503 [1:24:28<03:59, 5126.64it/s]读取数据:  83%|████████▎ | 5859825/7086503 [1:24:28<04:04, 5016.32it/s]读取数据:  83%|████████▎ | 5860329/7086503 [1:24:28<04:05, 4996.07it/s]读取数据:  83%|████████▎ | 5860857/7086503 [1:24:28<04:01, 5073.69it/s]读取数据:  83%|████████▎ | 5861366/7086503 [1:24:28<04:02, 5044.90it/s]读取数据:  83%|████████▎ | 5861895/7086503 [1:24:28<03:59, 5116.42it/s]读取数据:  83%|████████▎ | 5862413/7086503 [1:24:28<03:58, 5132.35it/s]读取数据:  83%|████████▎ | 5862927/7086503 [1:24:28<03:58, 5130.01it/s]读取数据:  83%|████████▎ | 5863441/7086503 [1:24:29<04:00, 5090.66it/s]读取数据:  83%|████████▎ | 5863969/7086503 [1:24:29<03:57, 5146.41it/s]读取数据:  83%|████████▎ | 5864503/7086503 [1:24:29<03:54, 5200.56it/s]读取数据:  83%|████████▎ | 5865024/7086503 [1:24:29<03:55, 5195.10it/s]读取数据:  83%|████████▎ | 5865602/7086503 [1:24:29<03:47, 5369.54it/s]读取数据:  83%|████████▎ | 5866140/7086503 [1:24:29<03:47, 5355.75it/s]读取数据:  83%|████████▎ | 5866676/7086503 [1:24:29<03:49, 5324.58it/s]读取数据:  83%|████████▎ | 5867209/7086503 [1:24:29<03:50, 5289.23it/s]读取数据:  83%|████████▎ | 5867739/7086503 [1:24:29<03:51, 5274.57it/s]读取数据:  83%|████████▎ | 5868288/7086503 [1:24:29<03:48, 5337.71it/s]读取数据:  83%|████████▎ | 5868822/7086503 [1:24:30<03:48, 5336.57it/s]读取数据:  83%|████████▎ | 5869385/7086503 [1:24:30<03:44, 5420.04it/s]读取数据:  83%|████████▎ | 5869928/7086503 [1:24:30<03:48, 5326.76it/s]读取数据:  83%|████████▎ | 5870494/7086503 [1:24:30<03:44, 5423.53it/s]读取数据:  83%|████████▎ | 5871037/7086503 [1:24:30<03:44, 5412.65it/s]读取数据:  83%|████████▎ | 5871590/7086503 [1:24:30<03:43, 5445.48it/s]读取数据:  83%|████████▎ | 5872135/7086503 [1:24:30<03:44, 5411.69it/s]读取数据:  83%|████████▎ | 5872695/7086503 [1:24:30<03:42, 5466.68it/s]读取数据:  83%|████████▎ | 5873251/7086503 [1:24:30<03:40, 5494.02it/s]读取数据:  83%|████████▎ | 5873824/7086503 [1:24:30<03:37, 5562.79it/s]读取数据:  83%|████████▎ | 5874412/7086503 [1:24:31<03:34, 5656.17it/s]读取数据:  83%|████████▎ | 5874985/7086503 [1:24:31<03:33, 5676.39it/s]读取数据:  83%|████████▎ | 5875569/7086503 [1:24:31<03:31, 5725.26it/s]读取数据:  83%|████████▎ | 5876142/7086503 [1:24:31<03:32, 5682.79it/s]读取数据:  83%|████████▎ | 5876756/7086503 [1:24:31<03:27, 5818.69it/s]读取数据:  83%|████████▎ | 5877358/7086503 [1:24:31<03:25, 5877.48it/s]读取数据:  83%|████████▎ | 5877994/7086503 [1:24:31<03:20, 6019.50it/s]读取数据:  83%|████████▎ | 5878620/7086503 [1:24:31<03:18, 6089.34it/s]读取数据:  83%|████████▎ | 5879230/7086503 [1:24:31<03:20, 6007.40it/s]读取数据:  83%|████████▎ | 5879875/7086503 [1:24:31<03:16, 6135.86it/s]读取数据:  83%|████████▎ | 5880517/7086503 [1:24:32<03:14, 6214.68it/s]读取数据:  83%|████████▎ | 5881143/7086503 [1:24:32<03:13, 6227.69it/s]读取数据:  83%|████████▎ | 5881780/7086503 [1:24:32<03:12, 6267.73it/s]读取数据:  83%|████████▎ | 5882440/7086503 [1:24:32<03:09, 6361.98it/s]读取数据:  83%|████████▎ | 5883077/7086503 [1:24:32<03:18, 6058.97it/s]读取数据:  83%|████████▎ | 5883754/7086503 [1:24:32<03:12, 6262.25it/s]读取数据:  83%|████████▎ | 5884429/7086503 [1:24:32<03:07, 6404.51it/s]读取数据:  83%|████████▎ | 5885167/7086503 [1:24:32<02:59, 6689.74it/s]读取数据:  83%|████████▎ | 5885881/7086503 [1:24:32<02:55, 6822.33it/s]读取数据:  83%|████████▎ | 5886608/7086503 [1:24:32<02:52, 6955.07it/s]读取数据:  83%|████████▎ | 5887342/7086503 [1:24:33<02:49, 7069.69it/s]读取数据:  83%|████████▎ | 5888084/7086503 [1:24:33<02:47, 7163.34it/s]读取数据:  83%|████████▎ | 5888807/7086503 [1:24:33<02:46, 7177.37it/s]读取数据:  83%|████████▎ | 5889590/7086503 [1:24:33<02:42, 7371.81it/s]读取数据:  83%|████████▎ | 5890402/7086503 [1:24:33<02:37, 7592.15it/s]读取数据:  83%|████████▎ | 5891192/7086503 [1:24:33<02:35, 7674.53it/s]读取数据:  83%|████████▎ | 5891990/7086503 [1:24:33<02:33, 7765.48it/s]读取数据:  83%|████████▎ | 5892803/7086503 [1:24:33<02:31, 7871.38it/s]读取数据:  83%|████████▎ | 5893635/7086503 [1:24:33<02:29, 8001.11it/s]读取数据:  83%|████████▎ | 5894467/7086503 [1:24:33<02:27, 8096.06it/s]读取数据:  83%|████████▎ | 5895310/7086503 [1:24:34<02:25, 8192.74it/s]读取数据:  83%|████████▎ | 5896174/7086503 [1:24:34<02:23, 8315.43it/s]读取数据:  83%|████████▎ | 5897024/7086503 [1:24:34<02:22, 8363.16it/s]读取数据:  83%|████████▎ | 5897872/7086503 [1:24:34<02:21, 8394.64it/s]读取数据:  83%|████████▎ | 5898712/7086503 [1:24:34<02:22, 8345.46it/s]读取数据:  83%|████████▎ | 5899547/7086503 [1:24:34<02:22, 8338.32it/s]读取数据:  83%|████████▎ | 5900381/7086503 [1:24:35<08:56, 2212.06it/s]读取数据:  83%|████████▎ | 5900990/7086503 [1:24:35<07:42, 2564.71it/s]读取数据:  83%|████████▎ | 5901574/7086503 [1:24:35<06:50, 2885.09it/s]读取数据:  83%|████████▎ | 5902123/7086503 [1:24:35<06:07, 3219.28it/s]读取数据:  83%|████████▎ | 5902656/7086503 [1:24:36<05:35, 3531.17it/s]读取数据:  83%|████████▎ | 5903177/7086503 [1:24:36<05:10, 3811.67it/s]读取数据:  83%|████████▎ | 5903689/7086503 [1:24:36<04:50, 4075.80it/s]读取数据:  83%|████████▎ | 5904198/7086503 [1:24:36<04:37, 4267.63it/s]读取数据:  83%|████████▎ | 5904706/7086503 [1:24:36<04:24, 4468.99it/s]读取数据:  83%|████████▎ | 5905210/7086503 [1:24:36<04:19, 4554.46it/s]读取数据:  83%|████████▎ | 5905728/7086503 [1:24:36<04:10, 4720.63it/s]读取数据:  83%|████████▎ | 5906231/7086503 [1:24:36<04:39, 4222.12it/s]读取数据:  83%|████████▎ | 5906684/7086503 [1:24:37<06:14, 3151.42it/s]读取数据:  83%|████████▎ | 5907058/7086503 [1:24:37<07:53, 2489.16it/s]读取数据:  83%|████████▎ | 5907365/7086503 [1:24:37<11:35, 1694.57it/s]读取数据:  83%|████████▎ | 5907604/7086503 [1:24:38<18:46, 1046.73it/s]读取数据:  83%|████████▎ | 5907784/7086503 [1:24:38<17:40, 1111.86it/s]读取数据:  83%|████████▎ | 5908224/7086503 [1:24:38<12:39, 1552.28it/s]读取数据:  83%|████████▎ | 5908744/7086503 [1:24:38<09:10, 2138.52it/s]读取数据:  83%|████████▎ | 5909253/7086503 [1:24:38<07:17, 2688.61it/s]读取数据:  83%|████████▎ | 5909749/7086503 [1:24:38<06:11, 3166.34it/s]读取数据:  83%|████████▎ | 5910255/7086503 [1:24:38<05:26, 3603.60it/s]读取数据:  83%|████████▎ | 5910795/7086503 [1:24:39<04:50, 4048.03it/s]读取数据:  83%|████████▎ | 5911339/7086503 [1:24:39<04:26, 4406.73it/s]读取数据:  83%|████████▎ | 5911839/7086503 [1:24:39<04:17, 4566.10it/s]读取数据:  83%|████████▎ | 5912345/7086503 [1:24:39<04:09, 4700.35it/s]读取数据:  83%|████████▎ | 5912885/7086503 [1:24:39<03:59, 4898.68it/s]读取数据:  83%|████████▎ | 5913440/7086503 [1:24:39<03:50, 5086.01it/s]读取数据:  83%|████████▎ | 5913975/7086503 [1:24:39<03:47, 5161.03it/s]读取数据:  83%|████████▎ | 5914502/7086503 [1:24:39<03:46, 5178.85it/s]读取数据:  83%|████████▎ | 5915072/7086503 [1:24:39<03:39, 5332.16it/s]读取数据:  83%|████████▎ | 5915655/7086503 [1:24:39<03:33, 5479.57it/s]读取数据:  83%|████████▎ | 5916207/7086503 [1:24:40<03:34, 5461.71it/s]读取数据:  83%|████████▎ | 5916765/7086503 [1:24:40<03:32, 5492.32it/s]读取数据:  84%|████████▎ | 5917324/7086503 [1:24:40<03:31, 5520.29it/s]读取数据:  84%|████████▎ | 5917938/7086503 [1:24:40<03:24, 5704.26it/s]读取数据:  84%|████████▎ | 5918521/7086503 [1:24:40<03:23, 5739.18it/s]读取数据:  84%|████████▎ | 5919105/7086503 [1:24:40<03:22, 5765.61it/s]读取数据:  84%|████████▎ | 5919723/7086503 [1:24:40<03:18, 5889.47it/s]读取数据:  84%|████████▎ | 5920334/7086503 [1:24:40<03:15, 5954.40it/s]读取数据:  84%|████████▎ | 5920939/7086503 [1:24:40<03:14, 5980.89it/s]读取数据:  84%|████████▎ | 5921568/7086503 [1:24:40<03:11, 6072.27it/s]读取数据:  84%|████████▎ | 5922177/7086503 [1:24:41<03:11, 6071.61it/s]读取数据:  84%|████████▎ | 5922785/7086503 [1:24:41<03:13, 6027.12it/s]读取数据:  84%|████████▎ | 5923398/7086503 [1:24:41<03:12, 6057.15it/s]读取数据:  84%|████████▎ | 5924066/7086503 [1:24:41<03:06, 6241.02it/s]读取数据:  84%|████████▎ | 5924691/7086503 [1:24:41<03:13, 6004.04it/s]读取数据:  84%|████████▎ | 5925327/7086503 [1:24:41<03:10, 6105.68it/s]读取数据:  84%|████████▎ | 5925940/7086503 [1:24:41<03:21, 5751.81it/s]读取数据:  84%|████████▎ | 5926573/7086503 [1:24:41<03:16, 5914.46it/s]读取数据:  84%|████████▎ | 5927221/7086503 [1:24:41<03:10, 6075.55it/s]读取数据:  84%|████████▎ | 5927894/7086503 [1:24:41<03:04, 6265.04it/s]读取数据:  84%|████████▎ | 5928551/7086503 [1:24:42<03:02, 6353.11it/s]读取数据:  84%|████████▎ | 5929201/7086503 [1:24:42<03:01, 6393.11it/s]读取数据:  84%|████████▎ | 5929879/7086503 [1:24:42<02:57, 6505.56it/s]读取数据:  84%|████████▎ | 5930589/7086503 [1:24:42<02:53, 6679.86it/s]读取数据:  84%|████████▎ | 5931259/7086503 [1:24:42<02:52, 6680.99it/s]读取数据:  84%|████████▎ | 5931970/7086503 [1:24:42<02:49, 6807.56it/s]读取数据:  84%|████████▎ | 5932721/7086503 [1:24:42<02:44, 7014.13it/s]读取数据:  84%|████████▎ | 5933471/7086503 [1:24:42<02:41, 7159.08it/s]读取数据:  84%|████████▎ | 5934190/7086503 [1:24:42<02:40, 7167.33it/s]读取数据:  84%|████████▍ | 5934995/7086503 [1:24:42<02:34, 7429.42it/s]读取数据:  84%|████████▍ | 5935798/7086503 [1:24:43<02:31, 7608.02it/s]读取数据:  84%|████████▍ | 5936583/7086503 [1:24:43<02:29, 7679.18it/s]读取数据:  84%|████████▍ | 5937414/7086503 [1:24:43<02:26, 7868.03it/s]读取数据:  84%|████████▍ | 5938284/7086503 [1:24:43<02:21, 8115.33it/s]读取数据:  84%|████████▍ | 5939154/7086503 [1:24:43<02:18, 8288.65it/s]读取数据:  84%|████████▍ | 5940048/7086503 [1:24:43<02:15, 8481.24it/s]读取数据:  84%|████████▍ | 5941004/7086503 [1:24:43<02:10, 8801.85it/s]读取数据:  84%|████████▍ | 5941986/7086503 [1:24:43<02:05, 9105.80it/s]读取数据:  84%|████████▍ | 5942999/7086503 [1:24:43<02:01, 9408.94it/s]读取数据:  84%|████████▍ | 5944084/7086503 [1:24:43<01:56, 9837.28it/s]读取数据:  84%|████████▍ | 5945190/7086503 [1:24:44<01:51, 10202.57it/s]读取数据:  84%|████████▍ | 5946351/7086503 [1:24:44<01:47, 10624.30it/s]读取数据:  84%|████████▍ | 5947552/7086503 [1:24:44<01:43, 11038.63it/s]读取数据:  84%|████████▍ | 5948754/7086503 [1:24:44<01:40, 11330.91it/s]读取数据:  84%|████████▍ | 5949888/7086503 [1:24:44<01:40, 11316.57it/s]读取数据:  84%|████████▍ | 5951020/7086503 [1:24:45<06:59, 2705.51it/s] 读取数据:  84%|████████▍ | 5951842/7086503 [1:24:45<06:12, 3047.84it/s]读取数据:  84%|████████▍ | 5952572/7086503 [1:24:45<05:38, 3346.88it/s]读取数据:  84%|████████▍ | 5953232/7086503 [1:24:46<05:15, 3593.30it/s]读取数据:  84%|████████▍ | 5953837/7086503 [1:24:46<04:56, 3814.97it/s]读取数据:  84%|████████▍ | 5954405/7086503 [1:24:46<04:38, 4069.04it/s]读取数据:  84%|████████▍ | 5954958/7086503 [1:24:46<04:22, 4307.28it/s]读取数据:  84%|████████▍ | 5955502/7086503 [1:24:46<04:08, 4542.70it/s]读取数据:  84%|████████▍ | 5956045/7086503 [1:24:46<04:02, 4662.65it/s]读取数据:  84%|████████▍ | 5956576/7086503 [1:24:46<03:55, 4801.02it/s]读取数据:  84%|████████▍ | 5957104/7086503 [1:24:46<03:49, 4911.63it/s]读取数据:  84%|████████▍ | 5957670/7086503 [1:24:46<03:40, 5109.74it/s]读取数据:  84%|████████▍ | 5958208/7086503 [1:24:47<03:40, 5125.02it/s]读取数据:  84%|████████▍ | 5958740/7086503 [1:24:47<03:37, 5177.25it/s]读取数据:  84%|████████▍ | 5959272/7086503 [1:24:47<03:38, 5158.23it/s]读取数据:  84%|████████▍ | 5959798/7086503 [1:24:47<03:42, 5062.18it/s]读取数据:  84%|████████▍ | 5960349/7086503 [1:24:47<03:37, 5188.93it/s]读取数据:  84%|████████▍ | 5960907/7086503 [1:24:47<03:32, 5295.04it/s]读取数据:  84%|████████▍ | 5961444/7086503 [1:24:47<03:31, 5308.81it/s]读取数据:  84%|████████▍ | 5961978/7086503 [1:24:47<04:10, 4486.08it/s]读取数据:  84%|████████▍ | 5962450/7086503 [1:24:47<04:44, 3948.16it/s]读取数据:  84%|████████▍ | 5962871/7086503 [1:24:48<04:45, 3932.81it/s]读取数据:  84%|████████▍ | 5963370/7086503 [1:24:48<04:27, 4198.62it/s]读取数据:  84%|████████▍ | 5963807/7086503 [1:24:48<04:33, 4100.40it/s]读取数据:  84%|████████▍ | 5964345/7086503 [1:24:48<04:12, 4444.93it/s]读取数据:  84%|████████▍ | 5964893/7086503 [1:24:48<03:57, 4728.76it/s]读取数据:  84%|████████▍ | 5965456/7086503 [1:24:48<03:45, 4975.41it/s]读取数据:  84%|████████▍ | 5965996/7086503 [1:24:48<03:39, 5096.47it/s]读取数据:  84%|████████▍ | 5966531/7086503 [1:24:48<03:36, 5170.17it/s]读取数据:  84%|████████▍ | 5967084/7086503 [1:24:48<03:32, 5274.86it/s]读取数据:  84%|████████▍ | 5967635/7086503 [1:24:48<03:29, 5343.33it/s]读取数据:  84%|████████▍ | 5968195/7086503 [1:24:49<03:26, 5419.17it/s]读取数据:  84%|████████▍ | 5968776/7086503 [1:24:49<03:21, 5535.06it/s]读取数据:  84%|████████▍ | 5969336/7086503 [1:24:49<03:21, 5552.04it/s]读取数据:  84%|████████▍ | 5969925/7086503 [1:24:49<03:17, 5648.26it/s]读取数据:  84%|████████▍ | 5970502/7086503 [1:24:49<03:16, 5683.75it/s]读取数据:  84%|████████▍ | 5971087/7086503 [1:24:49<03:14, 5730.64it/s]读取数据:  84%|████████▍ | 5971661/7086503 [1:24:49<03:16, 5673.92it/s]读取数据:  84%|████████▍ | 5972264/7086503 [1:24:49<03:12, 5778.20it/s]读取数据:  84%|████████▍ | 5972875/7086503 [1:24:49<03:09, 5874.62it/s]读取数据:  84%|████████▍ | 5973487/7086503 [1:24:49<03:07, 5945.48it/s]读取数据:  84%|████████▍ | 5974116/7086503 [1:24:50<03:03, 6048.37it/s]读取数据:  84%|████████▍ | 5974722/7086503 [1:24:50<03:04, 6041.18it/s]读取数据:  84%|████████▍ | 5975358/7086503 [1:24:50<03:01, 6133.49it/s]读取数据:  84%|████████▍ | 5975977/7086503 [1:24:50<03:00, 6148.52it/s]读取数据:  84%|████████▍ | 5976620/7086503 [1:24:50<02:58, 6231.59it/s]读取数据:  84%|████████▍ | 5977307/7086503 [1:24:50<02:52, 6419.04it/s]读取数据:  84%|████████▍ | 5978011/7086503 [1:24:50<02:47, 6604.00it/s]读取数据:  84%|████████▍ | 5978715/7086503 [1:24:50<02:44, 6734.39it/s]读取数据:  84%|████████▍ | 5979389/7086503 [1:24:50<02:44, 6719.38it/s]读取数据:  84%|████████▍ | 5980061/7086503 [1:24:50<02:45, 6696.20it/s]读取数据:  84%|████████▍ | 5980795/7086503 [1:24:51<02:40, 6886.94it/s]读取数据:  84%|████████▍ | 5981506/7086503 [1:24:51<02:38, 6950.17it/s]读取数据:  84%|████████▍ | 5982241/7086503 [1:24:51<02:36, 7069.43it/s]读取数据:  84%|████████▍ | 5982996/7086503 [1:24:51<02:32, 7213.28it/s]读取数据:  84%|████████▍ | 5983751/7086503 [1:24:51<02:30, 7313.42it/s]读取数据:  84%|████████▍ | 5984518/7086503 [1:24:51<02:28, 7416.03it/s]读取数据:  84%|████████▍ | 5985339/7086503 [1:24:51<02:23, 7650.95it/s]读取数据:  84%|████████▍ | 5986151/7086503 [1:24:51<02:21, 7790.39it/s]读取数据:  84%|████████▍ | 5986964/7086503 [1:24:51<02:19, 7890.66it/s]读取数据:  84%|████████▍ | 5987825/7086503 [1:24:51<02:15, 8103.49it/s]读取数据:  85%|████████▍ | 5988636/7086503 [1:24:52<03:04, 5940.52it/s]读取数据:  85%|████████▍ | 5989339/7086503 [1:24:52<02:56, 6199.47it/s]读取数据:  85%|████████▍ | 5990024/7086503 [1:24:52<03:15, 5617.31it/s]读取数据:  85%|████████▍ | 5990872/7086503 [1:24:52<02:53, 6312.20it/s]读取数据:  85%|████████▍ | 5991617/7086503 [1:24:52<02:45, 6598.08it/s]读取数据:  85%|████████▍ | 5992481/7086503 [1:24:52<02:33, 7146.00it/s]读取数据:  85%|████████▍ | 5993243/7086503 [1:24:52<02:43, 6687.97it/s]读取数据:  85%|████████▍ | 5993942/7086503 [1:24:53<06:49, 2668.87it/s]读取数据:  85%|████████▍ | 5994463/7086503 [1:24:54<10:44, 1695.20it/s]读取数据:  85%|████████▍ | 5994850/7086503 [1:24:55<20:51, 872.57it/s] 读取数据:  85%|████████▍ | 5995130/7086503 [1:24:55<18:55, 961.34it/s]读取数据:  85%|████████▍ | 5995385/7086503 [1:24:56<19:44, 920.85it/s]读取数据:  85%|████████▍ | 5995587/7086503 [1:24:56<21:25, 848.41it/s]读取数据:  85%|████████▍ | 5995747/7086503 [1:24:56<26:25, 687.82it/s]读取数据:  85%|████████▍ | 5995883/7086503 [1:24:56<24:31, 741.07it/s]读取数据:  85%|████████▍ | 5996607/7086503 [1:24:57<12:20, 1470.89it/s]读取数据:  85%|████████▍ | 5997220/7086503 [1:24:57<09:15, 1961.23it/s]读取数据:  85%|████████▍ | 5997550/7086503 [1:24:57<14:14, 1275.06it/s]读取数据:  85%|████████▍ | 5997888/7086503 [1:24:57<11:57, 1517.20it/s]读取数据:  85%|████████▍ | 5998164/7086503 [1:24:58<15:27, 1173.31it/s]读取数据:  85%|████████▍ | 5998377/7086503 [1:24:58<18:14, 994.14it/s] 读取数据:  85%|████████▍ | 5999368/7086503 [1:24:58<08:49, 2054.24it/s]读取数据:  85%|████████▍ | 5999368/7086503 [1:25:17<08:49, 2054.24it/s]读取数据:  85%|████████▍ | 6000000/7086503 [1:34:23<92:39:49,  3.26it/s]读取数据:  85%|████████▍ | 6000203/7086503 [1:34:23<80:03:38,  3.77it/s]读取数据:  85%|████████▍ | 6000716/7086503 [1:34:23<53:40:56,  5.62it/s]读取数据:  85%|████████▍ | 6001234/7086503 [1:34:23<36:23:32,  8.28it/s]读取数据:  85%|████████▍ | 6001746/7086503 [1:34:23<25:01:17, 12.04it/s]读取数据:  85%|████████▍ | 6002236/7086503 [1:34:24<17:32:22, 17.17it/s]读取数据:  85%|████████▍ | 6002753/7086503 [1:34:24<12:05:50, 24.88it/s]读取数据:  85%|████████▍ | 6003261/7086503 [1:34:24<8:26:07, 35.67it/s] 读取数据:  85%|████████▍ | 6003790/7086503 [1:34:24<5:49:27, 51.64it/s]读取数据:  85%|████████▍ | 6004298/7086503 [1:34:24<4:05:49, 73.37it/s]读取数据:  85%|████████▍ | 6004826/7086503 [1:34:24<2:51:09, 105.33it/s]读取数据:  85%|████████▍ | 6005338/7086503 [1:34:24<2:01:00, 148.91it/s]读取数据:  85%|████████▍ | 6005856/7086503 [1:34:24<1:25:31, 210.60it/s]读取数据:  85%|████████▍ | 6006411/7086503 [1:34:24<59:30, 302.53it/s]  读取数据:  85%|████████▍ | 6006961/7086503 [1:34:24<42:06, 427.26it/s]读取数据:  85%|████████▍ | 6007494/7086503 [1:34:25<30:30, 589.54it/s]读取数据:  85%|████████▍ | 6008034/7086503 [1:34:25<22:16, 806.81it/s]读取数据:  85%|████████▍ | 6008567/7086503 [1:34:25<16:39, 1078.15it/s]读取数据:  85%|████████▍ | 6009094/7086503 [1:34:25<12:43, 1410.86it/s]读取数据:  85%|████████▍ | 6009634/7086503 [1:34:25<09:52, 1817.37it/s]读取数据:  85%|████████▍ | 6010174/7086503 [1:34:25<07:53, 2271.87it/s]读取数据:  85%|████████▍ | 6010708/7086503 [1:34:25<06:32, 2743.27it/s]读取数据:  85%|████████▍ | 6011258/7086503 [1:34:25<05:32, 3237.50it/s]读取数据:  85%|████████▍ | 6011802/7086503 [1:34:25<04:51, 3687.43it/s]读取数据:  85%|████████▍ | 6012361/7086503 [1:34:25<04:20, 4116.43it/s]读取数据:  85%|████████▍ | 6012906/7086503 [1:34:26<04:02, 4432.88it/s]读取数据:  85%|████████▍ | 6013476/7086503 [1:34:26<03:45, 4759.40it/s]读取数据:  85%|████████▍ | 6014044/7086503 [1:34:26<03:34, 5006.51it/s]读取数据:  85%|████████▍ | 6014607/7086503 [1:34:26<03:27, 5174.34it/s]读取数据:  85%|████████▍ | 6015168/7086503 [1:34:26<03:22, 5297.50it/s]读取数据:  85%|████████▍ | 6015741/7086503 [1:34:26<03:17, 5421.89it/s]读取数据:  85%|████████▍ | 6016304/7086503 [1:34:26<03:17, 5429.11it/s]读取数据:  85%|████████▍ | 6016874/7086503 [1:34:26<03:14, 5507.06it/s]读取数据:  85%|████████▍ | 6017450/7086503 [1:34:26<03:11, 5580.04it/s]读取数据:  85%|████████▍ | 6018016/7086503 [1:34:26<03:11, 5592.79it/s]读取数据:  85%|████████▍ | 6018584/7086503 [1:34:27<03:10, 5615.36it/s]读取数据:  85%|████████▍ | 6019159/7086503 [1:34:27<03:08, 5653.76it/s]读取数据:  85%|████████▍ | 6019727/7086503 [1:34:27<03:08, 5659.27it/s]读取数据:  85%|████████▍ | 6020295/7086503 [1:34:27<03:16, 5436.20it/s]读取数据:  85%|████████▍ | 6020842/7086503 [1:34:27<04:35, 3864.19it/s]读取数据:  85%|████████▍ | 6021293/7086503 [1:34:27<04:36, 3853.70it/s]读取数据:  85%|████████▍ | 6021867/7086503 [1:34:27<04:07, 4301.70it/s]读取数据:  85%|████████▍ | 6022423/7086503 [1:34:27<03:50, 4620.27it/s]读取数据:  85%|████████▍ | 6022922/7086503 [1:34:27<03:48, 4647.93it/s]读取数据:  85%|████████▍ | 6023509/7086503 [1:34:28<03:33, 4978.91it/s]读取数据:  85%|████████▌ | 6024049/7086503 [1:34:28<03:28, 5095.66it/s]读取数据:  85%|████████▌ | 6024623/7086503 [1:34:28<03:21, 5279.53it/s]读取数据:  85%|████████▌ | 6025170/7086503 [1:34:28<03:18, 5334.06it/s]读取数据:  85%|████████▌ | 6025746/7086503 [1:34:28<03:14, 5454.28it/s]读取数据:  85%|████████▌ | 6026345/7086503 [1:34:28<03:08, 5609.51it/s]读取数据:  85%|████████▌ | 6026950/7086503 [1:34:28<03:04, 5739.56it/s]读取数据:  85%|████████▌ | 6027544/7086503 [1:34:28<03:02, 5798.55it/s]读取数据:  85%|████████▌ | 6028127/7086503 [1:34:28<03:14, 5428.45it/s]读取数据:  85%|████████▌ | 6028699/7086503 [1:34:29<03:12, 5508.08it/s]读取数据:  85%|████████▌ | 6029332/7086503 [1:34:29<03:04, 5739.39it/s]读取数据:  85%|████████▌ | 6029948/7086503 [1:34:29<03:00, 5861.50it/s]读取数据:  85%|████████▌ | 6030558/7086503 [1:34:29<02:58, 5931.05it/s]读取数据:  85%|████████▌ | 6031159/7086503 [1:34:29<02:57, 5951.97it/s]读取数据:  85%|████████▌ | 6031793/7086503 [1:34:29<02:53, 6065.74it/s]读取数据:  85%|████████▌ | 6032436/7086503 [1:34:29<02:50, 6169.30it/s]读取数据:  85%|████████▌ | 6033054/7086503 [1:34:29<02:50, 6169.12it/s]读取数据:  85%|████████▌ | 6033724/7086503 [1:34:29<02:46, 6326.42it/s]读取数据:  85%|████████▌ | 6034358/7086503 [1:34:29<02:47, 6297.48it/s]读取数据:  85%|████████▌ | 6034989/7086503 [1:34:30<02:48, 6247.29it/s]读取数据:  85%|████████▌ | 6035615/7086503 [1:34:30<02:54, 6024.08it/s]读取数据:  85%|████████▌ | 6036320/7086503 [1:34:30<02:46, 6320.33it/s]读取数据:  85%|████████▌ | 6036955/7086503 [1:34:30<03:33, 4919.80it/s]读取数据:  85%|████████▌ | 6037496/7086503 [1:34:30<05:25, 3222.04it/s]读取数据:  85%|████████▌ | 6038193/7086503 [1:34:30<04:28, 3907.39it/s]读取数据:  85%|████████▌ | 6038701/7086503 [1:34:31<04:36, 3790.43it/s]读取数据:  85%|████████▌ | 6039208/7086503 [1:34:31<04:20, 4024.19it/s]读取数据:  85%|████████▌ | 6039676/7086503 [1:34:31<05:00, 3484.19it/s]读取数据:  85%|████████▌ | 6040404/7086503 [1:34:31<04:03, 4303.20it/s]读取数据:  85%|████████▌ | 6041135/7086503 [1:34:31<03:28, 5012.25it/s]读取数据:  85%|████████▌ | 6041921/7086503 [1:34:31<03:02, 5728.25it/s]读取数据:  85%|████████▌ | 6042754/7086503 [1:34:31<02:42, 6415.57it/s]读取数据:  85%|████████▌ | 6043607/7086503 [1:34:31<02:29, 6994.06it/s]读取数据:  85%|████████▌ | 6044439/7086503 [1:34:31<02:21, 7367.06it/s]读取数据:  85%|████████▌ | 6045305/7086503 [1:34:32<02:14, 7737.33it/s]读取数据:  85%|████████▌ | 6046182/7086503 [1:34:32<02:09, 8028.37it/s]读取数据:  85%|████████▌ | 6047007/7086503 [1:34:32<02:08, 8092.46it/s]读取数据:  85%|████████▌ | 6047873/7086503 [1:34:32<02:05, 8259.23it/s]读取数据:  85%|████████▌ | 6048740/7086503 [1:34:32<02:03, 8379.03it/s]读取数据:  85%|████████▌ | 6049585/7086503 [1:34:32<02:03, 8397.18it/s]读取数据:  85%|████████▌ | 6050430/7086503 [1:34:33<07:55, 2180.94it/s]读取数据:  85%|████████▌ | 6051045/7086503 [1:34:33<06:54, 2496.97it/s]读取数据:  85%|████████▌ | 6051616/7086503 [1:34:33<06:09, 2797.95it/s]读取数据:  85%|████████▌ | 6052152/7086503 [1:34:33<05:29, 3138.68it/s]读取数据:  85%|████████▌ | 6052679/7086503 [1:34:34<04:57, 3470.55it/s]读取数据:  85%|████████▌ | 6053199/7086503 [1:34:34<04:34, 3770.56it/s]读取数据:  85%|████████▌ | 6053712/7086503 [1:34:34<04:20, 3959.92it/s]读取数据:  85%|████████▌ | 6054209/7086503 [1:34:34<04:10, 4118.77it/s]读取数据:  85%|████████▌ | 6054697/7086503 [1:34:34<03:59, 4304.59it/s]读取数据:  85%|████████▌ | 6055191/7086503 [1:34:34<03:50, 4468.71it/s]读取数据:  85%|████████▌ | 6055680/7086503 [1:34:34<03:50, 4469.14it/s]读取数据:  85%|████████▌ | 6056183/7086503 [1:34:34<03:43, 4616.21it/s]读取数据:  85%|████████▌ | 6056667/7086503 [1:34:34<03:42, 4636.27it/s]读取数据:  85%|████████▌ | 6057162/7086503 [1:34:34<03:37, 4724.61it/s]读取数据:  85%|████████▌ | 6057646/7086503 [1:34:35<03:38, 4709.83it/s]读取数据:  85%|████████▌ | 6058125/7086503 [1:34:35<03:39, 4688.51it/s]读取数据:  85%|████████▌ | 6058614/7086503 [1:34:35<03:36, 4745.23it/s]读取数据:  86%|████████▌ | 6059093/7086503 [1:34:35<03:38, 4704.02it/s]读取数据:  86%|████████▌ | 6059571/7086503 [1:34:35<03:37, 4724.32it/s]读取数据:  86%|████████▌ | 6060065/7086503 [1:34:35<03:34, 4782.21it/s]读取数据:  86%|████████▌ | 6060545/7086503 [1:34:35<03:41, 4642.29it/s]读取数据:  86%|████████▌ | 6061041/7086503 [1:34:35<03:36, 4733.99it/s]读取数据:  86%|████████▌ | 6061553/7086503 [1:34:35<03:31, 4845.04it/s]读取数据:  86%|████████▌ | 6062077/7086503 [1:34:35<03:26, 4959.33it/s]读取数据:  86%|████████▌ | 6062590/7086503 [1:34:36<03:24, 5005.64it/s]读取数据:  86%|████████▌ | 6063113/7086503 [1:34:36<03:21, 5071.46it/s]读取数据:  86%|████████▌ | 6063621/7086503 [1:34:36<03:26, 4948.30it/s]读取数据:  86%|████████▌ | 6064162/7086503 [1:34:36<03:21, 5082.53it/s]读取数据:  86%|████████▌ | 6064705/7086503 [1:34:36<03:17, 5184.30it/s]读取数据:  86%|████████▌ | 6065225/7086503 [1:34:36<03:19, 5131.20it/s]读取数据:  86%|████████▌ | 6065757/7086503 [1:34:36<03:16, 5182.10it/s]读取数据:  86%|████████▌ | 6066281/7086503 [1:34:36<03:16, 5199.20it/s]读取数据:  86%|████████▌ | 6066802/7086503 [1:34:36<03:19, 5106.99it/s]读取数据:  86%|████████▌ | 6067314/7086503 [1:34:37<03:28, 4886.59it/s]读取数据:  86%|████████▌ | 6067860/7086503 [1:34:37<03:21, 5049.03it/s]读取数据:  86%|████████▌ | 6068430/7086503 [1:34:37<03:14, 5236.40it/s]读取数据:  86%|████████▌ | 6068980/7086503 [1:34:37<03:11, 5312.19it/s]读取数据:  86%|████████▌ | 6069548/7086503 [1:34:37<03:07, 5420.42it/s]读取数据:  86%|████████▌ | 6070112/7086503 [1:34:37<03:05, 5483.71it/s]读取数据:  86%|████████▌ | 6070703/7086503 [1:34:37<03:01, 5607.52it/s]读取数据:  86%|████████▌ | 6071265/7086503 [1:34:37<03:01, 5587.87it/s]读取数据:  86%|████████▌ | 6071825/7086503 [1:34:37<03:01, 5575.73it/s]读取数据:  86%|████████▌ | 6072418/7086503 [1:34:37<02:58, 5676.99it/s]读取数据:  86%|████████▌ | 6072987/7086503 [1:34:38<02:59, 5660.47it/s]读取数据:  86%|████████▌ | 6073555/7086503 [1:34:38<02:58, 5660.08it/s]读取数据:  86%|████████▌ | 6074156/7086503 [1:34:38<02:55, 5764.01it/s]读取数据:  86%|████████▌ | 6074747/7086503 [1:34:38<02:54, 5805.13it/s]读取数据:  86%|████████▌ | 6075337/7086503 [1:34:38<02:53, 5829.31it/s]读取数据:  86%|████████▌ | 6075973/7086503 [1:34:38<02:48, 5987.16it/s]读取数据:  86%|████████▌ | 6076589/7086503 [1:34:38<02:47, 6038.19it/s]读取数据:  86%|████████▌ | 6077193/7086503 [1:34:38<02:47, 6011.34it/s]读取数据:  86%|████████▌ | 6077804/7086503 [1:34:38<02:47, 6040.08it/s]读取数据:  86%|████████▌ | 6078425/7086503 [1:34:38<02:45, 6090.12it/s]读取数据:  86%|████████▌ | 6079035/7086503 [1:34:39<02:53, 5793.67it/s]读取数据:  86%|████████▌ | 6079618/7086503 [1:34:39<02:55, 5729.29it/s]读取数据:  86%|████████▌ | 6080266/7086503 [1:34:39<02:51, 5861.69it/s]读取数据:  86%|████████▌ | 6080909/7086503 [1:34:39<02:47, 6019.25it/s]读取数据:  86%|████████▌ | 6081541/7086503 [1:34:39<02:44, 6106.65it/s]读取数据:  86%|████████▌ | 6082186/7086503 [1:34:39<02:41, 6204.65it/s]读取数据:  86%|████████▌ | 6082844/7086503 [1:34:39<02:38, 6315.22it/s]读取数据:  86%|████████▌ | 6083477/7086503 [1:34:39<02:39, 6299.01it/s]读取数据:  86%|████████▌ | 6084108/7086503 [1:34:39<02:44, 6088.60it/s]读取数据:  86%|████████▌ | 6084719/7086503 [1:34:39<02:49, 5915.69it/s]读取数据:  86%|████████▌ | 6085361/7086503 [1:34:40<02:45, 6060.49it/s]读取数据:  86%|████████▌ | 6085984/7086503 [1:34:40<02:43, 6105.73it/s]读取数据:  86%|████████▌ | 6086700/7086503 [1:34:40<02:35, 6414.61it/s]读取数据:  86%|████████▌ | 6087420/7086503 [1:34:40<02:30, 6645.94it/s]读取数据:  86%|████████▌ | 6088198/7086503 [1:34:40<02:22, 6982.19it/s]读取数据:  86%|████████▌ | 6088974/7086503 [1:34:40<02:18, 7212.83it/s]读取数据:  86%|████████▌ | 6089715/7086503 [1:34:40<02:17, 7270.99it/s]读取数据:  86%|████████▌ | 6090506/7086503 [1:34:40<02:13, 7458.86it/s]读取数据:  86%|████████▌ | 6091257/7086503 [1:34:40<02:13, 7471.80it/s]读取数据:  86%|████████▌ | 6092074/7086503 [1:34:40<02:09, 7678.61it/s]读取数据:  86%|████████▌ | 6092866/7086503 [1:34:41<02:08, 7750.59it/s]读取数据:  86%|████████▌ | 6093681/7086503 [1:34:41<02:06, 7868.46it/s]读取数据:  86%|████████▌ | 6094474/7086503 [1:34:41<02:05, 7886.00it/s]读取数据:  86%|████████▌ | 6095263/7086503 [1:34:41<02:07, 7786.40it/s]读取数据:  86%|████████▌ | 6096077/7086503 [1:34:41<02:05, 7887.37it/s]读取数据:  86%|████████▌ | 6096924/7086503 [1:34:41<02:02, 8053.05it/s]读取数据:  86%|████████▌ | 6097853/7086503 [1:34:41<01:57, 8420.02it/s]读取数据:  86%|████████▌ | 6098843/7086503 [1:34:41<01:51, 8858.46it/s]读取数据:  86%|████████▌ | 6099824/7086503 [1:34:41<01:47, 9141.48it/s]读取数据:  86%|████████▌ | 6100739/7086503 [1:34:42<06:58, 2356.01it/s]读取数据:  86%|████████▌ | 6101406/7086503 [1:34:43<06:06, 2688.00it/s]读取数据:  86%|████████▌ | 6102020/7086503 [1:34:43<05:28, 2999.81it/s]读取数据:  86%|████████▌ | 6102593/7086503 [1:34:43<04:56, 3320.86it/s]读取数据:  86%|████████▌ | 6103144/7086503 [1:34:43<04:30, 3635.94it/s]读取数据:  86%|████████▌ | 6103683/7086503 [1:34:43<04:11, 3905.11it/s]读取数据:  86%|████████▌ | 6104209/7086503 [1:34:43<03:57, 4137.18it/s]读取数据:  86%|████████▌ | 6104726/7086503 [1:34:43<03:47, 4320.61it/s]读取数据:  86%|████████▌ | 6105235/7086503 [1:34:43<03:40, 4457.49it/s]读取数据:  86%|████████▌ | 6105738/7086503 [1:34:43<03:34, 4568.49it/s]读取数据:  86%|████████▌ | 6106264/7086503 [1:34:44<03:26, 4751.49it/s]读取数据:  86%|████████▌ | 6106805/7086503 [1:34:44<03:18, 4929.27it/s]读取数据:  86%|████████▌ | 6107332/7086503 [1:34:44<03:14, 5025.22it/s]读取数据:  86%|████████▌ | 6107852/7086503 [1:34:44<03:20, 4869.66it/s]读取数据:  86%|████████▌ | 6108363/7086503 [1:34:44<03:18, 4935.57it/s]读取数据:  86%|████████▌ | 6108866/7086503 [1:34:44<03:18, 4920.40it/s]读取数据:  86%|████████▌ | 6109365/7086503 [1:34:44<03:18, 4910.77it/s]读取数据:  86%|████████▌ | 6109876/7086503 [1:34:44<03:16, 4966.71it/s]读取数据:  86%|████████▌ | 6110377/7086503 [1:34:44<03:16, 4979.11it/s]读取数据:  86%|████████▌ | 6110887/7086503 [1:34:44<03:14, 5012.47it/s]读取数据:  86%|████████▌ | 6111390/7086503 [1:34:45<03:14, 5001.97it/s]读取数据:  86%|████████▌ | 6111915/7086503 [1:34:45<03:12, 5075.44it/s]读取数据:  86%|████████▋ | 6112467/7086503 [1:34:45<03:07, 5204.04it/s]读取数据:  86%|████████▋ | 6112989/7086503 [1:34:45<03:07, 5182.99it/s]读取数据:  86%|████████▋ | 6113508/7086503 [1:34:45<03:08, 5174.36it/s]读取数据:  86%|████████▋ | 6114050/7086503 [1:34:45<03:05, 5243.96it/s]读取数据:  86%|████████▋ | 6114600/7086503 [1:34:45<03:02, 5319.28it/s]读取数据:  86%|████████▋ | 6115133/7086503 [1:34:45<03:03, 5307.62it/s]读取数据:  86%|████████▋ | 6115717/7086503 [1:34:45<02:57, 5463.72it/s]读取数据:  86%|████████▋ | 6116274/7086503 [1:34:45<02:56, 5493.42it/s]读取数据:  86%|████████▋ | 6116827/7086503 [1:34:46<02:56, 5503.13it/s]读取数据:  86%|████████▋ | 6117378/7086503 [1:34:46<02:58, 5428.62it/s]读取数据:  86%|████████▋ | 6117943/7086503 [1:34:46<02:56, 5490.81it/s]读取数据:  86%|████████▋ | 6118493/7086503 [1:34:46<02:56, 5470.14it/s]读取数据:  86%|████████▋ | 6119068/7086503 [1:34:46<02:54, 5550.62it/s]读取数据:  86%|████████▋ | 6119638/7086503 [1:34:46<02:52, 5592.13it/s]读取数据:  86%|████████▋ | 6120198/7086503 [1:34:46<02:53, 5572.18it/s]读取数据:  86%|████████▋ | 6120756/7086503 [1:34:46<02:53, 5553.62it/s]读取数据:  86%|████████▋ | 6121312/7086503 [1:34:46<02:56, 5471.30it/s]读取数据:  86%|████████▋ | 6121872/7086503 [1:34:47<02:55, 5508.28it/s]读取数据:  86%|████████▋ | 6122427/7086503 [1:34:47<02:54, 5518.11it/s]读取数据:  86%|████████▋ | 6122994/7086503 [1:34:47<02:53, 5560.06it/s]读取数据:  86%|████████▋ | 6123580/7086503 [1:34:47<02:50, 5646.43it/s]读取数据:  86%|████████▋ | 6124151/7086503 [1:34:47<02:49, 5663.22it/s]读取数据:  86%|████████▋ | 6124754/7086503 [1:34:47<02:46, 5769.81it/s]读取数据:  86%|████████▋ | 6125343/7086503 [1:34:47<02:45, 5804.24it/s]读取数据:  86%|████████▋ | 6125934/7086503 [1:34:47<02:44, 5833.37it/s]读取数据:  86%|████████▋ | 6126518/7086503 [1:34:47<02:46, 5768.27it/s]读取数据:  86%|████████▋ | 6127128/7086503 [1:34:47<02:43, 5864.97it/s]读取数据:  86%|████████▋ | 6127741/7086503 [1:34:48<02:41, 5936.65it/s]读取数据:  86%|████████▋ | 6128346/7086503 [1:34:48<02:40, 5966.44it/s]读取数据:  86%|████████▋ | 6128950/7086503 [1:34:48<02:40, 5979.36it/s]读取数据:  86%|████████▋ | 6129605/7086503 [1:34:48<02:35, 6145.64it/s]读取数据:  87%|████████▋ | 6130258/7086503 [1:34:48<02:32, 6256.76it/s]读取数据:  87%|████████▋ | 6130884/7086503 [1:34:48<02:34, 6199.75it/s]读取数据:  87%|████████▋ | 6131556/7086503 [1:34:48<02:30, 6352.13it/s]读取数据:  87%|████████▋ | 6132236/7086503 [1:34:48<02:27, 6482.80it/s]读取数据:  87%|████████▋ | 6132913/7086503 [1:34:48<02:25, 6567.59it/s]读取数据:  87%|████████▋ | 6133578/7086503 [1:34:48<02:24, 6587.73it/s]读取数据:  87%|████████▋ | 6134311/7086503 [1:34:49<02:19, 6806.70it/s]读取数据:  87%|████████▋ | 6135023/7086503 [1:34:49<02:17, 6895.83it/s]读取数据:  87%|████████▋ | 6135775/7086503 [1:34:49<02:14, 7081.58it/s]读取数据:  87%|████████▋ | 6136550/7086503 [1:34:49<02:10, 7280.40it/s]读取数据:  87%|████████▋ | 6137314/7086503 [1:34:49<02:08, 7384.87it/s]读取数据:  87%|████████▋ | 6138082/7086503 [1:34:49<02:06, 7473.18it/s]读取数据:  87%|████████▋ | 6138866/7086503 [1:34:49<02:04, 7581.34it/s]读取数据:  87%|████████▋ | 6139625/7086503 [1:34:49<02:06, 7480.64it/s]读取数据:  87%|████████▋ | 6140376/7086503 [1:34:49<02:06, 7488.64it/s]读取数据:  87%|████████▋ | 6141199/7086503 [1:34:49<02:02, 7707.91it/s]读取数据:  87%|████████▋ | 6141987/7086503 [1:34:50<02:01, 7756.82it/s]读取数据:  87%|████████▋ | 6142800/7086503 [1:34:50<01:59, 7867.59it/s]读取数据:  87%|████████▋ | 6143644/7086503 [1:34:50<01:57, 8030.32it/s]读取数据:  87%|████████▋ | 6144453/7086503 [1:34:50<01:57, 8046.95it/s]读取数据:  87%|████████▋ | 6145287/7086503 [1:34:50<01:55, 8133.13it/s]读取数据:  87%|████████▋ | 6146126/7086503 [1:34:50<01:54, 8205.03it/s]读取数据:  87%|████████▋ | 6146960/7086503 [1:34:50<01:53, 8242.52it/s]读取数据:  87%|████████▋ | 6147831/7086503 [1:34:50<01:52, 8370.59it/s]读取数据:  87%|████████▋ | 6148751/7086503 [1:34:50<01:48, 8613.97it/s]读取数据:  87%|████████▋ | 6149613/7086503 [1:34:50<01:51, 8415.61it/s]读取数据:  87%|████████▋ | 6150456/7086503 [1:34:52<07:35, 2053.15it/s]读取数据:  87%|████████▋ | 6151068/7086503 [1:34:52<06:30, 2392.57it/s]读取数据:  87%|████████▋ | 6151653/7086503 [1:34:52<05:50, 2666.09it/s]读取数据:  87%|████████▋ | 6152187/7086503 [1:34:52<05:12, 2989.04it/s]读取数据:  87%|████████▋ | 6152706/7086503 [1:34:52<04:45, 3276.27it/s]读取数据:  87%|████████▋ | 6153208/7086503 [1:34:52<04:25, 3513.47it/s]读取数据:  87%|████████▋ | 6153693/7086503 [1:34:52<04:09, 3743.03it/s]读取数据:  87%|████████▋ | 6154184/7086503 [1:34:52<03:52, 4003.11it/s]读取数据:  87%|████████▋ | 6154672/7086503 [1:34:52<03:41, 4214.09it/s]读取数据:  87%|████████▋ | 6155155/7086503 [1:34:53<03:40, 4230.14it/s]读取数据:  87%|████████▋ | 6155622/7086503 [1:34:53<03:38, 4268.93it/s]读取数据:  87%|████████▋ | 6156099/7086503 [1:34:53<03:31, 4403.27it/s]读取数据:  87%|████████▋ | 6156602/7086503 [1:34:53<03:23, 4576.38it/s]读取数据:  87%|████████▋ | 6157107/7086503 [1:34:53<03:17, 4708.14it/s]读取数据:  87%|████████▋ | 6157618/7086503 [1:34:53<03:12, 4823.39it/s]读取数据:  87%|████████▋ | 6158133/7086503 [1:34:53<03:08, 4918.14it/s]读取数据:  87%|████████▋ | 6158632/7086503 [1:34:53<03:10, 4871.20it/s]读取数据:  87%|████████▋ | 6159148/7086503 [1:34:53<03:07, 4954.63it/s]读取数据:  87%|████████▋ | 6159648/7086503 [1:34:54<03:08, 4926.95it/s]读取数据:  87%|████████▋ | 6160182/7086503 [1:34:54<03:03, 5048.12it/s]读取数据:  87%|████████▋ | 6160692/7086503 [1:34:54<03:02, 5062.82it/s]读取数据:  87%|████████▋ | 6161200/7086503 [1:34:54<03:12, 4817.60it/s]读取数据:  87%|████████▋ | 6161706/7086503 [1:34:54<03:09, 4881.70it/s]读取数据:  87%|████████▋ | 6162197/7086503 [1:34:54<03:13, 4777.59it/s]读取数据:  87%|████████▋ | 6162701/7086503 [1:34:54<03:10, 4848.06it/s]读取数据:  87%|████████▋ | 6163209/7086503 [1:34:54<03:07, 4914.67it/s]读取数据:  87%|████████▋ | 6163702/7086503 [1:34:54<03:08, 4900.77it/s]读取数据:  87%|████████▋ | 6164234/7086503 [1:34:54<03:03, 5019.07it/s]读取数据:  87%|████████▋ | 6164798/7086503 [1:34:55<02:57, 5201.17it/s]读取数据:  87%|████████▋ | 6165332/7086503 [1:34:55<02:55, 5241.31it/s]读取数据:  87%|████████▋ | 6165857/7086503 [1:34:55<02:56, 5224.60it/s]读取数据:  87%|████████▋ | 6166410/7086503 [1:34:55<02:53, 5314.70it/s]读取数据:  87%|████████▋ | 6166942/7086503 [1:34:55<02:53, 5304.36it/s]读取数据:  87%|████████▋ | 6167515/7086503 [1:34:55<02:49, 5428.38it/s]读取数据:  87%|████████▋ | 6168059/7086503 [1:34:55<02:50, 5379.13it/s]读取数据:  87%|████████▋ | 6168598/7086503 [1:34:55<02:51, 5355.89it/s]读取数据:  87%|████████▋ | 6169134/7086503 [1:34:55<02:51, 5345.35it/s]读取数据:  87%|████████▋ | 6169681/7086503 [1:34:55<02:50, 5381.40it/s]读取数据:  87%|████████▋ | 6170220/7086503 [1:34:56<02:50, 5377.53it/s]读取数据:  87%|████████▋ | 6170758/7086503 [1:34:56<02:51, 5330.58it/s]读取数据:  87%|████████▋ | 6171296/7086503 [1:34:56<02:51, 5345.16it/s]读取数据:  87%|████████▋ | 6171845/7086503 [1:34:56<02:49, 5384.17it/s]读取数据:  87%|████████▋ | 6172397/7086503 [1:34:56<02:48, 5416.32it/s]读取数据:  87%|████████▋ | 6172944/7086503 [1:34:56<02:48, 5431.98it/s]读取数据:  87%|████████▋ | 6173527/7086503 [1:34:56<02:44, 5547.99it/s]读取数据:  87%|████████▋ | 6174109/7086503 [1:34:56<02:42, 5625.76it/s]读取数据:  87%|████████▋ | 6174692/7086503 [1:34:56<02:40, 5686.45it/s]读取数据:  87%|████████▋ | 6175299/7086503 [1:34:56<02:37, 5796.33it/s]读取数据:  87%|████████▋ | 6175909/7086503 [1:34:57<02:34, 5886.53it/s]读取数据:  87%|████████▋ | 6176524/7086503 [1:34:57<02:32, 5953.69it/s]读取数据:  87%|████████▋ | 6177140/7086503 [1:34:57<02:31, 6014.35it/s]读取数据:  87%|████████▋ | 6177752/7086503 [1:34:57<02:30, 6045.43it/s]读取数据:  87%|████████▋ | 6178377/7086503 [1:34:57<02:28, 6104.30it/s]读取数据:  87%|████████▋ | 6179031/7086503 [1:34:57<02:25, 6234.03it/s]读取数据:  87%|████████▋ | 6179655/7086503 [1:34:57<02:26, 6196.34it/s]读取数据:  87%|████████▋ | 6180305/7086503 [1:34:57<02:24, 6281.05it/s]读取数据:  87%|████████▋ | 6180958/7086503 [1:34:57<02:22, 6354.58it/s]读取数据:  87%|████████▋ | 6181606/7086503 [1:34:57<02:21, 6388.38it/s]读取数据:  87%|████████▋ | 6182245/7086503 [1:34:58<02:23, 6315.88it/s]读取数据:  87%|████████▋ | 6182884/7086503 [1:34:58<02:22, 6335.93it/s]读取数据:  87%|████████▋ | 6183526/7086503 [1:34:58<02:21, 6360.12it/s]读取数据:  87%|████████▋ | 6184169/7086503 [1:34:58<02:21, 6379.63it/s]读取数据:  87%|████████▋ | 6184863/7086503 [1:34:58<02:17, 6546.26it/s]读取数据:  87%|████████▋ | 6185578/7086503 [1:34:58<02:13, 6725.90it/s]读取数据:  87%|████████▋ | 6186287/7086503 [1:34:58<02:11, 6830.10it/s]读取数据:  87%|████████▋ | 6187006/7086503 [1:34:58<02:09, 6935.06it/s]读取数据:  87%|████████▋ | 6187727/7086503 [1:34:58<02:08, 7017.10it/s]读取数据:  87%|████████▋ | 6188429/7086503 [1:34:58<02:08, 6970.62it/s]读取数据:  87%|████████▋ | 6189200/7086503 [1:34:59<02:04, 7190.86it/s]读取数据:  87%|████████▋ | 6189956/7086503 [1:34:59<02:02, 7300.05it/s]读取数据:  87%|████████▋ | 6190756/7086503 [1:34:59<01:59, 7508.50it/s]读取数据:  87%|████████▋ | 6191554/7086503 [1:34:59<01:57, 7648.79it/s]读取数据:  87%|████████▋ | 6192327/7086503 [1:34:59<01:56, 7672.72it/s]读取数据:  87%|████████▋ | 6193095/7086503 [1:34:59<02:02, 7271.93it/s]读取数据:  87%|████████▋ | 6193848/7086503 [1:34:59<02:01, 7345.59it/s]读取数据:  87%|████████▋ | 6194635/7086503 [1:34:59<01:59, 7494.66it/s]读取数据:  87%|████████▋ | 6195451/7086503 [1:34:59<01:56, 7678.21it/s]读取数据:  87%|████████▋ | 6196291/7086503 [1:34:59<01:52, 7883.32it/s]读取数据:  87%|████████▋ | 6197082/7086503 [1:35:00<01:53, 7861.76it/s]读取数据:  87%|████████▋ | 6197960/7086503 [1:35:00<01:49, 8133.62it/s]读取数据:  87%|████████▋ | 6198952/7086503 [1:35:00<01:42, 8664.34it/s]读取数据:  87%|████████▋ | 6199863/7086503 [1:35:00<01:40, 8789.69it/s]读取数据:  88%|████████▊ | 6200743/7086503 [1:35:01<06:44, 2191.81it/s]读取数据:  88%|████████▊ | 6201383/7086503 [1:35:01<05:47, 2546.98it/s]读取数据:  88%|████████▊ | 6201991/7086503 [1:35:01<05:07, 2879.75it/s]读取数据:  88%|████████▊ | 6202562/7086503 [1:35:01<04:36, 3201.19it/s]读取数据:  88%|████████▊ | 6203108/7086503 [1:35:01<04:12, 3492.51it/s]读取数据:  88%|████████▊ | 6203634/7086503 [1:35:02<03:54, 3761.62it/s]读取数据:  88%|████████▊ | 6204147/7086503 [1:35:02<03:42, 3971.38it/s]读取数据:  88%|████████▊ | 6204648/7086503 [1:35:02<03:34, 4114.89it/s]读取数据:  88%|████████▊ | 6205136/7086503 [1:35:02<03:26, 4272.07it/s]读取数据:  88%|████████▊ | 6205620/7086503 [1:35:02<03:21, 4365.28it/s]读取数据:  88%|████████▊ | 6206098/7086503 [1:35:02<03:18, 4443.33it/s]读取数据:  88%|████████▊ | 6206572/7086503 [1:35:02<03:15, 4503.43it/s]读取数据:  88%|████████▊ | 6207060/7086503 [1:35:02<03:10, 4607.33it/s]读取数据:  88%|████████▊ | 6207539/7086503 [1:35:02<03:08, 4657.70it/s]读取数据:  88%|████████▊ | 6208024/7086503 [1:35:03<03:06, 4712.09it/s]读取数据:  88%|████████▊ | 6208536/7086503 [1:35:03<03:02, 4820.52it/s]读取数据:  88%|████████▊ | 6209034/7086503 [1:35:03<03:00, 4862.61it/s]读取数据:  88%|████████▊ | 6209525/7086503 [1:35:03<03:01, 4828.43it/s]读取数据:  88%|████████▊ | 6210048/7086503 [1:35:03<02:57, 4944.23it/s]读取数据:  88%|████████▊ | 6210559/7086503 [1:35:03<02:55, 4993.05it/s]读取数据:  88%|████████▊ | 6211060/7086503 [1:35:03<02:56, 4962.90it/s]读取数据:  88%|████████▊ | 6211601/7086503 [1:35:03<02:51, 5093.11it/s]读取数据:  88%|████████▊ | 6212112/7086503 [1:35:03<02:52, 5080.25it/s]读取数据:  88%|████████▊ | 6212626/7086503 [1:35:03<02:51, 5097.90it/s]读取数据:  88%|████████▊ | 6213137/7086503 [1:35:04<02:53, 5026.41it/s]读取数据:  88%|████████▊ | 6213658/7086503 [1:35:04<02:51, 5077.52it/s]读取数据:  88%|████████▊ | 6214167/7086503 [1:35:04<02:54, 5011.14it/s]读取数据:  88%|████████▊ | 6214699/7086503 [1:35:04<02:50, 5099.64it/s]读取数据:  88%|████████▊ | 6215212/7086503 [1:35:04<02:50, 5108.56it/s]读取数据:  88%|████████▊ | 6215759/7086503 [1:35:04<02:46, 5215.54it/s]读取数据:  88%|████████▊ | 6216295/7086503 [1:35:04<02:45, 5255.58it/s]读取数据:  88%|████████▊ | 6216835/7086503 [1:35:04<02:44, 5297.47it/s]读取数据:  88%|████████▊ | 6217365/7086503 [1:35:04<02:55, 4951.55it/s]读取数据:  88%|████████▊ | 6217886/7086503 [1:35:04<02:52, 5023.39it/s]读取数据:  88%|████████▊ | 6218432/7086503 [1:35:05<02:48, 5144.22it/s]读取数据:  88%|████████▊ | 6218979/7086503 [1:35:05<02:45, 5238.64it/s]读取数据:  88%|████████▊ | 6219544/7086503 [1:35:05<02:41, 5357.63it/s]读取数据:  88%|████████▊ | 6220082/7086503 [1:35:05<02:41, 5360.11it/s]读取数据:  88%|████████▊ | 6220645/7086503 [1:35:05<02:39, 5435.75it/s]读取数据:  88%|████████▊ | 6221194/7086503 [1:35:05<02:38, 5451.09it/s]读取数据:  88%|████████▊ | 6221777/7086503 [1:35:05<02:35, 5561.69it/s]读取数据:  88%|████████▊ | 6222348/7086503 [1:35:05<02:34, 5601.78it/s]读取数据:  88%|████████▊ | 6222910/7086503 [1:35:05<02:34, 5604.94it/s]读取数据:  88%|████████▊ | 6223502/7086503 [1:35:05<02:31, 5689.74it/s]读取数据:  88%|████████▊ | 6224098/7086503 [1:35:06<02:29, 5768.55it/s]读取数据:  88%|████████▊ | 6224722/7086503 [1:35:06<02:25, 5906.49it/s]读取数据:  88%|████████▊ | 6225338/7086503 [1:35:06<02:23, 5981.38it/s]读取数据:  88%|████████▊ | 6225945/7086503 [1:35:06<02:23, 6002.01it/s]读取数据:  88%|████████▊ | 6226551/7086503 [1:35:06<02:22, 6016.50it/s]读取数据:  88%|████████▊ | 6227180/7086503 [1:35:06<02:20, 6098.00it/s]读取数据:  88%|████████▊ | 6227790/7086503 [1:35:06<02:21, 6073.11it/s]读取数据:  88%|████████▊ | 6228400/7086503 [1:35:06<02:21, 6074.97it/s]读取数据:  88%|████████▊ | 6229012/7086503 [1:35:06<02:20, 6085.78it/s]读取数据:  88%|████████▊ | 6229684/7086503 [1:35:06<02:16, 6275.24it/s]读取数据:  88%|████████▊ | 6230312/7086503 [1:35:07<02:17, 6232.07it/s]读取数据:  88%|████████▊ | 6230950/7086503 [1:35:07<02:16, 6274.86it/s]读取数据:  88%|████████▊ | 6231584/7086503 [1:35:07<02:15, 6292.59it/s]读取数据:  88%|████████▊ | 6232246/7086503 [1:35:07<02:13, 6389.32it/s]读取数据:  88%|████████▊ | 6232918/7086503 [1:35:07<02:11, 6486.44it/s]读取数据:  88%|████████▊ | 6233588/7086503 [1:35:07<02:10, 6548.91it/s]读取数据:  88%|████████▊ | 6234270/7086503 [1:35:07<02:08, 6626.70it/s]读取数据:  88%|████████▊ | 6234975/7086503 [1:35:07<02:06, 6743.21it/s]读取数据:  88%|████████▊ | 6235660/7086503 [1:35:07<02:05, 6774.99it/s]读取数据:  88%|████████▊ | 6236379/7086503 [1:35:07<02:03, 6894.35it/s]读取数据:  88%|████████▊ | 6237069/7086503 [1:35:08<02:03, 6878.31it/s]读取数据:  88%|████████▊ | 6237787/7086503 [1:35:08<02:01, 6967.65it/s]读取数据:  88%|████████▊ | 6238515/7086503 [1:35:08<02:00, 7059.54it/s]读取数据:  88%|████████▊ | 6239278/7086503 [1:35:08<01:57, 7229.53it/s]读取数据:  88%|████████▊ | 6240033/7086503 [1:35:08<01:55, 7322.25it/s]读取数据:  88%|████████▊ | 6240834/7086503 [1:35:08<01:52, 7527.58it/s]读取数据:  88%|████████▊ | 6241631/7086503 [1:35:08<01:50, 7659.20it/s]读取数据:  88%|████████▊ | 6242489/7086503 [1:35:08<01:46, 7931.87it/s]读取数据:  88%|████████▊ | 6243381/7086503 [1:35:08<01:42, 8224.03it/s]读取数据:  88%|████████▊ | 6244277/7086503 [1:35:08<01:39, 8443.98it/s]读取数据:  88%|████████▊ | 6245182/7086503 [1:35:09<01:37, 8625.07it/s]读取数据:  88%|████████▊ | 6246156/7086503 [1:35:09<01:33, 8958.67it/s]读取数据:  88%|████████▊ | 6247146/7086503 [1:35:09<01:30, 9238.24it/s]读取数据:  88%|████████▊ | 6248190/7086503 [1:35:09<01:27, 9593.67it/s]读取数据:  88%|████████▊ | 6249205/7086503 [1:35:09<01:25, 9757.49it/s]读取数据:  88%|████████▊ | 6250181/7086503 [1:35:10<05:33, 2507.12it/s]读取数据:  88%|████████▊ | 6250892/7086503 [1:35:10<04:56, 2813.64it/s]读取数据:  88%|████████▊ | 6251529/7086503 [1:35:10<04:28, 3108.71it/s]读取数据:  88%|████████▊ | 6252117/7086503 [1:35:10<04:06, 3384.55it/s]读取数据:  88%|████████▊ | 6252671/7086503 [1:35:11<03:47, 3663.66it/s]读取数据:  88%|████████▊ | 6253208/7086503 [1:35:11<03:33, 3909.33it/s]读取数据:  88%|████████▊ | 6253731/7086503 [1:35:11<03:19, 4178.48it/s]读取数据:  88%|████████▊ | 6254253/7086503 [1:35:11<03:10, 4364.10it/s]读取数据:  88%|████████▊ | 6254768/7086503 [1:35:11<03:02, 4554.31it/s]读取数据:  88%|████████▊ | 6255323/7086503 [1:35:11<02:52, 4810.40it/s]读取数据:  88%|████████▊ | 6255850/7086503 [1:35:11<04:00, 3456.00it/s]读取数据:  88%|████████▊ | 6256280/7086503 [1:35:11<04:06, 3373.66it/s]读取数据:  88%|████████▊ | 6256770/7086503 [1:35:12<03:43, 3707.86it/s]读取数据:  88%|████████▊ | 6257194/7086503 [1:35:12<04:24, 3131.48it/s]读取数据:  88%|████████▊ | 6257692/7086503 [1:35:12<03:54, 3533.64it/s]读取数据:  88%|████████▊ | 6258228/7086503 [1:35:12<03:28, 3965.85it/s]读取数据:  88%|████████▊ | 6258730/7086503 [1:35:12<03:15, 4231.22it/s]读取数据:  88%|████████▊ | 6259227/7086503 [1:35:12<03:06, 4427.25it/s]读取数据:  88%|████████▊ | 6259747/7086503 [1:35:12<02:58, 4639.34it/s]读取数据:  88%|████████▊ | 6260269/7086503 [1:35:12<02:52, 4800.32it/s]读取数据:  88%|████████▊ | 6260766/7086503 [1:35:12<02:51, 4828.57it/s]读取数据:  88%|████████▊ | 6261261/7086503 [1:35:13<02:49, 4855.37it/s]读取数据:  88%|████████▊ | 6261811/7086503 [1:35:13<02:43, 5042.58it/s]读取数据:  88%|████████▊ | 6262322/7086503 [1:35:13<02:48, 4897.67it/s]读取数据:  88%|████████▊ | 6262829/7086503 [1:35:13<02:46, 4946.23it/s]读取数据:  88%|████████▊ | 6263370/7086503 [1:35:13<02:41, 5081.55it/s]读取数据:  88%|████████▊ | 6263882/7086503 [1:35:13<02:55, 4681.74it/s]读取数据:  88%|████████▊ | 6264381/7086503 [1:35:13<02:52, 4765.94it/s]读取数据:  88%|████████▊ | 6264878/7086503 [1:35:13<02:50, 4824.03it/s]读取数据:  88%|████████▊ | 6265410/7086503 [1:35:13<02:45, 4967.20it/s]读取数据:  88%|████████▊ | 6265911/7086503 [1:35:14<02:45, 4972.44it/s]读取数据:  88%|████████▊ | 6266411/7086503 [1:35:14<02:45, 4947.25it/s]读取数据:  88%|████████▊ | 6266931/7086503 [1:35:14<02:43, 5014.21it/s]读取数据:  88%|████████▊ | 6267467/7086503 [1:35:14<02:40, 5112.72it/s]读取数据:  88%|████████▊ | 6267981/7086503 [1:35:14<02:39, 5118.68it/s]读取数据:  88%|████████▊ | 6268514/7086503 [1:35:14<02:37, 5180.20it/s]读取数据:  88%|████████▊ | 6269058/7086503 [1:35:14<02:35, 5256.04it/s]读取数据:  88%|████████▊ | 6269600/7086503 [1:35:14<02:34, 5300.31it/s]读取数据:  88%|████████▊ | 6270131/7086503 [1:35:14<02:35, 5244.03it/s]读取数据:  88%|████████▊ | 6270656/7086503 [1:35:14<02:39, 5128.80it/s]读取数据:  88%|████████▊ | 6271224/7086503 [1:35:15<02:34, 5290.18it/s]读取数据:  89%|████████▊ | 6271756/7086503 [1:35:15<02:33, 5294.52it/s]读取数据:  89%|████████▊ | 6272287/7086503 [1:35:15<02:34, 5261.48it/s]读取数据:  89%|████████▊ | 6272876/7086503 [1:35:15<02:29, 5445.48it/s]读取数据:  89%|████████▊ | 6273433/7086503 [1:35:15<02:28, 5482.17it/s]读取数据:  89%|████████▊ | 6274042/7086503 [1:35:15<02:23, 5661.46it/s]读取数据:  89%|████████▊ | 6274609/7086503 [1:35:15<02:27, 5513.64it/s]读取数据:  89%|████████▊ | 6275163/7086503 [1:35:15<02:26, 5519.60it/s]读取数据:  89%|████████▊ | 6275771/7086503 [1:35:15<02:22, 5683.63it/s]读取数据:  89%|████████▊ | 6276406/7086503 [1:35:15<02:17, 5879.84it/s]读取数据:  89%|████████▊ | 6276995/7086503 [1:35:16<02:18, 5845.65it/s]读取数据:  89%|████████▊ | 6277611/7086503 [1:35:16<02:16, 5938.62it/s]读取数据:  89%|████████▊ | 6278206/7086503 [1:35:16<02:18, 5853.64it/s]读取数据:  89%|████████▊ | 6278815/7086503 [1:35:16<02:16, 5923.00it/s]读取数据:  89%|████████▊ | 6279408/7086503 [1:35:16<02:16, 5911.89it/s]读取数据:  89%|████████▊ | 6280028/7086503 [1:35:16<02:14, 5990.63it/s]读取数据:  89%|████████▊ | 6280628/7086503 [1:35:16<02:15, 5949.67it/s]读取数据:  89%|████████▊ | 6281270/7086503 [1:35:16<02:12, 6089.10it/s]读取数据:  89%|████████▊ | 6281883/7086503 [1:35:16<02:11, 6100.75it/s]读取数据:  89%|████████▊ | 6282494/7086503 [1:35:16<02:13, 6005.13it/s]读取数据:  89%|████████▊ | 6283180/7086503 [1:35:17<02:08, 6256.09it/s]读取数据:  89%|████████▊ | 6283830/7086503 [1:35:17<02:06, 6327.81it/s]读取数据:  89%|████████▊ | 6284485/7086503 [1:35:17<02:05, 6393.27it/s]读取数据:  89%|████████▊ | 6285149/7086503 [1:35:17<02:03, 6462.58it/s]读取数据:  89%|████████▊ | 6285866/7086503 [1:35:17<02:00, 6665.51it/s]读取数据:  89%|████████▊ | 6286581/7086503 [1:35:17<01:57, 6809.66it/s]读取数据:  89%|████████▊ | 6287263/7086503 [1:35:17<02:01, 6585.86it/s]读取数据:  89%|████████▊ | 6287944/7086503 [1:35:17<02:00, 6648.53it/s]读取数据:  89%|████████▊ | 6288679/7086503 [1:35:17<01:56, 6848.26it/s]读取数据:  89%|████████▉ | 6289395/7086503 [1:35:17<01:55, 6930.58it/s]读取数据:  89%|████████▉ | 6290132/7086503 [1:35:18<01:52, 7055.92it/s]读取数据:  89%|████████▉ | 6290921/7086503 [1:35:18<01:48, 7303.53it/s]读取数据:  89%|████████▉ | 6291689/7086503 [1:35:18<01:47, 7414.49it/s]读取数据:  89%|████████▉ | 6292453/7086503 [1:35:18<01:46, 7481.49it/s]读取数据:  89%|████████▉ | 6293298/7086503 [1:35:18<01:42, 7767.12it/s]读取数据:  89%|████████▉ | 6294142/7086503 [1:35:18<01:39, 7965.27it/s]读取数据:  89%|████████▉ | 6294964/7086503 [1:35:18<01:38, 8036.36it/s]读取数据:  89%|████████▉ | 6295810/7086503 [1:35:18<01:36, 8162.06it/s]读取数据:  89%|████████▉ | 6296680/7086503 [1:35:18<01:35, 8310.86it/s]读取数据:  89%|████████▉ | 6297512/7086503 [1:35:18<01:35, 8254.73it/s]读取数据:  89%|████████▉ | 6298384/7086503 [1:35:19<01:33, 8392.62it/s]读取数据:  89%|████████▉ | 6299303/7086503 [1:35:19<01:31, 8630.23it/s]读取数据:  89%|████████▉ | 6300167/7086503 [1:35:20<07:58, 1642.64it/s]读取数据:  89%|████████▉ | 6300789/7086503 [1:35:20<06:42, 1952.15it/s]读取数据:  89%|████████▉ | 6301375/7086503 [1:35:20<05:45, 2270.10it/s]读取数据:  89%|████████▉ | 6301926/7086503 [1:35:21<05:01, 2599.28it/s]读取数据:  89%|████████▉ | 6302453/7086503 [1:35:21<04:27, 2930.85it/s]读取数据:  89%|████████▉ | 6302965/7086503 [1:35:21<03:59, 3273.39it/s]读取数据:  89%|████████▉ | 6303471/7086503 [1:35:21<03:37, 3593.29it/s]读取数据:  89%|████████▉ | 6303973/7086503 [1:35:21<03:21, 3878.95it/s]读取数据:  89%|████████▉ | 6304472/7086503 [1:35:21<03:09, 4124.90it/s]读取数据:  89%|████████▉ | 6304969/7086503 [1:35:21<03:45, 3469.73it/s]读取数据:  89%|████████▉ | 6305477/7086503 [1:35:21<03:24, 3825.48it/s]读取数据:  89%|████████▉ | 6305964/7086503 [1:35:21<03:11, 4074.06it/s]读取数据:  89%|████████▉ | 6306452/7086503 [1:35:22<03:02, 4274.01it/s]读取数据:  89%|████████▉ | 6306944/7086503 [1:35:22<02:55, 4446.43it/s]读取数据:  89%|████████▉ | 6307445/7086503 [1:35:22<02:49, 4601.73it/s]读取数据:  89%|████████▉ | 6307977/7086503 [1:35:22<02:42, 4804.04it/s]读取数据:  89%|████████▉ | 6308489/7086503 [1:35:22<02:39, 4892.77it/s]读取数据:  89%|████████▉ | 6309016/7086503 [1:35:22<02:35, 4999.49it/s]读取数据:  89%|████████▉ | 6309525/7086503 [1:35:22<02:36, 4949.94it/s]读取数据:  89%|████████▉ | 6310027/7086503 [1:35:22<02:38, 4905.45it/s]读取数据:  89%|████████▉ | 6310528/7086503 [1:35:22<02:37, 4927.60it/s]读取数据:  89%|████████▉ | 6311038/7086503 [1:35:22<02:35, 4976.38it/s]读取数据:  89%|████████▉ | 6311569/7086503 [1:35:23<02:32, 5073.03it/s]读取数据:  89%|████████▉ | 6312083/7086503 [1:35:23<02:32, 5088.94it/s]读取数据:  89%|████████▉ | 6312594/7086503 [1:35:23<02:38, 4888.51it/s]读取数据:  89%|████████▉ | 6313086/7086503 [1:35:23<02:48, 4593.90it/s]读取数据:  89%|████████▉ | 6313551/7086503 [1:35:23<02:51, 4515.78it/s]读取数据:  89%|████████▉ | 6314051/7086503 [1:35:23<02:46, 4651.86it/s]读取数据:  89%|████████▉ | 6314542/7086503 [1:35:23<02:43, 4721.01it/s]读取数据:  89%|████████▉ | 6315068/7086503 [1:35:23<02:38, 4876.59it/s]读取数据:  89%|████████▉ | 6315592/7086503 [1:35:23<02:34, 4976.94it/s]读取数据:  89%|████████▉ | 6316134/7086503 [1:35:24<02:30, 5106.26it/s]读取数据:  89%|████████▉ | 6316701/7086503 [1:35:24<02:26, 5272.15it/s]读取数据:  89%|████████▉ | 6317252/7086503 [1:35:24<02:23, 5342.56it/s]读取数据:  89%|████████▉ | 6317789/7086503 [1:35:24<02:23, 5345.81it/s]读取数据:  89%|████████▉ | 6318355/7086503 [1:35:24<02:21, 5438.76it/s]读取数据:  89%|████████▉ | 6318910/7086503 [1:35:24<02:20, 5465.80it/s]读取数据:  89%|████████▉ | 6319472/7086503 [1:35:24<02:19, 5511.03it/s]读取数据:  89%|████████▉ | 6320043/7086503 [1:35:24<02:17, 5568.85it/s]读取数据:  89%|████████▉ | 6320601/7086503 [1:35:24<02:17, 5558.13it/s]读取数据:  89%|████████▉ | 6321158/7086503 [1:35:24<02:17, 5561.36it/s]读取数据:  89%|████████▉ | 6321747/7086503 [1:35:25<02:15, 5655.08it/s]读取数据:  89%|████████▉ | 6322314/7086503 [1:35:25<02:15, 5658.15it/s]读取数据:  89%|████████▉ | 6322904/7086503 [1:35:25<02:13, 5727.99it/s]读取数据:  89%|████████▉ | 6323492/7086503 [1:35:25<02:12, 5771.91it/s]读取数据:  89%|████████▉ | 6324075/7086503 [1:35:25<02:12, 5768.78it/s]读取数据:  89%|████████▉ | 6324677/7086503 [1:35:25<02:10, 5841.32it/s]读取数据:  89%|████████▉ | 6325297/7086503 [1:35:25<02:08, 5943.93it/s]读取数据:  89%|████████▉ | 6325893/7086503 [1:35:25<02:07, 5943.43it/s]读取数据:  89%|████████▉ | 6326488/7086503 [1:35:25<02:16, 5566.96it/s]读取数据:  89%|████████▉ | 6327108/7086503 [1:35:25<02:12, 5747.45it/s]读取数据:  89%|████████▉ | 6327778/7086503 [1:35:26<02:05, 6022.39it/s]读取数据:  89%|████████▉ | 6328404/7086503 [1:35:26<02:04, 6090.36it/s]读取数据:  89%|████████▉ | 6329038/7086503 [1:35:26<02:02, 6163.75it/s]读取数据:  89%|████████▉ | 6329657/7086503 [1:35:26<02:04, 6076.41it/s]读取数据:  89%|████████▉ | 6330267/7086503 [1:35:26<02:04, 6065.71it/s]读取数据:  89%|████████▉ | 6330875/7086503 [1:35:26<02:04, 6048.65it/s]读取数据:  89%|████████▉ | 6331500/7086503 [1:35:26<02:03, 6100.73it/s]读取数据:  89%|████████▉ | 6332196/7086503 [1:35:26<01:58, 6355.79it/s]读取数据:  89%|████████▉ | 6332876/7086503 [1:35:26<01:56, 6482.97it/s]读取数据:  89%|████████▉ | 6333541/7086503 [1:35:26<01:55, 6531.70it/s]读取数据:  89%|████████▉ | 6334228/7086503 [1:35:27<01:53, 6632.61it/s]读取数据:  89%|████████▉ | 6334935/7086503 [1:35:27<01:51, 6760.70it/s]读取数据:  89%|████████▉ | 6335626/7086503 [1:35:27<01:50, 6804.11it/s]读取数据:  89%|████████▉ | 6336349/7086503 [1:35:27<01:48, 6929.43it/s]读取数据:  89%|████████▉ | 6337081/7086503 [1:35:27<01:46, 7043.32it/s]读取数据:  89%|████████▉ | 6337849/7086503 [1:35:27<01:43, 7231.79it/s]读取数据:  89%|████████▉ | 6338610/7086503 [1:35:27<01:41, 7341.23it/s]读取数据:  89%|████████▉ | 6339345/7086503 [1:35:27<01:42, 7290.78it/s]读取数据:  89%|████████▉ | 6340085/7086503 [1:35:27<01:41, 7323.05it/s]读取数据:  89%|████████▉ | 6340881/7086503 [1:35:27<01:39, 7511.53it/s]读取数据:  89%|████████▉ | 6341696/7086503 [1:35:28<01:36, 7701.23it/s]读取数据:  90%|████████▉ | 6342497/7086503 [1:35:28<01:35, 7788.78it/s]读取数据:  90%|████████▉ | 6343297/7086503 [1:35:28<01:34, 7849.33it/s]读取数据:  90%|████████▉ | 6344126/7086503 [1:35:28<01:33, 7979.93it/s]读取数据:  90%|████████▉ | 6344940/7086503 [1:35:28<01:32, 8026.57it/s]读取数据:  90%|████████▉ | 6345767/7086503 [1:35:28<01:31, 8098.01it/s]读取数据:  90%|████████▉ | 6346629/7086503 [1:35:28<01:29, 8251.80it/s]读取数据:  90%|████████▉ | 6347503/7086503 [1:35:28<01:28, 8396.71it/s]读取数据:  90%|████████▉ | 6348371/7086503 [1:35:28<01:27, 8479.48it/s]读取数据:  90%|████████▉ | 6349219/7086503 [1:35:28<01:28, 8303.93it/s]读取数据:  90%|████████▉ | 6350051/7086503 [1:35:29<05:21, 2292.98it/s]读取数据:  90%|████████▉ | 6350659/7086503 [1:35:30<04:39, 2631.36it/s]读取数据:  90%|████████▉ | 6351236/7086503 [1:35:30<04:08, 2962.05it/s]读取数据:  90%|████████▉ | 6351786/7086503 [1:35:30<03:41, 3316.39it/s]读取数据:  90%|████████▉ | 6352327/7086503 [1:35:30<03:23, 3611.78it/s]读取数据:  90%|████████▉ | 6352852/7086503 [1:35:30<03:08, 3898.77it/s]读取数据:  90%|████████▉ | 6353372/7086503 [1:35:30<02:55, 4182.57it/s]读取数据:  90%|████████▉ | 6353890/7086503 [1:35:30<02:47, 4372.72it/s]读取数据:  90%|████████▉ | 6354411/7086503 [1:35:30<02:39, 4582.98it/s]读取数据:  90%|████████▉ | 6354926/7086503 [1:35:30<02:38, 4612.36it/s]读取数据:  90%|████████▉ | 6355427/7086503 [1:35:31<02:44, 4457.05it/s]读取数据:  90%|████████▉ | 6355921/7086503 [1:35:31<02:39, 4581.65it/s]读取数据:  90%|████████▉ | 6356445/7086503 [1:35:31<02:33, 4762.14it/s]读取数据:  90%|████████▉ | 6356938/7086503 [1:35:31<02:33, 4756.81it/s]读取数据:  90%|████████▉ | 6357426/7086503 [1:35:31<02:33, 4756.94it/s]读取数据:  90%|████████▉ | 6357911/7086503 [1:35:31<02:32, 4782.41it/s]读取数据:  90%|████████▉ | 6358426/7086503 [1:35:31<02:29, 4884.41it/s]读取数据:  90%|████████▉ | 6358930/7086503 [1:35:31<02:27, 4929.51it/s]读取数据:  90%|████████▉ | 6359427/7086503 [1:35:31<02:35, 4664.19it/s]读取数据:  90%|████████▉ | 6359938/7086503 [1:35:31<02:31, 4790.33it/s]读取数据:  90%|████████▉ | 6360437/7086503 [1:35:32<02:29, 4847.83it/s]读取数据:  90%|████████▉ | 6360932/7086503 [1:35:32<02:28, 4876.43it/s]读取数据:  90%|████████▉ | 6361422/7086503 [1:35:32<02:28, 4882.71it/s]读取数据:  90%|████████▉ | 6361923/7086503 [1:35:32<02:27, 4916.74it/s]读取数据:  90%|████████▉ | 6362417/7086503 [1:35:32<02:27, 4919.15it/s]读取数据:  90%|████████▉ | 6362910/7086503 [1:35:32<02:27, 4920.66it/s]读取数据:  90%|████████▉ | 6363433/7086503 [1:35:32<02:24, 5012.39it/s]读取数据:  90%|████████▉ | 6363960/7086503 [1:35:32<02:22, 5086.70it/s]读取数据:  90%|████████▉ | 6364477/7086503 [1:35:32<02:21, 5111.10it/s]读取数据:  90%|████████▉ | 6364989/7086503 [1:35:32<02:21, 5107.75it/s]读取数据:  90%|████████▉ | 6365505/7086503 [1:35:33<02:20, 5122.90it/s]读取数据:  90%|████████▉ | 6366018/7086503 [1:35:33<02:23, 5038.10it/s]读取数据:  90%|████████▉ | 6366577/7086503 [1:35:33<02:18, 5199.57it/s]读取数据:  90%|████████▉ | 6367098/7086503 [1:35:33<02:20, 5135.97it/s]读取数据:  90%|████████▉ | 6367637/7086503 [1:35:33<02:17, 5210.43it/s]读取数据:  90%|████████▉ | 6368162/7086503 [1:35:33<02:17, 5215.10it/s]读取数据:  90%|████████▉ | 6368726/7086503 [1:35:33<02:14, 5341.17it/s]读取数据:  90%|████████▉ | 6369314/7086503 [1:35:33<02:10, 5500.15it/s]读取数据:  90%|████████▉ | 6369868/7086503 [1:35:33<02:10, 5510.65it/s]读取数据:  90%|████████▉ | 6370433/7086503 [1:35:34<02:12, 5400.28it/s]读取数据:  90%|████████▉ | 6370974/7086503 [1:35:34<02:16, 5241.71it/s]读取数据:  90%|████████▉ | 6371574/7086503 [1:35:34<02:10, 5460.81it/s]读取数据:  90%|████████▉ | 6372155/7086503 [1:35:34<02:08, 5562.51it/s]读取数据:  90%|████████▉ | 6372773/7086503 [1:35:34<02:04, 5742.94it/s]读取数据:  90%|████████▉ | 6373422/7086503 [1:35:34<01:59, 5960.86it/s]读取数据:  90%|████████▉ | 6374064/7086503 [1:35:34<01:56, 6093.42it/s]读取数据:  90%|████████▉ | 6374675/7086503 [1:35:34<01:58, 6017.30it/s]读取数据:  90%|████████▉ | 6375283/7086503 [1:35:34<01:57, 6027.43it/s]读取数据:  90%|████████▉ | 6375933/7086503 [1:35:34<01:55, 6166.60it/s]读取数据:  90%|████████▉ | 6376551/7086503 [1:35:35<01:56, 6113.31it/s]读取数据:  90%|████████▉ | 6377217/7086503 [1:35:35<01:53, 6270.98it/s]读取数据:  90%|█████████ | 6377871/7086503 [1:35:35<01:51, 6350.61it/s]读取数据:  90%|█████████ | 6378530/7086503 [1:35:35<01:50, 6421.01it/s]读取数据:  90%|█████████ | 6379215/7086503 [1:35:35<01:48, 6547.57it/s]读取数据:  90%|█████████ | 6379871/7086503 [1:35:35<01:47, 6546.28it/s]读取数据:  90%|█████████ | 6380526/7086503 [1:35:35<01:48, 6506.30it/s]读取数据:  90%|█████████ | 6381187/7086503 [1:35:35<01:47, 6531.59it/s]读取数据:  90%|█████████ | 6381841/7086503 [1:35:35<01:48, 6467.60it/s]读取数据:  90%|█████████ | 6382488/7086503 [1:35:35<01:50, 6385.86it/s]读取数据:  90%|█████████ | 6383150/7086503 [1:35:36<01:49, 6452.37it/s]读取数据:  90%|█████████ | 6383796/7086503 [1:35:36<01:50, 6349.30it/s]读取数据:  90%|█████████ | 6384454/7086503 [1:35:36<01:49, 6412.43it/s]读取数据:  90%|█████████ | 6385108/7086503 [1:35:36<01:48, 6445.98it/s]读取数据:  90%|█████████ | 6385809/7086503 [1:35:36<01:46, 6607.82it/s]读取数据:  90%|█████████ | 6386471/7086503 [1:35:36<01:46, 6592.84it/s]读取数据:  90%|█████████ | 6387131/7086503 [1:35:36<01:52, 6218.91it/s]读取数据:  90%|█████████ | 6387758/7086503 [1:35:36<01:53, 6176.20it/s]读取数据:  90%|█████████ | 6388379/7086503 [1:35:36<01:53, 6175.25it/s]读取数据:  90%|█████████ | 6389003/7086503 [1:35:36<01:52, 6193.46it/s]读取数据:  90%|█████████ | 6389624/7086503 [1:35:37<01:52, 6194.31it/s]读取数据:  90%|█████████ | 6390268/7086503 [1:35:37<01:51, 6266.48it/s]读取数据:  90%|█████████ | 6390896/7086503 [1:35:37<01:52, 6193.39it/s]读取数据:  90%|█████████ | 6391545/7086503 [1:35:37<01:50, 6277.55it/s]读取数据:  90%|█████████ | 6392189/7086503 [1:35:37<01:49, 6324.66it/s]读取数据:  90%|█████████ | 6392836/7086503 [1:35:37<01:48, 6364.15it/s]读取数据:  90%|█████████ | 6393505/7086503 [1:35:37<01:47, 6459.81it/s]读取数据:  90%|█████████ | 6394199/7086503 [1:35:37<01:44, 6603.09it/s]读取数据:  90%|█████████ | 6394860/7086503 [1:35:37<01:45, 6563.76it/s]读取数据:  90%|█████████ | 6395517/7086503 [1:35:38<01:56, 5927.65it/s]读取数据:  90%|█████████ | 6396167/7086503 [1:35:38<01:53, 6083.11it/s]读取数据:  90%|█████████ | 6396785/7086503 [1:35:38<01:53, 6093.52it/s]读取数据:  90%|█████████ | 6397405/7086503 [1:35:38<01:52, 6115.72it/s]读取数据:  90%|█████████ | 6398088/7086503 [1:35:38<01:49, 6314.72it/s]读取数据:  90%|█████████ | 6398724/7086503 [1:35:38<01:49, 6269.80it/s]读取数据:  90%|█████████ | 6399431/7086503 [1:35:38<01:45, 6492.39it/s]读取数据:  90%|█████████ | 6400083/7086503 [1:35:39<05:58, 1912.72it/s]读取数据:  90%|█████████ | 6400665/7086503 [1:35:39<04:52, 2343.76it/s]读取数据:  90%|█████████ | 6401252/7086503 [1:35:39<04:02, 2823.53it/s]读取数据:  90%|█████████ | 6401860/7086503 [1:35:39<03:24, 3353.71it/s]读取数据:  90%|█████████ | 6402458/7086503 [1:35:39<02:57, 3849.24it/s]读取数据:  90%|█████████ | 6403049/7086503 [1:35:40<02:39, 4286.55it/s]读取数据:  90%|█████████ | 6403639/7086503 [1:35:40<02:26, 4661.65it/s]读取数据:  90%|█████████ | 6404244/7086503 [1:35:40<02:16, 5007.07it/s]读取数据:  90%|█████████ | 6404831/7086503 [1:35:40<02:11, 5195.82it/s]读取数据:  90%|█████████ | 6405414/7086503 [1:35:40<02:07, 5353.84it/s]读取数据:  90%|█████████ | 6406001/7086503 [1:35:40<02:03, 5494.19it/s]读取数据:  90%|█████████ | 6406584/7086503 [1:35:40<02:02, 5528.88it/s]读取数据:  90%|█████████ | 6407190/7086503 [1:35:40<01:59, 5680.59it/s]读取数据:  90%|█████████ | 6407775/7086503 [1:35:40<01:59, 5683.38it/s]读取数据:  90%|█████████ | 6408376/7086503 [1:35:40<01:57, 5763.72it/s]读取数据:  90%|█████████ | 6408961/7086503 [1:35:41<01:59, 5672.98it/s]读取数据:  90%|█████████ | 6409544/7086503 [1:35:41<01:58, 5717.27it/s]读取数据:  90%|█████████ | 6410202/7086503 [1:35:41<01:53, 5969.83it/s]读取数据:  90%|█████████ | 6410856/7086503 [1:35:41<01:50, 6137.86it/s]读取数据:  90%|█████████ | 6411587/7086503 [1:35:41<01:44, 6485.18it/s]读取数据:  90%|█████████ | 6412238/7086503 [1:35:41<01:45, 6367.31it/s]读取数据:  90%|█████████ | 6412877/7086503 [1:35:41<01:46, 6309.55it/s]读取数据:  91%|█████████ | 6413515/7086503 [1:35:41<01:46, 6330.11it/s]读取数据:  91%|█████████ | 6414165/7086503 [1:35:41<01:45, 6378.34it/s]读取数据:  91%|█████████ | 6414868/7086503 [1:35:41<01:42, 6571.75it/s]读取数据:  91%|█████████ | 6415537/7086503 [1:35:42<01:41, 6601.86it/s]读取数据:  91%|█████████ | 6416198/7086503 [1:35:42<01:41, 6578.09it/s]读取数据:  91%|█████████ | 6416857/7086503 [1:35:42<01:44, 6435.16it/s]读取数据:  91%|█████████ | 6417502/7086503 [1:35:42<01:45, 6349.68it/s]读取数据:  91%|█████████ | 6418148/7086503 [1:35:42<01:44, 6380.10it/s]读取数据:  91%|█████████ | 6418794/7086503 [1:35:42<01:44, 6399.88it/s]读取数据:  91%|█████████ | 6419446/7086503 [1:35:42<01:43, 6427.11it/s]读取数据:  91%|█████████ | 6420124/7086503 [1:35:42<01:42, 6531.84it/s]读取数据:  91%|█████████ | 6420836/7086503 [1:35:42<01:39, 6706.42it/s]读取数据:  91%|█████████ | 6421507/7086503 [1:35:42<01:40, 6613.72it/s]读取数据:  91%|█████████ | 6422203/7086503 [1:35:43<01:39, 6707.61it/s]读取数据:  91%|█████████ | 6422912/7086503 [1:35:43<01:37, 6817.88it/s]读取数据:  91%|█████████ | 6423629/7086503 [1:35:43<01:35, 6920.26it/s]读取数据:  91%|█████████ | 6424322/7086503 [1:35:43<01:36, 6894.15it/s]读取数据:  91%|█████████ | 6425049/7086503 [1:35:43<01:34, 7005.74it/s]读取数据:  91%|█████████ | 6425750/7086503 [1:35:43<01:34, 6963.37it/s]读取数据:  91%|█████████ | 6426449/7086503 [1:35:43<01:34, 6971.02it/s]读取数据:  91%|█████████ | 6427147/7086503 [1:35:43<01:35, 6889.70it/s]读取数据:  91%|█████████ | 6427889/7086503 [1:35:43<01:33, 7045.45it/s]读取数据:  91%|█████████ | 6428594/7086503 [1:35:43<01:33, 7007.66it/s]读取数据:  91%|█████████ | 6429311/7086503 [1:35:44<01:33, 7053.94it/s]读取数据:  91%|█████████ | 6430118/7086503 [1:35:44<01:29, 7354.92it/s]读取数据:  91%|█████████ | 6430854/7086503 [1:35:44<01:31, 7193.82it/s]读取数据:  91%|█████████ | 6431575/7086503 [1:35:44<01:33, 7036.05it/s]读取数据:  91%|█████████ | 6432280/7086503 [1:35:44<01:33, 6990.80it/s]读取数据:  91%|█████████ | 6432982/7086503 [1:35:44<01:33, 6990.61it/s]读取数据:  91%|█████████ | 6433682/7086503 [1:35:44<01:36, 6794.03it/s]读取数据:  91%|█████████ | 6434363/7086503 [1:35:44<01:37, 6716.68it/s]读取数据:  91%|█████████ | 6435042/7086503 [1:35:44<01:41, 6407.82it/s]读取数据:  91%|█████████ | 6435741/7086503 [1:35:45<01:39, 6570.76it/s]读取数据:  91%|█████████ | 6436490/7086503 [1:35:45<01:35, 6830.50it/s]读取数据:  91%|█████████ | 6437177/7086503 [1:35:45<01:36, 6723.56it/s]读取数据:  91%|█████████ | 6437853/7086503 [1:35:45<01:36, 6733.95it/s]读取数据:  91%|█████████ | 6438580/7086503 [1:35:45<01:34, 6890.69it/s]读取数据:  91%|█████████ | 6439323/7086503 [1:35:45<01:31, 7045.42it/s]读取数据:  91%|█████████ | 6440833/7086503 [1:35:45<01:08, 9432.64it/s]读取数据:  91%|█████████ | 6442271/7086503 [1:35:45<00:59, 10902.90it/s]读取数据:  91%|█████████ | 6443493/7086503 [1:35:45<00:56, 11285.52it/s]读取数据:  91%|█████████ | 6444957/7086503 [1:35:45<00:52, 12286.69it/s]读取数据:  91%|█████████ | 6446420/7086503 [1:35:46<00:49, 12986.62it/s]读取数据:  91%|█████████ | 6447721/7086503 [1:35:46<00:52, 12088.82it/s]读取数据:  91%|█████████ | 6448944/7086503 [1:35:46<01:00, 10466.34it/s]读取数据:  91%|█████████ | 6450036/7086503 [1:35:47<03:02, 3481.05it/s] 读取数据:  91%|█████████ | 6450837/7086503 [1:35:47<02:42, 3904.78it/s]读取数据:  91%|█████████ | 6451605/7086503 [1:35:47<02:28, 4262.49it/s]读取数据:  91%|█████████ | 6452327/7086503 [1:35:47<02:19, 4562.31it/s]读取数据:  91%|█████████ | 6453009/7086503 [1:35:47<02:11, 4805.47it/s]读取数据:  91%|█████████ | 6453660/7086503 [1:35:47<02:04, 5087.14it/s]读取数据:  91%|█████████ | 6454301/7086503 [1:35:47<01:59, 5305.03it/s]读取数据:  91%|█████████ | 6454931/7086503 [1:35:48<01:54, 5513.31it/s]读取数据:  91%|█████████ | 6455558/7086503 [1:35:48<01:51, 5649.17it/s]读取数据:  91%|█████████ | 6456198/7086503 [1:35:48<01:47, 5837.38it/s]读取数据:  91%|█████████ | 6456829/7086503 [1:35:48<01:45, 5964.44it/s]读取数据:  91%|█████████ | 6457456/7086503 [1:35:48<01:45, 5940.79it/s]读取数据:  91%|█████████ | 6458072/7086503 [1:35:49<04:49, 2174.17it/s]读取数据:  91%|█████████ | 6458529/7086503 [1:35:49<05:42, 1831.23it/s]读取数据:  91%|█████████ | 6458885/7086503 [1:35:49<06:16, 1665.14it/s]读取数据:  91%|█████████ | 6459171/7086503 [1:35:50<08:25, 1241.01it/s]读取数据:  91%|█████████ | 6459390/7086503 [1:35:50<08:17, 1260.81it/s]读取数据:  91%|█████████ | 6459612/7086503 [1:35:50<07:34, 1378.89it/s]读取数据:  91%|█████████ | 6459814/7086503 [1:35:51<14:08, 738.82it/s] 读取数据:  91%|█████████ | 6459964/7086503 [1:35:51<13:59, 746.67it/s]读取数据:  91%|█████████ | 6460092/7086503 [1:35:51<13:47, 757.01it/s]读取数据:  91%|█████████ | 6460227/7086503 [1:35:51<12:44, 819.30it/s]读取数据:  91%|█████████ | 6460342/7086503 [1:35:52<14:36, 714.13it/s]读取数据:  91%|█████████ | 6460437/7086503 [1:35:52<13:54, 750.20it/s]读取数据:  91%|█████████ | 6460532/7086503 [1:35:52<15:23, 677.87it/s]读取数据:  91%|█████████ | 6460663/7086503 [1:35:52<13:13, 788.58it/s]读取数据:  91%|█████████ | 6460759/7086503 [1:35:52<13:16, 785.61it/s]读取数据:  91%|█████████ | 6460896/7086503 [1:35:52<11:25, 912.34it/s]读取数据:  91%|█████████ | 6461000/7086503 [1:35:52<11:57, 871.95it/s]读取数据:  91%|█████████ | 6461127/7086503 [1:35:52<11:57, 871.80it/s]读取数据:  91%|█████████ | 6461228/7086503 [1:35:53<14:18, 728.24it/s]读取数据:  91%|█████████ | 6461354/7086503 [1:35:53<12:23, 840.99it/s]读取数据:  91%|█████████ | 6461490/7086503 [1:35:53<10:50, 961.22it/s]读取数据:  91%|█████████ | 6461623/7086503 [1:35:53<09:55, 1050.01it/s]读取数据:  91%|█████████ | 6461737/7086503 [1:35:53<10:16, 1013.73it/s]读取数据:  91%|█████████ | 6461857/7086503 [1:35:53<09:48, 1062.04it/s]读取数据:  91%|█████████ | 6461969/7086503 [1:35:53<14:35, 713.55it/s] 读取数据:  91%|█████████ | 6462059/7086503 [1:35:54<14:08, 735.98it/s]读取数据:  91%|█████████ | 6462165/7086503 [1:35:54<15:36, 666.36it/s]读取数据:  91%|█████████ | 6462243/7086503 [1:35:54<17:10, 605.53it/s]读取数据:  91%|█████████ | 6462415/7086503 [1:35:54<12:55, 804.96it/s]读取数据:  91%|█████████ | 6462564/7086503 [1:35:54<11:20, 917.21it/s]读取数据:  91%|█████████ | 6462775/7086503 [1:35:54<08:42, 1194.53it/s]读取数据:  91%|█████████ | 6462910/7086503 [1:35:54<09:15, 1122.73it/s]读取数据:  91%|█████████ | 6463060/7086503 [1:35:55<10:03, 1033.65it/s]读取数据:  91%|█████████ | 6463173/7086503 [1:35:55<10:22, 1001.23it/s]读取数据:  91%|█████████ | 6463279/7086503 [1:35:55<10:43, 968.92it/s] 读取数据:  91%|█████████ | 6463431/7086503 [1:35:55<09:33, 1086.09it/s]读取数据:  91%|█████████ | 6463545/7086503 [1:35:55<12:40, 819.58it/s] 读取数据:  91%|█████████ | 6463639/7086503 [1:35:55<15:30, 669.68it/s]读取数据:  91%|█████████ | 6463830/7086503 [1:35:56<13:24, 774.45it/s]读取数据:  91%|█████████ | 6463996/7086503 [1:35:56<11:00, 942.84it/s]读取数据:  91%|█████████ | 6464482/7086503 [1:35:56<05:48, 1782.92it/s]读取数据:  91%|█████████ | 6464960/7086503 [1:35:56<04:10, 2485.71it/s]读取数据:  91%|█████████ | 6465394/7086503 [1:35:56<03:30, 2950.44it/s]读取数据:  91%|█████████ | 6465734/7086503 [1:35:56<04:20, 2383.95it/s]读取数据:  91%|█████████▏| 6466848/7086503 [1:35:56<02:21, 4366.77it/s]读取数据:  91%|█████████▏| 6467519/7086503 [1:35:56<02:10, 4728.54it/s]读取数据:  91%|█████████▏| 6468064/7086503 [1:36:01<26:57, 382.34it/s] 读取数据:  91%|█████████▏| 6468449/7086503 [1:36:05<41:09, 250.29it/s]读取数据:  91%|█████████▏| 6468722/7086503 [1:36:05<38:53, 264.71it/s]读取数据:  91%|█████████▏| 6468927/7086503 [1:36:06<33:27, 307.68it/s]读取数据:  91%|█████████▏| 6469163/7086503 [1:36:06<28:09, 365.39it/s]读取数据:  91%|█████████▏| 6469337/7086503 [1:36:06<24:12, 424.98it/s]读取数据:  91%|█████████▏| 6469549/7086503 [1:36:06<19:32, 526.24it/s]读取数据:  91%|█████████▏| 6469731/7086503 [1:36:06<17:31, 586.63it/s]读取数据:  91%|█████████▏| 6469888/7086503 [1:36:06<16:55, 606.98it/s]读取数据:  91%|█████████▏| 6470021/7086503 [1:36:07<16:37, 618.30it/s]读取数据:  91%|█████████▏| 6470143/7086503 [1:36:07<15:25, 665.81it/s]读取数据:  91%|█████████▏| 6470275/7086503 [1:36:07<13:30, 759.91it/s]读取数据:  91%|█████████▏| 6470389/7086503 [1:36:07<12:32, 818.28it/s]读取数据:  91%|█████████▏| 6470502/7086503 [1:36:07<11:57, 858.33it/s]读取数据:  91%|█████████▏| 6470611/7086503 [1:36:07<13:05, 784.12it/s]读取数据:  91%|█████████▏| 6470733/7086503 [1:36:07<11:45, 872.46it/s]读取数据:  91%|█████████▏| 6470854/7086503 [1:36:07<10:49, 948.06it/s]读取数据:  91%|█████████▏| 6471050/7086503 [1:36:07<09:08, 1121.99it/s]读取数据:  91%|█████████▏| 6471172/7086503 [1:36:08<08:58, 1142.11it/s]读取数据:  91%|█████████▏| 6471294/7086503 [1:36:08<10:05, 1015.57it/s]读取数据:  91%|█████████▏| 6471489/7086503 [1:36:08<08:14, 1243.79it/s]读取数据:  91%|█████████▏| 6471624/7086503 [1:36:08<08:14, 1243.16it/s]读取数据:  91%|█████████▏| 6471756/7086503 [1:36:08<09:22, 1093.10it/s]读取数据:  91%|█████████▏| 6471911/7086503 [1:36:08<08:30, 1204.39it/s]读取数据:  91%|█████████▏| 6472053/7086503 [1:36:08<08:08, 1258.59it/s]读取数据:  91%|█████████▏| 6472241/7086503 [1:36:09<09:03, 1129.78it/s]读取数据:  91%|█████████▏| 6472389/7086503 [1:36:09<10:21, 988.58it/s] 读取数据:  91%|█████████▏| 6472498/7086503 [1:36:09<10:43, 954.06it/s]读取数据:  91%|█████████▏| 6472599/7086503 [1:36:09<14:57, 684.15it/s]读取数据:  91%|█████████▏| 6472681/7086503 [1:36:09<14:40, 697.40it/s]读取数据:  91%|█████████▏| 6472793/7086503 [1:36:09<13:02, 784.46it/s]读取数据:  91%|█████████▏| 6472907/7086503 [1:36:09<12:59, 787.62it/s]读取数据:  91%|█████████▏| 6473019/7086503 [1:36:10<13:58, 731.49it/s]读取数据:  91%|█████████▏| 6473160/7086503 [1:36:10<12:49, 796.73it/s]读取数据:  91%|█████████▏| 6473299/7086503 [1:36:10<11:02, 926.11it/s]读取数据:  91%|█████████▏| 6473400/7086503 [1:36:11<30:04, 339.67it/s]读取数据:  91%|█████████▏| 6473635/7086503 [1:36:11<18:18, 558.05it/s]读取数据:  91%|█████████▏| 6473757/7086503 [1:36:11<17:19, 589.37it/s]读取数据:  91%|█████████▏| 6473949/7086503 [1:36:11<12:57, 787.46it/s]读取数据:  91%|█████████▏| 6474081/7086503 [1:36:12<18:03, 565.31it/s]读取数据:  91%|█████████▏| 6474183/7086503 [1:36:12<22:00, 463.82it/s]读取数据:  91%|█████████▏| 6474337/7086503 [1:36:12<17:30, 582.82it/s]读取数据:  91%|█████████▏| 6474528/7086503 [1:36:12<13:02, 781.80it/s]读取数据:  91%|█████████▏| 6474700/7086503 [1:36:12<11:01, 924.56it/s]读取数据:  91%|█████████▏| 6474831/7086503 [1:36:12<11:10, 912.74it/s]读取数据:  91%|█████████▏| 6474950/7086503 [1:36:12<10:46, 945.72it/s]读取数据:  91%|█████████▏| 6475079/7086503 [1:36:13<10:18, 989.12it/s]读取数据:  91%|█████████▏| 6475193/7086503 [1:36:13<12:39, 804.59it/s]读取数据:  91%|█████████▏| 6475289/7086503 [1:36:13<12:53, 789.80it/s]读取数据:  91%|█████████▏| 6475469/7086503 [1:36:13<10:04, 1011.18it/s]读取数据:  91%|█████████▏| 6475615/7086503 [1:36:13<09:58, 1020.97it/s]读取数据:  91%|█████████▏| 6475728/7086503 [1:36:13<12:41, 801.96it/s] 读取数据:  91%|█████████▏| 6475822/7086503 [1:36:14<14:44, 690.81it/s]读取数据:  91%|█████████▏| 6476222/7086503 [1:36:14<07:34, 1342.00it/s]读取数据:  91%|█████████▏| 6476686/7086503 [1:36:14<04:55, 2061.06it/s]读取数据:  91%|█████████▏| 6477013/7086503 [1:36:14<04:19, 2348.94it/s]读取数据:  91%|█████████▏| 6477325/7086503 [1:36:14<03:59, 2544.17it/s]读取数据:  91%|█████████▏| 6478760/7086503 [1:36:14<01:46, 5686.11it/s]读取数据:  91%|█████████▏| 6479836/7086503 [1:36:14<01:25, 7083.21it/s]读取数据:  91%|█████████▏| 6481117/7086503 [1:36:14<01:09, 8697.21it/s]读取数据:  91%|█████████▏| 6483625/7086503 [1:36:14<00:44, 13404.24it/s]读取数据:  92%|█████████▏| 6485891/7086503 [1:36:15<00:37, 16097.11it/s]读取数据:  92%|█████████▏| 6488324/7086503 [1:36:15<00:32, 18514.06it/s]读取数据:  92%|█████████▏| 6490634/7086503 [1:36:15<00:29, 19867.48it/s]读取数据:  92%|█████████▏| 6492887/7086503 [1:36:15<00:28, 20652.65it/s]读取数据:  92%|█████████▏| 6495230/7086503 [1:36:15<00:27, 21478.44it/s]读取数据:  92%|█████████▏| 6497577/7086503 [1:36:15<00:26, 22072.10it/s]读取数据:  92%|█████████▏| 6499929/7086503 [1:36:15<00:26, 22504.10it/s]读取数据:  92%|█████████▏| 6499929/7086503 [1:36:28<00:26, 22504.10it/s]读取数据:  92%|█████████▏| 6500000/7086503 [1:46:33<18:51:02,  8.64it/s]读取数据:  92%|█████████▏| 6502100/7086503 [1:46:33<12:01:51, 13.49it/s]读取数据:  92%|█████████▏| 6504358/7086503 [1:46:33<7:43:21, 20.94it/s] 读取数据:  92%|█████████▏| 6506583/7086503 [1:46:33<5:07:41, 31.41it/s]读取数据:  92%|█████████▏| 6508795/7086503 [1:46:33<3:28:05, 46.27it/s]读取数据:  92%|█████████▏| 6511060/7086503 [1:46:34<2:21:05, 67.97it/s]读取数据:  92%|█████████▏| 6513382/7086503 [1:46:34<1:35:49, 99.68it/s]读取数据:  92%|█████████▏| 6515739/7086503 [1:46:34<1:05:22, 145.51it/s]读取数据:  92%|█████████▏| 6518088/7086503 [1:46:34<45:00, 210.45it/s]  读取数据:  92%|█████████▏| 6520470/7086503 [1:46:34<31:02, 303.90it/s]读取数据:  92%|█████████▏| 6522927/7086503 [1:46:34<21:19, 440.35it/s]读取数据:  92%|█████████▏| 6525295/7086503 [1:46:34<14:57, 625.54it/s]读取数据:  92%|█████████▏| 6527712/7086503 [1:46:34<10:27, 890.55it/s]读取数据:  92%|█████████▏| 6530202/7086503 [1:46:34<07:17, 1270.49it/s]读取数据:  92%|█████████▏| 6532616/7086503 [1:46:34<05:11, 1775.59it/s]读取数据:  92%|█████████▏| 6535049/7086503 [1:46:35<03:43, 2465.89it/s]读取数据:  92%|█████████▏| 6537463/7086503 [1:46:35<02:42, 3372.35it/s]读取数据:  92%|█████████▏| 6539869/7086503 [1:46:35<02:00, 4539.86it/s]读取数据:  92%|█████████▏| 6542314/7086503 [1:46:35<01:30, 6025.32it/s]读取数据:  92%|█████████▏| 6544800/7086503 [1:46:35<01:09, 7839.28it/s]读取数据:  92%|█████████▏| 6547238/7086503 [1:46:35<00:54, 9836.92it/s]读取数据:  92%|█████████▏| 6549689/7086503 [1:46:35<00:44, 11997.99it/s]读取数据:  92%|█████████▏| 6552130/7086503 [1:46:36<01:10, 7569.59it/s] 读取数据:  92%|█████████▏| 6554643/7086503 [1:46:36<00:55, 9627.95it/s]读取数据:  93%|█████████▎| 6557151/7086503 [1:46:36<00:44, 11843.78it/s]读取数据:  93%|█████████▎| 6559611/7086503 [1:46:36<00:37, 14012.86it/s]读取数据:  93%|█████████▎| 6562056/7086503 [1:46:36<00:32, 16051.80it/s]读取数据:  93%|█████████▎| 6564580/7086503 [1:46:36<00:28, 18056.34it/s]读取数据:  93%|█████████▎| 6567143/7086503 [1:46:36<00:26, 19856.02it/s]读取数据:  93%|█████████▎| 6569577/7086503 [1:46:36<00:26, 19369.75it/s]读取数据:  93%|█████████▎| 6572021/7086503 [1:46:37<00:24, 20639.11it/s]读取数据:  93%|█████████▎| 6574388/7086503 [1:46:37<00:23, 21437.00it/s]读取数据:  93%|█████████▎| 6576899/7086503 [1:46:37<00:22, 22440.28it/s]读取数据:  93%|█████████▎| 6579414/7086503 [1:46:37<00:21, 23199.29it/s]读取数据:  93%|█████████▎| 6581915/7086503 [1:46:37<00:21, 23716.89it/s]读取数据:  93%|█████████▎| 6584361/7086503 [1:46:37<00:20, 23930.16it/s]读取数据:  93%|█████████▎| 6586809/7086503 [1:46:37<00:20, 24090.85it/s]读取数据:  93%|█████████▎| 6589341/7086503 [1:46:37<00:20, 24452.80it/s]读取数据:  93%|█████████▎| 6591813/7086503 [1:46:37<00:20, 24494.30it/s]读取数据:  93%|█████████▎| 6594281/7086503 [1:46:38<00:34, 14226.87it/s]读取数据:  93%|█████████▎| 6596224/7086503 [1:46:38<00:51, 9490.91it/s] 读取数据:  93%|█████████▎| 6597727/7086503 [1:46:38<01:01, 7958.90it/s]读取数据:  93%|█████████▎| 6598931/7086503 [1:46:39<01:08, 7102.24it/s]读取数据:  93%|█████████▎| 6599922/7086503 [1:46:39<01:13, 6631.45it/s]读取数据:  93%|█████████▎| 6600771/7086503 [1:46:40<02:21, 3430.07it/s]读取数据:  93%|█████████▎| 6601399/7086503 [1:46:40<02:16, 3543.58it/s]读取数据:  93%|█████████▎| 6601966/7086503 [1:46:40<02:10, 3721.53it/s]读取数据:  93%|█████████▎| 6602509/7086503 [1:46:40<02:04, 3889.02it/s]读取数据:  93%|█████████▎| 6603033/7086503 [1:46:40<01:58, 4085.35it/s]读取数据:  93%|█████████▎| 6603551/7086503 [1:46:40<01:53, 4261.14it/s]读取数据:  93%|█████████▎| 6604063/7086503 [1:46:40<01:52, 4269.45it/s]读取数据:  93%|█████████▎| 6604553/7086503 [1:46:40<01:49, 4410.75it/s]读取数据:  93%|█████████▎| 6605071/7086503 [1:46:40<01:44, 4598.25it/s]读取数据:  93%|█████████▎| 6605581/7086503 [1:46:41<01:41, 4725.89it/s]读取数据:  93%|█████████▎| 6606082/7086503 [1:46:41<01:40, 4795.44it/s]读取数据:  93%|█████████▎| 6606632/7086503 [1:46:41<01:36, 4989.64it/s]读取数据:  93%|█████████▎| 6607147/7086503 [1:46:41<01:35, 5011.75it/s]读取数据:  93%|█████████▎| 6607660/7086503 [1:46:41<01:36, 4951.42it/s]读取数据:  93%|█████████▎| 6608188/7086503 [1:46:41<01:34, 5040.15it/s]读取数据:  93%|█████████▎| 6608715/7086503 [1:46:41<01:33, 5102.74it/s]读取数据:  93%|█████████▎| 6609238/7086503 [1:46:41<01:32, 5138.42it/s]读取数据:  93%|█████████▎| 6609773/7086503 [1:46:41<01:31, 5192.88it/s]读取数据:  93%|█████████▎| 6610323/7086503 [1:46:42<01:30, 5279.88it/s]读取数据:  93%|█████████▎| 6610853/7086503 [1:46:42<01:30, 5255.01it/s]读取数据:  93%|█████████▎| 6611380/7086503 [1:46:42<01:31, 5215.67it/s]读取数据:  93%|█████████▎| 6611903/7086503 [1:46:42<01:33, 5068.52it/s]读取数据:  93%|█████████▎| 6612412/7086503 [1:46:42<01:34, 5041.90it/s]读取数据:  93%|█████████▎| 6612918/7086503 [1:46:42<01:37, 4856.91it/s]读取数据:  93%|█████████▎| 6613406/7086503 [1:46:42<01:38, 4827.31it/s]读取数据:  93%|█████████▎| 6613890/7086503 [1:46:42<01:38, 4809.85it/s]读取数据:  93%|█████████▎| 6614393/7086503 [1:46:42<01:36, 4867.62it/s]读取数据:  93%|█████████▎| 6614892/7086503 [1:46:42<01:36, 4903.09it/s]读取数据:  93%|█████████▎| 6615383/7086503 [1:46:43<01:36, 4858.05it/s]读取数据:  93%|█████████▎| 6615870/7086503 [1:46:43<01:37, 4843.50it/s]读取数据:  93%|█████████▎| 6616355/7086503 [1:46:43<01:37, 4833.04it/s]读取数据:  93%|█████████▎| 6616839/7086503 [1:46:43<01:38, 4792.38it/s]读取数据:  93%|█████████▎| 6617356/7086503 [1:46:43<01:35, 4889.21it/s]读取数据:  93%|█████████▎| 6617846/7086503 [1:46:43<01:36, 4841.57it/s]读取数据:  93%|█████████▎| 6618331/7086503 [1:46:43<01:39, 4722.37it/s]读取数据:  93%|█████████▎| 6618804/7086503 [1:46:43<01:40, 4664.79it/s]读取数据:  93%|█████████▎| 6619271/7086503 [1:46:43<01:40, 4636.25it/s]读取数据:  93%|█████████▎| 6619735/7086503 [1:46:43<01:41, 4594.95it/s]读取数据:  93%|█████████▎| 6620195/7086503 [1:46:44<01:42, 4567.21it/s]读取数据:  93%|█████████▎| 6620686/7086503 [1:46:44<01:39, 4667.54it/s]读取数据:  93%|█████████▎| 6621158/7086503 [1:46:44<01:39, 4680.57it/s]读取数据:  93%|█████████▎| 6621627/7086503 [1:46:44<01:39, 4672.88it/s]读取数据:  93%|█████████▎| 6622095/7086503 [1:46:44<01:40, 4609.93it/s]读取数据:  93%|█████████▎| 6622564/7086503 [1:46:44<01:40, 4630.10it/s]读取数据:  93%|█████████▎| 6623028/7086503 [1:46:44<01:40, 4632.75it/s]读取数据:  93%|█████████▎| 6623516/7086503 [1:46:44<01:38, 4706.08it/s]读取数据:  93%|█████████▎| 6624008/7086503 [1:46:44<01:36, 4768.68it/s]读取数据:  93%|█████████▎| 6624486/7086503 [1:46:44<01:38, 4684.59it/s]读取数据:  93%|█████████▎| 6624955/7086503 [1:46:45<01:39, 4628.91it/s]读取数据:  93%|█████████▎| 6625419/7086503 [1:46:45<01:40, 4597.51it/s]读取数据:  93%|█████████▎| 6625879/7086503 [1:46:45<01:41, 4519.74it/s]读取数据:  94%|█████████▎| 6626332/7086503 [1:46:45<01:42, 4509.28it/s]读取数据:  94%|█████████▎| 6626790/7086503 [1:46:45<01:41, 4527.52it/s]读取数据:  94%|█████████▎| 6627283/7086503 [1:46:45<01:38, 4643.48it/s]读取数据:  94%|█████████▎| 6627748/7086503 [1:46:45<01:41, 4528.79it/s]读取数据:  94%|█████████▎| 6628202/7086503 [1:46:45<01:41, 4496.08it/s]读取数据:  94%|█████████▎| 6628672/7086503 [1:46:45<01:40, 4554.87it/s]读取数据:  94%|█████████▎| 6629128/7086503 [1:46:46<01:42, 4462.90it/s]读取数据:  94%|█████████▎| 6629588/7086503 [1:46:46<01:41, 4494.53it/s]读取数据:  94%|█████████▎| 6630045/7086503 [1:46:46<01:41, 4516.11it/s]读取数据:  94%|█████████▎| 6630531/7086503 [1:46:46<01:38, 4617.26it/s]读取数据:  94%|█████████▎| 6630994/7086503 [1:46:46<01:38, 4616.56it/s]读取数据:  94%|█████████▎| 6631456/7086503 [1:46:46<01:46, 4281.29it/s]读取数据:  94%|█████████▎| 6631935/7086503 [1:46:46<01:42, 4421.35it/s]读取数据:  94%|█████████▎| 6632384/7086503 [1:46:46<01:42, 4440.64it/s]读取数据:  94%|█████████▎| 6632909/7086503 [1:46:46<01:37, 4675.81it/s]读取数据:  94%|█████████▎| 6633450/7086503 [1:46:46<01:32, 4890.83it/s]读取数据:  94%|█████████▎| 6633982/7086503 [1:46:47<01:30, 5017.23it/s]读取数据:  94%|█████████▎| 6634527/7086503 [1:46:47<01:27, 5143.78it/s]读取数据:  94%|█████████▎| 6635055/7086503 [1:46:47<01:27, 5179.78it/s]读取数据:  94%|█████████▎| 6635588/7086503 [1:46:47<01:26, 5219.40it/s]读取数据:  94%|█████████▎| 6636151/7086503 [1:46:47<01:24, 5340.15it/s]读取数据:  94%|█████████▎| 6636698/7086503 [1:46:47<01:23, 5377.49it/s]读取数据:  94%|█████████▎| 6637254/7086503 [1:46:47<01:23, 5390.83it/s]读取数据:  94%|█████████▎| 6637794/7086503 [1:46:47<01:23, 5371.75it/s]读取数据:  94%|█████████▎| 6638332/7086503 [1:46:47<01:23, 5365.00it/s]读取数据:  94%|█████████▎| 6638880/7086503 [1:46:47<01:22, 5396.48it/s]读取数据:  94%|█████████▎| 6639422/7086503 [1:46:48<01:22, 5398.36it/s]读取数据:  94%|█████████▎| 6639970/7086503 [1:46:48<01:22, 5422.50it/s]读取数据:  94%|█████████▎| 6640531/7086503 [1:46:48<01:21, 5475.02it/s]读取数据:  94%|█████████▎| 6641085/7086503 [1:46:48<01:21, 5483.53it/s]读取数据:  94%|█████████▎| 6641653/7086503 [1:46:48<01:20, 5541.92it/s]读取数据:  94%|█████████▎| 6642216/7086503 [1:46:48<01:19, 5567.94it/s]读取数据:  94%|█████████▎| 6642773/7086503 [1:46:48<01:20, 5537.11it/s]读取数据:  94%|█████████▎| 6643332/7086503 [1:46:48<01:19, 5545.42it/s]读取数据:  94%|█████████▍| 6643920/7086503 [1:46:48<01:18, 5644.21it/s]读取数据:  94%|█████████▍| 6644485/7086503 [1:46:48<01:19, 5561.80it/s]读取数据:  94%|█████████▍| 6645043/7086503 [1:46:49<01:19, 5566.12it/s]读取数据:  94%|█████████▍| 6645603/7086503 [1:46:49<01:19, 5573.25it/s]读取数据:  94%|█████████▍| 6646185/7086503 [1:46:49<01:17, 5645.78it/s]读取数据:  94%|█████████▍| 6646756/7086503 [1:46:49<01:17, 5659.34it/s]读取数据:  94%|█████████▍| 6647337/7086503 [1:46:49<01:17, 5703.35it/s]读取数据:  94%|█████████▍| 6647908/7086503 [1:46:49<01:17, 5674.55it/s]读取数据:  94%|█████████▍| 6648476/7086503 [1:46:49<01:18, 5560.88it/s]读取数据:  94%|█████████▍| 6649033/7086503 [1:46:49<01:24, 5182.51it/s]读取数据:  94%|█████████▍| 6649573/7086503 [1:46:49<01:23, 5243.52it/s]读取数据:  94%|█████████▍| 6650102/7086503 [1:46:51<06:31, 1113.71it/s]读取数据:  94%|█████████▍| 6650484/7086503 [1:46:51<05:46, 1257.86it/s]读取数据:  94%|█████████▍| 6650818/7086503 [1:46:51<05:09, 1407.57it/s]读取数据:  94%|█████████▍| 6651124/7086503 [1:46:51<04:37, 1568.34it/s]读取数据:  94%|█████████▍| 6651416/7086503 [1:46:51<04:11, 1727.27it/s]读取数据:  94%|█████████▍| 6651698/7086503 [1:46:51<03:52, 1871.98it/s]读取数据:  94%|█████████▍| 6651974/7086503 [1:46:52<03:33, 2037.66it/s]读取数据:  94%|█████████▍| 6652248/7086503 [1:46:52<03:19, 2177.34it/s]读取数据:  94%|█████████▍| 6652533/7086503 [1:46:52<03:06, 2332.25it/s]读取数据:  94%|█████████▍| 6652826/7086503 [1:46:52<02:54, 2480.30it/s]读取数据:  94%|█████████▍| 6653118/7086503 [1:46:52<02:47, 2594.96it/s]读取数据:  94%|█████████▍| 6653403/7086503 [1:46:52<02:42, 2659.40it/s]读取数据:  94%|█████████▍| 6653709/7086503 [1:46:52<02:36, 2770.77it/s]读取数据:  94%|█████████▍| 6654014/7086503 [1:46:52<02:31, 2847.78it/s]读取数据:  94%|█████████▍| 6654309/7086503 [1:46:52<02:30, 2863.34it/s]读取数据:  94%|█████████▍| 6654620/7086503 [1:46:52<02:27, 2933.58it/s]读取数据:  94%|█████████▍| 6654940/7086503 [1:46:53<02:23, 3010.51it/s]读取数据:  94%|█████████▍| 6655269/7086503 [1:46:53<02:19, 3093.07it/s]读取数据:  94%|█████████▍| 6655592/7086503 [1:46:53<02:17, 3131.66it/s]读取数据:  94%|█████████▍| 6655927/7086503 [1:46:53<02:14, 3194.15it/s]读取数据:  94%|█████████▍| 6656297/7086503 [1:46:53<02:08, 3343.83it/s]读取数据:  94%|█████████▍| 6656633/7086503 [1:46:53<02:38, 2717.12it/s]读取数据:  94%|█████████▍| 6656925/7086503 [1:46:53<02:35, 2757.34it/s]读取数据:  94%|█████████▍| 6657275/7086503 [1:46:53<02:25, 2955.80it/s]读取数据:  94%|█████████▍| 6657649/7086503 [1:46:53<02:15, 3172.40it/s]读取数据:  94%|█████████▍| 6658046/7086503 [1:46:54<02:06, 3394.94it/s]读取数据:  94%|█████████▍| 6658448/7086503 [1:46:54<01:59, 3572.95it/s]读取数据:  94%|█████████▍| 6658844/7086503 [1:46:54<01:56, 3685.17it/s]读取数据:  94%|█████████▍| 6659235/7086503 [1:46:54<01:53, 3749.45it/s]读取数据:  94%|█████████▍| 6659626/7086503 [1:46:54<01:52, 3788.81it/s]读取数据:  94%|█████████▍| 6660039/7086503 [1:46:54<01:49, 3889.61it/s]读取数据:  94%|█████████▍| 6660485/7086503 [1:46:54<01:44, 4058.95it/s]读取数据:  94%|█████████▍| 6660939/7086503 [1:46:54<01:41, 4201.66it/s]读取数据:  94%|█████████▍| 6661400/7086503 [1:46:54<01:38, 4323.12it/s]读取数据:  94%|█████████▍| 6661867/7086503 [1:46:54<01:35, 4425.50it/s]读取数据:  94%|█████████▍| 6662369/7086503 [1:46:55<01:32, 4602.09it/s]读取数据:  94%|█████████▍| 6662830/7086503 [1:46:55<01:32, 4565.15it/s]读取数据:  94%|█████████▍| 6663287/7086503 [1:46:55<01:32, 4561.74it/s]读取数据:  94%|█████████▍| 6663779/7086503 [1:46:55<01:30, 4661.04it/s]读取数据:  94%|█████████▍| 6664271/7086503 [1:46:55<01:29, 4733.54it/s]读取数据:  94%|█████████▍| 6664755/7086503 [1:46:55<01:28, 4765.21it/s]读取数据:  94%|█████████▍| 6665260/7086503 [1:46:55<01:26, 4845.58it/s]读取数据:  94%|█████████▍| 6665760/7086503 [1:46:55<01:26, 4889.17it/s]读取数据:  94%|█████████▍| 6666279/7086503 [1:46:55<01:24, 4973.63it/s]读取数据:  94%|█████████▍| 6666799/7086503 [1:46:55<01:23, 5038.98it/s]读取数据:  94%|█████████▍| 6667303/7086503 [1:46:56<01:23, 5017.72it/s]读取数据:  94%|█████████▍| 6667805/7086503 [1:46:56<02:04, 3354.97it/s]读取数据:  94%|█████████▍| 6668213/7086503 [1:46:56<02:32, 2744.40it/s]读取数据:  94%|█████████▍| 6668553/7086503 [1:46:56<02:31, 2759.79it/s]读取数据:  94%|█████████▍| 6668998/7086503 [1:46:56<02:13, 3120.84it/s]读取数据:  94%|█████████▍| 6669364/7086503 [1:46:56<02:08, 3240.23it/s]读取数据:  94%|█████████▍| 6669813/7086503 [1:46:56<01:57, 3552.84it/s]读取数据:  94%|█████████▍| 6670224/7086503 [1:46:57<01:52, 3695.85it/s]读取数据:  94%|█████████▍| 6670647/7086503 [1:46:57<01:48, 3840.53it/s]读取数据:  94%|█████████▍| 6671108/7086503 [1:46:57<01:42, 4050.94it/s]读取数据:  94%|█████████▍| 6671534/7086503 [1:46:57<01:40, 4109.66it/s]读取数据:  94%|█████████▍| 6671968/7086503 [1:46:57<01:39, 4176.21it/s]读取数据:  94%|█████████▍| 6672398/7086503 [1:46:57<01:38, 4205.72it/s]读取数据:  94%|█████████▍| 6672846/7086503 [1:46:57<01:36, 4285.08it/s]读取数据:  94%|█████████▍| 6673279/7086503 [1:46:57<01:46, 3879.85it/s]读取数据:  94%|█████████▍| 6673677/7086503 [1:46:57<01:46, 3858.19it/s]读取数据:  94%|█████████▍| 6674103/7086503 [1:46:57<01:43, 3969.53it/s]读取数据:  94%|█████████▍| 6674506/7086503 [1:46:58<01:47, 3826.37it/s]读取数据:  94%|█████████▍| 6674951/7086503 [1:46:58<01:46, 3874.15it/s]读取数据:  94%|█████████▍| 6675342/7086503 [1:46:58<02:04, 3305.97it/s]读取数据:  94%|█████████▍| 6675777/7086503 [1:46:58<01:55, 3568.44it/s]读取数据:  94%|█████████▍| 6676211/7086503 [1:46:58<01:48, 3772.27it/s]读取数据:  94%|█████████▍| 6676602/7086503 [1:46:58<01:54, 3576.93it/s]读取数据:  94%|█████████▍| 6677028/7086503 [1:46:58<01:48, 3757.99it/s]读取数据:  94%|█████████▍| 6677479/7086503 [1:46:58<01:43, 3966.40it/s]读取数据:  94%|█████████▍| 6677927/7086503 [1:46:59<01:48, 3769.18it/s]读取数据:  94%|█████████▍| 6678313/7086503 [1:46:59<02:17, 2970.58it/s]读取数据:  94%|█████████▍| 6678640/7086503 [1:46:59<02:29, 2722.52it/s]读取数据:  94%|█████████▍| 6678935/7086503 [1:46:59<02:28, 2736.38it/s]读取数据:  94%|█████████▍| 6679328/7086503 [1:46:59<02:14, 3027.82it/s]读取数据:  94%|█████████▍| 6679779/7086503 [1:46:59<01:59, 3401.92it/s]读取数据:  94%|█████████▍| 6680251/7086503 [1:46:59<01:48, 3755.19it/s]读取数据:  94%|█████████▍| 6680745/7086503 [1:46:59<01:39, 4084.05it/s]读取数据:  94%|█████████▍| 6681221/7086503 [1:47:00<01:34, 4271.74it/s]读取数据:  94%|█████████▍| 6681661/7086503 [1:47:00<01:33, 4308.45it/s]读取数据:  94%|█████████▍| 6682133/7086503 [1:47:00<01:31, 4428.20it/s]读取数据:  94%|█████████▍| 6682582/7086503 [1:47:00<01:31, 4395.72it/s]读取数据:  94%|█████████▍| 6683026/7086503 [1:47:00<01:31, 4406.80it/s]读取数据:  94%|█████████▍| 6683470/7086503 [1:47:00<01:32, 4359.67it/s]读取数据:  94%|█████████▍| 6683924/7086503 [1:47:00<01:31, 4402.15it/s]读取数据:  94%|█████████▍| 6684401/7086503 [1:47:00<01:29, 4510.73it/s]读取数据:  94%|█████████▍| 6684854/7086503 [1:47:00<01:39, 4053.59it/s]读取数据:  94%|█████████▍| 6685333/7086503 [1:47:00<01:34, 4256.33it/s]读取数据:  94%|█████████▍| 6685790/7086503 [1:47:01<01:32, 4343.84it/s]读取数据:  94%|█████████▍| 6686268/7086503 [1:47:01<01:29, 4469.03it/s]读取数据:  94%|█████████▍| 6686739/7086503 [1:47:01<01:28, 4539.04it/s]读取数据:  94%|█████████▍| 6687197/7086503 [1:47:01<01:28, 4519.10it/s]读取数据:  94%|█████████▍| 6687683/7086503 [1:47:01<01:26, 4614.25it/s]读取数据:  94%|█████████▍| 6688147/7086503 [1:47:01<01:27, 4542.50it/s]读取数据:  94%|█████████▍| 6688603/7086503 [1:47:01<01:28, 4490.71it/s]读取数据:  94%|█████████▍| 6689054/7086503 [1:47:01<01:29, 4432.62it/s]读取数据:  94%|█████████▍| 6689500/7086503 [1:47:01<01:29, 4440.13it/s]读取数据:  94%|█████████▍| 6689948/7086503 [1:47:01<01:29, 4440.97it/s]读取数据:  94%|█████████▍| 6690394/7086503 [1:47:02<01:29, 4436.68it/s]读取数据:  94%|█████████▍| 6690851/7086503 [1:47:02<01:28, 4472.63it/s]读取数据:  94%|█████████▍| 6691308/7086503 [1:47:02<01:27, 4500.95it/s]读取数据:  94%|█████████▍| 6691782/7086503 [1:47:02<01:26, 4569.72it/s]读取数据:  94%|█████████▍| 6692253/7086503 [1:47:02<01:25, 4607.35it/s]读取数据:  94%|█████████▍| 6692714/7086503 [1:47:02<01:31, 4290.96it/s]读取数据:  94%|█████████▍| 6693178/7086503 [1:47:02<01:29, 4387.82it/s]读取数据:  94%|█████████▍| 6693621/7086503 [1:47:02<01:29, 4370.28it/s]读取数据:  94%|█████████▍| 6694061/7086503 [1:47:02<01:33, 4210.51it/s]读取数据:  94%|█████████▍| 6694541/7086503 [1:47:03<01:29, 4374.39it/s]读取数据:  94%|█████████▍| 6695009/7086503 [1:47:03<01:27, 4461.14it/s]读取数据:  94%|█████████▍| 6695501/7086503 [1:47:03<01:25, 4589.69it/s]读取数据:  94%|█████████▍| 6695962/7086503 [1:47:03<01:37, 4006.05it/s]读取数据:  94%|█████████▍| 6696405/7086503 [1:47:03<01:34, 4112.23it/s]读取数据:  95%|█████████▍| 6696848/7086503 [1:47:03<01:32, 4199.99it/s]读取数据:  95%|█████████▍| 6697306/7086503 [1:47:03<01:30, 4307.20it/s]读取数据:  95%|█████████▍| 6697744/7086503 [1:47:03<01:29, 4319.91it/s]读取数据:  95%|█████████▍| 6698216/7086503 [1:47:03<01:27, 4435.43it/s]读取数据:  95%|█████████▍| 6698675/7086503 [1:47:03<01:26, 4471.96it/s]读取数据:  95%|█████████▍| 6699153/7086503 [1:47:04<01:24, 4561.38it/s]读取数据:  95%|█████████▍| 6699643/7086503 [1:47:04<01:23, 4659.66it/s]读取数据:  95%|█████████▍| 6700111/7086503 [1:47:05<05:03, 1271.51it/s]读取数据:  95%|█████████▍| 6700453/7086503 [1:47:05<04:32, 1414.64it/s]读取数据:  95%|█████████▍| 6700759/7086503 [1:47:05<04:07, 1559.23it/s]读取数据:  95%|█████████▍| 6701044/7086503 [1:47:05<03:46, 1701.20it/s]读取数据:  95%|█████████▍| 6701316/7086503 [1:47:05<03:27, 1853.40it/s]读取数据:  95%|█████████▍| 6701584/7086503 [1:47:05<03:11, 2011.19it/s]读取数据:  95%|█████████▍| 6701869/7086503 [1:47:05<02:55, 2190.71it/s]读取数据:  95%|█████████▍| 6702160/7086503 [1:47:05<02:43, 2357.45it/s]读取数据:  95%|█████████▍| 6702442/7086503 [1:47:06<02:35, 2471.59it/s]读取数据:  95%|█████████▍| 6702729/7086503 [1:47:06<02:28, 2576.00it/s]读取数据:  95%|█████████▍| 6703011/7086503 [1:47:06<02:25, 2633.52it/s]读取数据:  95%|█████████▍| 6703292/7086503 [1:47:06<02:23, 2671.52it/s]读取数据:  95%|█████████▍| 6703578/7086503 [1:47:06<02:20, 2717.74it/s]读取数据:  95%|█████████▍| 6703870/7086503 [1:47:06<02:17, 2773.93it/s]读取数据:  95%|█████████▍| 6704166/7086503 [1:47:06<02:15, 2827.74it/s]读取数据:  95%|█████████▍| 6704467/7086503 [1:47:06<02:12, 2880.68it/s]读取数据:  95%|█████████▍| 6704772/7086503 [1:47:06<02:10, 2928.82it/s]读取数据:  95%|█████████▍| 6705068/7086503 [1:47:06<02:09, 2937.47it/s]读取数据:  95%|█████████▍| 6705379/7086503 [1:47:07<02:07, 2985.83it/s]读取数据:  95%|█████████▍| 6705700/7086503 [1:47:07<02:05, 3044.77it/s]读取数据:  95%|█████████▍| 6706025/7086503 [1:47:07<02:02, 3104.28it/s]读取数据:  95%|█████████▍| 6706367/7086503 [1:47:07<01:58, 3198.48it/s]读取数据:  95%|█████████▍| 6706698/7086503 [1:47:07<01:57, 3228.95it/s]读取数据:  95%|█████████▍| 6707043/7086503 [1:47:07<01:55, 3293.56it/s]读取数据:  95%|█████████▍| 6707387/7086503 [1:47:07<01:53, 3335.94it/s]读取数据:  95%|█████████▍| 6707743/7086503 [1:47:07<01:51, 3401.27it/s]读取数据:  95%|█████████▍| 6708097/7086503 [1:47:07<01:49, 3441.22it/s]读取数据:  95%|█████████▍| 6708451/7086503 [1:47:07<01:49, 3467.22it/s]读取数据:  95%|█████████▍| 6708827/7086503 [1:47:08<01:46, 3553.80it/s]读取数据:  95%|█████████▍| 6709217/7086503 [1:47:08<01:43, 3655.05it/s]读取数据:  95%|█████████▍| 6709583/7086503 [1:47:08<01:43, 3645.16it/s]读取数据:  95%|█████████▍| 6709968/7086503 [1:47:08<01:41, 3703.01it/s]读取数据:  95%|█████████▍| 6710363/7086503 [1:47:08<01:39, 3775.57it/s]读取数据:  95%|█████████▍| 6710782/7086503 [1:47:08<01:36, 3897.46it/s]读取数据:  95%|█████████▍| 6711204/7086503 [1:47:08<01:33, 3993.92it/s]读取数据:  95%|█████████▍| 6711604/7086503 [1:47:08<01:33, 3990.40it/s]读取数据:  95%|█████████▍| 6712032/7086503 [1:47:08<01:31, 4076.36it/s]读取数据:  95%|█████████▍| 6712519/7086503 [1:47:08<01:26, 4311.39it/s]读取数据:  95%|█████████▍| 6712971/7086503 [1:47:09<01:25, 4369.36it/s]读取数据:  95%|█████████▍| 6713470/7086503 [1:47:09<01:21, 4549.26it/s]读取数据:  95%|█████████▍| 6713935/7086503 [1:47:09<01:21, 4578.66it/s]读取数据:  95%|█████████▍| 6714418/7086503 [1:47:09<01:19, 4652.44it/s]读取数据:  95%|█████████▍| 6714892/7086503 [1:47:09<01:19, 4677.20it/s]读取数据:  95%|█████████▍| 6715398/7086503 [1:47:09<01:17, 4791.34it/s]读取数据:  95%|█████████▍| 6715878/7086503 [1:47:09<01:17, 4753.77it/s]读取数据:  95%|█████████▍| 6716372/7086503 [1:47:09<01:16, 4806.99it/s]读取数据:  95%|█████████▍| 6716885/7086503 [1:47:09<01:15, 4901.27it/s]读取数据:  95%|█████████▍| 6717376/7086503 [1:47:09<01:15, 4857.65it/s]读取数据:  95%|█████████▍| 6717862/7086503 [1:47:10<01:15, 4857.82it/s]读取数据:  95%|█████████▍| 6718363/7086503 [1:47:10<01:15, 4901.95it/s]读取数据:  95%|█████████▍| 6718854/7086503 [1:47:10<01:14, 4903.73it/s]读取数据:  95%|█████████▍| 6719345/7086503 [1:47:10<01:15, 4882.79it/s]读取数据:  95%|█████████▍| 6719834/7086503 [1:47:10<01:15, 4842.31it/s]读取数据:  95%|█████████▍| 6720353/7086503 [1:47:10<01:14, 4942.91it/s]读取数据:  95%|█████████▍| 6720857/7086503 [1:47:10<01:13, 4971.76it/s]读取数据:  95%|█████████▍| 6721380/7086503 [1:47:10<01:12, 5048.06it/s]读取数据:  95%|█████████▍| 6721895/7086503 [1:47:10<01:11, 5077.18it/s]读取数据:  95%|█████████▍| 6722403/7086503 [1:47:10<01:11, 5074.46it/s]读取数据:  95%|█████████▍| 6722944/7086503 [1:47:11<01:10, 5173.73it/s]读取数据:  95%|█████████▍| 6723462/7086503 [1:47:11<01:10, 5141.39it/s]读取数据:  95%|█████████▍| 6723977/7086503 [1:47:11<01:35, 3794.22it/s]读取数据:  95%|█████████▍| 6724487/7086503 [1:47:11<01:28, 4106.27it/s]读取数据:  95%|█████████▍| 6724942/7086503 [1:47:11<01:29, 4030.45it/s]读取数据:  95%|█████████▍| 6725376/7086503 [1:47:11<01:32, 3917.01it/s]读取数据:  95%|█████████▍| 6725789/7086503 [1:47:11<01:33, 3859.53it/s]读取数据:  95%|█████████▍| 6726190/7086503 [1:47:11<01:33, 3872.44it/s]读取数据:  95%|█████████▍| 6726588/7086503 [1:47:12<01:34, 3801.27it/s]读取数据:  95%|█████████▍| 6726984/7086503 [1:47:12<01:33, 3843.32it/s]读取数据:  95%|█████████▍| 6727374/7086503 [1:47:12<01:34, 3806.80it/s]读取数据:  95%|█████████▍| 6727759/7086503 [1:47:12<01:34, 3808.29it/s]读取数据:  95%|█████████▍| 6728143/7086503 [1:47:12<01:34, 3795.40it/s]读取数据:  95%|█████████▍| 6728525/7086503 [1:47:12<01:34, 3777.71it/s]读取数据:  95%|█████████▍| 6728904/7086503 [1:47:12<01:35, 3760.76it/s]读取数据:  95%|█████████▍| 6729281/7086503 [1:47:12<01:35, 3748.01it/s]读取数据:  95%|█████████▍| 6729657/7086503 [1:47:12<01:35, 3741.45it/s]读取数据:  95%|█████████▍| 6730032/7086503 [1:47:12<01:35, 3735.74it/s]读取数据:  95%|█████████▍| 6730411/7086503 [1:47:13<01:34, 3750.94it/s]读取数据:  95%|█████████▍| 6730798/7086503 [1:47:13<01:34, 3783.26it/s]读取数据:  95%|█████████▍| 6731177/7086503 [1:47:13<01:34, 3765.51it/s]读取数据:  95%|█████████▍| 6731554/7086503 [1:47:13<02:00, 2953.24it/s]读取数据:  95%|█████████▍| 6731877/7086503 [1:47:13<02:43, 2174.90it/s]读取数据:  95%|█████████▌| 6732186/7086503 [1:47:13<02:30, 2359.49it/s]读取数据:  95%|█████████▌| 6732463/7086503 [1:47:13<02:27, 2398.82it/s]读取数据:  95%|█████████▌| 6732767/7086503 [1:47:14<02:18, 2551.83it/s]读取数据:  95%|█████████▌| 6733083/7086503 [1:47:14<02:10, 2705.95it/s]读取数据:  95%|█████████▌| 6733398/7086503 [1:47:14<02:05, 2823.77it/s]读取数据:  95%|█████████▌| 6733696/7086503 [1:47:14<02:06, 2790.38it/s]读取数据:  95%|█████████▌| 6734011/7086503 [1:47:14<02:02, 2886.61it/s]读取数据:  95%|█████████▌| 6734308/7086503 [1:47:14<02:04, 2817.72it/s]读取数据:  95%|█████████▌| 6734596/7086503 [1:47:14<02:57, 1983.56it/s]读取数据:  95%|█████████▌| 6734850/7086503 [1:47:14<02:47, 2105.36it/s]读取数据:  95%|█████████▌| 6735172/7086503 [1:47:15<02:28, 2371.57it/s]读取数据:  95%|█████████▌| 6735489/7086503 [1:47:15<02:16, 2570.18it/s]读取数据:  95%|█████████▌| 6735811/7086503 [1:47:15<02:07, 2742.21it/s]读取数据:  95%|█████████▌| 6736151/7086503 [1:47:15<02:00, 2918.72it/s]读取数据:  95%|█████████▌| 6736458/7086503 [1:47:15<02:05, 2790.96it/s]读取数据:  95%|█████████▌| 6736749/7086503 [1:47:15<02:09, 2691.33it/s]读取数据:  95%|█████████▌| 6737027/7086503 [1:47:15<02:19, 2496.49it/s]读取数据:  95%|█████████▌| 6737345/7086503 [1:47:15<02:10, 2675.58it/s]读取数据:  95%|█████████▌| 6737621/7086503 [1:47:15<02:21, 2466.03it/s]读取数据:  95%|█████████▌| 6737940/7086503 [1:47:16<02:11, 2655.82it/s]读取数据:  95%|█████████▌| 6738214/7086503 [1:47:16<02:35, 2239.21it/s]读取数据:  95%|█████████▌| 6738511/7086503 [1:47:16<02:23, 2418.24it/s]读取数据:  95%|█████████▌| 6738825/7086503 [1:47:16<02:13, 2605.25it/s]读取数据:  95%|█████████▌| 6739099/7086503 [1:47:16<02:21, 2461.57it/s]读取数据:  95%|█████████▌| 6739363/7086503 [1:47:16<02:18, 2506.99it/s]读取数据:  95%|█████████▌| 6739657/7086503 [1:47:16<02:12, 2624.23it/s]读取数据:  95%|█████████▌| 6739926/7086503 [1:47:16<02:12, 2614.10it/s]读取数据:  95%|█████████▌| 6740237/7086503 [1:47:16<02:05, 2753.33it/s]读取数据:  95%|█████████▌| 6740546/7086503 [1:47:17<02:01, 2848.77it/s]读取数据:  95%|█████████▌| 6740869/7086503 [1:47:17<01:56, 2958.37it/s]读取数据:  95%|█████████▌| 6741185/7086503 [1:47:17<01:54, 3015.08it/s]读取数据:  95%|█████████▌| 6741510/7086503 [1:47:17<01:51, 3081.35it/s]读取数据:  95%|█████████▌| 6741820/7086503 [1:47:17<01:52, 3062.54it/s]读取数据:  95%|█████████▌| 6742128/7086503 [1:47:17<01:54, 3004.84it/s]读取数据:  95%|█████████▌| 6742457/7086503 [1:47:17<01:51, 3087.81it/s]读取数据:  95%|█████████▌| 6742767/7086503 [1:47:17<01:51, 3078.64it/s]读取数据:  95%|█████████▌| 6743079/7086503 [1:47:17<01:51, 3090.77it/s]读取数据:  95%|█████████▌| 6743401/7086503 [1:47:17<01:49, 3127.37it/s]读取数据:  95%|█████████▌| 6743767/7086503 [1:47:18<01:44, 3285.52it/s]读取数据:  95%|█████████▌| 6744154/7086503 [1:47:18<01:39, 3455.36it/s]读取数据:  95%|█████████▌| 6744523/7086503 [1:47:18<01:37, 3524.63it/s]读取数据:  95%|█████████▌| 6744889/7086503 [1:47:18<01:35, 3565.05it/s]读取数据:  95%|█████████▌| 6745253/7086503 [1:47:18<01:35, 3584.22it/s]读取数据:  95%|█████████▌| 6745613/7086503 [1:47:18<01:35, 3585.40it/s]读取数据:  95%|█████████▌| 6745977/7086503 [1:47:18<01:34, 3599.30it/s]读取数据:  95%|█████████▌| 6746342/7086503 [1:47:18<01:34, 3613.48it/s]读取数据:  95%|█████████▌| 6746719/7086503 [1:47:18<01:32, 3654.83it/s]读取数据:  95%|█████████▌| 6747085/7086503 [1:47:18<01:34, 3603.40it/s]读取数据:  95%|█████████▌| 6747450/7086503 [1:47:19<01:33, 3615.88it/s]读取数据:  95%|█████████▌| 6747812/7086503 [1:47:19<01:33, 3614.26it/s]读取数据:  95%|█████████▌| 6748174/7086503 [1:47:19<01:36, 3491.41it/s]读取数据:  95%|█████████▌| 6748552/7086503 [1:47:19<01:34, 3573.50it/s]读取数据:  95%|█████████▌| 6748919/7086503 [1:47:19<01:33, 3598.83it/s]读取数据:  95%|█████████▌| 6749293/7086503 [1:47:19<01:32, 3637.15it/s]读取数据:  95%|█████████▌| 6749658/7086503 [1:47:19<01:33, 3610.19it/s]读取数据:  95%|█████████▌| 6750020/7086503 [1:47:20<06:08, 913.95it/s] 读取数据:  95%|█████████▌| 6750283/7086503 [1:47:20<05:39, 988.88it/s]读取数据:  95%|█████████▌| 6750508/7086503 [1:47:21<05:19, 1051.97it/s]读取数据:  95%|█████████▌| 6750706/7086503 [1:47:21<04:59, 1120.27it/s]读取数据:  95%|█████████▌| 6750889/7086503 [1:47:21<05:24, 1032.77it/s]读取数据:  95%|█████████▌| 6751041/7086503 [1:47:21<05:05, 1098.83it/s]读取数据:  95%|█████████▌| 6751195/7086503 [1:47:21<04:44, 1176.88it/s]读取数据:  95%|█████████▌| 6751346/7086503 [1:47:21<05:03, 1105.67it/s]读取数据:  95%|█████████▌| 6751498/7086503 [1:47:21<04:41, 1189.26it/s]读取数据:  95%|█████████▌| 6751637/7086503 [1:47:22<04:39, 1199.76it/s]读取数据:  95%|█████████▌| 6751783/7086503 [1:47:22<04:26, 1256.44it/s]读取数据:  95%|█████████▌| 6751936/7086503 [1:47:22<04:12, 1324.93it/s]读取数据:  95%|█████████▌| 6752083/7086503 [1:47:22<04:05, 1362.96it/s]读取数据:  95%|█████████▌| 6752228/7086503 [1:47:22<04:01, 1384.19it/s]读取数据:  95%|█████████▌| 6752385/7086503 [1:47:22<03:52, 1435.89it/s]读取数据:  95%|█████████▌| 6752533/7086503 [1:47:22<04:07, 1350.79it/s]读取数据:  95%|█████████▌| 6752673/7086503 [1:47:22<04:04, 1364.26it/s]读取数据:  95%|█████████▌| 6752823/7086503 [1:47:22<03:57, 1402.45it/s]读取数据:  95%|█████████▌| 6752974/7086503 [1:47:23<03:53, 1430.89it/s]读取数据:  95%|█████████▌| 6753119/7086503 [1:47:23<03:52, 1433.82it/s]读取数据:  95%|█████████▌| 6753266/7086503 [1:47:23<03:50, 1443.57it/s]读取数据:  95%|█████████▌| 6753427/7086503 [1:47:23<03:43, 1491.50it/s]读取数据:  95%|█████████▌| 6753577/7086503 [1:47:23<03:42, 1493.45it/s]读取数据:  95%|█████████▌| 6753730/7086503 [1:47:23<03:41, 1503.84it/s]读取数据:  95%|█████████▌| 6753881/7086503 [1:47:23<03:43, 1490.30it/s]读取数据:  95%|█████████▌| 6754041/7086503 [1:47:23<03:38, 1521.13it/s]读取数据:  95%|█████████▌| 6754208/7086503 [1:47:23<03:32, 1564.12it/s]读取数据:  95%|█████████▌| 6754370/7086503 [1:47:23<03:30, 1577.90it/s]读取数据:  95%|█████████▌| 6754532/7086503 [1:47:24<03:29, 1587.61it/s]读取数据:  95%|█████████▌| 6754691/7086503 [1:47:24<03:29, 1585.46it/s]读取数据:  95%|█████████▌| 6754850/7086503 [1:47:24<03:29, 1585.31it/s]读取数据:  95%|█████████▌| 6755015/7086503 [1:47:24<03:27, 1600.15it/s]读取数据:  95%|█████████▌| 6755183/7086503 [1:47:24<03:24, 1621.56it/s]读取数据:  95%|█████████▌| 6755350/7086503 [1:47:24<03:22, 1631.45it/s]读取数据:  95%|█████████▌| 6755514/7086503 [1:47:24<03:23, 1624.87it/s]读取数据:  95%|█████████▌| 6755677/7086503 [1:47:24<03:25, 1607.02it/s]读取数据:  95%|█████████▌| 6755840/7086503 [1:47:24<03:25, 1610.70it/s]读取数据:  95%|█████████▌| 6756003/7086503 [1:47:24<03:24, 1615.91it/s]读取数据:  95%|█████████▌| 6756170/7086503 [1:47:25<03:22, 1628.41it/s]读取数据:  95%|█████████▌| 6756347/7086503 [1:47:25<03:17, 1669.12it/s]读取数据:  95%|█████████▌| 6756520/7086503 [1:47:25<03:16, 1682.47it/s]读取数据:  95%|█████████▌| 6756689/7086503 [1:47:25<03:16, 1678.27it/s]读取数据:  95%|█████████▌| 6756857/7086503 [1:47:25<03:16, 1678.50it/s]读取数据:  95%|█████████▌| 6757025/7086503 [1:47:25<03:16, 1675.18it/s]读取数据:  95%|█████████▌| 6757205/7086503 [1:47:25<03:12, 1711.07it/s]读取数据:  95%|█████████▌| 6757387/7086503 [1:47:25<03:08, 1742.51it/s]读取数据:  95%|█████████▌| 6757574/7086503 [1:47:25<03:05, 1771.76it/s]读取数据:  95%|█████████▌| 6757756/7086503 [1:47:25<03:04, 1785.32it/s]读取数据:  95%|█████████▌| 6757935/7086503 [1:47:26<03:07, 1755.08it/s]读取数据:  95%|█████████▌| 6758111/7086503 [1:47:26<03:21, 1632.86it/s]读取数据:  95%|█████████▌| 6758279/7086503 [1:47:26<03:19, 1645.39it/s]读取数据:  95%|█████████▌| 6758462/7086503 [1:47:26<03:13, 1695.93it/s]读取数据:  95%|█████████▌| 6758634/7086503 [1:47:26<03:12, 1701.96it/s]读取数据:  95%|█████████▌| 6758827/7086503 [1:47:26<03:05, 1766.48it/s]读取数据:  95%|█████████▌| 6759005/7086503 [1:47:26<03:06, 1757.72it/s]读取数据:  95%|█████████▌| 6759188/7086503 [1:47:26<03:04, 1777.77it/s]读取数据:  95%|█████████▌| 6759367/7086503 [1:47:26<03:03, 1778.92it/s]读取数据:  95%|█████████▌| 6759548/7086503 [1:47:27<03:22, 1611.89it/s]读取数据:  95%|█████████▌| 6759713/7086503 [1:47:27<03:24, 1595.08it/s]读取数据:  95%|█████████▌| 6759875/7086503 [1:47:27<03:27, 1574.38it/s]读取数据:  95%|█████████▌| 6760053/7086503 [1:47:27<03:20, 1630.01it/s]读取数据:  95%|█████████▌| 6760237/7086503 [1:47:27<03:13, 1689.57it/s]读取数据:  95%|█████████▌| 6760412/7086503 [1:47:27<03:11, 1706.68it/s]读取数据:  95%|█████████▌| 6760584/7086503 [1:47:27<03:18, 1644.93it/s]读取数据:  95%|█████████▌| 6760750/7086503 [1:47:27<03:39, 1484.70it/s]读取数据:  95%|█████████▌| 6760902/7086503 [1:47:27<03:39, 1483.79it/s]读取数据:  95%|█████████▌| 6761079/7086503 [1:47:27<03:28, 1562.55it/s]读取数据:  95%|█████████▌| 6761251/7086503 [1:47:28<03:22, 1606.59it/s]读取数据:  95%|█████████▌| 6761455/7086503 [1:47:28<03:07, 1731.37it/s]读取数据:  95%|█████████▌| 6761649/7086503 [1:47:28<03:01, 1791.70it/s]读取数据:  95%|█████████▌| 6761848/7086503 [1:47:28<02:55, 1849.75it/s]读取数据:  95%|█████████▌| 6762051/7086503 [1:47:28<02:50, 1902.87it/s]读取数据:  95%|█████████▌| 6762259/7086503 [1:47:28<03:14, 1662.88it/s]读取数据:  95%|█████████▌| 6762432/7086503 [1:47:28<04:09, 1300.70it/s]读取数据:  95%|█████████▌| 6762623/7086503 [1:47:28<03:45, 1438.45it/s]读取数据:  95%|█████████▌| 6762826/7086503 [1:47:29<03:24, 1582.88it/s]读取数据:  95%|█████████▌| 6762999/7086503 [1:47:29<03:22, 1595.70it/s]读取数据:  95%|█████████▌| 6763181/7086503 [1:47:29<03:15, 1652.90it/s]读取数据:  95%|█████████▌| 6763364/7086503 [1:47:29<03:09, 1701.55it/s]读取数据:  95%|█████████▌| 6763567/7086503 [1:47:29<03:00, 1791.09it/s]读取数据:  95%|█████████▌| 6763774/7086503 [1:47:29<02:52, 1870.63it/s]读取数据:  95%|█████████▌| 6763998/7086503 [1:47:29<02:43, 1977.42it/s]读取数据:  95%|█████████▌| 6764205/7086503 [1:47:29<02:40, 2002.66it/s]读取数据:  95%|█████████▌| 6764408/7086503 [1:47:29<02:40, 2001.04it/s]读取数据:  95%|█████████▌| 6764623/7086503 [1:47:29<02:37, 2043.45it/s]读取数据:  95%|█████████▌| 6764839/7086503 [1:47:30<02:34, 2077.62it/s]读取数据:  95%|█████████▌| 6765048/7086503 [1:47:30<02:34, 2077.77it/s]读取数据:  95%|█████████▌| 6765257/7086503 [1:47:30<02:34, 2077.21it/s]读取数据:  95%|█████████▌| 6765481/7086503 [1:47:30<02:31, 2122.25it/s]读取数据:  95%|█████████▌| 6765694/7086503 [1:47:30<02:31, 2119.25it/s]读取数据:  95%|█████████▌| 6765907/7086503 [1:47:30<02:31, 2112.94it/s]读取数据:  95%|█████████▌| 6766132/7086503 [1:47:30<02:28, 2150.63it/s]读取数据:  95%|█████████▌| 6766364/7086503 [1:47:30<02:25, 2200.63it/s]读取数据:  95%|█████████▌| 6766594/7086503 [1:47:30<02:23, 2229.00it/s]读取数据:  95%|█████████▌| 6766817/7086503 [1:47:30<02:23, 2220.77it/s]读取数据:  95%|█████████▌| 6767040/7086503 [1:47:31<02:24, 2210.52it/s]读取数据:  95%|█████████▌| 6767262/7086503 [1:47:31<02:24, 2202.29it/s]读取数据:  95%|█████████▌| 6767500/7086503 [1:47:31<02:21, 2252.53it/s]读取数据:  96%|█████████▌| 6767731/7086503 [1:47:31<02:20, 2267.86it/s]读取数据:  96%|█████████▌| 6767958/7086503 [1:47:31<02:20, 2260.57it/s]读取数据:  96%|█████████▌| 6768185/7086503 [1:47:31<02:22, 2236.17it/s]读取数据:  96%|█████████▌| 6768428/7086503 [1:47:31<02:18, 2292.48it/s]读取数据:  96%|█████████▌| 6768658/7086503 [1:47:31<02:20, 2264.12it/s]读取数据:  96%|█████████▌| 6768907/7086503 [1:47:31<02:16, 2329.71it/s]读取数据:  96%|█████████▌| 6769152/7086503 [1:47:31<02:14, 2364.71it/s]读取数据:  96%|█████████▌| 6769389/7086503 [1:47:32<02:17, 2309.58it/s]读取数据:  96%|█████████▌| 6769630/7086503 [1:47:32<02:15, 2336.34it/s]读取数据:  96%|█████████▌| 6769864/7086503 [1:47:32<02:16, 2320.25it/s]读取数据:  96%|█████████▌| 6770109/7086503 [1:47:32<02:14, 2357.50it/s]读取数据:  96%|█████████▌| 6770351/7086503 [1:47:32<02:13, 2375.39it/s]读取数据:  96%|█████████▌| 6770589/7086503 [1:47:32<02:12, 2375.91it/s]读取数据:  96%|█████████▌| 6770827/7086503 [1:47:32<02:13, 2356.71it/s]读取数据:  96%|█████████▌| 6771070/7086503 [1:47:32<02:18, 2283.21it/s]读取数据:  96%|█████████▌| 6771299/7086503 [1:47:32<02:18, 2280.80it/s]读取数据:  96%|█████████▌| 6771545/7086503 [1:47:33<02:15, 2332.17it/s]读取数据:  96%|█████████▌| 6771796/7086503 [1:47:33<02:12, 2383.39it/s]读取数据:  96%|█████████▌| 6772038/7086503 [1:47:33<02:11, 2392.33it/s]读取数据:  96%|█████████▌| 6772278/7086503 [1:47:33<02:11, 2389.39it/s]读取数据:  96%|█████████▌| 6772530/7086503 [1:47:33<02:09, 2427.34it/s]读取数据:  96%|█████████▌| 6772781/7086503 [1:47:33<02:08, 2450.61it/s]读取数据:  96%|█████████▌| 6773027/7086503 [1:47:33<02:08, 2448.68it/s]读取数据:  96%|█████████▌| 6773281/7086503 [1:47:33<02:06, 2469.99it/s]读取数据:  96%|█████████▌| 6773543/7086503 [1:47:33<02:04, 2510.90it/s]读取数据:  96%|█████████▌| 6773803/7086503 [1:47:33<02:03, 2533.18it/s]读取数据:  96%|█████████▌| 6774060/7086503 [1:47:34<02:02, 2543.47it/s]读取数据:  96%|█████████▌| 6774315/7086503 [1:47:34<02:05, 2493.74it/s]读取数据:  96%|█████████▌| 6774573/7086503 [1:47:34<02:03, 2518.02it/s]读取数据:  96%|█████████▌| 6774831/7086503 [1:47:34<02:02, 2535.69it/s]读取数据:  96%|█████████▌| 6775085/7086503 [1:47:34<02:03, 2527.11it/s]读取数据:  96%|█████████▌| 6775344/7086503 [1:47:34<02:02, 2541.90it/s]读取数据:  96%|█████████▌| 6775612/7086503 [1:47:34<02:00, 2581.97it/s]读取数据:  96%|█████████▌| 6775879/7086503 [1:47:34<01:59, 2607.75it/s]读取数据:  96%|█████████▌| 6776140/7086503 [1:47:34<02:00, 2572.71it/s]读取数据:  96%|█████████▌| 6776398/7086503 [1:47:34<02:00, 2572.90it/s]读取数据:  96%|█████████▌| 6776656/7086503 [1:47:35<02:00, 2566.67it/s]读取数据:  96%|█████████▌| 6776913/7086503 [1:47:35<02:02, 2535.87it/s]读取数据:  96%|█████████▌| 6777191/7086503 [1:47:35<01:58, 2607.59it/s]读取数据:  96%|█████████▌| 6777467/7086503 [1:47:35<01:56, 2652.79it/s]读取数据:  96%|█████████▌| 6777733/7086503 [1:47:35<01:57, 2627.76it/s]读取数据:  96%|█████████▌| 6778004/7086503 [1:47:35<01:56, 2651.82it/s]读取数据:  96%|█████████▌| 6778279/7086503 [1:47:35<01:55, 2677.66it/s]读取数据:  96%|█████████▌| 6778561/7086503 [1:47:35<01:53, 2720.00it/s]读取数据:  96%|█████████▌| 6778834/7086503 [1:47:35<01:53, 2706.33it/s]读取数据:  96%|█████████▌| 6779116/7086503 [1:47:35<01:52, 2739.91it/s]读取数据:  96%|█████████▌| 6779391/7086503 [1:47:36<01:54, 2692.99it/s]读取数据:  96%|█████████▌| 6779666/7086503 [1:47:36<01:53, 2704.04it/s]读取数据:  96%|█████████▌| 6779937/7086503 [1:47:36<01:54, 2679.12it/s]读取数据:  96%|█████████▌| 6780206/7086503 [1:47:36<01:56, 2626.21it/s]读取数据:  96%|█████████▌| 6780469/7086503 [1:47:36<02:03, 2469.67it/s]读取数据:  96%|█████████▌| 6780746/7086503 [1:47:36<01:59, 2554.03it/s]读取数据:  96%|█████████▌| 6781006/7086503 [1:47:36<01:59, 2567.10it/s]读取数据:  96%|█████████▌| 6781288/7086503 [1:47:36<01:55, 2639.44it/s]读取数据:  96%|█████████▌| 6781556/7086503 [1:47:36<01:55, 2648.56it/s]读取数据:  96%|█████████▌| 6781824/7086503 [1:47:36<01:54, 2652.70it/s]读取数据:  96%|█████████▌| 6782090/7086503 [1:47:37<02:01, 2513.38it/s]读取数据:  96%|█████████▌| 6782381/7086503 [1:47:37<01:55, 2624.76it/s]读取数据:  96%|█████████▌| 6782646/7086503 [1:47:37<02:01, 2497.29it/s]读取数据:  96%|█████████▌| 6782910/7086503 [1:47:37<01:59, 2532.30it/s]读取数据:  96%|█████████▌| 6783194/7086503 [1:47:37<01:55, 2617.83it/s]读取数据:  96%|█████████▌| 6783465/7086503 [1:47:37<01:54, 2644.14it/s]读取数据:  96%|█████████▌| 6783742/7086503 [1:47:37<01:52, 2679.39it/s]读取数据:  96%|█████████▌| 6784015/7086503 [1:47:37<01:52, 2688.43it/s]读取数据:  96%|█████████▌| 6784285/7086503 [1:47:37<01:53, 2672.33it/s]读取数据:  96%|█████████▌| 6784563/7086503 [1:47:38<01:51, 2696.25it/s]读取数据:  96%|█████████▌| 6784835/7086503 [1:47:38<01:51, 2695.85it/s]读取数据:  96%|█████████▌| 6785105/7086503 [1:47:38<01:53, 2644.01it/s]读取数据:  96%|█████████▌| 6785375/7086503 [1:47:38<01:53, 2658.56it/s]读取数据:  96%|█████████▌| 6785664/7086503 [1:47:38<01:50, 2726.48it/s]读取数据:  96%|█████████▌| 6785952/7086503 [1:47:38<01:48, 2772.00it/s]读取数据:  96%|█████████▌| 6786230/7086503 [1:47:38<01:48, 2758.38it/s]读取数据:  96%|█████████▌| 6786526/7086503 [1:47:38<01:46, 2814.83it/s]读取数据:  96%|█████████▌| 6786808/7086503 [1:47:38<01:55, 2595.88it/s]读取数据:  96%|█████████▌| 6787092/7086503 [1:47:38<01:52, 2664.60it/s]读取数据:  96%|█████████▌| 6787364/7086503 [1:47:39<01:51, 2680.02it/s]读取数据:  96%|█████████▌| 6787646/7086503 [1:47:39<01:49, 2717.79it/s]读取数据:  96%|█████████▌| 6787920/7086503 [1:47:39<01:50, 2713.90it/s]读取数据:  96%|█████████▌| 6788197/7086503 [1:47:39<01:49, 2728.95it/s]读取数据:  96%|█████████▌| 6788481/7086503 [1:47:39<01:47, 2760.58it/s]读取数据:  96%|█████████▌| 6788758/7086503 [1:47:39<01:47, 2763.00it/s]读取数据:  96%|█████████▌| 6789040/7086503 [1:47:39<01:47, 2777.68it/s]读取数据:  96%|█████████▌| 6789319/7086503 [1:47:39<01:47, 2777.26it/s]读取数据:  96%|█████████▌| 6789605/7086503 [1:47:39<01:46, 2800.61it/s]读取数据:  96%|█████████▌| 6789886/7086503 [1:47:39<01:54, 2583.47it/s]读取数据:  96%|█████████▌| 6790164/7086503 [1:47:40<01:52, 2636.44it/s]读取数据:  96%|█████████▌| 6790434/7086503 [1:47:40<01:51, 2650.77it/s]读取数据:  96%|█████████▌| 6790714/7086503 [1:47:40<01:49, 2692.62it/s]读取数据:  96%|█████████▌| 6790996/7086503 [1:47:40<01:48, 2729.52it/s]读取数据:  96%|█████████▌| 6791274/7086503 [1:47:40<01:47, 2743.32it/s]读取数据:  96%|█████████▌| 6791560/7086503 [1:47:40<01:46, 2776.50it/s]读取数据:  96%|█████████▌| 6791856/7086503 [1:47:40<01:44, 2826.16it/s]读取数据:  96%|█████████▌| 6792141/7086503 [1:47:40<01:43, 2832.75it/s]读取数据:  96%|█████████▌| 6792433/7086503 [1:47:40<01:42, 2858.01it/s]读取数据:  96%|█████████▌| 6792720/7086503 [1:47:40<01:43, 2841.62it/s]读取数据:  96%|█████████▌| 6793012/7086503 [1:47:41<01:42, 2860.00it/s]读取数据:  96%|█████████▌| 6793299/7086503 [1:47:41<01:44, 2800.63it/s]读取数据:  96%|█████████▌| 6793590/7086503 [1:47:41<01:43, 2828.87it/s]读取数据:  96%|█████████▌| 6793874/7086503 [1:47:41<01:43, 2820.80it/s]读取数据:  96%|█████████▌| 6794171/7086503 [1:47:41<01:42, 2863.22it/s]读取数据:  96%|█████████▌| 6794458/7086503 [1:47:41<01:42, 2842.38it/s]读取数据:  96%|█████████▌| 6794753/7086503 [1:47:41<01:41, 2870.91it/s]读取数据:  96%|█████████▌| 6795041/7086503 [1:47:41<01:43, 2820.69it/s]读取数据:  96%|█████████▌| 6795324/7086503 [1:47:42<06:14, 777.75it/s] 读取数据:  96%|█████████▌| 6795531/7086503 [1:47:43<06:16, 772.81it/s]读取数据:  96%|█████████▌| 6795699/7086503 [1:47:43<06:05, 795.49it/s]读取数据:  96%|█████████▌| 6795843/7086503 [1:47:43<08:44, 554.42it/s]读取数据:  96%|█████████▌| 6795952/7086503 [1:47:44<09:20, 518.01it/s]读取数据:  96%|█████████▌| 6796092/7086503 [1:47:44<07:51, 615.56it/s]读取数据:  96%|█████████▌| 6796196/7086503 [1:47:44<07:15, 666.09it/s]读取数据:  96%|█████████▌| 6796349/7086503 [1:47:44<06:00, 804.80it/s]读取数据:  96%|█████████▌| 6796466/7086503 [1:47:44<06:45, 715.64it/s]读取数据:  96%|█████████▌| 6796564/7086503 [1:47:44<07:59, 604.44it/s]读取数据:  96%|█████████▌| 6796645/7086503 [1:47:45<08:50, 546.52it/s]读取数据:  96%|█████████▌| 6796735/7086503 [1:47:45<08:17, 582.61it/s]读取数据:  96%|█████████▌| 6796805/7086503 [1:47:45<09:08, 528.38it/s]读取数据:  96%|█████████▌| 6796992/7086503 [1:47:45<06:08, 785.40it/s]读取数据:  96%|█████████▌| 6797145/7086503 [1:47:45<05:17, 910.82it/s]读取数据:  96%|█████████▌| 6797253/7086503 [1:47:45<05:53, 818.38it/s]读取数据:  96%|█████████▌| 6797375/7086503 [1:47:45<05:18, 906.41it/s]读取数据:  96%|█████████▌| 6797478/7086503 [1:47:45<05:30, 874.45it/s]读取数据:  96%|█████████▌| 6797652/7086503 [1:47:46<04:26, 1083.24it/s]读取数据:  96%|█████████▌| 6797772/7086503 [1:47:46<07:17, 660.61it/s] 读取数据:  96%|█████████▌| 6797866/7086503 [1:47:46<09:53, 486.18it/s]读取数据:  96%|█████████▌| 6797957/7086503 [1:47:46<08:45, 548.76it/s]读取数据:  96%|█████████▌| 6798171/7086503 [1:47:47<06:27, 743.24it/s]读取数据:  96%|█████████▌| 6798265/7086503 [1:47:47<07:59, 601.42it/s]读取数据:  96%|█████████▌| 6798342/7086503 [1:47:47<09:15, 518.42it/s]读取数据:  96%|█████████▌| 6798420/7086503 [1:47:47<08:33, 561.34it/s]读取数据:  96%|█████████▌| 6798488/7086503 [1:47:47<08:56, 536.43it/s]读取数据:  96%|█████████▌| 6798550/7086503 [1:47:47<09:44, 492.67it/s]读取数据:  96%|█████████▌| 6798605/7086503 [1:47:48<09:37, 498.63it/s]读取数据:  96%|█████████▌| 6798659/7086503 [1:47:48<09:35, 500.59it/s]读取数据:  96%|█████████▌| 6798719/7086503 [1:47:48<09:10, 522.53it/s]读取数据:  96%|█████████▌| 6798786/7086503 [1:47:48<09:09, 523.44it/s]读取数据:  96%|█████████▌| 6798850/7086503 [1:47:48<08:42, 551.00it/s]读取数据:  96%|█████████▌| 6798909/7086503 [1:47:48<10:00, 479.00it/s]读取数据:  96%|█████████▌| 6798992/7086503 [1:47:48<08:30, 563.42it/s]读取数据:  96%|█████████▌| 6799058/7086503 [1:47:48<08:37, 555.81it/s]读取数据:  96%|█████████▌| 6799117/7086503 [1:47:49<10:08, 472.10it/s]读取数据:  96%|█████████▌| 6799168/7086503 [1:47:49<12:05, 396.03it/s]读取数据:  96%|█████████▌| 6799212/7086503 [1:47:49<12:32, 381.71it/s]读取数据:  96%|█████████▌| 6799253/7086503 [1:47:49<12:51, 372.22it/s]读取数据:  96%|█████████▌| 6799296/7086503 [1:47:49<12:25, 385.49it/s]读取数据:  96%|█████████▌| 6799417/7086503 [1:47:49<08:13, 581.62it/s]读取数据:  96%|█████████▌| 6799479/7086503 [1:47:49<10:05, 474.40it/s]读取数据:  96%|█████████▌| 6799532/7086503 [1:47:50<11:59, 398.94it/s]读取数据:  96%|█████████▌| 6799643/7086503 [1:47:50<08:42, 549.36it/s]读取数据:  96%|█████████▌| 6799862/7086503 [1:47:50<05:08, 929.54it/s]读取数据:  96%|█████████▌| 6800000/7086503 [1:47:51<16:36, 287.62it/s]读取数据:  96%|█████████▌| 6800082/7086503 [1:47:51<18:22, 259.72it/s]读取数据:  96%|█████████▌| 6800223/7086503 [1:47:51<13:08, 363.29it/s]读取数据:  96%|█████████▌| 6800362/7086503 [1:47:52<09:56, 479.91it/s]读取数据:  96%|█████████▌| 6800496/7086503 [1:47:52<07:56, 599.96it/s]读取数据:  96%|█████████▌| 6800624/7086503 [1:47:52<06:41, 712.71it/s]读取数据:  96%|█████████▌| 6800763/7086503 [1:47:52<05:39, 842.36it/s]读取数据:  96%|█████████▌| 6800904/7086503 [1:47:52<04:56, 963.37it/s]读取数据:  96%|█████████▌| 6801044/7086503 [1:47:52<04:28, 1065.09it/s]读取数据:  96%|█████████▌| 6801179/7086503 [1:47:52<04:11, 1132.69it/s]读取数据:  96%|█████████▌| 6801317/7086503 [1:47:52<03:58, 1197.41it/s]读取数据:  96%|█████████▌| 6801464/7086503 [1:47:52<03:44, 1270.80it/s]读取数据:  96%|█████████▌| 6801610/7086503 [1:47:53<03:35, 1321.55it/s]读取数据:  96%|█████████▌| 6801752/7086503 [1:47:53<03:31, 1348.42it/s]读取数据:  96%|█████████▌| 6801893/7086503 [1:47:53<03:29, 1356.78it/s]读取数据:  96%|█████████▌| 6802043/7086503 [1:47:53<03:23, 1396.05it/s]读取数据:  96%|█████████▌| 6802205/7086503 [1:47:53<03:14, 1461.36it/s]读取数据:  96%|█████████▌| 6802354/7086503 [1:47:53<03:15, 1453.52it/s]读取数据:  96%|█████████▌| 6802501/7086503 [1:47:53<03:22, 1399.51it/s]读取数据:  96%|█████████▌| 6802643/7086503 [1:47:53<03:28, 1362.87it/s]读取数据:  96%|█████████▌| 6802781/7086503 [1:47:53<03:28, 1360.45it/s]读取数据:  96%|█████████▌| 6802918/7086503 [1:47:53<03:30, 1349.60it/s]读取数据:  96%|█████████▌| 6803069/7086503 [1:47:54<03:23, 1393.82it/s]读取数据:  96%|█████████▌| 6803219/7086503 [1:47:54<03:19, 1423.37it/s]读取数据:  96%|█████████▌| 6803362/7086503 [1:47:54<03:20, 1414.29it/s]读取数据:  96%|█████████▌| 6803505/7086503 [1:47:54<03:19, 1415.15it/s]读取数据:  96%|█████████▌| 6803647/7086503 [1:47:54<03:20, 1411.18it/s]读取数据:  96%|█████████▌| 6803798/7086503 [1:47:54<03:16, 1440.20it/s]读取数据:  96%|█████████▌| 6803944/7086503 [1:47:54<03:15, 1445.76it/s]读取数据:  96%|█████████▌| 6804089/7086503 [1:47:54<03:19, 1414.97it/s]读取数据:  96%|█████████▌| 6804235/7086503 [1:47:54<03:17, 1427.46it/s]读取数据:  96%|█████████▌| 6804378/7086503 [1:47:54<03:22, 1391.31it/s]读取数据:  96%|█████████▌| 6804525/7086503 [1:47:55<03:20, 1409.34it/s]读取数据:  96%|█████████▌| 6804685/7086503 [1:47:55<03:12, 1464.62it/s]读取数据:  96%|█████████▌| 6804835/7086503 [1:47:55<03:11, 1472.44it/s]读取数据:  96%|█████████▌| 6804983/7086503 [1:47:55<03:11, 1469.25it/s]读取数据:  96%|█████████▌| 6805146/7086503 [1:47:55<03:05, 1513.37it/s]读取数据:  96%|█████████▌| 6805304/7086503 [1:47:55<03:04, 1527.82it/s]读取数据:  96%|█████████▌| 6805457/7086503 [1:47:55<03:04, 1521.62it/s]读取数据:  96%|█████████▌| 6805610/7086503 [1:47:55<03:06, 1507.91it/s]读取数据:  96%|█████████▌| 6805767/7086503 [1:47:55<03:04, 1525.39it/s]读取数据:  96%|█████████▌| 6805920/7086503 [1:47:55<03:05, 1509.70it/s]读取数据:  96%|█████████▌| 6806072/7086503 [1:47:56<03:10, 1470.30it/s]读取数据:  96%|█████████▌| 6806230/7086503 [1:47:56<03:06, 1500.86it/s]读取数据:  96%|█████████▌| 6806388/7086503 [1:47:56<03:03, 1522.66it/s]读取数据:  96%|█████████▌| 6806541/7086503 [1:47:56<03:08, 1485.23it/s]读取数据:  96%|█████████▌| 6806698/7086503 [1:47:56<03:05, 1508.33it/s]读取数据:  96%|█████████▌| 6806855/7086503 [1:47:56<03:03, 1526.41it/s]读取数据:  96%|█████████▌| 6807008/7086503 [1:47:56<03:05, 1508.01it/s]读取数据:  96%|█████████▌| 6807159/7086503 [1:47:56<03:07, 1490.25it/s]读取数据:  96%|█████████▌| 6807313/7086503 [1:47:56<03:05, 1502.09it/s]读取数据:  96%|█████████▌| 6807478/7086503 [1:47:57<03:00, 1544.13it/s]读取数据:  96%|█████████▌| 6807641/7086503 [1:47:57<02:57, 1568.87it/s]读取数据:  96%|█████████▌| 6807808/7086503 [1:47:57<02:54, 1598.24it/s]读取数据:  96%|█████████▌| 6807968/7086503 [1:47:57<02:57, 1573.15it/s]读取数据:  96%|█████████▌| 6808126/7086503 [1:47:57<02:58, 1558.78it/s]读取数据:  96%|█████████▌| 6808283/7086503 [1:47:57<02:58, 1560.52it/s]读取数据:  96%|█████████▌| 6808441/7086503 [1:47:57<02:57, 1565.30it/s]读取数据:  96%|█████████▌| 6808615/7086503 [1:47:57<02:51, 1616.46it/s]读取数据:  96%|█████████▌| 6808777/7086503 [1:47:57<02:55, 1581.43it/s]读取数据:  96%|█████████▌| 6808938/7086503 [1:47:57<02:54, 1588.43it/s]读取数据:  96%|█████████▌| 6809098/7086503 [1:47:58<03:00, 1534.19it/s]读取数据:  96%|█████████▌| 6809254/7086503 [1:47:58<03:00, 1538.69it/s]读取数据:  96%|█████████▌| 6809409/7086503 [1:47:58<03:00, 1534.41it/s]读取数据:  96%|█████████▌| 6809571/7086503 [1:47:58<02:58, 1554.66it/s]读取数据:  96%|█████████▌| 6809727/7086503 [1:47:58<03:01, 1525.78it/s]读取数据:  96%|█████████▌| 6809889/7086503 [1:47:58<02:58, 1550.67it/s]读取数据:  96%|█████████▌| 6810045/7086503 [1:47:58<03:00, 1532.80it/s]读取数据:  96%|█████████▌| 6810199/7086503 [1:47:58<03:00, 1533.43it/s]读取数据:  96%|█████████▌| 6810357/7086503 [1:47:58<02:58, 1546.30it/s]读取数据:  96%|█████████▌| 6810533/7086503 [1:47:58<02:51, 1607.55it/s]读取数据:  96%|█████████▌| 6810694/7086503 [1:47:59<02:51, 1604.35it/s]读取数据:  96%|█████████▌| 6810866/7086503 [1:47:59<02:48, 1637.42it/s]读取数据:  96%|█████████▌| 6811049/7086503 [1:47:59<02:42, 1692.64it/s]读取数据:  96%|█████████▌| 6811219/7086503 [1:47:59<02:46, 1650.26it/s]读取数据:  96%|█████████▌| 6811385/7086503 [1:47:59<02:51, 1604.08it/s]读取数据:  96%|█████████▌| 6811546/7086503 [1:47:59<02:53, 1587.85it/s]读取数据:  96%|█████████▌| 6811719/7086503 [1:47:59<02:48, 1627.57it/s]读取数据:  96%|█████████▌| 6811888/7086503 [1:47:59<02:46, 1645.68it/s]读取数据:  96%|█████████▌| 6812053/7086503 [1:47:59<02:47, 1639.67it/s]读取数据:  96%|█████████▌| 6812226/7086503 [1:47:59<02:45, 1660.85it/s]读取数据:  96%|█████████▌| 6812393/7086503 [1:48:00<02:46, 1649.00it/s]读取数据:  96%|█████████▌| 6812559/7086503 [1:48:00<02:48, 1630.03it/s]读取数据:  96%|█████████▌| 6812729/7086503 [1:48:00<02:45, 1650.10it/s]读取数据:  96%|█████████▌| 6812912/7086503 [1:48:00<02:40, 1702.66it/s]读取数据:  96%|█████████▌| 6813083/7086503 [1:48:00<02:42, 1683.96it/s]读取数据:  96%|█████████▌| 6813264/7086503 [1:48:00<02:38, 1720.86it/s]读取数据:  96%|█████████▌| 6813437/7086503 [1:48:00<02:39, 1712.26it/s]读取数据:  96%|█████████▌| 6813609/7086503 [1:48:00<02:39, 1707.52it/s]读取数据:  96%|█████████▌| 6813784/7086503 [1:48:00<02:39, 1709.79it/s]读取数据:  96%|█████████▌| 6813959/7086503 [1:48:01<02:38, 1718.48it/s]读取数据:  96%|█████████▌| 6814131/7086503 [1:48:01<02:40, 1694.31it/s]读取数据:  96%|█████████▌| 6814311/7086503 [1:48:01<02:37, 1724.93it/s]读取数据:  96%|█████████▌| 6814485/7086503 [1:48:01<02:37, 1728.11it/s]读取数据:  96%|█████████▌| 6814662/7086503 [1:48:01<02:36, 1740.39it/s]读取数据:  96%|█████████▌| 6814837/7086503 [1:48:01<02:35, 1741.86it/s]读取数据:  96%|█████████▌| 6815012/7086503 [1:48:01<02:35, 1742.86it/s]读取数据:  96%|█████████▌| 6815187/7086503 [1:48:01<02:35, 1741.67it/s]读取数据:  96%|█████████▌| 6815366/7086503 [1:48:01<02:34, 1751.07it/s]读取数据:  96%|█████████▌| 6815542/7086503 [1:48:01<02:36, 1734.18it/s]读取数据:  96%|█████████▌| 6815736/7086503 [1:48:02<02:30, 1794.40it/s]读取数据:  96%|█████████▌| 6815916/7086503 [1:48:02<02:32, 1771.83it/s]读取数据:  96%|█████████▌| 6816097/7086503 [1:48:02<02:31, 1781.53it/s]读取数据:  96%|█████████▌| 6816291/7086503 [1:48:02<02:27, 1827.93it/s]读取数据:  96%|█████████▌| 6816474/7086503 [1:48:02<02:28, 1823.36it/s]读取数据:  96%|█████████▌| 6816657/7086503 [1:48:02<02:28, 1812.40it/s]读取数据:  96%|█████████▌| 6816842/7086503 [1:48:02<02:28, 1821.84it/s]读取数据:  96%|█████████▌| 6817025/7086503 [1:48:02<02:29, 1801.86it/s]读取数据:  96%|█████████▌| 6817209/7086503 [1:48:02<02:28, 1809.46it/s]读取数据:  96%|█████████▌| 6817397/7086503 [1:48:02<02:27, 1829.63it/s]读取数据:  96%|█████████▌| 6817585/7086503 [1:48:03<02:26, 1837.03it/s]读取数据:  96%|█████████▌| 6817778/7086503 [1:48:03<02:24, 1862.25it/s]读取数据:  96%|█████████▌| 6817965/7086503 [1:48:03<02:25, 1848.11it/s]读取数据:  96%|█████████▌| 6818155/7086503 [1:48:03<02:24, 1858.84it/s]读取数据:  96%|█████████▌| 6818385/7086503 [1:48:03<02:14, 1989.59it/s]读取数据:  96%|█████████▌| 6818855/7086503 [1:48:03<01:35, 2795.62it/s]读取数据:  96%|█████████▌| 6819280/7086503 [1:48:03<01:22, 3229.31it/s]读取数据:  96%|█████████▌| 6819786/7086503 [1:48:03<01:10, 3774.70it/s]读取数据:  96%|█████████▌| 6820262/7086503 [1:48:03<01:05, 4068.49it/s]读取数据:  96%|█████████▋| 6820774/7086503 [1:48:03<01:00, 4379.61it/s]读取数据:  96%|█████████▋| 6821273/7086503 [1:48:04<00:58, 4561.30it/s]读取数据:  96%|█████████▋| 6821749/7086503 [1:48:04<00:57, 4620.09it/s]读取数据:  96%|█████████▋| 6822263/7086503 [1:48:04<00:55, 4775.47it/s]读取数据:  96%|█████████▋| 6822764/7086503 [1:48:04<00:54, 4842.14it/s]读取数据:  96%|█████████▋| 6823276/7086503 [1:48:04<00:53, 4925.07it/s]读取数据:  96%|█████████▋| 6823806/7086503 [1:48:04<00:52, 5036.69it/s]读取数据:  96%|█████████▋| 6824310/7086503 [1:48:04<00:52, 4958.59it/s]读取数据:  96%|█████████▋| 6824842/7086503 [1:48:04<00:51, 5062.65it/s]读取数据:  96%|█████████▋| 6825368/7086503 [1:48:04<00:50, 5120.80it/s]读取数据:  96%|█████████▋| 6825913/7086503 [1:48:04<00:49, 5216.80it/s]读取数据:  96%|█████████▋| 6826465/7086503 [1:48:05<00:49, 5305.67it/s]读取数据:  96%|█████████▋| 6827008/7086503 [1:48:05<00:48, 5340.75it/s]读取数据:  96%|█████████▋| 6827545/7086503 [1:48:05<00:48, 5343.66it/s]读取数据:  96%|█████████▋| 6828126/7086503 [1:48:05<00:47, 5480.77it/s]读取数据:  96%|█████████▋| 6828706/7086503 [1:48:05<00:46, 5574.76it/s]读取数据:  96%|█████████▋| 6829275/7086503 [1:48:05<00:45, 5608.46it/s]读取数据:  96%|█████████▋| 6829896/7086503 [1:48:05<00:44, 5785.37it/s]读取数据:  96%|█████████▋| 6830523/7086503 [1:48:05<00:43, 5929.94it/s]读取数据:  96%|█████████▋| 6831146/7086503 [1:48:05<00:42, 6016.97it/s]读取数据:  96%|█████████▋| 6831814/7086503 [1:48:05<00:40, 6214.31it/s]读取数据:  96%|█████████▋| 6832469/7086503 [1:48:06<00:40, 6314.07it/s]读取数据:  96%|█████████▋| 6833149/7086503 [1:48:06<00:39, 6456.45it/s]读取数据:  96%|█████████▋| 6833796/7086503 [1:48:06<00:39, 6459.20it/s]读取数据:  96%|█████████▋| 6834523/7086503 [1:48:06<00:37, 6699.88it/s]读取数据:  96%|█████████▋| 6835233/7086503 [1:48:06<00:36, 6818.03it/s]读取数据:  96%|█████████▋| 6835952/7086503 [1:48:06<00:36, 6926.23it/s]读取数据:  96%|█████████▋| 6836645/7086503 [1:48:06<00:38, 6429.36it/s]读取数据:  96%|█████████▋| 6837339/7086503 [1:48:06<00:37, 6573.98it/s]读取数据:  96%|█████████▋| 6838050/7086503 [1:48:06<00:36, 6728.36it/s]读取数据:  97%|█████████▋| 6838744/7086503 [1:48:06<00:36, 6787.23it/s]读取数据:  97%|█████████▋| 6839437/7086503 [1:48:07<00:36, 6826.74it/s]读取数据:  97%|█████████▋| 6840130/7086503 [1:48:07<00:35, 6855.73it/s]读取数据:  97%|█████████▋| 6840865/7086503 [1:48:07<00:35, 7001.22it/s]读取数据:  97%|█████████▋| 6841574/7086503 [1:48:07<00:34, 7027.48it/s]读取数据:  97%|█████████▋| 6842278/7086503 [1:48:07<00:34, 7020.15it/s]读取数据:  97%|█████████▋| 6842981/7086503 [1:48:07<00:34, 7022.16it/s]读取数据:  97%|█████████▋| 6843684/7086503 [1:48:07<00:35, 6892.53it/s]读取数据:  97%|█████████▋| 6844375/7086503 [1:48:07<00:35, 6881.93it/s]读取数据:  97%|█████████▋| 6845094/7086503 [1:48:07<00:34, 6970.78it/s]读取数据:  97%|█████████▋| 6845796/7086503 [1:48:07<00:34, 6980.13it/s]读取数据:  97%|█████████▋| 6846512/7086503 [1:48:08<00:34, 7028.58it/s]读取数据:  97%|█████████▋| 6847216/7086503 [1:48:08<00:34, 6949.04it/s]读取数据:  97%|█████████▋| 6847912/7086503 [1:48:08<00:34, 6908.87it/s]读取数据:  97%|█████████▋| 6848604/7086503 [1:48:08<00:35, 6637.07it/s]读取数据:  97%|█████████▋| 6849280/7086503 [1:48:08<00:35, 6670.47it/s]读取数据:  97%|█████████▋| 6849949/7086503 [1:48:08<00:36, 6568.02it/s]读取数据:  97%|█████████▋| 6850608/7086503 [1:48:10<03:17, 1196.06it/s]读取数据:  97%|█████████▋| 6851209/7086503 [1:48:10<02:33, 1534.52it/s]读取数据:  97%|█████████▋| 6851760/7086503 [1:48:10<02:03, 1897.39it/s]读取数据:  97%|█████████▋| 6852384/7086503 [1:48:10<01:37, 2397.84it/s]读取数据:  97%|█████████▋| 6853002/7086503 [1:48:10<01:19, 2932.20it/s]读取数据:  97%|█████████▋| 6853642/7086503 [1:48:10<01:06, 3514.73it/s]读取数据:  97%|█████████▋| 6854284/7086503 [1:48:10<00:56, 4074.72it/s]读取数据:  97%|█████████▋| 6854906/7086503 [1:48:10<00:51, 4537.36it/s]读取数据:  97%|█████████▋| 6855517/7086503 [1:48:11<00:49, 4660.66it/s]读取数据:  97%|█████████▋| 6856095/7086503 [1:48:11<00:48, 4770.21it/s]读取数据:  97%|█████████▋| 6856656/7086503 [1:48:11<00:46, 4980.48it/s]读取数据:  97%|█████████▋| 6857214/7086503 [1:48:11<00:46, 4960.06it/s]读取数据:  97%|█████████▋| 6857752/7086503 [1:48:11<00:45, 5053.94it/s]读取数据:  97%|█████████▋| 6858336/7086503 [1:48:11<00:43, 5270.02it/s]读取数据:  97%|█████████▋| 6858910/7086503 [1:48:11<00:42, 5401.59it/s]读取数据:  97%|█████████▋| 6859499/7086503 [1:48:11<00:40, 5541.30it/s]读取数据:  97%|█████████▋| 6860066/7086503 [1:48:11<00:42, 5391.31it/s]读取数据:  97%|█████████▋| 6860615/7086503 [1:48:12<00:43, 5185.75it/s]读取数据:  97%|█████████▋| 6861142/7086503 [1:48:12<00:44, 5102.90it/s]读取数据:  97%|█████████▋| 6861658/7086503 [1:48:12<00:44, 5041.10it/s]读取数据:  97%|█████████▋| 6862183/7086503 [1:48:12<00:43, 5100.03it/s]读取数据:  97%|█████████▋| 6862696/7086503 [1:48:12<00:43, 5099.76it/s]读取数据:  97%|█████████▋| 6863231/7086503 [1:48:12<00:43, 5172.34it/s]读取数据:  97%|█████████▋| 6863773/7086503 [1:48:12<00:42, 5242.29it/s]读取数据:  97%|█████████▋| 6864331/7086503 [1:48:12<00:41, 5339.95it/s]读取数据:  97%|█████████▋| 6864885/7086503 [1:48:12<00:41, 5399.17it/s]读取数据:  97%|█████████▋| 6865429/7086503 [1:48:12<00:40, 5409.47it/s]读取数据:  97%|█████████▋| 6866032/7086503 [1:48:13<00:39, 5593.78it/s]读取数据:  97%|█████████▋| 6866616/7086503 [1:48:13<00:38, 5664.98it/s]读取数据:  97%|█████████▋| 6867212/7086503 [1:48:13<00:38, 5751.56it/s]读取数据:  97%|█████████▋| 6867788/7086503 [1:48:13<00:38, 5715.11it/s]读取数据:  97%|█████████▋| 6868396/7086503 [1:48:13<00:37, 5819.63it/s]读取数据:  97%|█████████▋| 6868979/7086503 [1:48:13<00:37, 5801.37it/s]读取数据:  97%|█████████▋| 6869560/7086503 [1:48:13<00:37, 5772.67it/s]读取数据:  97%|█████████▋| 6870163/7086503 [1:48:13<00:36, 5848.64it/s]读取数据:  97%|█████████▋| 6870763/7086503 [1:48:13<00:36, 5891.17it/s]读取数据:  97%|█████████▋| 6871364/7086503 [1:48:13<00:36, 5925.89it/s]读取数据:  97%|█████████▋| 6871964/7086503 [1:48:14<00:36, 5944.81it/s]读取数据:  97%|█████████▋| 6872559/7086503 [1:48:14<00:36, 5928.68it/s]读取数据:  97%|█████████▋| 6873152/7086503 [1:48:14<00:36, 5851.98it/s]读取数据:  97%|█████████▋| 6873775/7086503 [1:48:14<00:35, 5963.03it/s]读取数据:  97%|█████████▋| 6874372/7086503 [1:48:14<00:35, 5935.08it/s]读取数据:  97%|█████████▋| 6874966/7086503 [1:48:14<00:36, 5725.02it/s]读取数据:  97%|█████████▋| 6875541/7086503 [1:48:14<00:37, 5594.73it/s]读取数据:  97%|█████████▋| 6876102/7086503 [1:48:14<00:38, 5507.41it/s]读取数据:  97%|█████████▋| 6876654/7086503 [1:48:14<00:38, 5438.89it/s]读取数据:  97%|█████████▋| 6877199/7086503 [1:48:14<00:39, 5363.97it/s]读取数据:  97%|█████████▋| 6877750/7086503 [1:48:15<00:38, 5402.02it/s]读取数据:  97%|█████████▋| 6878300/7086503 [1:48:15<00:38, 5424.79it/s]读取数据:  97%|█████████▋| 6878850/7086503 [1:48:15<00:38, 5446.40it/s]读取数据:  97%|█████████▋| 6879415/7086503 [1:48:15<00:37, 5506.10it/s]读取数据:  97%|█████████▋| 6879966/7086503 [1:48:15<00:37, 5477.36it/s]读取数据:  97%|█████████▋| 6880514/7086503 [1:48:15<00:38, 5410.58it/s]读取数据:  97%|█████████▋| 6881070/7086503 [1:48:15<00:37, 5453.41it/s]读取数据:  97%|█████████▋| 6881616/7086503 [1:48:15<00:37, 5398.30it/s]读取数据:  97%|█████████▋| 6882167/7086503 [1:48:15<00:37, 5430.14it/s]读取数据:  97%|█████████▋| 6882711/7086503 [1:48:16<00:37, 5403.84it/s]读取数据:  97%|█████████▋| 6883252/7086503 [1:48:16<00:38, 5337.13it/s]读取数据:  97%|█████████▋| 6883786/7086503 [1:48:16<00:38, 5326.73it/s]读取数据:  97%|█████████▋| 6884337/7086503 [1:48:16<00:37, 5380.82it/s]读取数据:  97%|█████████▋| 6884876/7086503 [1:48:16<00:37, 5353.65it/s]读取数据:  97%|█████████▋| 6885421/7086503 [1:48:16<00:37, 5382.17it/s]读取数据:  97%|█████████▋| 6885960/7086503 [1:48:16<00:37, 5369.25it/s]读取数据:  97%|█████████▋| 6886498/7086503 [1:48:16<00:37, 5291.98it/s]读取数据:  97%|█████████▋| 6887028/7086503 [1:48:16<00:39, 5048.70it/s]读取数据:  97%|█████████▋| 6887536/7086503 [1:48:16<00:40, 4963.65it/s]读取数据:  97%|█████████▋| 6888034/7086503 [1:48:17<00:40, 4877.90it/s]读取数据:  97%|█████████▋| 6888523/7086503 [1:48:17<00:41, 4750.07it/s]读取数据:  97%|█████████▋| 6889000/7086503 [1:48:17<00:42, 4670.77it/s]读取数据:  97%|█████████▋| 6889468/7086503 [1:48:17<00:42, 4608.32it/s]读取数据:  97%|█████████▋| 6889930/7086503 [1:48:17<00:42, 4611.53it/s]读取数据:  97%|█████████▋| 6890410/7086503 [1:48:17<00:42, 4662.63it/s]读取数据:  97%|█████████▋| 6890892/7086503 [1:48:17<00:41, 4707.48it/s]读取数据:  97%|█████████▋| 6891380/7086503 [1:48:17<00:41, 4757.50it/s]读取数据:  97%|█████████▋| 6891943/7086503 [1:48:17<00:38, 5010.31it/s]读取数据:  97%|█████████▋| 6892491/7086503 [1:48:17<00:37, 5148.65it/s]读取数据:  97%|█████████▋| 6893007/7086503 [1:48:18<00:38, 4973.61it/s]读取数据:  97%|█████████▋| 6894160/7086503 [1:48:18<00:27, 6882.18it/s]读取数据:  97%|█████████▋| 6895223/7086503 [1:48:18<00:23, 7976.02it/s]读取数据:  97%|█████████▋| 6896226/7086503 [1:48:18<00:22, 8581.20it/s]读取数据:  97%|█████████▋| 6897252/7086503 [1:48:18<00:20, 9074.13it/s]读取数据:  97%|█████████▋| 6898223/7086503 [1:48:18<00:20, 9261.44it/s]读取数据:  97%|█████████▋| 6899180/7086503 [1:48:18<00:20, 9353.24it/s]读取数据:  97%|█████████▋| 6900118/7086503 [1:48:19<01:15, 2471.03it/s]读取数据:  97%|█████████▋| 6901152/7086503 [1:48:19<00:56, 3267.81it/s]读取数据:  97%|█████████▋| 6902320/7086503 [1:48:19<00:42, 4330.43it/s]读取数据:  97%|█████████▋| 6903553/7086503 [1:48:20<00:32, 5553.31it/s]读取数据:  97%|█████████▋| 6904747/7086503 [1:48:20<00:27, 6697.95it/s]读取数据:  97%|█████████▋| 6906090/7086503 [1:48:20<00:22, 8069.66it/s]读取数据:  97%|█████████▋| 6907537/7086503 [1:48:20<00:18, 9512.25it/s]读取数据:  97%|█████████▋| 6908940/7086503 [1:48:20<00:16, 10612.64it/s]读取数据:  98%|█████████▊| 6910325/7086503 [1:48:20<00:15, 11444.39it/s]读取数据:  98%|█████████▊| 6911976/7086503 [1:48:20<00:13, 12807.41it/s]读取数据:  98%|█████████▊| 6913650/7086503 [1:48:20<00:12, 13896.49it/s]读取数据:  98%|█████████▊| 6915294/7086503 [1:48:20<00:11, 14617.53it/s]读取数据:  98%|█████████▊| 6916952/7086503 [1:48:20<00:11, 15183.85it/s]读取数据:  98%|█████████▊| 6918526/7086503 [1:48:21<00:11, 14481.76it/s]读取数据:  98%|█████████▊| 6920020/7086503 [1:48:21<00:11, 13904.03it/s]读取数据:  98%|█████████▊| 6921446/7086503 [1:48:21<00:14, 11726.78it/s]读取数据:  98%|█████████▊| 6922696/7086503 [1:48:21<00:14, 11130.08it/s]读取数据:  98%|█████████▊| 6924040/7086503 [1:48:21<00:13, 11706.06it/s]读取数据:  98%|█████████▊| 6925417/7086503 [1:48:21<00:13, 12247.09it/s]读取数据:  98%|█████████▊| 6926888/7086503 [1:48:21<00:12, 12918.48it/s]读取数据:  98%|█████████▊| 6928504/7086503 [1:48:21<00:11, 13827.48it/s]读取数据:  98%|█████████▊| 6930040/7086503 [1:48:21<00:10, 14264.93it/s]读取数据:  98%|█████████▊| 6931691/7086503 [1:48:22<00:10, 14915.72it/s]读取数据:  98%|█████████▊| 6933239/7086503 [1:48:22<00:10, 15080.35it/s]读取数据:  98%|█████████▊| 6934761/7086503 [1:48:22<00:10, 14847.75it/s]读取数据:  98%|█████████▊| 6936301/7086503 [1:48:22<00:10, 15008.56it/s]读取数据:  98%|█████████▊| 6937810/7086503 [1:48:22<00:12, 12135.83it/s]读取数据:  98%|█████████▊| 6939117/7086503 [1:48:22<00:14, 10321.82it/s]读取数据:  98%|█████████▊| 6940252/7086503 [1:48:22<00:15, 9393.53it/s] 读取数据:  98%|█████████▊| 6941268/7086503 [1:48:23<00:16, 8849.95it/s]读取数据:  98%|█████████▊| 6942204/7086503 [1:48:23<00:17, 8448.77it/s]读取数据:  98%|█████████▊| 6943081/7086503 [1:48:23<00:17, 8165.35it/s]读取数据:  98%|█████████▊| 6943917/7086503 [1:48:23<00:17, 7953.60it/s]读取数据:  98%|█████████▊| 6944724/7086503 [1:48:23<00:18, 7749.28it/s]读取数据:  98%|█████████▊| 6945505/7086503 [1:48:23<00:18, 7608.21it/s]读取数据:  98%|█████████▊| 6946273/7086503 [1:48:23<00:18, 7625.10it/s]读取数据:  98%|█████████▊| 6947056/7086503 [1:48:23<00:18, 7670.92it/s]读取数据:  98%|█████████▊| 6947826/7086503 [1:48:23<00:19, 7295.78it/s]读取数据:  98%|█████████▊| 6948626/7086503 [1:48:24<00:18, 7489.97it/s]读取数据:  98%|█████████▊| 6949380/7086503 [1:48:24<00:19, 7069.15it/s]读取数据:  98%|█████████▊| 6950093/7086503 [1:48:25<01:04, 2129.32it/s]读取数据:  98%|█████████▊| 6950615/7086503 [1:48:25<00:56, 2395.59it/s]读取数据:  98%|█████████▊| 6951107/7086503 [1:48:25<00:50, 2679.25it/s]读取数据:  98%|█████████▊| 6951583/7086503 [1:48:25<00:45, 2993.15it/s]读取数据:  98%|█████████▊| 6952058/7086503 [1:48:25<00:40, 3287.62it/s]读取数据:  98%|█████████▊| 6952528/7086503 [1:48:25<00:37, 3547.97it/s]读取数据:  98%|█████████▊| 6953004/7086503 [1:48:25<00:34, 3817.99it/s]读取数据:  98%|█████████▊| 6953484/7086503 [1:48:25<00:32, 4054.24it/s]读取数据:  98%|█████████▊| 6953968/7086503 [1:48:25<00:31, 4255.54it/s]读取数据:  98%|█████████▊| 6954444/7086503 [1:48:26<00:30, 4390.36it/s]读取数据:  98%|█████████▊| 6954920/7086503 [1:48:26<00:29, 4437.67it/s]读取数据:  98%|█████████▊| 6955390/7086503 [1:48:26<00:29, 4459.77it/s]读取数据:  98%|█████████▊| 6955871/7086503 [1:48:26<00:28, 4555.11it/s]读取数据:  98%|█████████▊| 6956356/7086503 [1:48:26<00:28, 4639.74it/s]读取数据:  98%|█████████▊| 6956895/7086503 [1:48:26<00:26, 4848.15it/s]读取数据:  98%|█████████▊| 6957389/7086503 [1:48:26<00:26, 4874.82it/s]读取数据:  98%|█████████▊| 6957925/7086503 [1:48:26<00:25, 5018.20it/s]读取数据:  98%|█████████▊| 6958498/7086503 [1:48:26<00:24, 5227.36it/s]读取数据:  98%|█████████▊| 6959085/7086503 [1:48:26<00:23, 5418.00it/s]读取数据:  98%|█████████▊| 6959674/7086503 [1:48:27<00:22, 5557.44it/s]读取数据:  98%|█████████▊| 6960310/7086503 [1:48:27<00:21, 5797.08it/s]读取数据:  98%|█████████▊| 6960945/7086503 [1:48:27<00:21, 5960.30it/s]读取数据:  98%|█████████▊| 6961593/7086503 [1:48:27<00:20, 6112.52it/s]读取数据:  98%|█████████▊| 6962279/7086503 [1:48:27<00:19, 6335.62it/s]读取数据:  98%|█████████▊| 6962982/7086503 [1:48:27<00:18, 6542.04it/s]读取数据:  98%|█████████▊| 6963712/7086503 [1:48:27<00:18, 6767.20it/s]读取数据:  98%|█████████▊| 6964451/7086503 [1:48:27<00:17, 6953.01it/s]读取数据:  98%|█████████▊| 6965196/7086503 [1:48:27<00:17, 7101.03it/s]读取数据:  98%|█████████▊| 6965928/7086503 [1:48:27<00:16, 7166.35it/s]读取数据:  98%|█████████▊| 6966645/7086503 [1:48:28<00:16, 7105.44it/s]读取数据:  98%|█████████▊| 6967356/7086503 [1:48:28<00:16, 7086.59it/s]读取数据:  98%|█████████▊| 6968065/7086503 [1:48:28<00:16, 7047.91it/s]读取数据:  98%|█████████▊| 6968770/7086503 [1:48:28<00:16, 6994.59it/s]读取数据:  98%|█████████▊| 6969470/7086503 [1:48:28<00:16, 6924.84it/s]读取数据:  98%|█████████▊| 6970183/7086503 [1:48:28<00:16, 6984.37it/s]读取数据:  98%|█████████▊| 6970882/7086503 [1:48:28<00:16, 6968.32it/s]读取数据:  98%|█████████▊| 6971583/7086503 [1:48:28<00:16, 6980.26it/s]读取数据:  98%|█████████▊| 6972282/7086503 [1:48:28<00:16, 6978.77it/s]读取数据:  98%|█████████▊| 6972982/7086503 [1:48:28<00:16, 6984.03it/s]读取数据:  98%|█████████▊| 6973690/7086503 [1:48:29<00:16, 7010.42it/s]读取数据:  98%|█████████▊| 6974404/7086503 [1:48:29<00:15, 7048.20it/s]读取数据:  98%|█████████▊| 6975130/7086503 [1:48:29<00:15, 7111.33it/s]读取数据:  98%|█████████▊| 6975842/7086503 [1:48:29<00:15, 7107.46it/s]读取数据:  98%|█████████▊| 6976555/7086503 [1:48:29<00:15, 7113.61it/s]读取数据:  98%|█████████▊| 6977281/7086503 [1:48:29<00:15, 7155.43it/s]读取数据:  98%|█████████▊| 6977997/7086503 [1:48:29<00:15, 7123.14it/s]读取数据:  98%|█████████▊| 6978710/7086503 [1:48:29<00:15, 7064.99it/s]读取数据:  98%|█████████▊| 6979417/7086503 [1:48:29<00:15, 6999.03it/s]读取数据:  98%|█████████▊| 6980118/7086503 [1:48:29<00:16, 6549.93it/s]读取数据:  99%|█████████▊| 6980779/7086503 [1:48:30<00:16, 6330.12it/s]读取数据:  99%|█████████▊| 6981446/7086503 [1:48:30<00:16, 6425.43it/s]读取数据:  99%|█████████▊| 6982160/7086503 [1:48:30<00:15, 6629.38it/s]读取数据:  99%|█████████▊| 6982882/7086503 [1:48:30<00:15, 6799.67it/s]读取数据:  99%|█████████▊| 6983577/7086503 [1:48:30<00:15, 6842.71it/s]读取数据:  99%|█████████▊| 6984295/7086503 [1:48:30<00:14, 6941.57it/s]读取数据:  99%|█████████▊| 6984996/7086503 [1:48:30<00:14, 6957.38it/s]读取数据:  99%|█████████▊| 6985693/7086503 [1:48:30<00:15, 6495.67it/s]读取数据:  99%|█████████▊| 6986367/7086503 [1:48:30<00:15, 6560.68it/s]读取数据:  99%|█████████▊| 6987051/7086503 [1:48:31<00:14, 6639.51it/s]读取数据:  99%|█████████▊| 6987769/7086503 [1:48:31<00:14, 6795.97it/s]读取数据:  99%|█████████▊| 6988455/7086503 [1:48:31<00:14, 6813.65it/s]读取数据:  99%|█████████▊| 6989167/7086503 [1:48:31<00:14, 6902.66it/s]读取数据:  99%|█████████▊| 6989859/7086503 [1:48:31<00:15, 6319.43it/s]读取数据:  99%|█████████▊| 6990502/7086503 [1:48:31<00:15, 6149.47it/s]读取数据:  99%|█████████▊| 6991229/7086503 [1:48:31<00:14, 6461.30it/s]读取数据:  99%|█████████▊| 6991915/7086503 [1:48:31<00:14, 6573.93it/s]读取数据:  99%|█████████▊| 6992612/7086503 [1:48:31<00:14, 6687.04it/s]读取数据:  99%|█████████▊| 6993292/7086503 [1:48:31<00:13, 6717.34it/s]读取数据:  99%|█████████▊| 6993967/7086503 [1:48:32<00:13, 6660.67it/s]读取数据:  99%|█████████▊| 6994636/7086503 [1:48:32<00:13, 6662.81it/s]读取数据:  99%|█████████▊| 6995307/7086503 [1:48:32<00:13, 6675.52it/s]读取数据:  99%|█████████▊| 6996000/7086503 [1:48:32<00:13, 6748.92it/s]读取数据:  99%|█████████▊| 6996676/7086503 [1:48:32<00:13, 6729.32it/s]读取数据:  99%|█████████▊| 6997350/7086503 [1:48:32<00:13, 6616.81it/s]读取数据:  99%|█████████▉| 6998014/7086503 [1:48:32<00:13, 6623.14it/s]读取数据:  99%|█████████▉| 6998677/7086503 [1:48:32<00:13, 6539.52it/s]读取数据:  99%|█████████▉| 6999388/7086503 [1:48:32<00:12, 6706.78it/s]读取数据:  99%|█████████▉| 6999388/7086503 [1:48:48<00:12, 6706.78it/s]读取数据:  99%|█████████▉| 7000000/7086503 [1:59:26<7:07:23,  3.37it/s]读取数据:  99%|█████████▉| 7000534/7086503 [1:59:26<5:15:39,  4.54it/s]读取数据:  99%|█████████▉| 7001164/7086503 [1:59:26<3:38:42,  6.50it/s]读取数据:  99%|█████████▉| 7001780/7086503 [1:59:26<2:32:44,  9.24it/s]读取数据:  99%|█████████▉| 7002454/7086503 [1:59:26<1:43:34, 13.53it/s]读取数据:  99%|█████████▉| 7003153/7086503 [1:59:26<1:09:57, 19.86it/s]读取数据:  99%|█████████▉| 7003849/7086503 [1:59:26<47:45, 28.85it/s]  读取数据:  99%|█████████▉| 7004533/7086503 [1:59:27<32:58, 41.43it/s]读取数据:  99%|█████████▉| 7005290/7086503 [1:59:27<22:06, 61.24it/s]读取数据:  99%|█████████▉| 7005986/7086503 [1:59:27<15:24, 87.07it/s]读取数据:  99%|█████████▉| 7006720/7086503 [1:59:27<10:34, 125.66it/s]读取数据:  99%|█████████▉| 7007464/7086503 [1:59:27<07:17, 180.84it/s]读取数据:  99%|█████████▉| 7008181/7086503 [1:59:27<05:06, 255.25it/s]读取数据:  99%|█████████▉| 7008907/7086503 [1:59:27<03:35, 360.30it/s]读取数据:  99%|█████████▉| 7009621/7086503 [1:59:27<02:33, 502.49it/s]读取数据:  99%|█████████▉| 7010335/7086503 [1:59:27<01:49, 694.41it/s]读取数据:  99%|█████████▉| 7011058/7086503 [1:59:28<01:19, 954.74it/s]读取数据:  99%|█████████▉| 7011770/7086503 [1:59:28<00:58, 1286.62it/s]读取数据:  99%|█████████▉| 7012490/7086503 [1:59:28<00:43, 1708.90it/s]读取数据:  99%|█████████▉| 7013301/7086503 [1:59:28<00:31, 2301.16it/s]读取数据:  99%|█████████▉| 7014113/7086503 [1:59:28<00:24, 2980.58it/s]读取数据:  99%|█████████▉| 7014959/7086503 [1:59:28<00:19, 3763.62it/s]读取数据:  99%|█████████▉| 7015834/7086503 [1:59:28<00:15, 4608.42it/s]读取数据:  99%|█████████▉| 7016691/7086503 [1:59:28<00:12, 5380.45it/s]读取数据:  99%|█████████▉| 7017618/7086503 [1:59:28<00:11, 6227.28it/s]读取数据:  99%|█████████▉| 7018475/7086503 [1:59:28<00:10, 6631.31it/s]读取数据:  99%|█████████▉| 7019309/7086503 [1:59:29<00:09, 6881.56it/s]读取数据:  99%|█████████▉| 7020120/7086503 [1:59:29<00:09, 7118.39it/s]读取数据:  99%|█████████▉| 7020921/7086503 [1:59:29<00:09, 7255.79it/s]读取数据:  99%|█████████▉| 7021710/7086503 [1:59:29<00:08, 7374.38it/s]读取数据:  99%|█████████▉| 7022493/7086503 [1:59:29<00:08, 7494.78it/s]读取数据:  99%|█████████▉| 7023276/7086503 [1:59:29<00:08, 7537.41it/s]读取数据:  99%|█████████▉| 7024053/7086503 [1:59:29<00:08, 7514.28it/s]读取数据:  99%|█████████▉| 7024821/7086503 [1:59:29<00:08, 7444.90it/s]读取数据:  99%|█████████▉| 7025577/7086503 [1:59:29<00:08, 7405.41it/s]读取数据:  99%|█████████▉| 7026326/7086503 [1:59:29<00:08, 7288.47it/s]读取数据:  99%|█████████▉| 7027061/7086503 [1:59:30<00:08, 7119.24it/s]读取数据:  99%|█████████▉| 7027778/7086503 [1:59:30<00:08, 6993.14it/s]读取数据:  99%|█████████▉| 7028481/7086503 [1:59:30<00:08, 6915.25it/s]读取数据:  99%|█████████▉| 7029175/7086503 [1:59:30<00:08, 6866.99it/s]读取数据:  99%|█████████▉| 7029864/7086503 [1:59:30<00:08, 6801.68it/s]读取数据:  99%|█████████▉| 7030564/7086503 [1:59:30<00:08, 6858.35it/s]读取数据:  99%|█████████▉| 7031310/7086503 [1:59:30<00:07, 7029.30it/s]读取数据:  99%|█████████▉| 7032094/7086503 [1:59:30<00:07, 7268.01it/s]读取数据:  99%|█████████▉| 7032857/7086503 [1:59:30<00:07, 7371.58it/s]读取数据:  99%|█████████▉| 7033595/7086503 [1:59:30<00:07, 7163.99it/s]读取数据:  99%|█████████▉| 7034314/7086503 [1:59:31<00:07, 7101.37it/s]读取数据:  99%|█████████▉| 7035030/7086503 [1:59:31<00:07, 7117.74it/s]读取数据:  99%|█████████▉| 7035743/7086503 [1:59:31<00:07, 7028.95it/s]读取数据:  99%|█████████▉| 7036447/7086503 [1:59:31<00:07, 6940.18it/s]读取数据:  99%|█████████▉| 7037142/7086503 [1:59:31<00:07, 6754.12it/s]读取数据:  99%|█████████▉| 7037819/7086503 [1:59:31<00:07, 6629.64it/s]读取数据:  99%|█████████▉| 7038483/7086503 [1:59:31<00:07, 6571.25it/s]读取数据:  99%|█████████▉| 7039141/7086503 [1:59:31<00:07, 6557.52it/s]读取数据:  99%|█████████▉| 7039798/7086503 [1:59:31<00:07, 6498.97it/s]读取数据:  99%|█████████▉| 7040449/7086503 [1:59:32<00:07, 6436.01it/s]读取数据:  99%|█████████▉| 7041093/7086503 [1:59:32<00:07, 6433.74it/s]读取数据:  99%|█████████▉| 7041745/7086503 [1:59:32<00:06, 6453.75it/s]读取数据:  99%|█████████▉| 7042391/7086503 [1:59:32<00:06, 6384.34it/s]读取数据:  99%|█████████▉| 7043030/7086503 [1:59:32<00:06, 6246.80it/s]读取数据:  99%|█████████▉| 7043785/7086503 [1:59:32<00:06, 6626.54it/s]读取数据:  99%|█████████▉| 7044542/7086503 [1:59:32<00:06, 6895.04it/s]读取数据:  99%|█████████▉| 7045455/7086503 [1:59:32<00:05, 7555.34it/s]读取数据:  99%|█████████▉| 7046562/7086503 [1:59:32<00:04, 8596.39it/s]读取数据:  99%|█████████▉| 7047730/7086503 [1:59:32<00:04, 9513.62it/s]读取数据:  99%|█████████▉| 7048883/7086503 [1:59:33<00:03, 10113.86it/s]读取数据:  99%|█████████▉| 7050000/7086503 [1:59:34<00:14, 2592.19it/s] 读取数据:  99%|█████████▉| 7050740/7086503 [1:59:34<00:12, 2759.35it/s]读取数据: 100%|█████████▉| 7051758/7086503 [1:59:34<00:09, 3576.83it/s]读取数据: 100%|█████████▉| 7052863/7086503 [1:59:34<00:07, 4593.05it/s]读取数据: 100%|█████████▉| 7053993/7086503 [1:59:34<00:05, 5681.84it/s]读取数据: 100%|█████████▉| 7055230/7086503 [1:59:34<00:04, 6939.58it/s]读取数据: 100%|█████████▉| 7056424/7086503 [1:59:34<00:03, 8000.03it/s]读取数据: 100%|█████████▉| 7057710/7086503 [1:59:34<00:03, 9129.95it/s]读取数据: 100%|█████████▉| 7058931/7086503 [1:59:35<00:02, 9897.16it/s]读取数据: 100%|█████████▉| 7060094/7086503 [1:59:35<00:02, 10302.74it/s]读取数据: 100%|█████████▉| 7061251/7086503 [1:59:35<00:02, 10548.26it/s]读取数据: 100%|█████████▉| 7062434/7086503 [1:59:35<00:02, 10903.63it/s]读取数据: 100%|█████████▉| 7063591/7086503 [1:59:35<00:02, 11002.79it/s]读取数据: 100%|█████████▉| 7064738/7086503 [1:59:35<00:02, 10663.31it/s]读取数据: 100%|█████████▉| 7065839/7086503 [1:59:35<00:02, 10020.53it/s]读取数据: 100%|█████████▉| 7066872/7086503 [1:59:35<00:02, 9552.96it/s] 读取数据: 100%|█████████▉| 7067851/7086503 [1:59:35<00:02, 8926.41it/s]读取数据: 100%|█████████▉| 7068764/7086503 [1:59:36<00:02, 8492.88it/s]读取数据: 100%|█████████▉| 7069628/7086503 [1:59:36<00:02, 8098.87it/s]读取数据: 100%|█████████▉| 7070449/7086503 [1:59:36<00:02, 7951.68it/s]读取数据: 100%|█████████▉| 7071251/7086503 [1:59:36<00:01, 7816.13it/s]读取数据: 100%|█████████▉| 7072036/7086503 [1:59:36<00:01, 7535.64it/s]读取数据: 100%|█████████▉| 7072792/7086503 [1:59:36<00:01, 7278.02it/s]读取数据: 100%|█████████▉| 7073522/7086503 [1:59:36<00:01, 7092.03it/s]读取数据: 100%|█████████▉| 7074260/7086503 [1:59:36<00:01, 7169.37it/s]读取数据: 100%|█████████▉| 7075036/7086503 [1:59:36<00:01, 7335.39it/s]读取数据: 100%|█████████▉| 7075854/7086503 [1:59:37<00:01, 7577.48it/s]读取数据: 100%|█████████▉| 7076657/7086503 [1:59:37<00:01, 7707.89it/s]读取数据: 100%|█████████▉| 7077430/7086503 [1:59:37<00:01, 7690.48it/s]读取数据: 100%|█████████▉| 7078201/7086503 [1:59:37<00:01, 7669.79it/s]读取数据: 100%|█████████▉| 7078995/7086503 [1:59:37<00:00, 7748.33it/s]读取数据: 100%|█████████▉| 7079818/7086503 [1:59:37<00:00, 7869.94it/s]读取数据: 100%|█████████▉| 7080610/7086503 [1:59:37<00:00, 7884.31it/s]读取数据: 100%|█████████▉| 7081399/7086503 [1:59:37<00:00, 7724.23it/s]读取数据: 100%|█████████▉| 7082173/7086503 [1:59:37<00:00, 7696.29it/s]读取数据: 100%|█████████▉| 7082944/7086503 [1:59:38<00:00, 7106.48it/s]读取数据: 100%|█████████▉| 7083664/7086503 [1:59:38<00:00, 6969.74it/s]读取数据: 100%|█████████▉| 7084506/7086503 [1:59:38<00:00, 7376.61it/s]读取数据: 100%|█████████▉| 7085346/7086503 [1:59:38<00:00, 7667.23it/s]读取数据: 100%|█████████▉| 7086140/7086503 [1:59:38<00:00, 7743.84it/s]读取数据: 100%|██████████| 7086503/7086503 [1:59:38<00:00, 987.19it/s] 
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理第 1 批数据 (每批 50000 条)
已处理 50000 条数据
处理第 2 批数据 (每批 50000 条)
已处理 100000 条数据
处理第 3 批数据 (每批 50000 条)
已处理 150000 条数据
处理第 4 批数据 (每批 50000 条)
已处理 200000 条数据
处理第 5 批数据 (每批 50000 条)
已处理 250000 条数据
处理第 6 批数据 (每批 50000 条)
已处理 300000 条数据
处理第 7 批数据 (每批 50000 条)
已处理 350000 条数据
处理第 8 批数据 (每批 50000 条)
已处理 400000 条数据
处理第 9 批数据 (每批 50000 条)
已处理 450000 条数据
处理第 10 批数据 (每批 50000 条)
已保存中间结果，当前处理了 500000 条记录
已处理 500000 条数据
处理第 11 批数据 (每批 50000 条)
已处理 550000 条数据
处理第 12 批数据 (每批 50000 条)
已处理 600000 条数据
处理第 13 批数据 (每批 50000 条)
已处理 650000 条数据
处理第 14 批数据 (每批 50000 条)
已处理 700000 条数据
处理第 15 批数据 (每批 50000 条)
已处理 750000 条数据
处理第 16 批数据 (每批 50000 条)
已处理 800000 条数据
处理第 17 批数据 (每批 50000 条)
已处理 850000 条数据
处理第 18 批数据 (每批 50000 条)
已处理 900000 条数据
处理第 19 批数据 (每批 50000 条)
已处理 950000 条数据
处理第 20 批数据 (每批 50000 条)
已保存中间结果，当前处理了 1000000 条记录
已处理 1000000 条数据
处理第 21 批数据 (每批 50000 条)
已处理 1050000 条数据
处理第 22 批数据 (每批 50000 条)
已处理 1100000 条数据
处理第 23 批数据 (每批 50000 条)
已处理 1150000 条数据
处理第 24 批数据 (每批 50000 条)
已处理 1200000 条数据
处理第 25 批数据 (每批 50000 条)
已处理 1250000 条数据
处理第 26 批数据 (每批 50000 条)
已处理 1300000 条数据
处理第 27 批数据 (每批 50000 条)
已处理 1350000 条数据
处理第 28 批数据 (每批 50000 条)
已处理 1400000 条数据
处理第 29 批数据 (每批 50000 条)
已处理 1450000 条数据
处理第 30 批数据 (每批 50000 条)
已保存中间结果，当前处理了 1500000 条记录
已处理 1500000 条数据
处理第 31 批数据 (每批 50000 条)
已处理 1550000 条数据
处理第 32 批数据 (每批 50000 条)
已处理 1600000 条数据
处理第 33 批数据 (每批 50000 条)
已处理 1650000 条数据
处理第 34 批数据 (每批 50000 条)
已处理 1700000 条数据
处理第 35 批数据 (每批 50000 条)
已处理 1750000 条数据
处理第 36 批数据 (每批 50000 条)
已处理 1800000 条数据
处理第 37 批数据 (每批 50000 条)
已处理 1850000 条数据
处理第 38 批数据 (每批 50000 条)
已处理 1900000 条数据
处理第 39 批数据 (每批 50000 条)
已处理 1950000 条数据
处理第 40 批数据 (每批 50000 条)
已保存中间结果，当前处理了 2000000 条记录
已处理 2000000 条数据
处理第 41 批数据 (每批 50000 条)
已处理 2050000 条数据
处理第 42 批数据 (每批 50000 条)
已处理 2100000 条数据
处理第 43 批数据 (每批 50000 条)
已处理 2150000 条数据
处理第 44 批数据 (每批 50000 条)
已处理 2200000 条数据
处理第 45 批数据 (每批 50000 条)
已处理 2250000 条数据
处理第 46 批数据 (每批 50000 条)
已处理 2300000 条数据
处理第 47 批数据 (每批 50000 条)
已处理 2350000 条数据
处理第 48 批数据 (每批 50000 条)
已处理 2400000 条数据
处理第 49 批数据 (每批 50000 条)
已处理 2450000 条数据
处理第 50 批数据 (每批 50000 条)
已保存中间结果，当前处理了 2500000 条记录
已处理 2500000 条数据
处理第 51 批数据 (每批 50000 条)
已处理 2550000 条数据
处理第 52 批数据 (每批 50000 条)
已处理 2600000 条数据
处理第 53 批数据 (每批 50000 条)
已处理 2650000 条数据
处理第 54 批数据 (每批 50000 条)
已处理 2700000 条数据
处理第 55 批数据 (每批 50000 条)
已处理 2750000 条数据
处理第 56 批数据 (每批 50000 条)
已处理 2800000 条数据
处理第 57 批数据 (每批 50000 条)
已处理 2850000 条数据
处理第 58 批数据 (每批 50000 条)
已处理 2900000 条数据
处理第 59 批数据 (每批 50000 条)
已处理 2950000 条数据
处理第 60 批数据 (每批 50000 条)
已保存中间结果，当前处理了 3000000 条记录
已处理 3000000 条数据
处理第 61 批数据 (每批 50000 条)
已处理 3050000 条数据
处理第 62 批数据 (每批 50000 条)
已处理 3100000 条数据
处理第 63 批数据 (每批 50000 条)
已处理 3150000 条数据
处理第 64 批数据 (每批 50000 条)
已处理 3200000 条数据
处理第 65 批数据 (每批 50000 条)
已处理 3250000 条数据
处理第 66 批数据 (每批 50000 条)
已处理 3300000 条数据
处理第 67 批数据 (每批 50000 条)
已处理 3350000 条数据
处理第 68 批数据 (每批 50000 条)
已处理 3400000 条数据
处理第 69 批数据 (每批 50000 条)
已处理 3450000 条数据
处理第 70 批数据 (每批 50000 条)
已保存中间结果，当前处理了 3500000 条记录
已处理 3500000 条数据
处理第 71 批数据 (每批 50000 条)
已处理 3550000 条数据
处理第 72 批数据 (每批 50000 条)
已处理 3600000 条数据
处理第 73 批数据 (每批 50000 条)
已处理 3650000 条数据
处理第 74 批数据 (每批 50000 条)
已处理 3700000 条数据
处理第 75 批数据 (每批 50000 条)
已处理 3750000 条数据
处理第 76 批数据 (每批 50000 条)
已处理 3800000 条数据
处理第 77 批数据 (每批 50000 条)
已处理 3850000 条数据
处理第 78 批数据 (每批 50000 条)
已处理 3900000 条数据
处理第 79 批数据 (每批 50000 条)
已处理 3950000 条数据
处理第 80 批数据 (每批 50000 条)
已保存中间结果，当前处理了 4000000 条记录
已处理 4000000 条数据
处理第 81 批数据 (每批 50000 条)
已处理 4050000 条数据
处理第 82 批数据 (每批 50000 条)
已处理 4100000 条数据
处理第 83 批数据 (每批 50000 条)
已处理 4150000 条数据
处理第 84 批数据 (每批 50000 条)
已处理 4200000 条数据
处理第 85 批数据 (每批 50000 条)
已处理 4250000 条数据
处理第 86 批数据 (每批 50000 条)
已处理 4300000 条数据
处理第 87 批数据 (每批 50000 条)
已处理 4350000 条数据
处理第 88 批数据 (每批 50000 条)
已处理 4400000 条数据
处理第 89 批数据 (每批 50000 条)
已处理 4450000 条数据
处理第 90 批数据 (每批 50000 条)
已保存中间结果，当前处理了 4500000 条记录
已处理 4500000 条数据
处理第 91 批数据 (每批 50000 条)
已处理 4550000 条数据
处理第 92 批数据 (每批 50000 条)
已处理 4600000 条数据
处理第 93 批数据 (每批 50000 条)
已处理 4650000 条数据
处理第 94 批数据 (每批 50000 条)
已处理 4700000 条数据
处理第 95 批数据 (每批 50000 条)
已处理 4750000 条数据
处理第 96 批数据 (每批 50000 条)
已处理 4800000 条数据
处理第 97 批数据 (每批 50000 条)
已处理 4850000 条数据
处理第 98 批数据 (每批 50000 条)
已处理 4900000 条数据
处理第 99 批数据 (每批 50000 条)
已处理 4950000 条数据
处理第 100 批数据 (每批 50000 条)
已保存中间结果，当前处理了 5000000 条记录
已处理 5000000 条数据
处理第 101 批数据 (每批 50000 条)
已处理 5050000 条数据
处理第 102 批数据 (每批 50000 条)
已处理 5100000 条数据
处理第 103 批数据 (每批 50000 条)
已处理 5150000 条数据
处理第 104 批数据 (每批 50000 条)
已处理 5200000 条数据
处理第 105 批数据 (每批 50000 条)
已处理 5250000 条数据
处理第 106 批数据 (每批 50000 条)
已处理 5300000 条数据
处理第 107 批数据 (每批 50000 条)
已处理 5350000 条数据
处理第 108 批数据 (每批 50000 条)
已处理 5400000 条数据
处理第 109 批数据 (每批 50000 条)
已处理 5450000 条数据
处理第 110 批数据 (每批 50000 条)
已保存中间结果，当前处理了 5500000 条记录
已处理 5500000 条数据
处理第 111 批数据 (每批 50000 条)
已处理 5550000 条数据
处理第 112 批数据 (每批 50000 条)
已处理 5600000 条数据
处理第 113 批数据 (每批 50000 条)
已处理 5650000 条数据
处理第 114 批数据 (每批 50000 条)
已处理 5700000 条数据
处理第 115 批数据 (每批 50000 条)
已处理 5750000 条数据
处理第 116 批数据 (每批 50000 条)
已处理 5800000 条数据
处理第 117 批数据 (每批 50000 条)
已处理 5850000 条数据
处理第 118 批数据 (每批 50000 条)
已处理 5900000 条数据
处理第 119 批数据 (每批 50000 条)
已处理 5950000 条数据
处理第 120 批数据 (每批 50000 条)
已保存中间结果，当前处理了 6000000 条记录
已处理 6000000 条数据
处理第 121 批数据 (每批 50000 条)
已处理 6050000 条数据
处理第 122 批数据 (每批 50000 条)
已处理 6100000 条数据
处理第 123 批数据 (每批 50000 条)
已处理 6150000 条数据
处理第 124 批数据 (每批 50000 条)
已处理 6200000 条数据
处理第 125 批数据 (每批 50000 条)
已处理 6250000 条数据
处理第 126 批数据 (每批 50000 条)
已处理 6300000 条数据
处理第 127 批数据 (每批 50000 条)
已处理 6350000 条数据
处理第 128 批数据 (每批 50000 条)
已处理 6400000 条数据
处理第 129 批数据 (每批 50000 条)
已处理 6450000 条数据
处理第 130 批数据 (每批 50000 条)
已保存中间结果，当前处理了 6500000 条记录
已处理 6500000 条数据
处理第 131 批数据 (每批 50000 条)
已处理 6550000 条数据
处理第 132 批数据 (每批 50000 条)
已处理 6600000 条数据
处理第 133 批数据 (每批 50000 条)
已处理 6650000 条数据
处理第 134 批数据 (每批 50000 条)
已处理 6700000 条数据
处理第 135 批数据 (每批 50000 条)
已处理 6750000 条数据
处理第 136 批数据 (每批 50000 条)
已处理 6800000 条数据
处理第 137 批数据 (每批 50000 条)
已处理 6850000 条数据
处理第 138 批数据 (每批 50000 条)
已处理 6900000 条数据
处理第 139 批数据 (每批 50000 条)
已处理 6950000 条数据
处理第 140 批数据 (每批 50000 条)
已保存中间结果，当前处理了 7000000 条记录
已处理 7000000 条数据
处理第 141 批数据 (每批 50000 条)
已处理 7050000 条数据
处理第 142 批数据 (每批 50000 条)
数据读取完成，共 7086503 条原始记录，完全相同prompt去重后 6160102 条
开始为所有数据生成嵌入向量，使用GPU 3
处理嵌入批次 0 到 10
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:04,  6.45s/it]processing embeddings:  18%|█▊        | 2/11 [00:11<00:53,  5.91s/it]processing embeddings:  27%|██▋       | 3/11 [00:15<00:39,  4.96s/it]processing embeddings:  36%|███▋      | 4/11 [00:19<00:30,  4.32s/it]processing embeddings:  45%|████▌     | 5/11 [00:22<00:24,  4.12s/it]processing embeddings:  55%|█████▍    | 6/11 [00:26<00:19,  3.98s/it]processing embeddings:  64%|██████▎   | 7/11 [00:30<00:15,  3.90s/it]processing embeddings:  73%|███████▎  | 8/11 [00:34<00:11,  3.86s/it]processing embeddings:  82%|████████▏ | 9/11 [00:38<00:08,  4.00s/it]processing embeddings:  91%|█████████ | 10/11 [00:42<00:03,  3.95s/it]processing embeddings:  91%|█████████ | 10/11 [00:42<00:04,  4.24s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 10 到 20
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:42,  4.26s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.88s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:31,  3.97s/it]processing embeddings:  36%|███▋      | 4/11 [00:16<00:29,  4.14s/it]processing embeddings:  45%|████▌     | 5/11 [00:20<00:23,  3.99s/it]processing embeddings:  55%|█████▍    | 6/11 [00:23<00:19,  3.81s/it]processing embeddings:  64%|██████▎   | 7/11 [00:27<00:15,  3.75s/it]processing embeddings:  73%|███████▎  | 8/11 [00:31<00:11,  3.78s/it]processing embeddings:  82%|████████▏ | 9/11 [00:34<00:07,  3.78s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.90s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.90s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 20 到 30
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:42,  4.21s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.83s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.79s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.73s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.62s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:17,  3.58s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.59s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.73s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.79s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.82s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.75s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 30 到 40
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.59s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.68s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.75s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:26,  3.73s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.76s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.78s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:15,  3.80s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.70s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.69s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.68s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.72s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 40 到 50
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.72s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.72s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:29,  3.64s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.71s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.60s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.59s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.63s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.66s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.68s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.73s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.69s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 50 到 60
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.68s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.75s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.73s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.69s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.67s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.63s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.64s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.64s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.63s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.68s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.67s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 60 到 70
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:41,  4.19s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.82s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.81s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:27,  3.93s/it]processing embeddings:  45%|████▌     | 5/11 [00:19<00:23,  3.91s/it]processing embeddings:  55%|█████▍    | 6/11 [00:23<00:20,  4.04s/it]processing embeddings:  64%|██████▎   | 7/11 [00:27<00:15,  3.94s/it]processing embeddings:  73%|███████▎  | 8/11 [00:31<00:11,  3.88s/it]processing embeddings:  82%|████████▏ | 9/11 [00:35<00:07,  3.87s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.84s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.89s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 70 到 80
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.78s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.87s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.80s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.78s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.70s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.64s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.56s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.54s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.61s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 80 到 90
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.57s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.63s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:29,  3.64s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.59s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.52s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.50s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.53s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.53s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.48s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.42s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.53s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 90 到 100
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:49,  4.91s/it]processing embeddings:  18%|█▊        | 2/11 [00:09<00:40,  4.49s/it]processing embeddings:  27%|██▋       | 3/11 [00:12<00:33,  4.17s/it]processing embeddings:  36%|███▋      | 4/11 [00:16<00:27,  3.95s/it]processing embeddings:  45%|████▌     | 5/11 [00:20<00:23,  3.92s/it]processing embeddings:  55%|█████▍    | 6/11 [00:24<00:19,  3.89s/it]processing embeddings:  64%|██████▎   | 7/11 [00:27<00:15,  3.82s/it]processing embeddings:  73%|███████▎  | 8/11 [00:31<00:11,  3.78s/it]processing embeddings:  82%|████████▏ | 9/11 [00:35<00:07,  3.75s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.62s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.87s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 100 到 110
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.68s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.58s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.55s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.50s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.49s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.46s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.46s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.51s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.52s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.54s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.53s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 110 到 120
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.63s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.56s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:29,  3.64s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.58s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.52s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.43s/it]processing embeddings:  64%|██████▎   | 7/11 [00:27<00:18,  4.53s/it]processing embeddings:  73%|███████▎  | 8/11 [00:34<00:15,  5.09s/it]processing embeddings:  82%|████████▏ | 9/11 [00:38<00:09,  4.81s/it]processing embeddings:  91%|█████████ | 10/11 [00:41<00:04,  4.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:42<00:04,  4.23s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 120 到 130
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:39,  3.96s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.72s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.72s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.71s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:23,  3.84s/it]processing embeddings:  55%|█████▍    | 6/11 [00:23<00:19,  3.99s/it]processing embeddings:  64%|██████▎   | 7/11 [00:27<00:16,  4.15s/it]processing embeddings:  73%|███████▎  | 8/11 [00:31<00:12,  4.02s/it]processing embeddings:  82%|████████▏ | 9/11 [00:35<00:07,  3.91s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.79s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.90s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 130 到 140
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.63s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.55s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.80s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:26,  3.75s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.74s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.64s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.70s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.63s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.71s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.68s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.72s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 140 到 150
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.65s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.72s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.75s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.67s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.60s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.59s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.63s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.73s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.71s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.66s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.77s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 150 到 160
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.58s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.67s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.82s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:26,  3.74s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.74s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.70s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:15,  3.76s/it]processing embeddings:  73%|███████▎  | 8/11 [00:30<00:11,  3.83s/it]processing embeddings:  82%|████████▏ | 9/11 [00:34<00:07,  3.88s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.96s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.89s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 160 到 170
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.73s/it]processing embeddings:  18%|█▊        | 2/11 [00:08<00:38,  4.30s/it]processing embeddings:  27%|██▋       | 3/11 [00:17<00:50,  6.36s/it]processing embeddings:  36%|███▋      | 4/11 [00:26<00:52,  7.49s/it]processing embeddings:  45%|████▌     | 5/11 [00:31<00:39,  6.62s/it]processing embeddings:  55%|█████▍    | 6/11 [00:35<00:29,  5.88s/it]processing embeddings:  64%|██████▎   | 7/11 [00:40<00:21,  5.35s/it]processing embeddings:  73%|███████▎  | 8/11 [00:44<00:15,  5.07s/it]processing embeddings:  82%|████████▏ | 9/11 [00:49<00:09,  4.86s/it]processing embeddings:  91%|█████████ | 10/11 [00:53<00:04,  4.76s/it]processing embeddings:  91%|█████████ | 10/11 [00:53<00:05,  5.40s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 170 到 180
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:42,  4.21s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:30,  3.44s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.13s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:20,  2.94s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:17,  2.85s/it]processing embeddings:  55%|█████▍    | 6/11 [00:17<00:13,  2.75s/it]processing embeddings:  64%|██████▎   | 7/11 [00:20<00:11,  2.76s/it]processing embeddings:  73%|███████▎  | 8/11 [00:23<00:08,  2.81s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:09,  4.60s/it]processing embeddings:  91%|█████████ | 10/11 [00:42<00:06,  6.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:42<00:04,  4.22s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 180 到 190
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:10<01:46, 10.63s/it]processing embeddings:  18%|█▊        | 2/11 [00:21<01:36, 10.75s/it]processing embeddings:  27%|██▋       | 3/11 [00:32<01:26, 10.77s/it]processing embeddings:  36%|███▋      | 4/11 [00:45<01:22, 11.83s/it]processing embeddings:  45%|████▌     | 5/11 [00:59<01:15, 12.52s/it]processing embeddings:  55%|█████▍    | 6/11 [01:11<01:02, 12.41s/it]processing embeddings:  64%|██████▎   | 7/11 [01:16<00:39,  9.78s/it]processing embeddings:  73%|███████▎  | 8/11 [01:19<00:23,  7.80s/it]processing embeddings:  82%|████████▏ | 9/11 [01:23<00:13,  6.51s/it]processing embeddings:  91%|█████████ | 10/11 [01:26<00:05,  5.59s/it]processing embeddings:  91%|█████████ | 10/11 [01:26<00:08,  8.69s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 190 到 200
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.44s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.49s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.48s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.65s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.64s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.64s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.62s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.62s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.58s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.61s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.62s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 200 到 210
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.70s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.80s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:31,  3.96s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.79s/it]processing embeddings:  45%|████▌     | 5/11 [00:19<00:23,  3.95s/it]processing embeddings:  55%|█████▍    | 6/11 [00:23<00:19,  3.84s/it]processing embeddings:  64%|██████▎   | 7/11 [00:27<00:15,  3.90s/it]processing embeddings:  73%|███████▎  | 8/11 [00:31<00:11,  3.97s/it]processing embeddings:  82%|████████▏ | 9/11 [00:34<00:07,  3.85s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.74s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.83s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 210 到 220
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.53s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.52s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.53s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.49s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.55s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.64s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.62s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.61s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.67s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.65s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.63s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 220 到 230
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:38,  3.87s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.72s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.64s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.63s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.59s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.58s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.58s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.56s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.37s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.18s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.47s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 230 到 240
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:26,  2.69s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:24,  2.76s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:22,  2.78s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:19,  2.80s/it]processing embeddings:  45%|████▌     | 5/11 [00:14<00:16,  2.83s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:14,  2.80s/it]processing embeddings:  64%|██████▎   | 7/11 [00:19<00:11,  2.75s/it]processing embeddings:  73%|███████▎  | 8/11 [00:22<00:08,  2.77s/it]processing embeddings:  82%|████████▏ | 9/11 [00:25<00:05,  2.79s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.78s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.79s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 240 到 250
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:28,  2.82s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:25,  2.81s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:22,  2.75s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:19,  2.75s/it]processing embeddings:  45%|████▌     | 5/11 [00:13<00:16,  2.76s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:13,  2.74s/it]processing embeddings:  64%|██████▎   | 7/11 [00:19<00:10,  2.70s/it]processing embeddings:  73%|███████▎  | 8/11 [00:21<00:08,  2.73s/it]processing embeddings:  82%|████████▏ | 9/11 [00:24<00:05,  2.73s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.76s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.75s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 250 到 260
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:26,  2.64s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:24,  2.73s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:21,  2.73s/it]processing embeddings:  36%|███▋      | 4/11 [00:10<00:19,  2.72s/it]processing embeddings:  45%|████▌     | 5/11 [00:13<00:16,  2.75s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:13,  2.78s/it]processing embeddings:  64%|██████▎   | 7/11 [00:19<00:11,  2.84s/it]processing embeddings:  73%|███████▎  | 8/11 [00:22<00:08,  2.82s/it]processing embeddings:  82%|████████▏ | 9/11 [00:25<00:05,  2.80s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.79s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.78s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 260 到 270
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:27,  2.80s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:25,  2.79s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:21,  2.73s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:19,  2.75s/it]processing embeddings:  45%|████▌     | 5/11 [00:13<00:16,  2.79s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:13,  2.80s/it]processing embeddings:  64%|██████▎   | 7/11 [00:19<00:10,  2.74s/it]processing embeddings:  73%|███████▎  | 8/11 [00:22<00:08,  2.73s/it]processing embeddings:  82%|████████▏ | 9/11 [00:24<00:05,  2.74s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.78s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.78s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 270 到 280
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:27,  2.77s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:24,  2.69s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:21,  2.74s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:19,  2.79s/it]processing embeddings:  45%|████▌     | 5/11 [00:13<00:16,  2.81s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:14,  2.81s/it]processing embeddings:  64%|██████▎   | 7/11 [00:19<00:11,  2.80s/it]processing embeddings:  73%|███████▎  | 8/11 [00:22<00:08,  2.79s/it]processing embeddings:  82%|████████▏ | 9/11 [00:25<00:05,  2.80s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.78s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.79s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 280 到 290
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:27,  2.75s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:24,  2.73s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:22,  2.76s/it]processing embeddings:  36%|███▋      | 4/11 [00:10<00:19,  2.73s/it]processing embeddings:  45%|████▌     | 5/11 [00:13<00:16,  2.73s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:13,  2.71s/it]processing embeddings:  64%|██████▎   | 7/11 [00:19<00:10,  2.72s/it]processing embeddings:  73%|███████▎  | 8/11 [00:21<00:08,  2.73s/it]processing embeddings:  82%|████████▏ | 9/11 [00:24<00:05,  2.72s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.69s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.75s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 290 到 300
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:28,  2.83s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:25,  2.82s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:22,  2.83s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:19,  2.80s/it]processing embeddings:  45%|████▌     | 5/11 [00:13<00:16,  2.74s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:13,  2.78s/it]processing embeddings:  64%|██████▎   | 7/11 [00:20<00:12,  3.22s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:10,  3.56s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:07,  3.78s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.79s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.35s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 300 到 310
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:39,  3.92s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.84s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:31,  3.93s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:27,  3.95s/it]processing embeddings:  45%|████▌     | 5/11 [00:19<00:23,  3.90s/it]processing embeddings:  55%|█████▍    | 6/11 [00:23<00:19,  3.90s/it]processing embeddings:  64%|██████▎   | 7/11 [00:27<00:15,  3.92s/it]processing embeddings:  73%|███████▎  | 8/11 [00:31<00:12,  4.00s/it]processing embeddings:  82%|████████▏ | 9/11 [00:35<00:08,  4.00s/it]processing embeddings:  91%|█████████ | 10/11 [00:39<00:03,  3.98s/it]processing embeddings:  91%|█████████ | 10/11 [00:39<00:03,  3.97s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 310 到 320
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:39,  3.98s/it]processing embeddings:  18%|█▊        | 2/11 [00:08<00:39,  4.34s/it]processing embeddings:  27%|██▋       | 3/11 [00:13<00:36,  4.60s/it]processing embeddings:  36%|███▋      | 4/11 [00:21<00:40,  5.76s/it]processing embeddings:  45%|████▌     | 5/11 [00:30<00:42,  7.13s/it]processing embeddings:  55%|█████▍    | 6/11 [00:40<00:41,  8.23s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:34,  8.69s/it]processing embeddings:  73%|███████▎  | 8/11 [01:00<00:27,  9.11s/it]processing embeddings:  82%|████████▏ | 9/11 [01:10<00:18,  9.31s/it]processing embeddings:  91%|█████████ | 10/11 [01:20<00:09,  9.62s/it]processing embeddings:  91%|█████████ | 10/11 [01:20<00:08,  8.10s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 320 到 330
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:10<01:40, 10.09s/it]processing embeddings:  18%|█▊        | 2/11 [00:19<01:29,  9.95s/it]processing embeddings:  27%|██▋       | 3/11 [00:29<01:18,  9.84s/it]processing embeddings:  36%|███▋      | 4/11 [00:39<01:09,  9.98s/it]processing embeddings:  45%|████▌     | 5/11 [00:49<01:00, 10.04s/it]processing embeddings:  55%|█████▍    | 6/11 [01:01<00:52, 10.49s/it]processing embeddings:  64%|██████▎   | 7/11 [01:16<00:47, 11.95s/it]processing embeddings:  73%|███████▎  | 8/11 [01:31<00:39, 13.02s/it]processing embeddings:  82%|████████▏ | 9/11 [01:47<00:27, 13.77s/it]processing embeddings:  91%|█████████ | 10/11 [02:01<00:14, 14.13s/it]processing embeddings:  91%|█████████ | 10/11 [02:02<00:12, 12.21s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 330 到 340
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:15<02:30, 15.06s/it]processing embeddings:  18%|█▊        | 2/11 [00:22<01:37, 10.85s/it]processing embeddings:  27%|██▋       | 3/11 [00:27<01:03,  7.94s/it]processing embeddings:  36%|███▋      | 4/11 [00:32<00:46,  6.64s/it]processing embeddings:  45%|████▌     | 5/11 [00:36<00:35,  5.92s/it]processing embeddings:  55%|█████▍    | 6/11 [00:41<00:27,  5.51s/it]processing embeddings:  64%|██████▎   | 7/11 [00:46<00:20,  5.23s/it]processing embeddings:  73%|███████▎  | 8/11 [00:50<00:14,  4.99s/it]processing embeddings:  82%|████████▏ | 9/11 [00:55<00:09,  4.85s/it]processing embeddings:  91%|█████████ | 10/11 [00:59<00:04,  4.77s/it]processing embeddings:  91%|█████████ | 10/11 [00:59<00:05,  5.99s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 340 到 350
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:45,  4.55s/it]processing embeddings:  18%|█▊        | 2/11 [00:08<00:38,  4.29s/it]processing embeddings:  27%|██▋       | 3/11 [00:12<00:33,  4.22s/it]processing embeddings:  36%|███▋      | 4/11 [00:16<00:29,  4.20s/it]processing embeddings:  45%|████▌     | 5/11 [00:21<00:25,  4.27s/it]processing embeddings:  55%|█████▍    | 6/11 [00:25<00:21,  4.28s/it]processing embeddings:  64%|██████▎   | 7/11 [00:29<00:17,  4.25s/it]processing embeddings:  73%|███████▎  | 8/11 [00:33<00:12,  4.19s/it]processing embeddings:  82%|████████▏ | 9/11 [00:36<00:07,  3.79s/it]processing embeddings:  91%|█████████ | 10/11 [00:39<00:03,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:39<00:03,  3.95s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 350 到 360
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:25,  2.58s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:22,  2.55s/it]processing embeddings:  27%|██▋       | 3/11 [00:07<00:20,  2.56s/it]processing embeddings:  36%|███▋      | 4/11 [00:10<00:18,  2.59s/it]processing embeddings:  45%|████▌     | 5/11 [00:12<00:15,  2.62s/it]processing embeddings:  55%|█████▍    | 6/11 [00:15<00:13,  2.62s/it]processing embeddings:  64%|██████▎   | 7/11 [00:18<00:10,  2.58s/it]processing embeddings:  73%|███████▎  | 8/11 [00:20<00:07,  2.60s/it]processing embeddings:  82%|████████▏ | 9/11 [00:23<00:05,  2.61s/it]processing embeddings:  91%|█████████ | 10/11 [00:25<00:02,  2.60s/it]processing embeddings:  91%|█████████ | 10/11 [00:26<00:02,  2.62s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 360 到 370
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:25,  2.55s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:23,  2.61s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:31,  3.95s/it]processing embeddings:  36%|███▋      | 4/11 [00:19<00:41,  5.98s/it]processing embeddings:  45%|████▌     | 5/11 [00:24<00:32,  5.37s/it]processing embeddings:  55%|█████▍    | 6/11 [00:28<00:24,  4.90s/it]processing embeddings:  64%|██████▎   | 7/11 [00:31<00:17,  4.48s/it]processing embeddings:  73%|███████▎  | 8/11 [00:35<00:12,  4.20s/it]processing embeddings:  82%|████████▏ | 9/11 [00:38<00:07,  3.97s/it]processing embeddings:  91%|█████████ | 10/11 [00:42<00:03,  3.83s/it]processing embeddings:  91%|█████████ | 10/11 [00:42<00:04,  4.23s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 370 到 380
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.67s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.68s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:29,  3.63s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.61s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.57s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.62s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.58s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.62s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.67s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.87s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.70s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 380 到 390
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.43s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.56s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.56s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.59s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.60s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.67s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.68s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.72s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.77s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.77s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.69s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 390 到 400
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.73s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.88s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.82s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.78s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.76s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.72s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:14,  3.74s/it]processing embeddings:  73%|███████▎  | 8/11 [00:30<00:11,  3.78s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.76s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.74s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.76s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 400 到 410
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.46s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.61s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:29,  3.65s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.59s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.72s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.72s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.64s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.70s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:06,  3.48s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.52s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 410 到 420
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:26,  2.69s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:24,  2.70s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:21,  2.70s/it]processing embeddings:  36%|███▋      | 4/11 [00:10<00:19,  2.72s/it]processing embeddings:  45%|████▌     | 5/11 [00:13<00:16,  2.77s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:13,  2.79s/it]processing embeddings:  64%|██████▎   | 7/11 [00:19<00:11,  2.82s/it]processing embeddings:  73%|███████▎  | 8/11 [00:22<00:08,  2.83s/it]processing embeddings:  82%|████████▏ | 9/11 [00:25<00:06,  3.08s/it]processing embeddings:  91%|█████████ | 10/11 [00:28<00:02,  2.99s/it]processing embeddings:  91%|█████████ | 10/11 [00:28<00:02,  2.87s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 420 到 430
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:28,  2.87s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:24,  2.75s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:23,  2.91s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:19,  2.84s/it]processing embeddings:  45%|████▌     | 5/11 [00:14<00:17,  2.98s/it]processing embeddings:  55%|█████▍    | 6/11 [00:17<00:14,  2.94s/it]processing embeddings:  64%|██████▎   | 7/11 [00:20<00:11,  2.96s/it]processing embeddings:  73%|███████▎  | 8/11 [00:23<00:08,  2.91s/it]processing embeddings:  82%|████████▏ | 9/11 [00:25<00:05,  2.85s/it]processing embeddings:  91%|█████████ | 10/11 [00:28<00:02,  2.84s/it]processing embeddings:  91%|█████████ | 10/11 [00:28<00:02,  2.88s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 430 到 440
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:28,  2.85s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:25,  2.82s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:22,  2.87s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:19,  2.85s/it]processing embeddings:  45%|████▌     | 5/11 [00:14<00:16,  2.80s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:14,  2.82s/it]processing embeddings:  64%|██████▎   | 7/11 [00:19<00:11,  2.82s/it]processing embeddings:  73%|███████▎  | 8/11 [00:22<00:08,  2.80s/it]processing embeddings:  82%|████████▏ | 9/11 [00:25<00:05,  2.81s/it]processing embeddings:  91%|█████████ | 10/11 [00:28<00:02,  2.84s/it]processing embeddings:  91%|█████████ | 10/11 [00:28<00:02,  2.83s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 440 到 450
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:28,  2.84s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:25,  2.88s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:24,  3.09s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:21,  3.03s/it]processing embeddings:  45%|████▌     | 5/11 [00:14<00:17,  2.94s/it]processing embeddings:  55%|█████▍    | 6/11 [00:18<00:16,  3.33s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.49s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:11,  3.68s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:07,  3.76s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.76s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.45s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 450 到 460
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:38,  3.87s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.75s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.69s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.78s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.73s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.75s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:15,  3.76s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.74s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.73s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.74s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.75s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 460 到 470
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.56s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.64s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:29,  3.65s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.67s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.66s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.63s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.61s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.60s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.59s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.61s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 470 到 480
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.53s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.58s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:29,  3.68s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:26,  3.74s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.69s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.72s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.68s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.70s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.69s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.70s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.69s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 480 到 490
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:38,  3.80s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.78s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.64s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.58s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.59s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.53s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.55s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.59s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.66s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.79s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.67s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 490 到 500
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.72s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.70s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.76s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.81s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.74s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.66s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.67s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.64s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.73s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.78s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.73s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 500 到 510
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:38,  3.89s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:35,  3.91s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.78s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.76s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.73s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.72s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:14,  3.66s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.60s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.64s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.68s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.70s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 510 到 520
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.55s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.72s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.72s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.70s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.81s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:19,  3.86s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:15,  3.82s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.71s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.74s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.74s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.75s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 520 到 530
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:38,  3.89s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.82s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.72s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.75s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.77s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:19,  3.82s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:14,  3.74s/it]processing embeddings:  73%|███████▎  | 8/11 [00:30<00:11,  3.76s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.73s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.67s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.74s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 530 到 540
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.79s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.86s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.39s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:21,  3.13s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:18,  3.05s/it]processing embeddings:  55%|█████▍    | 6/11 [00:18<00:14,  2.97s/it]processing embeddings:  64%|██████▎   | 7/11 [00:21<00:11,  2.88s/it]processing embeddings:  73%|███████▎  | 8/11 [00:24<00:08,  2.87s/it]processing embeddings:  82%|████████▏ | 9/11 [00:27<00:05,  2.84s/it]processing embeddings:  91%|█████████ | 10/11 [00:30<00:02,  2.83s/it]processing embeddings:  91%|█████████ | 10/11 [00:30<00:03,  3.01s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 540 到 550
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:28,  2.83s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:25,  2.80s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:22,  2.75s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:19,  2.79s/it]processing embeddings:  45%|████▌     | 5/11 [00:13<00:16,  2.78s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:13,  2.74s/it]processing embeddings:  64%|██████▎   | 7/11 [00:19<00:10,  2.73s/it]processing embeddings:  73%|███████▎  | 8/11 [00:22<00:08,  2.78s/it]processing embeddings:  82%|████████▏ | 9/11 [00:24<00:05,  2.78s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.81s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.78s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 550 到 560
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:28,  2.82s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:25,  2.79s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:22,  2.79s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:19,  2.82s/it]processing embeddings:  45%|████▌     | 5/11 [00:14<00:17,  2.83s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:13,  2.80s/it]processing embeddings:  64%|██████▎   | 7/11 [00:19<00:11,  2.79s/it]processing embeddings:  73%|███████▎  | 8/11 [00:22<00:08,  2.79s/it]processing embeddings:  82%|████████▏ | 9/11 [00:25<00:05,  2.88s/it]processing embeddings:  91%|█████████ | 10/11 [00:28<00:02,  2.84s/it]processing embeddings:  91%|█████████ | 10/11 [00:28<00:02,  2.82s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 560 到 570
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.41s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.29s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:24,  3.09s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:21,  3.01s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:17,  2.93s/it]processing embeddings:  55%|█████▍    | 6/11 [00:17<00:14,  2.88s/it]processing embeddings:  64%|██████▎   | 7/11 [00:20<00:11,  2.85s/it]processing embeddings:  73%|███████▎  | 8/11 [00:23<00:08,  2.79s/it]processing embeddings:  82%|████████▏ | 9/11 [00:26<00:05,  2.78s/it]processing embeddings:  91%|█████████ | 10/11 [00:28<00:02,  2.77s/it]processing embeddings:  91%|█████████ | 10/11 [00:28<00:02,  2.89s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 570 到 580
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:28,  2.82s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:25,  2.83s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.52s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:27,  3.99s/it]processing embeddings:  45%|████▌     | 5/11 [00:19<00:25,  4.18s/it]processing embeddings:  55%|█████▍    | 6/11 [00:23<00:21,  4.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:28<00:17,  4.36s/it]processing embeddings:  73%|███████▎  | 8/11 [00:32<00:13,  4.42s/it]processing embeddings:  82%|████████▏ | 9/11 [00:37<00:08,  4.46s/it]processing embeddings:  91%|█████████ | 10/11 [00:41<00:04,  4.47s/it]processing embeddings:  91%|█████████ | 10/11 [00:41<00:04,  4.18s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 580 到 590
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:46,  4.64s/it]processing embeddings:  18%|█▊        | 2/11 [00:09<00:41,  4.64s/it]processing embeddings:  27%|██▋       | 3/11 [00:13<00:36,  4.58s/it]processing embeddings:  36%|███▋      | 4/11 [00:18<00:32,  4.59s/it]processing embeddings:  45%|████▌     | 5/11 [00:23<00:28,  4.77s/it]processing embeddings:  55%|█████▍    | 6/11 [00:28<00:23,  4.71s/it]processing embeddings:  64%|██████▎   | 7/11 [00:33<00:19,  4.80s/it]processing embeddings:  73%|███████▎  | 8/11 [00:37<00:14,  4.67s/it]processing embeddings:  82%|████████▏ | 9/11 [00:41<00:09,  4.50s/it]processing embeddings:  91%|█████████ | 10/11 [00:45<00:04,  4.44s/it]processing embeddings:  91%|█████████ | 10/11 [00:45<00:04,  4.59s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 590 到 600
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:42,  4.29s/it]processing embeddings:  18%|█▊        | 2/11 [00:08<00:37,  4.19s/it]processing embeddings:  27%|██▋       | 3/11 [00:12<00:33,  4.19s/it]processing embeddings:  36%|███▋      | 4/11 [00:17<00:30,  4.33s/it]processing embeddings:  45%|████▌     | 5/11 [00:24<00:32,  5.39s/it]processing embeddings:  55%|█████▍    | 6/11 [00:27<00:23,  4.72s/it]processing embeddings:  64%|██████▎   | 7/11 [00:31<00:17,  4.41s/it]processing embeddings:  73%|███████▎  | 8/11 [00:34<00:12,  4.05s/it]processing embeddings:  82%|████████▏ | 9/11 [00:38<00:07,  3.87s/it]processing embeddings:  91%|█████████ | 10/11 [00:42<00:03,  3.81s/it]processing embeddings:  91%|█████████ | 10/11 [00:42<00:04,  4.20s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 600 到 610
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:40,  4.07s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:35,  3.89s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.70s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.56s/it]processing embeddings:  45%|████▌     | 5/11 [00:19<00:23,  3.90s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.75s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:14,  3.63s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.55s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.56s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.53s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.64s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 610 到 620
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.54s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.63s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.54s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.61s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.57s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.49s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.53s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.56s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.59s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.56s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 620 到 630
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.64s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.44s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.52s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.68s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.61s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.61s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.56s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.58s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.52s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.52s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.56s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 630 到 640
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.60s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.44s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.57s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.59s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.57s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.50s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.45s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.51s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.49s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.49s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 640 到 650
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.49s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.60s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.46s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.48s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.54s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.56s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.48s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.55s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.61s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.55s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 650 到 660
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.56s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.47s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.59s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.53s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.46s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.53s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.48s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.57s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.63s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.56s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 660 到 670
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.58s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.58s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.49s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.51s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.53s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.51s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.50s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.46s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.48s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.50s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.50s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 670 到 680
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.53s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.66s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.44s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.39s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.37s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.38s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.46s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.49s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.48s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.53s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.48s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 680 到 690
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.74s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.61s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.49s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.48s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.43s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.43s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.48s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.49s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.62s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.55s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.53s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 690 到 700
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.25s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.26s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.43s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.66s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.62s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.73s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:15,  3.78s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.65s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.55s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.58s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.59s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 700 到 710
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.55s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.40s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.50s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.48s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.50s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.56s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.54s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.58s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.62s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.55s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 710 到 720
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.67s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.65s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.70s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.63s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.64s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.64s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.55s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.57s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.76s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.71s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.66s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 720 到 730
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.40s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.41s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.45s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.39s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.44s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.47s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.45s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.54s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.67s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.81s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.59s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 730 到 740
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.75s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.84s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.84s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:27,  3.91s/it]processing embeddings:  45%|████▌     | 5/11 [00:19<00:23,  3.93s/it]processing embeddings:  55%|█████▍    | 6/11 [00:23<00:19,  3.91s/it]processing embeddings:  64%|██████▎   | 7/11 [00:27<00:15,  3.91s/it]processing embeddings:  73%|███████▎  | 8/11 [00:31<00:11,  3.93s/it]processing embeddings:  82%|████████▏ | 9/11 [00:35<00:07,  3.94s/it]processing embeddings:  91%|█████████ | 10/11 [00:39<00:03,  3.92s/it]processing embeddings:  91%|█████████ | 10/11 [00:39<00:03,  3.91s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 740 到 750
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:40,  4.09s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:35,  3.96s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:31,  3.89s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:27,  3.89s/it]processing embeddings:  45%|████▌     | 5/11 [00:19<00:23,  3.94s/it]processing embeddings:  55%|█████▍    | 6/11 [00:23<00:19,  3.88s/it]processing embeddings:  64%|██████▎   | 7/11 [00:27<00:15,  3.87s/it]processing embeddings:  73%|███████▎  | 8/11 [00:31<00:11,  3.86s/it]processing embeddings:  82%|████████▏ | 9/11 [00:35<00:07,  3.88s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.89s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.90s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 750 到 760
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:39,  3.97s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:35,  3.99s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:31,  3.96s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:28,  4.00s/it]processing embeddings:  45%|████▌     | 5/11 [00:19<00:23,  3.98s/it]processing embeddings:  55%|█████▍    | 6/11 [00:23<00:19,  3.92s/it]processing embeddings:  64%|██████▎   | 7/11 [00:27<00:15,  3.92s/it]processing embeddings:  73%|███████▎  | 8/11 [00:31<00:11,  3.93s/it]processing embeddings:  82%|████████▏ | 9/11 [00:34<00:07,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.71s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 760 到 770
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:27,  2.75s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:25,  2.78s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:22,  2.77s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:19,  2.77s/it]processing embeddings:  45%|████▌     | 5/11 [00:13<00:16,  2.78s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:13,  2.78s/it]processing embeddings:  64%|██████▎   | 7/11 [00:19<00:11,  2.77s/it]processing embeddings:  73%|███████▎  | 8/11 [00:22<00:08,  2.79s/it]processing embeddings:  82%|████████▏ | 9/11 [00:24<00:05,  2.78s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.77s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.77s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 770 到 780
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:27,  2.74s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:24,  2.73s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:22,  2.76s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:19,  2.80s/it]processing embeddings:  45%|████▌     | 5/11 [00:13<00:16,  2.82s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:13,  2.80s/it]processing embeddings:  64%|██████▎   | 7/11 [00:19<00:11,  2.79s/it]processing embeddings:  73%|███████▎  | 8/11 [00:22<00:08,  2.75s/it]processing embeddings:  82%|████████▏ | 9/11 [00:24<00:05,  2.77s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.75s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.77s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 780 到 790
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:28,  2.85s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:25,  2.82s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:22,  2.83s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:19,  2.80s/it]processing embeddings:  45%|████▌     | 5/11 [00:13<00:16,  2.73s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:13,  2.76s/it]processing embeddings:  64%|██████▎   | 7/11 [00:19<00:11,  2.77s/it]processing embeddings:  73%|███████▎  | 8/11 [00:22<00:08,  2.76s/it]processing embeddings:  82%|████████▏ | 9/11 [00:24<00:05,  2.75s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.74s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.77s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 790 到 800
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:27,  2.77s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:24,  2.76s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:21,  2.74s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:19,  2.76s/it]processing embeddings:  45%|████▌     | 5/11 [00:13<00:16,  2.82s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:13,  2.79s/it]processing embeddings:  64%|██████▎   | 7/11 [00:19<00:11,  2.79s/it]processing embeddings:  73%|███████▎  | 8/11 [00:22<00:08,  2.78s/it]processing embeddings:  82%|████████▏ | 9/11 [00:25<00:05,  2.78s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.74s/it]processing embeddings:  91%|█████████ | 10/11 [00:27<00:02,  2.77s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 800 到 810
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:28,  2.88s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:25,  2.81s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:22,  2.78s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:19,  2.77s/it]processing embeddings:  45%|████▌     | 5/11 [00:13<00:16,  2.77s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:13,  2.75s/it]processing embeddings:  64%|██████▎   | 7/11 [00:19<00:10,  2.72s/it]processing embeddings:  73%|███████▎  | 8/11 [00:22<00:08,  2.89s/it]processing embeddings:  82%|████████▏ | 9/11 [00:25<00:05,  2.96s/it]processing embeddings:  91%|█████████ | 10/11 [00:28<00:02,  2.98s/it]processing embeddings:  91%|█████████ | 10/11 [00:28<00:02,  2.87s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 810 到 820
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:27,  2.75s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:24,  2.75s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:22,  2.76s/it]processing embeddings:  36%|███▋      | 4/11 [00:10<00:19,  2.74s/it]processing embeddings:  45%|████▌     | 5/11 [00:13<00:16,  2.74s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:13,  2.75s/it]processing embeddings:  64%|██████▎   | 7/11 [00:19<00:10,  2.72s/it]processing embeddings:  73%|███████▎  | 8/11 [00:22<00:08,  2.77s/it]processing embeddings:  82%|████████▏ | 9/11 [00:25<00:06,  3.04s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:03,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:02,  2.94s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 820 到 830
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.77s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.75s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.66s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.61s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.57s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.55s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.60s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.62s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.62s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.68s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.64s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 830 到 840
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.72s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.75s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.59s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:26,  3.73s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.70s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.72s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.62s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.60s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.64s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.63s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.66s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 840 到 850
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.79s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.72s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.77s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:27,  3.98s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.75s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.76s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:15,  3.92s/it]processing embeddings:  73%|███████▎  | 8/11 [00:30<00:11,  3.83s/it]processing embeddings:  82%|████████▏ | 9/11 [00:34<00:07,  3.82s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.89s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.85s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 850 到 860
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:42,  4.24s/it]processing embeddings:  18%|█▊        | 2/11 [00:08<00:37,  4.12s/it]processing embeddings:  27%|██▋       | 3/11 [00:12<00:33,  4.15s/it]processing embeddings:  36%|███▋      | 4/11 [00:16<00:30,  4.30s/it]processing embeddings:  45%|████▌     | 5/11 [00:21<00:25,  4.26s/it]processing embeddings:  55%|█████▍    | 6/11 [00:25<00:21,  4.26s/it]processing embeddings:  64%|██████▎   | 7/11 [00:29<00:17,  4.31s/it]processing embeddings:  73%|███████▎  | 8/11 [00:34<00:12,  4.30s/it]processing embeddings:  82%|████████▏ | 9/11 [00:38<00:08,  4.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:42<00:04,  4.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:42<00:04,  4.26s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 860 到 870
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:41,  4.13s/it]processing embeddings:  18%|█▊        | 2/11 [00:08<00:38,  4.30s/it]processing embeddings:  27%|██▋       | 3/11 [00:12<00:34,  4.31s/it]processing embeddings:  36%|███▋      | 4/11 [00:17<00:30,  4.36s/it]processing embeddings:  45%|████▌     | 5/11 [00:20<00:24,  4.05s/it]processing embeddings:  55%|█████▍    | 6/11 [00:23<00:17,  3.58s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:13,  3.27s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:09,  3.08s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:05,  2.98s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:02,  2.88s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.42s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 870 到 880
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:27,  2.72s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:23,  2.66s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:21,  2.69s/it]processing embeddings:  36%|███▋      | 4/11 [00:10<00:18,  2.69s/it]processing embeddings:  45%|████▌     | 5/11 [00:13<00:16,  2.69s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:13,  2.69s/it]processing embeddings:  64%|██████▎   | 7/11 [00:18<00:10,  2.67s/it]processing embeddings:  73%|███████▎  | 8/11 [00:21<00:07,  2.66s/it]processing embeddings:  82%|████████▏ | 9/11 [00:24<00:05,  2.71s/it]processing embeddings:  91%|█████████ | 10/11 [00:26<00:02,  2.71s/it]processing embeddings:  91%|█████████ | 10/11 [00:26<00:02,  2.69s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 880 到 890
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:26,  2.68s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:23,  2.58s/it]processing embeddings:  27%|██▋       | 3/11 [00:07<00:20,  2.61s/it]processing embeddings:  36%|███▋      | 4/11 [00:10<00:18,  2.60s/it]processing embeddings:  45%|████▌     | 5/11 [00:13<00:15,  2.62s/it]processing embeddings:  55%|█████▍    | 6/11 [00:15<00:13,  2.60s/it]processing embeddings:  64%|██████▎   | 7/11 [00:18<00:10,  2.62s/it]processing embeddings:  73%|███████▎  | 8/11 [00:20<00:07,  2.63s/it]processing embeddings:  82%|████████▏ | 9/11 [00:23<00:05,  2.65s/it]processing embeddings:  91%|█████████ | 10/11 [00:26<00:02,  2.73s/it]processing embeddings:  91%|█████████ | 10/11 [00:26<00:02,  2.66s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 890 到 900
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:08<01:24,  8.43s/it]processing embeddings:  18%|█▊        | 2/11 [00:19<01:28,  9.79s/it]processing embeddings:  27%|██▋       | 3/11 [00:29<01:21, 10.19s/it]processing embeddings:  36%|███▋      | 4/11 [00:40<01:12, 10.33s/it]processing embeddings:  45%|████▌     | 5/11 [00:51<01:02, 10.47s/it]processing embeddings:  55%|█████▍    | 6/11 [01:01<00:52, 10.49s/it]processing embeddings:  64%|██████▎   | 7/11 [01:12<00:42, 10.56s/it]processing embeddings:  73%|███████▎  | 8/11 [01:23<00:32, 10.70s/it]processing embeddings:  82%|████████▏ | 9/11 [01:28<00:17,  8.94s/it]processing embeddings:  91%|█████████ | 10/11 [01:32<00:07,  7.60s/it]processing embeddings:  91%|█████████ | 10/11 [01:33<00:09,  9.30s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 900 到 910
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:05<00:50,  5.00s/it]processing embeddings:  18%|█▊        | 2/11 [00:10<00:45,  5.04s/it]processing embeddings:  27%|██▋       | 3/11 [00:14<00:38,  4.86s/it]processing embeddings:  36%|███▋      | 4/11 [00:18<00:32,  4.63s/it]processing embeddings:  45%|████▌     | 5/11 [00:23<00:26,  4.47s/it]processing embeddings:  55%|█████▍    | 6/11 [00:26<00:21,  4.21s/it]processing embeddings:  64%|██████▎   | 7/11 [00:31<00:17,  4.47s/it]processing embeddings:  73%|███████▎  | 8/11 [00:37<00:14,  4.75s/it]processing embeddings:  82%|████████▏ | 9/11 [00:42<00:09,  4.98s/it]processing embeddings:  91%|█████████ | 10/11 [00:49<00:05,  5.46s/it]processing embeddings:  91%|█████████ | 10/11 [00:49<00:04,  4.93s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 910 到 920
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:40,  4.04s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.87s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.86s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:27,  3.87s/it]processing embeddings:  45%|████▌     | 5/11 [00:19<00:22,  3.80s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.77s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:14,  3.73s/it]processing embeddings:  73%|███████▎  | 8/11 [00:30<00:11,  3.69s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.60s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.61s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.72s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 920 到 930
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.69s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.86s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.81s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.76s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.66s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.68s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.64s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.73s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.66s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.67s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 930 到 940
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:38,  3.87s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.71s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.63s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.54s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.65s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.64s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.64s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.64s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.65s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.64s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.65s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 940 到 950
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:38,  3.87s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.80s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.86s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.76s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.74s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.72s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:14,  3.65s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.65s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.74s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.75s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.74s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 950 到 960
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:38,  3.88s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.87s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.78s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:27,  3.87s/it]processing embeddings:  45%|████▌     | 5/11 [00:19<00:23,  3.86s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.77s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:14,  3.63s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.54s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.53s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.52s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.66s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 960 到 970
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.52s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.44s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.40s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.43s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.45s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.43s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.42s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.43s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.45s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.39s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.42s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 970 到 980
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.61s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.57s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.54s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.54s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.49s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.44s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.47s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.41s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.41s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.46s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.47s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 980 到 990
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.38s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.29s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.48s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.47s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.41s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.45s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.43s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.40s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.41s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.47s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.44s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 990 到 1000
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:05<00:56,  5.69s/it]processing embeddings:  18%|█▊        | 2/11 [00:11<00:52,  5.79s/it]processing embeddings:  27%|██▋       | 3/11 [00:17<00:46,  5.86s/it]processing embeddings:  36%|███▋      | 4/11 [00:23<00:42,  6.08s/it]processing embeddings:  45%|████▌     | 5/11 [00:30<00:37,  6.27s/it]processing embeddings:  55%|█████▍    | 6/11 [00:37<00:31,  6.35s/it]processing embeddings:  64%|██████▎   | 7/11 [00:43<00:25,  6.35s/it]processing embeddings:  73%|███████▎  | 8/11 [00:49<00:19,  6.43s/it]processing embeddings:  82%|████████▏ | 9/11 [00:56<00:13,  6.60s/it]processing embeddings:  91%|█████████ | 10/11 [01:03<00:06,  6.59s/it]processing embeddings:  91%|█████████ | 10/11 [01:03<00:06,  6.35s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1000 到 1010
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:07,  6.77s/it]processing embeddings:  18%|█▊        | 2/11 [00:13<01:01,  6.82s/it]processing embeddings:  27%|██▋       | 3/11 [00:20<00:54,  6.80s/it]processing embeddings:  36%|███▋      | 4/11 [00:27<00:47,  6.81s/it]processing embeddings:  45%|████▌     | 5/11 [00:34<00:41,  6.92s/it]processing embeddings:  55%|█████▍    | 6/11 [00:41<00:34,  6.88s/it]processing embeddings:  64%|██████▎   | 7/11 [00:47<00:27,  6.78s/it]processing embeddings:  73%|███████▎  | 8/11 [00:53<00:19,  6.42s/it]processing embeddings:  82%|████████▏ | 9/11 [01:00<00:13,  6.71s/it]processing embeddings:  91%|█████████ | 10/11 [01:09<00:07,  7.34s/it]processing embeddings:  91%|█████████ | 10/11 [01:09<00:06,  6.95s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1010 到 1020
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:08<01:25,  8.51s/it]processing embeddings:  18%|█▊        | 2/11 [00:17<01:18,  8.71s/it]processing embeddings:  27%|██▋       | 3/11 [00:26<01:11,  8.92s/it]processing embeddings:  36%|███▋      | 4/11 [00:35<01:02,  8.88s/it]processing embeddings:  45%|████▌     | 5/11 [00:44<00:53,  8.84s/it]processing embeddings:  55%|█████▍    | 6/11 [00:54<00:47,  9.40s/it]processing embeddings:  64%|██████▎   | 7/11 [01:05<00:40, 10.00s/it]processing embeddings:  73%|███████▎  | 8/11 [01:16<00:30, 10.31s/it]processing embeddings:  82%|████████▏ | 9/11 [01:27<00:21, 10.50s/it]processing embeddings:  91%|█████████ | 10/11 [01:38<00:10, 10.64s/it]processing embeddings:  91%|█████████ | 10/11 [01:38<00:09,  9.87s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1020 到 1030
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:10<01:49, 10.95s/it]processing embeddings:  18%|█▊        | 2/11 [00:22<01:42, 11.34s/it]processing embeddings:  27%|██▋       | 3/11 [00:33<01:30, 11.35s/it]processing embeddings:  36%|███▋      | 4/11 [00:44<01:17, 11.01s/it]processing embeddings:  45%|████▌     | 5/11 [00:54<01:04, 10.76s/it]processing embeddings:  55%|█████▍    | 6/11 [01:04<00:52, 10.45s/it]processing embeddings:  64%|██████▎   | 7/11 [01:16<00:43, 10.83s/it]processing embeddings:  73%|███████▎  | 8/11 [01:27<00:33, 11.05s/it]processing embeddings:  82%|████████▏ | 9/11 [01:38<00:21, 10.99s/it]processing embeddings:  91%|█████████ | 10/11 [01:48<00:10, 10.73s/it]processing embeddings:  91%|█████████ | 10/11 [01:48<00:10, 10.87s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1030 到 1040
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:09<01:33,  9.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:15<01:08,  7.56s/it]processing embeddings:  27%|██▋       | 3/11 [00:22<00:56,  7.04s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:47,  6.84s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:40,  6.71s/it]processing embeddings:  55%|█████▍    | 6/11 [00:41<00:33,  6.72s/it]processing embeddings:  64%|██████▎   | 7/11 [00:48<00:26,  6.60s/it]processing embeddings:  73%|███████▎  | 8/11 [00:54<00:19,  6.55s/it]processing embeddings:  82%|████████▏ | 9/11 [01:01<00:13,  6.54s/it]processing embeddings:  91%|█████████ | 10/11 [01:07<00:06,  6.54s/it]processing embeddings:  91%|█████████ | 10/11 [01:07<00:06,  6.77s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1040 到 1050
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:03,  6.40s/it]processing embeddings:  18%|█▊        | 2/11 [00:13<01:00,  6.67s/it]processing embeddings:  27%|██▋       | 3/11 [00:19<00:53,  6.67s/it]processing embeddings:  36%|███▋      | 4/11 [00:26<00:47,  6.75s/it]processing embeddings:  45%|████▌     | 5/11 [00:33<00:40,  6.79s/it]processing embeddings:  55%|█████▍    | 6/11 [00:40<00:34,  6.84s/it]processing embeddings:  64%|██████▎   | 7/11 [00:47<00:27,  6.83s/it]processing embeddings:  73%|███████▎  | 8/11 [00:54<00:20,  6.76s/it]processing embeddings:  82%|████████▏ | 9/11 [01:00<00:13,  6.67s/it]processing embeddings:  91%|█████████ | 10/11 [01:07<00:06,  6.64s/it]processing embeddings:  91%|█████████ | 10/11 [01:07<00:06,  6.71s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1050 到 1060
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:05,  6.50s/it]processing embeddings:  18%|█▊        | 2/11 [00:12<00:58,  6.48s/it]processing embeddings:  27%|██▋       | 3/11 [00:19<00:52,  6.59s/it]processing embeddings:  36%|███▋      | 4/11 [00:26<00:46,  6.68s/it]processing embeddings:  45%|████▌     | 5/11 [00:33<00:40,  6.74s/it]processing embeddings:  55%|█████▍    | 6/11 [00:39<00:33,  6.71s/it]processing embeddings:  64%|██████▎   | 7/11 [00:47<00:27,  6.97s/it]processing embeddings:  73%|███████▎  | 8/11 [00:55<00:21,  7.20s/it]processing embeddings:  82%|████████▏ | 9/11 [01:02<00:14,  7.15s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.42s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.03s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1060 到 1070
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:08<01:20,  8.10s/it]processing embeddings:  18%|█▊        | 2/11 [00:15<01:10,  7.84s/it]processing embeddings:  27%|██▋       | 3/11 [00:23<01:00,  7.60s/it]processing embeddings:  36%|███▋      | 4/11 [00:31<00:56,  8.05s/it]processing embeddings:  45%|████▌     | 5/11 [00:40<00:50,  8.34s/it]processing embeddings:  55%|█████▍    | 6/11 [00:49<00:42,  8.42s/it]processing embeddings:  64%|██████▎   | 7/11 [00:57<00:33,  8.25s/it]processing embeddings:  73%|███████▎  | 8/11 [01:04<00:23,  7.98s/it]processing embeddings:  82%|████████▏ | 9/11 [01:11<00:15,  7.79s/it]processing embeddings:  91%|█████████ | 10/11 [01:19<00:07,  7.68s/it]processing embeddings:  91%|█████████ | 10/11 [01:19<00:07,  7.94s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1070 到 1080
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:08<01:25,  8.55s/it]processing embeddings:  18%|█▊        | 2/11 [00:17<01:19,  8.82s/it]processing embeddings:  27%|██▋       | 3/11 [00:26<01:10,  8.76s/it]processing embeddings:  36%|███▋      | 4/11 [00:33<00:56,  8.04s/it]processing embeddings:  45%|████▌     | 5/11 [00:36<00:38,  6.47s/it]processing embeddings:  55%|█████▍    | 6/11 [00:40<00:27,  5.57s/it]processing embeddings:  64%|██████▎   | 7/11 [00:44<00:19,  4.94s/it]processing embeddings:  73%|███████▎  | 8/11 [00:48<00:13,  4.64s/it]processing embeddings:  82%|████████▏ | 9/11 [00:51<00:08,  4.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:55<00:04,  4.09s/it]processing embeddings:  91%|█████████ | 10/11 [00:55<00:05,  5.55s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1080 到 1090
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.65s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.53s/it]processing embeddings:  27%|██▋       | 3/11 [00:14<00:43,  5.44s/it]processing embeddings:  36%|███▋      | 4/11 [00:25<00:52,  7.52s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:50,  8.47s/it]processing embeddings:  55%|█████▍    | 6/11 [00:46<00:45,  9.12s/it]processing embeddings:  64%|██████▎   | 7/11 [00:54<00:35,  8.97s/it]processing embeddings:  73%|███████▎  | 8/11 [01:00<00:23,  7.86s/it]processing embeddings:  82%|████████▏ | 9/11 [01:03<00:12,  6.44s/it]processing embeddings:  91%|█████████ | 10/11 [01:07<00:05,  5.61s/it]processing embeddings:  91%|█████████ | 10/11 [01:07<00:06,  6.73s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1090 到 1100
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:38,  3.89s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.71s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.72s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.58s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.38s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.35s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.32s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.52s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.52s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1100 到 1110
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.76s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.87s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.74s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.70s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.75s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.68s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.61s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.74s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.75s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.72s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.72s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1110 到 1120
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.42s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.39s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.36s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:29,  4.21s/it]processing embeddings:  45%|████▌     | 5/11 [00:24<00:36,  6.02s/it]processing embeddings:  55%|█████▍    | 6/11 [00:35<00:37,  7.43s/it]processing embeddings:  64%|██████▎   | 7/11 [00:44<00:31,  7.99s/it]processing embeddings:  73%|███████▎  | 8/11 [00:54<00:26,  8.75s/it]processing embeddings:  82%|████████▏ | 9/11 [01:05<00:19,  9.56s/it]processing embeddings:  91%|█████████ | 10/11 [01:13<00:09,  9.07s/it]processing embeddings:  91%|█████████ | 10/11 [01:13<00:07,  7.39s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1120 到 1130
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:08<01:23,  8.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:16<01:13,  8.21s/it]processing embeddings:  27%|██▋       | 3/11 [00:25<01:08,  8.62s/it]processing embeddings:  36%|███▋      | 4/11 [00:33<00:59,  8.50s/it]processing embeddings:  45%|████▌     | 5/11 [00:42<00:51,  8.51s/it]processing embeddings:  55%|█████▍    | 6/11 [00:50<00:41,  8.22s/it]processing embeddings:  64%|██████▎   | 7/11 [00:55<00:29,  7.27s/it]processing embeddings:  73%|███████▎  | 8/11 [01:00<00:20,  6.70s/it]processing embeddings:  82%|████████▏ | 9/11 [01:05<00:12,  6.16s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:05,  5.81s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.09s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1130 到 1140
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:05<00:51,  5.15s/it]processing embeddings:  18%|█▊        | 2/11 [00:10<00:45,  5.11s/it]processing embeddings:  27%|██▋       | 3/11 [00:15<00:41,  5.20s/it]processing embeddings:  36%|███▋      | 4/11 [00:20<00:36,  5.19s/it]processing embeddings:  45%|████▌     | 5/11 [00:26<00:31,  5.30s/it]processing embeddings:  55%|█████▍    | 6/11 [00:31<00:26,  5.23s/it]processing embeddings:  64%|██████▎   | 7/11 [00:36<00:20,  5.22s/it]processing embeddings:  73%|███████▎  | 8/11 [00:41<00:15,  5.02s/it]processing embeddings:  82%|████████▏ | 9/11 [00:45<00:09,  4.88s/it]processing embeddings:  91%|█████████ | 10/11 [00:50<00:04,  4.92s/it]processing embeddings:  91%|█████████ | 10/11 [00:50<00:05,  5.07s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1140 到 1150
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:46,  4.66s/it]processing embeddings:  18%|█▊        | 2/11 [00:09<00:41,  4.63s/it]processing embeddings:  27%|██▋       | 3/11 [00:13<00:35,  4.46s/it]processing embeddings:  36%|███▋      | 4/11 [00:17<00:31,  4.43s/it]processing embeddings:  45%|████▌     | 5/11 [00:22<00:26,  4.38s/it]processing embeddings:  55%|█████▍    | 6/11 [00:25<00:20,  4.05s/it]processing embeddings:  64%|██████▎   | 7/11 [00:28<00:15,  3.83s/it]processing embeddings:  73%|███████▎  | 8/11 [00:32<00:11,  3.73s/it]processing embeddings:  82%|████████▏ | 9/11 [00:36<00:07,  3.68s/it]processing embeddings:  91%|█████████ | 10/11 [00:39<00:03,  3.66s/it]processing embeddings:  91%|█████████ | 10/11 [00:39<00:03,  3.97s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1150 到 1160
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.45s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.49s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.49s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.47s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.55s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.55s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.54s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.52s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.48s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.53s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.52s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1160 到 1170
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.58s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.87s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:31,  3.98s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:27,  3.86s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.69s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:17,  3.55s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:13,  3.39s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:09,  3.25s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.12s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.09s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.40s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1170 到 1180
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:27,  2.77s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:25,  2.78s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:23,  2.93s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.17s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:19,  3.27s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.32s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.39s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.50s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.69s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.39s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1180 到 1190
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:43,  4.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:08<00:40,  4.49s/it]processing embeddings:  27%|██▋       | 3/11 [00:13<00:36,  4.62s/it]processing embeddings:  36%|███▋      | 4/11 [00:19<00:34,  4.91s/it]processing embeddings:  45%|████▌     | 5/11 [00:23<00:28,  4.79s/it]processing embeddings:  55%|█████▍    | 6/11 [00:27<00:21,  4.38s/it]processing embeddings:  64%|██████▎   | 7/11 [00:30<00:16,  4.06s/it]processing embeddings:  73%|███████▎  | 8/11 [00:33<00:11,  3.81s/it]processing embeddings:  82%|████████▏ | 9/11 [00:37<00:07,  3.71s/it]processing embeddings:  91%|█████████ | 10/11 [00:40<00:03,  3.65s/it]processing embeddings:  91%|█████████ | 10/11 [00:40<00:04,  4.09s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1190 到 1200
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.60s/it]processing embeddings:  18%|█▊        | 2/11 [00:09<00:43,  4.78s/it]processing embeddings:  27%|██▋       | 3/11 [00:14<00:40,  5.12s/it]processing embeddings:  36%|███▋      | 4/11 [00:20<00:36,  5.26s/it]processing embeddings:  45%|████▌     | 5/11 [00:25<00:32,  5.39s/it]processing embeddings:  55%|█████▍    | 6/11 [00:31<00:27,  5.44s/it]processing embeddings:  64%|██████▎   | 7/11 [00:36<00:21,  5.47s/it]processing embeddings:  73%|███████▎  | 8/11 [00:42<00:16,  5.45s/it]processing embeddings:  82%|████████▏ | 9/11 [00:47<00:10,  5.45s/it]processing embeddings:  91%|█████████ | 10/11 [00:53<00:05,  5.65s/it]processing embeddings:  91%|█████████ | 10/11 [00:53<00:05,  5.39s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1200 到 1210
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:05<00:53,  5.39s/it]processing embeddings:  18%|█▊        | 2/11 [00:10<00:49,  5.47s/it]processing embeddings:  27%|██▋       | 3/11 [00:16<00:42,  5.35s/it]processing embeddings:  36%|███▋      | 4/11 [00:21<00:37,  5.37s/it]processing embeddings:  45%|████▌     | 5/11 [00:26<00:32,  5.39s/it]processing embeddings:  55%|█████▍    | 6/11 [00:32<00:26,  5.40s/it]processing embeddings:  64%|██████▎   | 7/11 [00:37<00:21,  5.41s/it]processing embeddings:  73%|███████▎  | 8/11 [00:43<00:16,  5.37s/it]processing embeddings:  82%|████████▏ | 9/11 [00:48<00:10,  5.35s/it]processing embeddings:  91%|█████████ | 10/11 [00:53<00:05,  5.36s/it]processing embeddings:  91%|█████████ | 10/11 [00:53<00:05,  5.39s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1210 到 1220
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:05<00:54,  5.44s/it]processing embeddings:  18%|█▊        | 2/11 [00:10<00:47,  5.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:16<00:43,  5.41s/it]processing embeddings:  36%|███▋      | 4/11 [00:21<00:37,  5.38s/it]processing embeddings:  45%|████▌     | 5/11 [00:26<00:32,  5.35s/it]processing embeddings:  55%|█████▍    | 6/11 [00:32<00:27,  5.49s/it]processing embeddings:  64%|██████▎   | 7/11 [00:37<00:21,  5.47s/it]processing embeddings:  73%|███████▎  | 8/11 [00:43<00:16,  5.43s/it]processing embeddings:  82%|████████▏ | 9/11 [00:48<00:10,  5.49s/it]processing embeddings:  91%|█████████ | 10/11 [00:58<00:06,  6.61s/it]processing embeddings:  91%|█████████ | 10/11 [00:58<00:05,  5.82s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1220 到 1230
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:11<01:50, 11.10s/it]processing embeddings:  18%|█▊        | 2/11 [00:23<01:44, 11.65s/it]processing embeddings:  27%|██▋       | 3/11 [00:34<01:31, 11.43s/it]processing embeddings:  36%|███▋      | 4/11 [00:46<01:22, 11.78s/it]processing embeddings:  45%|████▌     | 5/11 [00:59<01:12, 12.05s/it]processing embeddings:  55%|█████▍    | 6/11 [01:11<01:01, 12.31s/it]processing embeddings:  64%|██████▎   | 7/11 [01:18<00:41, 10.42s/it]processing embeddings:  73%|███████▎  | 8/11 [01:25<00:28,  9.37s/it]processing embeddings:  82%|████████▏ | 9/11 [01:32<00:17,  8.66s/it]processing embeddings:  91%|█████████ | 10/11 [01:41<00:08,  8.66s/it]processing embeddings:  91%|█████████ | 10/11 [01:41<00:10, 10.14s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1230 到 1240
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:09<01:32,  9.29s/it]processing embeddings:  18%|█▊        | 2/11 [00:19<01:29, 10.00s/it]processing embeddings:  27%|██▋       | 3/11 [00:29<01:20, 10.08s/it]processing embeddings:  36%|███▋      | 4/11 [00:38<01:07,  9.64s/it]processing embeddings:  45%|████▌     | 5/11 [00:43<00:46,  7.71s/it]processing embeddings:  55%|█████▍    | 6/11 [00:46<00:31,  6.20s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:21,  5.37s/it]processing embeddings:  73%|███████▎  | 8/11 [00:53<00:14,  4.69s/it]processing embeddings:  82%|████████▏ | 9/11 [00:56<00:08,  4.25s/it]processing embeddings:  91%|█████████ | 10/11 [01:00<00:04,  4.06s/it]processing embeddings:  91%|█████████ | 10/11 [01:00<00:06,  6.03s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1240 到 1250
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.31s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:26,  2.94s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:24,  3.04s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:20,  2.87s/it]processing embeddings:  45%|████▌     | 5/11 [00:14<00:16,  2.77s/it]processing embeddings:  55%|█████▍    | 6/11 [00:16<00:13,  2.70s/it]processing embeddings:  64%|██████▎   | 7/11 [00:19<00:10,  2.70s/it]processing embeddings:  73%|███████▎  | 8/11 [00:22<00:08,  2.68s/it]processing embeddings:  82%|████████▏ | 9/11 [00:25<00:05,  2.79s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:03,  3.09s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:02,  2.93s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1250 到 1260
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:40,  4.09s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.86s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.81s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.79s/it]processing embeddings:  45%|████▌     | 5/11 [00:19<00:22,  3.82s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.62s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:13,  3.29s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:09,  3.10s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:05,  2.97s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:02,  2.91s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.32s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1260 到 1270
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:26,  2.65s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:24,  2.74s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:21,  2.67s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:22,  3.16s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:21,  3.56s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:19,  3.90s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:16,  4.06s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:12,  4.16s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:08,  4.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:04,  4.38s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.89s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1270 到 1280
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:45,  4.57s/it]processing embeddings:  18%|█▊        | 2/11 [00:08<00:38,  4.24s/it]processing embeddings:  27%|██▋       | 3/11 [00:12<00:31,  3.92s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.81s/it]processing embeddings:  45%|████▌     | 5/11 [00:19<00:22,  3.67s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.60s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.52s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.44s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:06,  3.37s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.44s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.69s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1280 到 1290
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.24s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.34s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.45s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.47s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.47s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.44s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.40s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.40s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.50s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.50s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.48s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1290 到 1300
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.33s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.39s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.31s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.30s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.47s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.57s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:16,  4.19s/it]processing embeddings:  73%|███████▎  | 8/11 [00:31<00:13,  4.47s/it]processing embeddings:  82%|████████▏ | 9/11 [00:35<00:08,  4.46s/it]processing embeddings:  91%|█████████ | 10/11 [00:40<00:04,  4.52s/it]processing embeddings:  91%|█████████ | 10/11 [00:40<00:04,  4.06s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1300 到 1310
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:42,  4.25s/it]processing embeddings:  18%|█▊        | 2/11 [00:08<00:36,  4.00s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.83s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:25,  3.71s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.70s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.67s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:14,  3.69s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.68s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.66s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.62s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.73s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1310 到 1320
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.52s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.61s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:29,  3.66s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.70s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.70s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.68s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.68s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.61s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.61s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.59s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.67s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1320 到 1330
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.50s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.54s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.59s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.69s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.71s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.67s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.61s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.62s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.59s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.61s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1330 到 1340
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.45s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.47s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.42s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.44s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.47s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.40s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.40s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.39s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.42s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.41s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.45s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1340 到 1350
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.48s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.40s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.44s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.38s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.44s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.41s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.44s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.62s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.77s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.70s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.57s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1350 到 1360
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:39,  3.96s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.86s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.82s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:27,  3.96s/it]processing embeddings:  45%|████▌     | 5/11 [00:19<00:22,  3.82s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.70s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:14,  3.65s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.65s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.66s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.59s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.71s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1360 到 1370
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.74s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.81s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.86s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.80s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.71s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.70s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:15,  3.82s/it]processing embeddings:  73%|███████▎  | 8/11 [00:30<00:12,  4.01s/it]processing embeddings:  82%|████████▏ | 9/11 [00:35<00:08,  4.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:40<00:04,  4.47s/it]processing embeddings:  91%|█████████ | 10/11 [00:40<00:04,  4.10s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1370 到 1380
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:05<00:51,  5.13s/it]processing embeddings:  18%|█▊        | 2/11 [00:10<00:48,  5.39s/it]processing embeddings:  27%|██▋       | 3/11 [00:16<00:43,  5.46s/it]processing embeddings:  36%|███▋      | 4/11 [00:22<00:40,  5.73s/it]processing embeddings:  45%|████▌     | 5/11 [00:29<00:36,  6.07s/it]processing embeddings:  55%|█████▍    | 6/11 [00:35<00:31,  6.22s/it]processing embeddings:  64%|██████▎   | 7/11 [00:42<00:25,  6.33s/it]processing embeddings:  73%|███████▎  | 8/11 [00:48<00:18,  6.32s/it]processing embeddings:  82%|████████▏ | 9/11 [00:54<00:12,  6.24s/it]processing embeddings:  91%|█████████ | 10/11 [01:00<00:06,  6.30s/it]processing embeddings:  91%|█████████ | 10/11 [01:01<00:06,  6.12s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1380 到 1390
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:03,  6.34s/it]processing embeddings:  18%|█▊        | 2/11 [00:12<00:56,  6.26s/it]processing embeddings:  27%|██▋       | 3/11 [00:18<00:50,  6.27s/it]processing embeddings:  36%|███▋      | 4/11 [00:25<00:44,  6.41s/it]processing embeddings:  45%|████▌     | 5/11 [00:31<00:38,  6.41s/it]processing embeddings:  55%|█████▍    | 6/11 [00:38<00:31,  6.39s/it]processing embeddings:  64%|██████▎   | 7/11 [00:44<00:25,  6.43s/it]processing embeddings:  73%|███████▎  | 8/11 [00:51<00:19,  6.39s/it]processing embeddings:  82%|████████▏ | 9/11 [00:57<00:12,  6.38s/it]processing embeddings:  91%|█████████ | 10/11 [01:03<00:06,  6.35s/it]processing embeddings:  91%|█████████ | 10/11 [01:03<00:06,  6.38s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1390 到 1400
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:02,  6.26s/it]processing embeddings:  18%|█▊        | 2/11 [00:12<00:56,  6.28s/it]processing embeddings:  27%|██▋       | 3/11 [00:18<00:49,  6.23s/it]processing embeddings:  36%|███▋      | 4/11 [00:24<00:43,  6.16s/it]processing embeddings:  45%|████▌     | 5/11 [00:30<00:36,  6.12s/it]processing embeddings:  55%|█████▍    | 6/11 [00:37<00:30,  6.19s/it]processing embeddings:  64%|██████▎   | 7/11 [00:43<00:25,  6.31s/it]processing embeddings:  73%|███████▎  | 8/11 [00:50<00:18,  6.32s/it]processing embeddings:  82%|████████▏ | 9/11 [00:56<00:12,  6.29s/it]processing embeddings:  91%|█████████ | 10/11 [01:02<00:06,  6.32s/it]processing embeddings:  91%|█████████ | 10/11 [01:02<00:06,  6.27s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1400 到 1410
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:04,  6.43s/it]processing embeddings:  18%|█▊        | 2/11 [00:12<00:56,  6.30s/it]processing embeddings:  27%|██▋       | 3/11 [00:19<00:52,  6.53s/it]processing embeddings:  36%|███▋      | 4/11 [00:26<00:46,  6.62s/it]processing embeddings:  45%|████▌     | 5/11 [00:32<00:38,  6.44s/it]processing embeddings:  55%|█████▍    | 6/11 [00:38<00:31,  6.37s/it]processing embeddings:  64%|██████▎   | 7/11 [00:44<00:25,  6.36s/it]processing embeddings:  73%|███████▎  | 8/11 [00:51<00:19,  6.34s/it]processing embeddings:  82%|████████▏ | 9/11 [00:57<00:12,  6.40s/it]processing embeddings:  91%|█████████ | 10/11 [01:03<00:06,  6.22s/it]processing embeddings:  91%|█████████ | 10/11 [01:03<00:06,  6.36s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1410 到 1420
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.49s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.49s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.59s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.64s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.68s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.67s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.64s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.66s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.78s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.73s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.69s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1420 到 1430
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.55s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.65s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.76s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.64s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.62s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.69s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:15,  3.75s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.82s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.75s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.73s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.72s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1430 到 1440
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.65s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.65s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.75s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.81s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.76s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.73s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:14,  3.74s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.72s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.73s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.71s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.73s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1440 到 1450
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.66s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.51s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.42s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.55s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.56s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.64s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.60s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.54s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.52s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.50s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.54s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1450 到 1460
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.58s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.31s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.28s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.33s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.35s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.40s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.45s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.44s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.40s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.39s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.39s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1460 到 1470
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.43s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.38s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.37s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.39s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.47s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.40s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.40s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.37s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.36s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.36s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1470 到 1480
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.11s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:27,  3.02s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:24,  3.08s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.16s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:18,  3.16s/it]processing embeddings:  55%|█████▍    | 6/11 [00:18<00:16,  3.21s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.23s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.17s/it]processing embeddings:  82%|████████▏ | 9/11 [00:28<00:06,  3.18s/it]processing embeddings:  91%|█████████ | 10/11 [00:31<00:03,  3.19s/it]processing embeddings:  91%|█████████ | 10/11 [00:31<00:03,  3.17s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1480 到 1490
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:30,  3.09s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.31s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:30,  3.75s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:27,  3.90s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:23,  3.87s/it]processing embeddings:  55%|█████▍    | 6/11 [00:23<00:20,  4.04s/it]processing embeddings:  64%|██████▎   | 7/11 [00:27<00:16,  4.13s/it]processing embeddings:  73%|███████▎  | 8/11 [00:31<00:12,  4.18s/it]processing embeddings:  82%|████████▏ | 9/11 [00:35<00:07,  3.96s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.81s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.87s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1490 到 1500
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.44s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.43s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.42s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.43s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.39s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.29s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.31s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.34s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.25s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.21s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1500 到 1510
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.26s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.28s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.32s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.34s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.40s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.43s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.48s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.49s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.61s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.62s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.49s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1510 到 1520
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.68s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.60s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.57s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.51s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.54s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.50s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.43s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.39s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.35s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.28s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.42s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1520 到 1530
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.51s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.45s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.46s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.59s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.74s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.54s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.46s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.43s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.38s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.44s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1530 到 1540
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.52s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.81s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.79s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.66s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.59s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.52s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.52s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.56s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:06,  3.47s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.50s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1540 到 1550
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:26,  2.67s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:26,  2.94s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:24,  3.09s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:21,  3.13s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:19,  3.19s/it]processing embeddings:  55%|█████▍    | 6/11 [00:18<00:16,  3.23s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:14,  3.56s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.53s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.39s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1550 到 1560
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.21s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.25s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.23s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.33s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.33s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.35s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.46s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.24s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.13s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.11s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.23s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1560 到 1570
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.24s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.19s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.28s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.29s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.30s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.38s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.42s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.13s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.40s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1570 到 1580
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:26,  2.63s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:23,  2.62s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:24,  3.03s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:21,  3.11s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:20,  3.35s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.37s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.37s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.29s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.23s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1580 到 1590
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.42s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.47s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.56s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.56s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.63s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.62s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.63s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.61s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.68s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.68s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.62s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1590 到 1600
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.65s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.60s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.60s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.64s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.69s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.65s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.58s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.52s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.38s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.53s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1600 到 1610
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:29,  2.98s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:27,  3.05s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:24,  3.02s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:21,  3.05s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:19,  3.28s/it]processing embeddings:  55%|█████▍    | 6/11 [00:18<00:15,  3.13s/it]processing embeddings:  64%|██████▎   | 7/11 [00:21<00:12,  3.10s/it]processing embeddings:  73%|███████▎  | 8/11 [00:24<00:09,  3.05s/it]processing embeddings:  82%|████████▏ | 9/11 [00:28<00:06,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:31<00:03,  3.36s/it]processing embeddings:  91%|█████████ | 10/11 [00:31<00:03,  3.20s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1610 到 1620
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.60s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.63s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.59s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.62s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.55s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.55s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.58s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.57s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.56s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.54s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.57s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1620 到 1630
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.51s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.44s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.56s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.58s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.54s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.52s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.51s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.54s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.56s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.56s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1630 到 1640
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.76s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.58s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.68s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.68s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.60s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.57s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.57s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.57s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.52s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.41s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.54s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1640 到 1650
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:30,  3.07s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.17s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:24,  3.08s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:21,  3.13s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:18,  3.03s/it]processing embeddings:  55%|█████▍    | 6/11 [00:18<00:14,  2.91s/it]processing embeddings:  64%|██████▎   | 7/11 [00:21<00:11,  2.96s/it]processing embeddings:  73%|███████▎  | 8/11 [00:23<00:08,  2.84s/it]processing embeddings:  82%|████████▏ | 9/11 [00:27<00:06,  3.01s/it]processing embeddings:  91%|█████████ | 10/11 [00:30<00:03,  3.21s/it]processing embeddings:  91%|█████████ | 10/11 [00:30<00:03,  3.07s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1650 到 1660
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.61s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.57s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.55s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.51s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.57s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.63s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.71s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.74s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.76s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.78s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.69s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1660 到 1670
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:39,  3.97s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.79s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.76s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.73s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.64s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.55s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.51s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.55s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.53s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.59s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1670 到 1680
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:38,  3.81s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.66s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.69s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.68s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.66s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.60s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.56s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.59s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.59s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.59s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.62s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1680 到 1690
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.47s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.50s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.52s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.54s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.53s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.47s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.55s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.63s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.64s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.57s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1690 到 1700
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.59s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.83s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.81s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.84s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.77s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.74s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:14,  3.69s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.64s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.52s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.66s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1700 到 1710
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.51s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.41s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.45s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.40s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.60s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.73s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:15,  3.80s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.71s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.66s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.64s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.64s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1710 到 1720
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.59s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.64s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.83s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.70s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.58s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.48s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.40s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.36s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.37s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.40s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.50s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1720 到 1730
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.80s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.71s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.66s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.56s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.52s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.46s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.42s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.39s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.50s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1730 到 1740
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.66s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.56s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.56s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.52s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.54s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.46s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.40s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.39s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.45s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.49s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.51s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1740 到 1750
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.45s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.40s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.38s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.35s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.35s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.45s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.50s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.55s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.59s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.51s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1750 到 1760
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.71s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.61s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.51s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.55s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.48s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.42s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.39s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.37s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.42s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1760 到 1770
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.17s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.15s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.14s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.23s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.41s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.52s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.43s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.45s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.40s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.38s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.37s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1770 到 1780
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.29s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.21s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:24,  3.12s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:21,  3.08s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:18,  3.16s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.22s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.23s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.24s/it]processing embeddings:  82%|████████▏ | 9/11 [00:28<00:06,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:31<00:03,  3.20s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.20s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1780 到 1790
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.29s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.23s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.13s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:21,  3.13s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:18,  3.14s/it]processing embeddings:  55%|█████▍    | 6/11 [00:18<00:15,  3.17s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.15s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.41s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:07,  3.55s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.53s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.35s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1790 到 1800
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.32s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.47s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.50s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.50s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.43s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.42s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.43s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.48s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.43s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1800 到 1810
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:30,  3.10s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.17s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.15s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:21,  3.12s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:19,  3.21s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.24s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.36s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:07,  3.59s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.69s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.43s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1810 到 1820
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.73s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.77s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.70s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.49s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.38s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.29s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:12,  3.22s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.21s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.21s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.19s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1820 到 1830
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:30,  3.08s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.16s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.14s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.19s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.44s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.59s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.73s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:11,  3.77s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.81s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.74s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.61s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1830 到 1840
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:30,  3.06s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.14s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.21s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.19s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:19,  3.20s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:15,  3.17s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.10s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.11s/it]processing embeddings:  82%|████████▏ | 9/11 [00:28<00:06,  3.09s/it]processing embeddings:  91%|█████████ | 10/11 [00:31<00:03,  3.08s/it]processing embeddings:  91%|█████████ | 10/11 [00:31<00:03,  3.12s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1840 到 1850
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.16s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.70s/it]processing embeddings:  27%|██▋       | 3/11 [00:20<01:05,  8.21s/it]processing embeddings:  36%|███▋      | 4/11 [00:36<01:18, 11.24s/it]processing embeddings:  45%|████▌     | 5/11 [00:53<01:18, 13.10s/it]processing embeddings:  55%|█████▍    | 6/11 [01:09<01:11, 14.21s/it]processing embeddings:  64%|██████▎   | 7/11 [01:25<00:59, 14.86s/it]processing embeddings:  73%|███████▎  | 8/11 [01:42<00:46, 15.34s/it]processing embeddings:  82%|████████▏ | 9/11 [01:58<00:31, 15.57s/it]processing embeddings:  91%|█████████ | 10/11 [02:14<00:15, 15.78s/it]processing embeddings:  91%|█████████ | 10/11 [02:14<00:13, 13.44s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1850 到 1860
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:16<02:41, 16.11s/it]processing embeddings:  18%|█▊        | 2/11 [00:32<02:26, 16.32s/it]processing embeddings:  27%|██▋       | 3/11 [00:49<02:11, 16.45s/it]processing embeddings:  36%|███▋      | 4/11 [01:06<01:56, 16.60s/it]processing embeddings:  45%|████▌     | 5/11 [01:22<01:39, 16.56s/it]processing embeddings:  55%|█████▍    | 6/11 [01:39<01:23, 16.65s/it]processing embeddings:  64%|██████▎   | 7/11 [01:55<01:06, 16.64s/it]processing embeddings:  73%|███████▎  | 8/11 [02:11<00:48, 16.18s/it]processing embeddings:  82%|████████▏ | 9/11 [02:26<00:31, 15.90s/it]processing embeddings:  91%|█████████ | 10/11 [02:41<00:15, 15.62s/it]processing embeddings:  91%|█████████ | 10/11 [02:41<00:16, 16.14s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1860 到 1870
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:15<02:35, 15.53s/it]processing embeddings:  18%|█▊        | 2/11 [00:30<02:16, 15.13s/it]processing embeddings:  27%|██▋       | 3/11 [00:45<01:59, 14.99s/it]processing embeddings:  36%|███▋      | 4/11 [01:00<01:45, 15.02s/it]processing embeddings:  45%|████▌     | 5/11 [01:15<01:30, 15.16s/it]processing embeddings:  55%|█████▍    | 6/11 [01:30<01:15, 15.19s/it]processing embeddings:  64%|██████▎   | 7/11 [01:45<01:00, 15.07s/it]processing embeddings:  73%|███████▎  | 8/11 [02:00<00:45, 15.11s/it]processing embeddings:  82%|████████▏ | 9/11 [02:15<00:30, 15.03s/it]processing embeddings:  91%|█████████ | 10/11 [02:30<00:15, 15.06s/it]processing embeddings:  91%|█████████ | 10/11 [02:30<00:15, 15.09s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1870 到 1880
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:15<02:35, 15.53s/it]processing embeddings:  18%|█▊        | 2/11 [00:31<02:20, 15.59s/it]processing embeddings:  27%|██▋       | 3/11 [00:47<02:08, 16.01s/it]processing embeddings:  36%|███▋      | 4/11 [01:04<01:53, 16.21s/it]processing embeddings:  45%|████▌     | 5/11 [01:20<01:38, 16.39s/it]processing embeddings:  55%|█████▍    | 6/11 [01:37<01:22, 16.55s/it]processing embeddings:  64%|██████▎   | 7/11 [01:54<01:06, 16.62s/it]processing embeddings:  73%|███████▎  | 8/11 [02:10<00:49, 16.50s/it]processing embeddings:  82%|████████▏ | 9/11 [02:25<00:31, 15.88s/it]processing embeddings:  91%|█████████ | 10/11 [02:39<00:15, 15.46s/it]processing embeddings:  91%|█████████ | 10/11 [02:39<00:15, 15.98s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1880 到 1890
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:14<02:26, 14.64s/it]processing embeddings:  18%|█▊        | 2/11 [00:29<02:12, 14.75s/it]processing embeddings:  27%|██▋       | 3/11 [00:44<01:59, 14.90s/it]processing embeddings:  36%|███▋      | 4/11 [00:59<01:45, 15.07s/it]processing embeddings:  45%|████▌     | 5/11 [01:15<01:31, 15.17s/it]processing embeddings:  55%|█████▍    | 6/11 [01:30<01:15, 15.12s/it]processing embeddings:  64%|██████▎   | 7/11 [01:47<01:03, 15.78s/it]processing embeddings:  73%|███████▎  | 8/11 [02:04<00:48, 16.24s/it]processing embeddings:  82%|████████▏ | 9/11 [02:22<00:33, 16.68s/it]processing embeddings:  91%|█████████ | 10/11 [02:39<00:16, 16.85s/it]processing embeddings:  91%|█████████ | 10/11 [02:39<00:15, 15.95s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1890 到 1900
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:17<02:53, 17.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:34<02:36, 17.37s/it]processing embeddings:  27%|██▋       | 3/11 [00:51<02:17, 17.24s/it]processing embeddings:  36%|███▋      | 4/11 [01:09<02:00, 17.22s/it]processing embeddings:  45%|████▌     | 5/11 [01:26<01:43, 17.20s/it]processing embeddings:  55%|█████▍    | 6/11 [01:43<01:25, 17.19s/it]processing embeddings:  64%|██████▎   | 7/11 [02:00<01:08, 17.17s/it]processing embeddings:  73%|███████▎  | 8/11 [02:08<00:42, 14.18s/it]processing embeddings:  82%|████████▏ | 9/11 [02:11<00:21, 10.86s/it]processing embeddings:  91%|█████████ | 10/11 [02:15<00:08,  8.65s/it]processing embeddings:  91%|█████████ | 10/11 [02:15<00:13, 13.55s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1900 到 1910
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.53s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.59s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.54s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.67s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.62s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.62s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:15,  3.79s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.82s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.77s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.66s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.68s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1910 到 1920
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.60s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.59s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.59s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.59s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.64s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.67s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.58s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.60s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.52s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.48s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.56s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1920 到 1930
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.57s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.51s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.41s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.44s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.43s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.45s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.52s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.50s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.47s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.47s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1930 到 1940
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.63s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.55s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.45s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.49s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.44s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.45s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.53s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.52s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.46s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.49s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1940 到 1950
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.42s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.56s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.43s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.47s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.54s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.60s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.55s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.48s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.56s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.52s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1950 到 1960
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.67s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.55s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.79s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:26,  3.73s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.73s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.58s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.52s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.63s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.58s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.68s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.65s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1960 到 1970
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.63s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.59s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.58s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.54s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.66s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.56s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.57s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.58s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.61s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.52s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.57s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1970 到 1980
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.44s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.33s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.48s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.49s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.54s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.60s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.53s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.51s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.48s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.46s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.49s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1980 到 1990
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.65s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.57s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:29,  3.63s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:26,  3.76s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.71s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.59s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.51s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.47s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.42s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.50s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.55s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 1990 到 2000
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.59s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.54s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:29,  3.64s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.59s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.55s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.54s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.57s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.56s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.55s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2000 到 2010
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.53s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.41s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.47s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.45s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.48s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.47s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.46s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.40s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.39s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.41s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.43s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2010 到 2020
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.70s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.56s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.53s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.45s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.50s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.51s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:15,  3.80s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.80s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.93s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.79s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.70s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2020 到 2030
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.54s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.54s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.43s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.37s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.44s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.45s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.50s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.54s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.56s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.58s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.52s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2030 到 2040
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.79s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.72s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.60s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.50s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.47s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.50s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.53s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.49s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.49s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.49s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.52s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2040 到 2050
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.51s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.56s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.45s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.47s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.41s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.49s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.54s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.53s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.58s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.61s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.54s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2050 到 2060
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.62s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.47s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.49s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.55s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.47s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.49s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.45s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.48s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.46s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.49s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2060 到 2070
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.67s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.52s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.44s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.55s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.49s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.49s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.49s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.49s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.47s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.49s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2070 到 2080
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.68s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.61s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.61s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.57s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.66s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.67s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.55s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.47s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.46s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.49s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.55s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2080 到 2090
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.68s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.60s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.56s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.62s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.73s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.79s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.74s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.66s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.60s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.62s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2090 到 2100
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.72s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.59s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.46s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.51s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.51s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.53s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.53s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.52s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.47s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.45s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.50s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2100 到 2110
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.41s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.34s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.42s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.41s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.43s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.37s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.38s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.52s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.56s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.52s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.47s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2110 到 2120
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.48s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.39s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.55s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.44s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.51s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.56s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.57s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.51s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.53s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.52s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2120 到 2130
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:40,  4.02s/it]processing embeddings:  18%|█▊        | 2/11 [00:08<00:36,  4.02s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:31,  3.95s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.79s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.64s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:17,  3.54s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:13,  3.50s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.56s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.55s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.64s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2130 到 2140
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.67s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.44s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.43s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.48s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.47s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.53s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.47s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.47s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.44s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.52s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.49s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2140 到 2150
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.64s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.60s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:29,  3.67s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.60s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.57s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.63s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.55s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.52s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.50s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.49s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.58s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2150 到 2160
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.38s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.37s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.46s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.54s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.55s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.48s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.49s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.48s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.49s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.52s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.52s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2160 到 2170
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.76s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.52s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.48s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.49s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.44s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.72s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.66s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.66s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.74s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.66s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.67s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2170 到 2180
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.48s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.53s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.46s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.51s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.44s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.46s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.55s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.47s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.44s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.40s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.47s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2180 到 2190
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.69s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.49s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.50s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.39s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.44s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.45s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.39s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.37s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.44s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.48s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.46s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2190 到 2200
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.43s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.52s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.43s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.53s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.53s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.52s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.53s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.47s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.49s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.50s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.53s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2200 到 2210
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.37s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.50s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.55s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.44s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.44s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.43s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.49s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.48s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.42s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.48s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2210 到 2220
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.50s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.56s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.59s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.60s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.56s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.58s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.60s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.71s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.90s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.89s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.73s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2220 到 2230
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.57s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.50s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.44s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.50s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.46s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.40s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.43s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.43s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.44s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.41s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.45s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2230 到 2240
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.56s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.65s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:29,  3.63s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.62s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.63s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.59s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.59s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.48s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.44s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.46s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.56s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2240 到 2250
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.57s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.57s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.52s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.54s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.55s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.58s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.56s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.53s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.67s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.60s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2250 到 2260
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:39,  3.95s/it]processing embeddings:  18%|█▊        | 2/11 [00:08<00:36,  4.04s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.82s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.60s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.63s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.62s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.63s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.65s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.64s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.60s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.67s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2260 到 2270
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.37s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.35s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.40s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.42s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.47s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.53s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.66s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.56s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.58s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.60s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.56s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2270 到 2280
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.58s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.66s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.52s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.58s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.53s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.50s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.59s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.51s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.48s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.50s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.53s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2280 到 2290
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.29s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.31s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.41s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.45s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.53s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.47s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.48s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.47s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.44s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.39s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.43s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2290 到 2300
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.73s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.53s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.52s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.48s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.54s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.52s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.53s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.45s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.54s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.52s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2300 到 2310
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.78s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.57s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.49s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.47s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.50s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.53s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.49s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.56s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.59s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.60s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.56s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2310 到 2320
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.54s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.50s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:29,  3.68s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.61s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.66s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.60s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.52s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.48s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.55s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2320 到 2330
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:43,  4.34s/it]processing embeddings:  18%|█▊        | 2/11 [00:08<00:35,  3.96s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.72s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.60s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.52s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.53s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:15,  3.83s/it]processing embeddings:  73%|███████▎  | 8/11 [00:30<00:11,  3.99s/it]processing embeddings:  82%|████████▏ | 9/11 [00:34<00:07,  3.86s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.72s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.76s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2330 到 2340
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.52s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.38s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.53s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.52s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.49s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.60s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.60s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.63s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.54s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.77s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.62s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2340 到 2350
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.67s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.67s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.53s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.57s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.51s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.58s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.60s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.61s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.77s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.99s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.74s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2350 到 2360
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.45s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.40s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.52s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.53s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.49s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.44s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.53s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.56s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.60s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.55s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.52s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2360 到 2370
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.54s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.53s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.49s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.50s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.45s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.53s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.52s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.56s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.55s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.52s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2370 到 2380
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.77s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.69s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.53s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.50s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.50s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.48s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.47s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.51s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.54s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.53s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2380 到 2390
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.51s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.58s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:29,  3.63s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.63s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.53s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.53s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.53s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.49s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.56s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.47s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.53s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2390 到 2400
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.65s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.61s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.50s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.55s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.48s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.50s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.47s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.48s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.49s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.42s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.48s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2400 到 2410
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.39s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.39s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.42s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.36s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.44s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.47s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.43s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.51s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.46s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.45s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.44s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2410 到 2420
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.66s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.58s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.49s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.51s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.50s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.56s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.56s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.54s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.46s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.68s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.58s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2420 到 2430
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:38,  3.86s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.72s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.64s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.58s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.56s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.47s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.44s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.44s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.42s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.41s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.49s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2430 到 2440
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.63s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.56s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.46s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.49s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.47s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.51s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.46s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.44s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.47s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.48s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2440 到 2450
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.51s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.54s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.60s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.58s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.47s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.51s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.52s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.58s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.59s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.55s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2450 到 2460
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.71s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.67s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.74s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:26,  3.76s/it]processing embeddings:  45%|████▌     | 5/11 [00:19<00:23,  3.89s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.73s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.63s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.61s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.60s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2460 到 2470
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.65s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.44s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.52s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.48s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.45s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.40s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.39s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.41s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.38s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.42s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.43s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2470 到 2480
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.32s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.29s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.36s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.40s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.41s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.47s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.47s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.54s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.50s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.46s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.44s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2480 到 2490
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.54s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.52s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:29,  3.70s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.70s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.69s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.64s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.53s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.55s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:06,  3.50s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.48s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.56s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2490 到 2500
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.42s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.47s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.44s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.47s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.44s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.40s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.40s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.44s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.64s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.58s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.50s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2500 到 2510
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:38,  3.84s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.73s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.71s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.63s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.72s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.62s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.62s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.60s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.65s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.67s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.66s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2510 到 2520
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.68s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.51s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.52s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.59s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.59s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.61s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.59s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.61s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.55s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.59s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.59s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2520 到 2530
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.34s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.62s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.56s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.57s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.61s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.73s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.60s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.56s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:06,  3.49s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.44s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.53s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2530 到 2540
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.43s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:36,  4.07s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:31,  3.91s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:27,  3.91s/it]processing embeddings:  45%|████▌     | 5/11 [00:19<00:23,  3.87s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.69s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:14,  3.67s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.57s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.68s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.68s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.73s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2540 到 2550
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.56s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.64s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:31,  3.88s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.84s/it]processing embeddings:  45%|████▌     | 5/11 [00:19<00:24,  4.04s/it]processing embeddings:  55%|█████▍    | 6/11 [00:23<00:19,  3.88s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:14,  3.72s/it]processing embeddings:  73%|███████▎  | 8/11 [00:30<00:10,  3.64s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.63s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.61s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.72s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2550 到 2560
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.65s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.69s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.62s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.60s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.60s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.59s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.61s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.51s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:06,  3.48s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.50s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.56s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2560 到 2570
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.52s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.50s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.49s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.49s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.44s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.42s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.48s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.39s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.45s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.52s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.48s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2570 到 2580
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.50s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.58s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.58s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.61s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.55s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.54s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.55s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.55s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.60s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.58s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.57s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2580 到 2590
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:39,  3.93s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.79s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.59s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.61s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.52s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.54s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.46s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.46s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.50s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.49s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.54s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2590 到 2600
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.43s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.58s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.59s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.59s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.61s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.60s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.67s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.54s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.56s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.59s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.59s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2600 到 2610
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.54s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.48s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.43s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.52s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.50s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.48s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.52s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.51s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.53s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.55s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.52s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2610 到 2620
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.76s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.64s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.77s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:27,  3.87s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.72s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:17,  3.59s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.51s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.51s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:06,  3.46s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.42s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.56s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2620 到 2630
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.54s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.50s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.54s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.60s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.57s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.46s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.50s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.52s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.52s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.52s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.53s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2630 到 2640
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.63s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.45s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.45s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.49s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.50s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.51s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:15,  3.77s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.86s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.67s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.65s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.62s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2640 到 2650
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.46s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.44s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.53s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.51s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.52s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.49s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.48s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.49s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.50s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.53s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.51s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2650 到 2660
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.70s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.53s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.50s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.47s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.45s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.47s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.51s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.46s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.52s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.50s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2660 到 2670
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.56s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.45s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.41s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.52s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.48s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.49s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.55s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.49s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.55s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.56s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.52s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2670 到 2680
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.65s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.65s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.46s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.52s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.55s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.60s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.54s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.50s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.54s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.55s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2680 到 2690
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.44s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.38s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.47s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.46s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.50s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.52s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.53s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.58s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.62s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.63s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.55s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2690 到 2700
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.63s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.53s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.53s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.48s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.47s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.52s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.52s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.46s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.50s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.50s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.50s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2700 到 2710
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.43s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.46s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.54s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.48s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.56s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.57s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.51s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.59s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.51s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.52s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2710 到 2720
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.46s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.34s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.40s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.55s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.56s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.59s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.59s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.57s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.47s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.47s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.51s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2720 到 2730
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.60s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.58s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.52s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.55s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.48s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.47s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.41s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.44s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.42s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.48s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.48s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2730 到 2740
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.58s/it]processing embeddings:  18%|█▊        | 2/11 [00:08<00:40,  4.54s/it]processing embeddings:  27%|██▋       | 3/11 [00:20<01:02,  7.80s/it]processing embeddings:  36%|███▋      | 4/11 [00:32<01:07,  9.60s/it]processing embeddings:  45%|████▌     | 5/11 [00:45<01:03, 10.60s/it]processing embeddings:  55%|█████▍    | 6/11 [00:56<00:54, 10.99s/it]processing embeddings:  64%|██████▎   | 7/11 [01:09<00:46, 11.53s/it]processing embeddings:  73%|███████▎  | 8/11 [01:21<00:35, 11.69s/it]processing embeddings:  82%|████████▏ | 9/11 [01:34<00:23, 11.99s/it]processing embeddings:  91%|█████████ | 10/11 [01:46<00:11, 11.92s/it]processing embeddings:  91%|█████████ | 10/11 [01:46<00:10, 10.61s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2740 到 2750
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:12<02:01, 12.14s/it]processing embeddings:  18%|█▊        | 2/11 [00:23<01:45, 11.69s/it]processing embeddings:  27%|██▋       | 3/11 [00:32<01:24, 10.57s/it]processing embeddings:  36%|███▋      | 4/11 [00:42<01:12, 10.31s/it]processing embeddings:  45%|████▌     | 5/11 [00:52<01:00, 10.05s/it]processing embeddings:  55%|█████▍    | 6/11 [01:01<00:49,  9.81s/it]processing embeddings:  64%|██████▎   | 7/11 [01:11<00:39,  9.81s/it]processing embeddings:  73%|███████▎  | 8/11 [01:20<00:29,  9.68s/it]processing embeddings:  82%|████████▏ | 9/11 [01:30<00:19,  9.54s/it]processing embeddings:  91%|█████████ | 10/11 [01:40<00:09,  9.86s/it]processing embeddings:  91%|█████████ | 10/11 [01:40<00:10, 10.06s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2750 到 2760
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:10<01:45, 10.51s/it]processing embeddings:  18%|█▊        | 2/11 [00:20<01:30, 10.10s/it]processing embeddings:  27%|██▋       | 3/11 [00:30<01:19,  9.99s/it]processing embeddings:  36%|███▋      | 4/11 [00:39<01:09,  9.91s/it]processing embeddings:  45%|████▌     | 5/11 [00:49<00:58,  9.72s/it]processing embeddings:  55%|█████▍    | 6/11 [00:59<00:48,  9.76s/it]processing embeddings:  64%|██████▎   | 7/11 [01:08<00:38,  9.73s/it]processing embeddings:  73%|███████▎  | 8/11 [01:19<00:29,  9.91s/it]processing embeddings:  82%|████████▏ | 9/11 [01:28<00:19,  9.85s/it]processing embeddings:  91%|█████████ | 10/11 [01:38<00:09,  9.93s/it]processing embeddings:  91%|█████████ | 10/11 [01:38<00:09,  9.90s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2760 到 2770
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:11<01:55, 11.57s/it]processing embeddings:  18%|█▊        | 2/11 [00:22<01:41, 11.28s/it]processing embeddings:  27%|██▋       | 3/11 [00:32<01:24, 10.58s/it]processing embeddings:  36%|███▋      | 4/11 [00:42<01:12, 10.40s/it]processing embeddings:  45%|████▌     | 5/11 [00:52<01:01, 10.26s/it]processing embeddings:  55%|█████▍    | 6/11 [01:02<00:50, 10.11s/it]processing embeddings:  64%|██████▎   | 7/11 [01:12<00:39,  9.99s/it]processing embeddings:  73%|███████▎  | 8/11 [01:22<00:30, 10.00s/it]processing embeddings:  82%|████████▏ | 9/11 [01:31<00:19,  9.89s/it]processing embeddings:  91%|█████████ | 10/11 [01:41<00:09,  9.94s/it]processing embeddings:  91%|█████████ | 10/11 [01:41<00:10, 10.18s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2770 到 2780
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:10<01:41, 10.12s/it]processing embeddings:  18%|█▊        | 2/11 [00:21<01:39, 11.05s/it]processing embeddings:  27%|██▋       | 3/11 [00:33<01:29, 11.14s/it]processing embeddings:  36%|███▋      | 4/11 [00:43<01:14, 10.66s/it]processing embeddings:  45%|████▌     | 5/11 [00:52<01:01, 10.27s/it]processing embeddings:  55%|█████▍    | 6/11 [01:02<00:51, 10.24s/it]processing embeddings:  64%|██████▎   | 7/11 [01:12<00:40, 10.12s/it]processing embeddings:  73%|███████▎  | 8/11 [01:22<00:30, 10.00s/it]processing embeddings:  82%|████████▏ | 9/11 [01:32<00:19,  9.90s/it]processing embeddings:  91%|█████████ | 10/11 [01:41<00:09,  9.90s/it]processing embeddings:  91%|█████████ | 10/11 [01:41<00:10, 10.20s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2780 到 2790
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:09<01:35,  9.51s/it]processing embeddings:  18%|█▊        | 2/11 [00:19<01:29,  9.91s/it]processing embeddings:  27%|██▋       | 3/11 [00:31<01:26, 10.79s/it]processing embeddings:  36%|███▋      | 4/11 [00:43<01:17, 11.12s/it]processing embeddings:  45%|████▌     | 5/11 [00:53<01:04, 10.78s/it]processing embeddings:  55%|█████▍    | 6/11 [01:03<00:52, 10.55s/it]processing embeddings:  64%|██████▎   | 7/11 [01:13<00:41, 10.28s/it]processing embeddings:  73%|███████▎  | 8/11 [01:23<00:30, 10.19s/it]processing embeddings:  82%|████████▏ | 9/11 [01:33<00:20, 10.09s/it]processing embeddings:  91%|█████████ | 10/11 [01:42<00:10, 10.05s/it]processing embeddings:  91%|█████████ | 10/11 [01:43<00:10, 10.30s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2790 到 2800
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:09<01:36,  9.68s/it]processing embeddings:  18%|█▊        | 2/11 [00:19<01:27,  9.78s/it]processing embeddings:  27%|██▋       | 3/11 [00:29<01:18,  9.76s/it]processing embeddings:  36%|███▋      | 4/11 [00:39<01:10, 10.11s/it]processing embeddings:  45%|████▌     | 5/11 [00:51<01:04, 10.68s/it]processing embeddings:  55%|█████▍    | 6/11 [01:01<00:52, 10.41s/it]processing embeddings:  64%|██████▎   | 7/11 [01:11<00:40, 10.23s/it]processing embeddings:  73%|███████▎  | 8/11 [01:21<00:30, 10.23s/it]processing embeddings:  82%|████████▏ | 9/11 [01:31<00:20, 10.07s/it]processing embeddings:  91%|█████████ | 10/11 [01:41<00:09,  9.98s/it]processing embeddings:  91%|█████████ | 10/11 [01:41<00:10, 10.11s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2800 到 2810
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:10<01:41, 10.16s/it]processing embeddings:  18%|█▊        | 2/11 [00:19<01:28,  9.88s/it]processing embeddings:  27%|██▋       | 3/11 [00:29<01:19,  9.91s/it]processing embeddings:  36%|███▋      | 4/11 [00:39<01:08,  9.81s/it]processing embeddings:  45%|████▌     | 5/11 [00:50<01:01, 10.22s/it]processing embeddings:  55%|█████▍    | 6/11 [01:02<00:53, 10.76s/it]processing embeddings:  64%|██████▎   | 7/11 [01:13<00:43, 10.80s/it]processing embeddings:  73%|███████▎  | 8/11 [01:23<00:31, 10.59s/it]processing embeddings:  82%|████████▏ | 9/11 [01:32<00:20, 10.31s/it]processing embeddings:  91%|█████████ | 10/11 [01:43<00:10, 10.30s/it]processing embeddings:  91%|█████████ | 10/11 [01:43<00:10, 10.32s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2810 到 2820
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:09<01:39, 10.00s/it]processing embeddings:  18%|█▊        | 2/11 [00:19<01:27,  9.71s/it]processing embeddings:  27%|██▋       | 3/11 [00:29<01:18,  9.84s/it]processing embeddings:  36%|███▋      | 4/11 [00:39<01:08,  9.78s/it]processing embeddings:  45%|████▌     | 5/11 [00:48<00:58,  9.74s/it]processing embeddings:  55%|█████▍    | 6/11 [00:58<00:48,  9.75s/it]processing embeddings:  64%|██████▎   | 7/11 [01:10<00:41, 10.37s/it]processing embeddings:  73%|███████▎  | 8/11 [01:21<00:31, 10.64s/it]processing embeddings:  82%|████████▏ | 9/11 [01:31<00:20, 10.34s/it]processing embeddings:  91%|█████████ | 10/11 [01:41<00:10, 10.21s/it]processing embeddings:  91%|█████████ | 10/11 [01:41<00:10, 10.11s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2820 到 2830
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:09<01:38,  9.84s/it]processing embeddings:  18%|█▊        | 2/11 [00:19<01:28,  9.85s/it]processing embeddings:  27%|██▋       | 3/11 [00:29<01:19,  9.90s/it]processing embeddings:  36%|███▋      | 4/11 [00:39<01:08,  9.79s/it]processing embeddings:  45%|████▌     | 5/11 [00:49<01:00, 10.05s/it]processing embeddings:  55%|█████▍    | 6/11 [00:59<00:50, 10.10s/it]processing embeddings:  64%|██████▎   | 7/11 [01:09<00:40, 10.04s/it]processing embeddings:  73%|███████▎  | 8/11 [01:21<00:31, 10.51s/it]processing embeddings:  82%|████████▏ | 9/11 [01:32<00:21, 10.77s/it]processing embeddings:  91%|█████████ | 10/11 [01:42<00:10, 10.42s/it]processing embeddings:  91%|█████████ | 10/11 [01:42<00:10, 10.24s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2830 到 2840
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:10<01:40, 10.08s/it]processing embeddings:  18%|█▊        | 2/11 [00:20<01:30, 10.02s/it]processing embeddings:  27%|██▋       | 3/11 [00:29<01:18,  9.87s/it]processing embeddings:  36%|███▋      | 4/11 [00:39<01:08,  9.73s/it]processing embeddings:  45%|████▌     | 5/11 [00:49<00:59,  9.90s/it]processing embeddings:  55%|█████▍    | 6/11 [00:59<00:49,  9.85s/it]processing embeddings:  64%|██████▎   | 7/11 [01:09<00:39,  9.84s/it]processing embeddings:  73%|███████▎  | 8/11 [01:19<00:29,  9.91s/it]processing embeddings:  82%|████████▏ | 9/11 [01:30<00:20, 10.29s/it]processing embeddings:  91%|█████████ | 10/11 [01:41<00:10, 10.44s/it]processing embeddings:  91%|█████████ | 10/11 [01:41<00:10, 10.10s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2840 到 2850
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:16,  7.64s/it]processing embeddings:  18%|█▊        | 2/11 [00:15<01:07,  7.48s/it]processing embeddings:  27%|██▋       | 3/11 [00:22<01:00,  7.51s/it]processing embeddings:  36%|███▋      | 4/11 [00:30<00:52,  7.51s/it]processing embeddings:  45%|████▌     | 5/11 [00:38<00:46,  7.73s/it]processing embeddings:  55%|█████▍    | 6/11 [00:45<00:38,  7.74s/it]processing embeddings:  64%|██████▎   | 7/11 [00:53<00:30,  7.58s/it]processing embeddings:  73%|███████▎  | 8/11 [01:00<00:22,  7.57s/it]processing embeddings:  82%|████████▏ | 9/11 [01:08<00:14,  7.48s/it]processing embeddings:  91%|█████████ | 10/11 [01:15<00:07,  7.37s/it]processing embeddings:  91%|█████████ | 10/11 [01:15<00:07,  7.52s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2850 到 2860
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:12,  7.30s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:04,  7.19s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:57,  7.14s/it]processing embeddings:  36%|███▋      | 4/11 [00:29<00:51,  7.30s/it]processing embeddings:  45%|████▌     | 5/11 [00:36<00:43,  7.33s/it]processing embeddings:  55%|█████▍    | 6/11 [00:43<00:36,  7.37s/it]processing embeddings:  64%|██████▎   | 7/11 [00:51<00:29,  7.41s/it]processing embeddings:  73%|███████▎  | 8/11 [00:58<00:21,  7.23s/it]processing embeddings:  82%|████████▏ | 9/11 [01:05<00:14,  7.34s/it]processing embeddings:  91%|█████████ | 10/11 [01:13<00:07,  7.32s/it]processing embeddings:  91%|█████████ | 10/11 [01:13<00:07,  7.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2860 到 2870
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:13,  7.38s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:05,  7.26s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:58,  7.34s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:50,  7.20s/it]processing embeddings:  45%|████▌     | 5/11 [00:36<00:43,  7.22s/it]processing embeddings:  55%|█████▍    | 6/11 [00:43<00:36,  7.32s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:28,  7.23s/it]processing embeddings:  73%|███████▎  | 8/11 [00:58<00:21,  7.31s/it]processing embeddings:  82%|████████▏ | 9/11 [01:05<00:14,  7.26s/it]processing embeddings:  91%|█████████ | 10/11 [01:12<00:07,  7.19s/it]processing embeddings:  91%|█████████ | 10/11 [01:12<00:07,  7.25s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2870 到 2880
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:16,  7.68s/it]processing embeddings:  18%|█▊        | 2/11 [00:15<01:07,  7.51s/it]processing embeddings:  27%|██▋       | 3/11 [00:22<00:59,  7.48s/it]processing embeddings:  36%|███▋      | 4/11 [00:30<00:52,  7.53s/it]processing embeddings:  45%|████▌     | 5/11 [00:37<00:44,  7.38s/it]processing embeddings:  55%|█████▍    | 6/11 [00:44<00:36,  7.32s/it]processing embeddings:  64%|██████▎   | 7/11 [00:51<00:28,  7.24s/it]processing embeddings:  73%|███████▎  | 8/11 [00:58<00:21,  7.20s/it]processing embeddings:  82%|████████▏ | 9/11 [01:05<00:14,  7.21s/it]processing embeddings:  91%|█████████ | 10/11 [01:13<00:07,  7.24s/it]processing embeddings:  91%|█████████ | 10/11 [01:13<00:07,  7.32s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2880 到 2890
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:12,  7.25s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:04,  7.20s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:56,  7.07s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:50,  7.24s/it]processing embeddings:  45%|████▌     | 5/11 [00:36<00:43,  7.31s/it]processing embeddings:  55%|█████▍    | 6/11 [00:43<00:36,  7.24s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:28,  7.22s/it]processing embeddings:  73%|███████▎  | 8/11 [00:57<00:21,  7.17s/it]processing embeddings:  82%|████████▏ | 9/11 [01:04<00:14,  7.05s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.04s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.14s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2890 到 2900
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:11,  7.16s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:04,  7.18s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:58,  7.34s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:49,  7.12s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:42,  7.05s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.10s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:28,  7.17s/it]processing embeddings:  73%|███████▎  | 8/11 [00:57<00:21,  7.13s/it]processing embeddings:  82%|████████▏ | 9/11 [01:03<00:14,  7.04s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.05s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.11s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2900 到 2910
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:10,  7.03s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:04,  7.18s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:56,  7.10s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:49,  7.03s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:42,  7.13s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.18s/it]processing embeddings:  64%|██████▎   | 7/11 [00:49<00:27,  6.98s/it]processing embeddings:  73%|███████▎  | 8/11 [00:56<00:21,  7.06s/it]processing embeddings:  82%|████████▏ | 9/11 [01:03<00:14,  7.07s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.18s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.12s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2910 到 2920
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:12,  7.21s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:03,  7.01s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:56,  7.05s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:50,  7.15s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:42,  7.16s/it]processing embeddings:  55%|█████▍    | 6/11 [00:43<00:36,  7.34s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:29,  7.42s/it]processing embeddings:  73%|███████▎  | 8/11 [00:58<00:21,  7.32s/it]processing embeddings:  82%|████████▏ | 9/11 [01:05<00:14,  7.41s/it]processing embeddings:  91%|█████████ | 10/11 [01:12<00:07,  7.35s/it]processing embeddings:  91%|█████████ | 10/11 [01:12<00:07,  7.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2920 到 2930
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:13,  7.31s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:03,  7.08s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:55,  6.95s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:49,  7.01s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:42,  7.06s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.03s/it]processing embeddings:  64%|██████▎   | 7/11 [00:49<00:28,  7.09s/it]processing embeddings:  73%|███████▎  | 8/11 [00:57<00:21,  7.32s/it]processing embeddings:  82%|████████▏ | 9/11 [01:04<00:14,  7.27s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.30s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.18s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2930 到 2940
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:12,  7.23s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:05,  7.24s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:57,  7.24s/it]processing embeddings:  36%|███▋      | 4/11 [00:29<00:51,  7.30s/it]processing embeddings:  45%|████▌     | 5/11 [00:36<00:43,  7.29s/it]processing embeddings:  55%|█████▍    | 6/11 [00:43<00:36,  7.25s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:28,  7.18s/it]processing embeddings:  73%|███████▎  | 8/11 [00:58<00:21,  7.31s/it]processing embeddings:  82%|████████▏ | 9/11 [01:05<00:14,  7.24s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.06s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.19s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2940 到 2950
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:12,  7.25s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:04,  7.18s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:58,  7.26s/it]processing embeddings:  36%|███▋      | 4/11 [00:29<00:51,  7.32s/it]processing embeddings:  45%|████▌     | 5/11 [00:36<00:44,  7.35s/it]processing embeddings:  55%|█████▍    | 6/11 [00:43<00:36,  7.36s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:28,  7.21s/it]processing embeddings:  73%|███████▎  | 8/11 [00:57<00:21,  7.17s/it]processing embeddings:  82%|████████▏ | 9/11 [01:05<00:14,  7.19s/it]processing embeddings:  91%|█████████ | 10/11 [01:12<00:07,  7.20s/it]processing embeddings:  91%|█████████ | 10/11 [01:12<00:07,  7.24s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2950 到 2960
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:16,  7.61s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:04,  7.12s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:57,  7.19s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:49,  7.11s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:41,  6.93s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.00s/it]processing embeddings:  64%|██████▎   | 7/11 [00:49<00:28,  7.11s/it]processing embeddings:  73%|███████▎  | 8/11 [00:56<00:21,  7.03s/it]processing embeddings:  82%|████████▏ | 9/11 [01:04<00:14,  7.16s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.17s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.13s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2960 到 2970
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:13,  7.32s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:05,  7.25s/it]processing embeddings:  27%|██▋       | 3/11 [00:22<00:59,  7.39s/it]processing embeddings:  36%|███▋      | 4/11 [00:29<00:52,  7.46s/it]processing embeddings:  45%|████▌     | 5/11 [00:36<00:44,  7.41s/it]processing embeddings:  55%|█████▍    | 6/11 [00:44<00:36,  7.33s/it]processing embeddings:  64%|██████▎   | 7/11 [00:51<00:28,  7.25s/it]processing embeddings:  73%|███████▎  | 8/11 [00:58<00:21,  7.28s/it]processing embeddings:  82%|████████▏ | 9/11 [01:06<00:14,  7.34s/it]processing embeddings:  91%|█████████ | 10/11 [01:13<00:07,  7.28s/it]processing embeddings:  91%|█████████ | 10/11 [01:13<00:07,  7.32s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2970 到 2980
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:12,  7.30s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:04,  7.16s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:56,  7.02s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:49,  7.04s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:43,  7.20s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.08s/it]processing embeddings:  64%|██████▎   | 7/11 [00:49<00:28,  7.01s/it]processing embeddings:  73%|███████▎  | 8/11 [00:56<00:20,  6.97s/it]processing embeddings:  82%|████████▏ | 9/11 [01:03<00:14,  7.05s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.05s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.07s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2980 到 2990
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:12,  7.20s/it]processing embeddings:  18%|█▊        | 2/11 [00:13<01:02,  6.95s/it]processing embeddings:  27%|██▋       | 3/11 [00:20<00:55,  6.95s/it]processing embeddings:  36%|███▋      | 4/11 [00:27<00:48,  6.99s/it]processing embeddings:  45%|████▌     | 5/11 [00:34<00:41,  6.88s/it]processing embeddings:  55%|█████▍    | 6/11 [00:41<00:34,  6.97s/it]processing embeddings:  64%|██████▎   | 7/11 [00:48<00:28,  7.03s/it]processing embeddings:  73%|███████▎  | 8/11 [00:56<00:21,  7.08s/it]processing embeddings:  82%|████████▏ | 9/11 [01:04<00:14,  7.33s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.43s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.17s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 2990 到 3000
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:14,  7.47s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:06,  7.44s/it]processing embeddings:  27%|██▋       | 3/11 [00:22<00:59,  7.40s/it]processing embeddings:  36%|███▋      | 4/11 [00:29<00:50,  7.16s/it]processing embeddings:  45%|████▌     | 5/11 [00:36<00:43,  7.26s/it]processing embeddings:  55%|█████▍    | 6/11 [00:43<00:36,  7.26s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:28,  7.17s/it]processing embeddings:  73%|███████▎  | 8/11 [00:57<00:21,  7.03s/it]processing embeddings:  82%|████████▏ | 9/11 [01:04<00:14,  7.05s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.15s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.19s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3000 到 3010
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:11,  7.14s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:03,  7.11s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:57,  7.22s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:49,  7.12s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:42,  7.12s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.12s/it]processing embeddings:  64%|██████▎   | 7/11 [00:49<00:28,  7.10s/it]processing embeddings:  73%|███████▎  | 8/11 [00:56<00:21,  7.06s/it]processing embeddings:  82%|████████▏ | 9/11 [01:04<00:14,  7.12s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.04s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.09s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3010 到 3020
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:08,  6.86s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:05,  7.23s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:58,  7.25s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:50,  7.20s/it]processing embeddings:  45%|████▌     | 5/11 [00:36<00:43,  7.23s/it]processing embeddings:  55%|█████▍    | 6/11 [00:43<00:36,  7.35s/it]processing embeddings:  64%|██████▎   | 7/11 [00:51<00:29,  7.40s/it]processing embeddings:  73%|███████▎  | 8/11 [00:58<00:22,  7.37s/it]processing embeddings:  82%|████████▏ | 9/11 [01:06<00:15,  7.52s/it]processing embeddings:  91%|█████████ | 10/11 [01:13<00:07,  7.39s/it]processing embeddings:  91%|█████████ | 10/11 [01:13<00:07,  7.34s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3020 到 3030
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:11,  7.11s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:02,  6.99s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:59,  7.44s/it]processing embeddings:  36%|███▋      | 4/11 [00:29<00:50,  7.28s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:42,  7.12s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.10s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:28,  7.17s/it]processing embeddings:  73%|███████▎  | 8/11 [00:57<00:21,  7.22s/it]processing embeddings:  82%|████████▏ | 9/11 [01:04<00:14,  7.18s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.17s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.18s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3030 到 3040
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:13,  7.33s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:03,  7.08s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:57,  7.18s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:49,  7.06s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:42,  7.08s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.19s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:29,  7.27s/it]processing embeddings:  73%|███████▎  | 8/11 [00:57<00:21,  7.19s/it]processing embeddings:  82%|████████▏ | 9/11 [01:04<00:14,  7.25s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.16s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.17s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3040 到 3050
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:11,  7.12s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:03,  7.09s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:56,  7.05s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:49,  7.11s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:42,  7.07s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.11s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:28,  7.25s/it]processing embeddings:  73%|███████▎  | 8/11 [00:57<00:21,  7.24s/it]processing embeddings:  82%|████████▏ | 9/11 [01:04<00:14,  7.18s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.16s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.15s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3050 到 3060
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:07,  6.77s/it]processing embeddings:  18%|█▊        | 2/11 [00:13<01:03,  7.02s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:56,  7.09s/it]processing embeddings:  36%|███▋      | 4/11 [00:29<00:51,  7.41s/it]processing embeddings:  45%|████▌     | 5/11 [00:36<00:44,  7.42s/it]processing embeddings:  55%|█████▍    | 6/11 [00:43<00:36,  7.33s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:29,  7.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:58<00:22,  7.40s/it]processing embeddings:  82%|████████▏ | 9/11 [01:05<00:14,  7.38s/it]processing embeddings:  91%|█████████ | 10/11 [01:12<00:07,  7.23s/it]processing embeddings:  91%|█████████ | 10/11 [01:12<00:07,  7.27s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3060 到 3070
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:09,  6.95s/it]processing embeddings:  18%|█▊        | 2/11 [00:13<01:02,  6.92s/it]processing embeddings:  27%|██▋       | 3/11 [00:20<00:55,  6.97s/it]processing embeddings:  36%|███▋      | 4/11 [00:27<00:48,  6.99s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:42,  7.11s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.05s/it]processing embeddings:  64%|██████▎   | 7/11 [00:49<00:28,  7.20s/it]processing embeddings:  73%|███████▎  | 8/11 [00:56<00:21,  7.14s/it]processing embeddings:  82%|████████▏ | 9/11 [01:03<00:13,  6.99s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.06s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.05s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3070 到 3080
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:12,  7.23s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:05,  7.32s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:57,  7.17s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:50,  7.17s/it]processing embeddings:  45%|████▌     | 5/11 [00:36<00:43,  7.20s/it]processing embeddings:  55%|█████▍    | 6/11 [00:43<00:35,  7.13s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:29,  7.25s/it]processing embeddings:  73%|███████▎  | 8/11 [00:58<00:22,  7.42s/it]processing embeddings:  82%|████████▏ | 9/11 [01:05<00:14,  7.35s/it]processing embeddings:  91%|█████████ | 10/11 [01:12<00:07,  7.37s/it]processing embeddings:  91%|█████████ | 10/11 [01:12<00:07,  7.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3080 到 3090
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:16,  7.69s/it]processing embeddings:  18%|█▊        | 2/11 [00:15<01:07,  7.49s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:57,  7.22s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:50,  7.15s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:42,  7.04s/it]processing embeddings:  55%|█████▍    | 6/11 [00:43<00:35,  7.09s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:28,  7.14s/it]processing embeddings:  73%|███████▎  | 8/11 [00:57<00:21,  7.15s/it]processing embeddings:  82%|████████▏ | 9/11 [01:04<00:14,  7.05s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.03s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.13s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3090 到 3100
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:16,  7.70s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:05,  7.28s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:56,  7.05s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:49,  7.02s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:41,  6.99s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.07s/it]processing embeddings:  64%|██████▎   | 7/11 [00:49<00:28,  7.14s/it]processing embeddings:  73%|███████▎  | 8/11 [00:56<00:21,  7.10s/it]processing embeddings:  82%|████████▏ | 9/11 [01:04<00:14,  7.16s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.08s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.11s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3100 到 3110
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:12,  7.21s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:06,  7.34s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:57,  7.18s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:50,  7.21s/it]processing embeddings:  45%|████▌     | 5/11 [00:36<00:43,  7.21s/it]processing embeddings:  55%|█████▍    | 6/11 [00:43<00:35,  7.18s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:28,  7.16s/it]processing embeddings:  73%|███████▎  | 8/11 [00:57<00:21,  7.14s/it]processing embeddings:  82%|████████▏ | 9/11 [01:05<00:14,  7.28s/it]processing embeddings:  91%|█████████ | 10/11 [01:12<00:07,  7.19s/it]processing embeddings:  91%|█████████ | 10/11 [01:12<00:07,  7.20s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3110 到 3120
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:12,  7.25s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:06,  7.40s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:58,  7.26s/it]processing embeddings:  36%|███▋      | 4/11 [00:29<00:50,  7.25s/it]processing embeddings:  45%|████▌     | 5/11 [00:36<00:43,  7.25s/it]processing embeddings:  55%|█████▍    | 6/11 [00:43<00:36,  7.35s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:29,  7.25s/it]processing embeddings:  73%|███████▎  | 8/11 [00:58<00:21,  7.25s/it]processing embeddings:  82%|████████▏ | 9/11 [01:05<00:14,  7.24s/it]processing embeddings:  91%|█████████ | 10/11 [01:12<00:07,  7.30s/it]processing embeddings:  91%|█████████ | 10/11 [01:12<00:07,  7.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3120 到 3130
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:11,  7.15s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:05,  7.30s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:57,  7.20s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:49,  7.06s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:42,  7.16s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.07s/it]processing embeddings:  64%|██████▎   | 7/11 [00:49<00:27,  6.92s/it]processing embeddings:  73%|███████▎  | 8/11 [00:56<00:20,  6.94s/it]processing embeddings:  82%|████████▏ | 9/11 [01:02<00:13,  6.78s/it]processing embeddings:  91%|█████████ | 10/11 [01:09<00:06,  6.83s/it]processing embeddings:  91%|█████████ | 10/11 [01:09<00:06,  6.97s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3130 到 3140
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:15,  7.52s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:04,  7.20s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:58,  7.29s/it]processing embeddings:  36%|███▋      | 4/11 [00:29<00:50,  7.27s/it]processing embeddings:  45%|████▌     | 5/11 [00:36<00:43,  7.25s/it]processing embeddings:  55%|█████▍    | 6/11 [00:43<00:36,  7.28s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:28,  7.19s/it]processing embeddings:  73%|███████▎  | 8/11 [00:57<00:20,  6.96s/it]processing embeddings:  82%|████████▏ | 9/11 [01:04<00:14,  7.12s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.09s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.17s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3140 到 3150
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:12,  7.26s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:03,  7.08s/it]processing embeddings:  27%|██▋       | 3/11 [00:20<00:55,  6.94s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:49,  7.03s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:43,  7.19s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:36,  7.21s/it]processing embeddings:  64%|██████▎   | 7/11 [00:49<00:28,  7.13s/it]processing embeddings:  73%|███████▎  | 8/11 [00:57<00:21,  7.27s/it]processing embeddings:  82%|████████▏ | 9/11 [01:04<00:14,  7.13s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.20s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.16s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3150 到 3160
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:08,  6.81s/it]processing embeddings:  18%|█▊        | 2/11 [00:13<01:03,  7.00s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:56,  7.11s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:49,  7.03s/it]processing embeddings:  45%|████▌     | 5/11 [00:36<00:44,  7.37s/it]processing embeddings:  55%|█████▍    | 6/11 [00:43<00:36,  7.29s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:28,  7.20s/it]processing embeddings:  73%|███████▎  | 8/11 [00:57<00:21,  7.14s/it]processing embeddings:  82%|████████▏ | 9/11 [01:04<00:14,  7.12s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.08s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.13s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3160 到 3170
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:13,  7.32s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:03,  7.00s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:56,  7.11s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:48,  6.99s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:42,  7.06s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.10s/it]processing embeddings:  64%|██████▎   | 7/11 [00:49<00:28,  7.21s/it]processing embeddings:  73%|███████▎  | 8/11 [00:56<00:20,  6.99s/it]processing embeddings:  82%|████████▏ | 9/11 [01:03<00:14,  7.10s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.08s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.09s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3170 到 3180
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:12,  7.21s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:04,  7.14s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:56,  7.07s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:49,  7.12s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:42,  7.15s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.11s/it]processing embeddings:  64%|██████▎   | 7/11 [00:49<00:28,  7.06s/it]processing embeddings:  73%|███████▎  | 8/11 [00:57<00:21,  7.16s/it]processing embeddings:  82%|████████▏ | 9/11 [01:04<00:14,  7.13s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.16s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.14s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3180 到 3190
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:09,  6.92s/it]processing embeddings:  18%|█▊        | 2/11 [00:13<01:00,  6.74s/it]processing embeddings:  27%|██▋       | 3/11 [00:20<00:56,  7.00s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:49,  7.11s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:42,  7.15s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:36,  7.25s/it]processing embeddings:  64%|██████▎   | 7/11 [00:49<00:28,  7.15s/it]processing embeddings:  73%|███████▎  | 8/11 [00:56<00:21,  7.19s/it]processing embeddings:  82%|████████▏ | 9/11 [01:04<00:14,  7.32s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.09s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.12s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3190 到 3200
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:06,  6.66s/it]processing embeddings:  18%|█▊        | 2/11 [00:13<00:59,  6.57s/it]processing embeddings:  27%|██▋       | 3/11 [00:20<00:54,  6.77s/it]processing embeddings:  36%|███▋      | 4/11 [00:26<00:47,  6.75s/it]processing embeddings:  45%|████▌     | 5/11 [00:34<00:41,  6.99s/it]processing embeddings:  55%|█████▍    | 6/11 [00:41<00:35,  7.07s/it]processing embeddings:  64%|██████▎   | 7/11 [00:48<00:27,  6.91s/it]processing embeddings:  73%|███████▎  | 8/11 [00:55<00:21,  7.11s/it]processing embeddings:  82%|████████▏ | 9/11 [01:03<00:14,  7.28s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.32s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.07s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3200 到 3210
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:08,  6.88s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:04,  7.12s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:58,  7.34s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:50,  7.19s/it]processing embeddings:  45%|████▌     | 5/11 [00:36<00:43,  7.30s/it]processing embeddings:  55%|█████▍    | 6/11 [00:43<00:36,  7.21s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:28,  7.21s/it]processing embeddings:  73%|███████▎  | 8/11 [00:57<00:21,  7.20s/it]processing embeddings:  82%|████████▏ | 9/11 [01:04<00:14,  7.19s/it]processing embeddings:  91%|█████████ | 10/11 [01:12<00:07,  7.22s/it]processing embeddings:  91%|█████████ | 10/11 [01:12<00:07,  7.21s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3210 到 3220
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:10,  7.09s/it]processing embeddings:  18%|█▊        | 2/11 [00:13<01:00,  6.70s/it]processing embeddings:  27%|██▋       | 3/11 [00:20<00:53,  6.64s/it]processing embeddings:  36%|███▋      | 4/11 [00:27<00:47,  6.78s/it]processing embeddings:  45%|████▌     | 5/11 [00:34<00:41,  6.84s/it]processing embeddings:  55%|█████▍    | 6/11 [00:41<00:35,  7.01s/it]processing embeddings:  64%|██████▎   | 7/11 [00:48<00:28,  7.13s/it]processing embeddings:  73%|███████▎  | 8/11 [00:55<00:21,  7.14s/it]processing embeddings:  82%|████████▏ | 9/11 [01:02<00:14,  7.12s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.11s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.01s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3220 到 3230
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:15,  7.58s/it]processing embeddings:  18%|█▊        | 2/11 [00:15<01:09,  7.67s/it]processing embeddings:  27%|██▋       | 3/11 [00:23<01:01,  7.72s/it]processing embeddings:  36%|███▋      | 4/11 [00:30<00:53,  7.63s/it]processing embeddings:  45%|████▌     | 5/11 [00:38<00:46,  7.67s/it]processing embeddings:  55%|█████▍    | 6/11 [00:45<00:37,  7.56s/it]processing embeddings:  64%|██████▎   | 7/11 [00:52<00:28,  7.21s/it]processing embeddings:  73%|███████▎  | 8/11 [00:59<00:21,  7.14s/it]processing embeddings:  82%|████████▏ | 9/11 [01:06<00:14,  7.17s/it]processing embeddings:  91%|█████████ | 10/11 [01:13<00:07,  7.15s/it]processing embeddings:  91%|█████████ | 10/11 [01:13<00:07,  7.35s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3230 到 3240
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:12,  7.26s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:04,  7.20s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:56,  7.09s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:49,  7.11s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:42,  7.11s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.06s/it]processing embeddings:  64%|██████▎   | 7/11 [00:49<00:28,  7.02s/it]processing embeddings:  73%|███████▎  | 8/11 [00:56<00:21,  7.04s/it]processing embeddings:  82%|████████▏ | 9/11 [01:03<00:13,  6.93s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:06,  6.93s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.02s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3240 到 3250
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:14,  7.43s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:05,  7.26s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:57,  7.19s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:49,  7.06s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:42,  7.07s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.06s/it]processing embeddings:  64%|██████▎   | 7/11 [00:49<00:28,  7.10s/it]processing embeddings:  73%|███████▎  | 8/11 [00:57<00:21,  7.21s/it]processing embeddings:  82%|████████▏ | 9/11 [01:04<00:14,  7.08s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.17s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.15s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3250 到 3260
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:10,  7.01s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:04,  7.18s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:56,  7.03s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:48,  6.98s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:41,  6.99s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.10s/it]processing embeddings:  64%|██████▎   | 7/11 [00:49<00:28,  7.04s/it]processing embeddings:  73%|███████▎  | 8/11 [00:56<00:21,  7.16s/it]processing embeddings:  82%|████████▏ | 9/11 [01:03<00:14,  7.08s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.04s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.06s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3260 到 3270
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:12,  7.26s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:04,  7.12s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:56,  7.05s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:49,  7.12s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:43,  7.19s/it]processing embeddings:  55%|█████▍    | 6/11 [00:43<00:36,  7.32s/it]processing embeddings:  64%|██████▎   | 7/11 [00:50<00:29,  7.28s/it]processing embeddings:  73%|███████▎  | 8/11 [00:57<00:21,  7.24s/it]processing embeddings:  82%|████████▏ | 9/11 [01:05<00:14,  7.33s/it]processing embeddings:  91%|█████████ | 10/11 [01:12<00:07,  7.23s/it]processing embeddings:  91%|█████████ | 10/11 [01:12<00:07,  7.23s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3270 到 3280
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:10,  7.01s/it]processing embeddings:  18%|█▊        | 2/11 [00:13<01:02,  6.98s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:56,  7.02s/it]processing embeddings:  36%|███▋      | 4/11 [00:27<00:48,  6.97s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:42,  7.02s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.15s/it]processing embeddings:  64%|██████▎   | 7/11 [00:49<00:28,  7.18s/it]processing embeddings:  73%|███████▎  | 8/11 [00:56<00:21,  7.13s/it]processing embeddings:  82%|████████▏ | 9/11 [01:03<00:14,  7.05s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.19s/it]processing embeddings:  91%|█████████ | 10/11 [01:11<00:07,  7.11s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3280 到 3290
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:13,  7.31s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:04,  7.16s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:57,  7.13s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:51,  7.29s/it]processing embeddings:  45%|████▌     | 5/11 [00:35<00:42,  7.14s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:35,  7.10s/it]processing embeddings:  64%|██████▎   | 7/11 [00:49<00:28,  7.01s/it]processing embeddings:  73%|███████▎  | 8/11 [00:56<00:21,  7.06s/it]processing embeddings:  82%|████████▏ | 9/11 [01:03<00:13,  6.90s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:06,  6.94s/it]processing embeddings:  91%|█████████ | 10/11 [01:10<00:07,  7.05s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3290 到 3300
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:16,  7.67s/it]processing embeddings:  18%|█▊        | 2/11 [00:14<01:05,  7.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:22<00:58,  7.33s/it]processing embeddings:  36%|███▋      | 4/11 [00:28<00:48,  6.90s/it]processing embeddings:  45%|████▌     | 5/11 [00:33<00:37,  6.22s/it]processing embeddings:  55%|█████▍    | 6/11 [00:38<00:28,  5.72s/it]processing embeddings:  64%|██████▎   | 7/11 [00:42<00:21,  5.43s/it]processing embeddings:  73%|███████▎  | 8/11 [00:47<00:15,  5.32s/it]processing embeddings:  82%|████████▏ | 9/11 [00:53<00:10,  5.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:57<00:05,  5.14s/it]processing embeddings:  91%|█████████ | 10/11 [00:57<00:05,  5.80s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3300 到 3310
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:05<00:51,  5.15s/it]processing embeddings:  18%|█▊        | 2/11 [00:10<00:45,  5.02s/it]processing embeddings:  27%|██▋       | 3/11 [00:14<00:38,  4.81s/it]processing embeddings:  36%|███▋      | 4/11 [00:19<00:33,  4.77s/it]processing embeddings:  45%|████▌     | 5/11 [00:24<00:28,  4.78s/it]processing embeddings:  55%|█████▍    | 6/11 [00:29<00:24,  4.87s/it]processing embeddings:  64%|██████▎   | 7/11 [00:34<00:19,  4.90s/it]processing embeddings:  73%|███████▎  | 8/11 [00:38<00:14,  4.88s/it]processing embeddings:  82%|████████▏ | 9/11 [00:44<00:09,  4.94s/it]processing embeddings:  91%|█████████ | 10/11 [00:50<00:05,  5.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:50<00:05,  5.02s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3310 到 3320
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:49,  4.99s/it]processing embeddings:  18%|█▊        | 2/11 [00:09<00:43,  4.87s/it]processing embeddings:  27%|██▋       | 3/11 [00:14<00:38,  4.85s/it]processing embeddings:  36%|███▋      | 4/11 [00:19<00:34,  4.87s/it]processing embeddings:  45%|████▌     | 5/11 [00:24<00:29,  4.90s/it]processing embeddings:  55%|█████▍    | 6/11 [00:29<00:24,  4.93s/it]processing embeddings:  64%|██████▎   | 7/11 [00:34<00:19,  4.92s/it]processing embeddings:  73%|███████▎  | 8/11 [00:39<00:14,  4.97s/it]processing embeddings:  82%|████████▏ | 9/11 [00:44<00:10,  5.01s/it]processing embeddings:  91%|█████████ | 10/11 [00:48<00:04,  4.83s/it]processing embeddings:  91%|█████████ | 10/11 [00:48<00:04,  4.90s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3320 到 3330
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:48,  4.82s/it]processing embeddings:  18%|█▊        | 2/11 [00:09<00:44,  4.89s/it]processing embeddings:  27%|██▋       | 3/11 [00:14<00:40,  5.01s/it]processing embeddings:  36%|███▋      | 4/11 [00:19<00:34,  5.00s/it]processing embeddings:  45%|████▌     | 5/11 [00:24<00:29,  4.90s/it]processing embeddings:  55%|█████▍    | 6/11 [00:29<00:24,  4.92s/it]processing embeddings:  64%|██████▎   | 7/11 [00:34<00:19,  4.89s/it]processing embeddings:  73%|███████▎  | 8/11 [00:39<00:14,  4.87s/it]processing embeddings:  82%|████████▏ | 9/11 [00:44<00:09,  4.89s/it]processing embeddings:  91%|█████████ | 10/11 [00:48<00:04,  4.83s/it]processing embeddings:  91%|█████████ | 10/11 [00:48<00:04,  4.89s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3330 到 3340
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:49,  4.91s/it]processing embeddings:  18%|█▊        | 2/11 [00:10<00:48,  5.44s/it]processing embeddings:  27%|██▋       | 3/11 [00:16<00:43,  5.43s/it]processing embeddings:  36%|███▋      | 4/11 [00:22<00:40,  5.72s/it]processing embeddings:  45%|████▌     | 5/11 [00:28<00:34,  5.80s/it]processing embeddings:  55%|█████▍    | 6/11 [00:33<00:27,  5.56s/it]processing embeddings:  64%|██████▎   | 7/11 [00:38<00:21,  5.33s/it]processing embeddings:  73%|███████▎  | 8/11 [00:42<00:15,  5.16s/it]processing embeddings:  82%|████████▏ | 9/11 [00:48<00:10,  5.14s/it]processing embeddings:  91%|█████████ | 10/11 [00:53<00:05,  5.11s/it]processing embeddings:  91%|█████████ | 10/11 [00:53<00:05,  5.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3340 到 3350
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:48,  4.85s/it]processing embeddings:  18%|█▊        | 2/11 [00:10<00:45,  5.10s/it]processing embeddings:  27%|██▋       | 3/11 [00:14<00:38,  4.87s/it]processing embeddings:  36%|███▋      | 4/11 [00:19<00:33,  4.84s/it]processing embeddings:  45%|████▌     | 5/11 [00:24<00:29,  4.87s/it]processing embeddings:  55%|█████▍    | 6/11 [00:29<00:24,  4.97s/it]processing embeddings:  64%|██████▎   | 7/11 [00:34<00:19,  4.97s/it]processing embeddings:  73%|███████▎  | 8/11 [00:39<00:14,  4.87s/it]processing embeddings:  82%|████████▏ | 9/11 [00:44<00:09,  4.87s/it]processing embeddings:  91%|█████████ | 10/11 [00:49<00:04,  4.91s/it]processing embeddings:  91%|█████████ | 10/11 [00:49<00:04,  4.91s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3350 到 3360
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:04<00:49,  4.93s/it]processing embeddings:  18%|█▊        | 2/11 [00:09<00:42,  4.72s/it]processing embeddings:  27%|██▋       | 3/11 [00:14<00:38,  4.81s/it]processing embeddings:  36%|███▋      | 4/11 [00:19<00:33,  4.84s/it]processing embeddings:  45%|████▌     | 5/11 [00:24<00:30,  5.06s/it]processing embeddings:  55%|█████▍    | 6/11 [00:29<00:25,  5.10s/it]processing embeddings:  64%|██████▎   | 7/11 [00:37<00:23,  5.82s/it]processing embeddings:  73%|███████▎  | 8/11 [00:42<00:16,  5.60s/it]processing embeddings:  82%|████████▏ | 9/11 [00:47<00:11,  5.55s/it]processing embeddings:  91%|█████████ | 10/11 [00:54<00:05,  5.93s/it]processing embeddings:  91%|█████████ | 10/11 [00:54<00:05,  5.46s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3360 到 3370
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:05<00:50,  5.00s/it]processing embeddings:  18%|█▊        | 2/11 [00:09<00:44,  4.94s/it]processing embeddings:  27%|██▋       | 3/11 [00:14<00:39,  4.92s/it]processing embeddings:  36%|███▋      | 4/11 [00:18<00:32,  4.63s/it]processing embeddings:  45%|████▌     | 5/11 [00:22<00:24,  4.06s/it]processing embeddings:  55%|█████▍    | 6/11 [00:25<00:18,  3.75s/it]processing embeddings:  64%|██████▎   | 7/11 [00:28<00:13,  3.48s/it]processing embeddings:  73%|███████▎  | 8/11 [00:31<00:10,  3.34s/it]processing embeddings:  82%|████████▏ | 9/11 [00:34<00:06,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.78s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3370 到 3380
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.42s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.13s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:23,  2.97s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:19,  2.80s/it]processing embeddings:  45%|████▌     | 5/11 [00:14<00:17,  2.91s/it]processing embeddings:  55%|█████▍    | 6/11 [00:18<00:15,  3.06s/it]processing embeddings:  64%|██████▎   | 7/11 [00:21<00:12,  3.04s/it]processing embeddings:  73%|███████▎  | 8/11 [00:23<00:08,  2.93s/it]processing embeddings:  82%|████████▏ | 9/11 [00:26<00:05,  2.92s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:02,  2.94s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:02,  2.97s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3380 到 3390
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:29,  2.98s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.13s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.16s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:21,  3.10s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:18,  3.00s/it]processing embeddings:  55%|█████▍    | 6/11 [00:18<00:15,  3.02s/it]processing embeddings:  64%|██████▎   | 7/11 [00:21<00:12,  3.10s/it]processing embeddings:  73%|███████▎  | 8/11 [00:24<00:09,  3.15s/it]processing embeddings:  82%|████████▏ | 9/11 [00:27<00:06,  3.08s/it]processing embeddings:  91%|█████████ | 10/11 [00:30<00:02,  2.99s/it]processing embeddings:  91%|█████████ | 10/11 [00:30<00:03,  3.05s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3390 到 3400
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.10s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:26,  2.96s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:22,  2.86s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:19,  2.77s/it]processing embeddings:  45%|████▌     | 5/11 [00:14<00:16,  2.81s/it]processing embeddings:  55%|█████▍    | 6/11 [00:17<00:14,  2.90s/it]processing embeddings:  64%|██████▎   | 7/11 [00:20<00:12,  3.03s/it]processing embeddings:  73%|███████▎  | 8/11 [00:23<00:08,  2.99s/it]processing embeddings:  82%|████████▏ | 9/11 [00:26<00:06,  3.00s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:03,  3.00s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:02,  2.95s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3400 到 3410
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.20s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.20s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:24,  3.11s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:21,  3.12s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:19,  3.21s/it]processing embeddings:  55%|█████▍    | 6/11 [00:18<00:15,  3.14s/it]processing embeddings:  64%|██████▎   | 7/11 [00:21<00:12,  3.12s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.11s/it]processing embeddings:  82%|████████▏ | 9/11 [00:28<00:06,  3.12s/it]processing embeddings:  91%|█████████ | 10/11 [00:31<00:03,  3.06s/it]processing embeddings:  91%|█████████ | 10/11 [00:31<00:03,  3.12s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3410 到 3420
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:30,  3.09s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:27,  3.06s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:23,  2.93s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:20,  2.96s/it]processing embeddings:  45%|████▌     | 5/11 [00:14<00:17,  2.94s/it]processing embeddings:  55%|█████▍    | 6/11 [00:18<00:15,  3.10s/it]processing embeddings:  64%|██████▎   | 7/11 [00:21<00:12,  3.16s/it]processing embeddings:  73%|███████▎  | 8/11 [00:24<00:09,  3.19s/it]processing embeddings:  82%|████████▏ | 9/11 [00:27<00:06,  3.20s/it]processing embeddings:  91%|█████████ | 10/11 [00:31<00:03,  3.20s/it]processing embeddings:  91%|█████████ | 10/11 [00:31<00:03,  3.12s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3420 到 3430
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.50s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.26s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.22s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.23s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.28s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.26s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.27s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.28s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3430 到 3440
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.14s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.30s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.24s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.26s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.29s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.35s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.33s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.28s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3440 到 3450
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.20s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.25s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.21s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.25s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.24s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.26s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.25s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.23s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.22s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3450 到 3460
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.29s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.22s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.30s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.29s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.25s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.29s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.37s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.33s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3460 到 3470
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.26s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.32s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.39s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.30s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.27s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.29s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.26s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.25s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.22s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3470 到 3480
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.32s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.37s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.36s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.32s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.26s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.26s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.29s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.28s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3480 到 3490
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.29s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.32s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.36s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.39s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.37s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.42s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.43s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.37s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.42s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.39s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3490 到 3500
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.24s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.23s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.18s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.22s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.25s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.35s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.33s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.36s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.39s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.32s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3500 到 3510
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.16s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.33s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.43s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.43s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.42s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.50s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.52s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.50s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.46s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.47s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.45s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3510 到 3520
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.55s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.39s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.32s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.52s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.40s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.42s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.38s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.43s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.37s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.39s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3520 到 3530
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.15s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:27,  3.11s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.31s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.26s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.24s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.25s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.22s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3530 到 3540
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.28s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.30s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.32s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.24s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.37s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.53s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.48s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.46s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.40s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.40s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3540 到 3550
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.11s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.42s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.28s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.25s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.31s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.34s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.32s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.38s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.39s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.35s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3550 到 3560
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.51s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.47s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.43s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.34s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.31s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.32s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.34s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.34s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3560 到 3570
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.27s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.30s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.19s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.19s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.19s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.26s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.31s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.25s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3570 到 3580
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.16s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.33s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.27s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.23s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.23s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.24s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.27s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.40s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.41s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.37s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.32s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3580 到 3590
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.22s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.28s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.20s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.24s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.38s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.43s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:14,  3.53s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.45s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.41s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.36s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3590 到 3600
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.26s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.22s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.19s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.38s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.28s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.24s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.21s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.20s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3600 到 3610
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.23s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.29s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.28s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.36s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.29s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.35s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.33s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3610 到 3620
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.23s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.37s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.23s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.22s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.22s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.23s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.28s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.29s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.25s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.25s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3620 到 3630
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.19s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.23s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.27s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.24s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.30s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.31s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.35s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.38s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.30s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3630 到 3640
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.17s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.17s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.22s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.20s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.25s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.21s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.19s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.20s/it]processing embeddings:  82%|████████▏ | 9/11 [00:28<00:06,  3.21s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.22s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3640 到 3650
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.54s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.31s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.26s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.21s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.20s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.23s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.19s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.19s/it]processing embeddings:  82%|████████▏ | 9/11 [00:28<00:06,  3.18s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.20s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3650 到 3660
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.25s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.36s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.29s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.38s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.30s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.31s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.31s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.29s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.41s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3660 到 3670
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.23s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.36s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.53s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.40s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.32s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.34s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.35s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.37s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.36s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3670 到 3680
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.25s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.26s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.32s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.23s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.28s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.25s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.31s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.27s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.25s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3680 到 3690
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.15s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.29s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.44s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.43s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.38s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.33s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.27s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.31s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.34s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3690 到 3700
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.13s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.37s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.28s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.24s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.36s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.32s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.29s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.26s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3700 到 3710
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.35s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.24s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.22s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.31s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.23s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.34s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.35s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.32s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3710 到 3720
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.49s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.36s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.40s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.32s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.30s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.25s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:12,  3.23s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.23s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3720 到 3730
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.29s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.31s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.28s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.26s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.27s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.35s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.34s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.40s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.34s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3730 到 3740
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.41s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.33s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.28s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.32s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.38s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.37s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.25s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.22s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3740 到 3750
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.47s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.36s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.31s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.29s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.39s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.29s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.23s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.32s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3750 到 3760
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.28s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.30s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.31s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.36s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.32s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.39s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.32s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.37s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.39s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3760 到 3770
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.45s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.38s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.34s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.30s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.27s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:15,  3.19s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.15s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.19s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.19s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.25s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.25s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3770 到 3780
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.45s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.43s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.37s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.28s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.30s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.24s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.32s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3780 到 3790
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.20s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.23s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.22s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.24s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.31s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.32s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.24s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.29s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3790 到 3800
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.22s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.28s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.31s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.28s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.24s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.21s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.21s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.28s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.25s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3800 到 3810
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.20s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.24s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.23s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.27s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.31s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.37s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.32s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.32s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3810 到 3820
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.41s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.41s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.40s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.36s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.40s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.37s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.36s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.34s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.34s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3820 到 3830
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.35s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.39s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.42s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.38s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.36s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.31s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.26s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.28s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3830 到 3840
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.32s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.29s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.29s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.29s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.35s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.30s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.24s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.34s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.36s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3840 到 3850
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.56s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.50s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.45s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.45s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.36s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.42s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.36s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:09,  3.30s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.36s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.38s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3850 到 3860
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.40s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.45s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.36s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.32s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.28s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.23s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.21s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.20s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3860 到 3870
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.24s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.26s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.30s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.32s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.36s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.34s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.28s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.24s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3870 到 3880
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.36s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.32s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.30s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.30s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.33s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.30s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3880 到 3890
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.32s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.32s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.25s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.26s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.24s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.22s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.25s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.25s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.20s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3890 到 3900
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.14s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.17s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.26s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.24s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.37s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.28s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.26s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.25s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.25s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.25s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3900 到 3910
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.41s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.29s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.20s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.21s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.17s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:15,  3.17s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.16s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.19s/it]processing embeddings:  82%|████████▏ | 9/11 [00:28<00:06,  3.21s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.25s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3910 到 3920
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.21s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.28s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.20s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.47s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.38s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.32s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.29s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.35s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.39s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.41s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.36s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3920 到 3930
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.35s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.58s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.53s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.41s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.31s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.35s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.33s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.42s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.42s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.38s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3930 到 3940
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.29s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.22s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.22s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.23s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.28s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.47s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.49s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.49s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.37s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.37s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3940 到 3950
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.62s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.47s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.35s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.35s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.31s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.33s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.43s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.34s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.35s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.35s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3950 到 3960
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.34s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.24s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.22s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.35s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.32s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.31s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3960 到 3970
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.23s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.16s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.14s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.15s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:19,  3.17s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:15,  3.17s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.21s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.20s/it]processing embeddings:  82%|████████▏ | 9/11 [00:28<00:06,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.21s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3970 到 3980
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.23s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.19s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.28s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.29s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.30s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.25s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.23s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3980 到 3990
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.38s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.36s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.35s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.24s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.23s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.21s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.29s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.24s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 3990 到 4000
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.14s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.20s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.19s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.20s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.23s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.26s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.32s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.25s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4000 到 4010
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.31s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.21s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.24s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.22s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.29s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.25s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.21s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4010 到 4020
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.39s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.42s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.43s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.36s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.34s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.28s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.38s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.42s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.45s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.49s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.42s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4020 到 4030
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.35s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.23s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.22s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.31s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.34s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.28s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.24s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.23s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4030 到 4040
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.30s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.33s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.30s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.21s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.25s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.24s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.24s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.23s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.20s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4040 到 4050
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.60s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.52s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.40s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.50s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.36s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.32s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.39s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.45s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.40s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.37s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.40s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4050 到 4060
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.31s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.31s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.32s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.27s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.26s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.42s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.46s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.37s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.36s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.37s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.36s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4060 到 4070
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.29s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.30s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.27s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.25s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.25s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.22s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.22s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.22s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4070 到 4080
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.28s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.23s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.24s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.33s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.40s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.36s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.32s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.32s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.22s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4080 到 4090
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.34s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.39s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.35s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.30s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.29s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.26s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.25s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4090 到 4100
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.32s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.25s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.24s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.25s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.25s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.30s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.29s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.29s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.25s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4100 到 4110
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.29s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.45s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.28s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.24s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.32s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.26s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.35s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.32s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.35s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.42s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.35s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4110 到 4120
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.50s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.33s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.30s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.35s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.36s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.30s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.27s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.36s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.30s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4120 到 4130
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.19s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.21s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.21s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.28s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.27s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.40s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.40s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.32s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4130 到 4140
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.39s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.25s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.35s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.26s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.26s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.31s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.33s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.30s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.30s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4140 到 4150
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.31s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.44s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.39s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.44s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.40s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.32s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.32s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.34s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.35s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4150 到 4160
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.37s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.34s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.24s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.37s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.33s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.43s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.36s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.40s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.35s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.34s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4160 到 4170
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.24s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.20s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.18s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.29s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.23s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.21s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.23s/it]processing embeddings:  82%|████████▏ | 9/11 [00:28<00:06,  3.20s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.19s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.23s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4170 到 4180
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.34s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.39s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.33s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.29s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.36s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.38s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.41s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.32s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.39s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4180 到 4190
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.27s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.24s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.25s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.25s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.24s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.24s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.24s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.34s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.40s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4190 到 4200
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.18s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.28s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.22s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.28s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.25s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.23s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.27s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.33s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.38s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4200 到 4210
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.34s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.25s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.27s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.30s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.30s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.27s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.21s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4210 到 4220
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.16s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.16s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.25s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.23s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.21s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.30s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.27s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.29s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4220 到 4230
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.64s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.59s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.42s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.44s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.31s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.24s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:12,  3.23s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.25s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.34s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4230 到 4240
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.39s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.37s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.32s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.27s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.43s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.39s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.35s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.28s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.22s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4240 到 4250
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.34s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.23s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.27s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.31s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.29s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.25s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.26s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.24s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4250 到 4260
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.27s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.17s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.20s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.19s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:19,  3.20s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.22s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.25s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.31s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4260 到 4270
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.55s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.46s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.38s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.30s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.28s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:12,  3.24s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.28s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.30s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4270 到 4280
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.50s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.26s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.22s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.20s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:15,  3.17s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.27s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.32s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.35s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4280 到 4290
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.35s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.32s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.32s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.28s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.25s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.25s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.20s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.33s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.45s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.37s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4290 到 4300
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.19s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.37s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.40s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.33s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.29s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.31s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.26s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.25s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.25s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.30s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4300 到 4310
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.23s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.21s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.31s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.26s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.33s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.29s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.30s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4310 到 4320
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.40s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.22s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.29s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.32s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.30s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.28s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.24s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.21s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.20s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.19s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4320 到 4330
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.42s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.22s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.27s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.30s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.42s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.40s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.34s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.38s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.35s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.34s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4330 到 4340
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.34s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.17s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.18s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.23s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.28s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.29s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.23s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4340 到 4350
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.32s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.41s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.44s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.46s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.45s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.35s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.28s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.25s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.36s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4350 到 4360
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.43s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.34s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.28s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.23s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.17s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:15,  3.15s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.16s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.18s/it]processing embeddings:  82%|████████▏ | 9/11 [00:28<00:06,  3.17s/it]processing embeddings:  91%|█████████ | 10/11 [00:31<00:03,  3.17s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.22s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4360 到 4370
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.21s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.23s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.30s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.20s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.26s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.24s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.23s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.21s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.21s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.18s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4370 到 4380
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.26s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.23s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.31s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.35s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.40s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.45s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.43s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.35s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.39s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.39s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4380 到 4390
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.30s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.31s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.25s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.19s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.27s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.22s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.16s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.15s/it]processing embeddings:  82%|████████▏ | 9/11 [00:28<00:06,  3.16s/it]processing embeddings:  91%|█████████ | 10/11 [00:31<00:03,  3.17s/it]processing embeddings:  91%|█████████ | 10/11 [00:31<00:03,  3.20s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4390 到 4400
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.30s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.37s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.39s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.34s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.30s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.36s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.32s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.32s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4400 到 4410
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.30s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.28s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.27s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.26s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.30s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.31s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4410 到 4420
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.42s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.34s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.29s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.25s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.22s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.25s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.23s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.29s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.35s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4420 到 4430
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.27s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.19s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.23s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.22s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:19,  3.18s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.21s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.20s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.25s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4430 到 4440
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.65s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.48s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.44s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.47s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.34s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.24s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:12,  3.24s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.20s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.35s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4440 到 4450
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.18s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.17s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.33s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.25s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.19s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.24s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.23s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.23s/it]processing embeddings:  82%|████████▏ | 9/11 [00:28<00:06,  3.21s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.18s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.21s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4450 到 4460
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.29s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.24s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.31s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.27s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.21s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.33s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.25s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.43s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.40s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4460 到 4470
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.28s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.27s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.23s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.25s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:15,  3.19s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.16s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.27s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.28s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4470 到 4480
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.42s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.29s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.27s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.36s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.32s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.29s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.38s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.36s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4480 到 4490
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.34s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.22s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.21s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.24s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.25s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.24s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.33s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4490 到 4500
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.28s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.19s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.15s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.19s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.23s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.33s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.28s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.26s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.37s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4500 到 4510
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.31s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.31s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.38s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.42s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.37s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.36s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.35s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.28s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.28s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.35s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.37s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4510 到 4520
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.19s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.21s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.22s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.34s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.28s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.22s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.26s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.28s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4520 到 4530
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.19s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.19s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.33s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.24s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.20s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.23s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.25s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.22s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.25s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4530 到 4540
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.32s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.43s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.35s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.48s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.38s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.35s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.43s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.33s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.28s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.35s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4540 到 4550
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.17s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.19s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.21s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.24s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.21s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.25s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.31s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.31s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.36s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4550 到 4560
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.40s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.25s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.26s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.25s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.34s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.31s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.29s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.25s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.19s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.19s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.25s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4560 到 4570
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.28s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.20s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.22s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.35s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.34s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.42s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.43s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.35s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.28s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4570 到 4580
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.37s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.28s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.38s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.34s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.29s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.38s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.37s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.36s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.36s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.35s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4580 到 4590
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.59s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.40s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.28s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.28s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.32s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.39s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.46s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.47s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.35s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.37s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.38s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4590 到 4600
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.30s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.36s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.33s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.31s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.35s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.44s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.38s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.36s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.35s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4600 到 4610
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.27s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.39s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.28s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.21s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.21s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:15,  3.18s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.16s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.19s/it]processing embeddings:  82%|████████▏ | 9/11 [00:28<00:06,  3.10s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.22s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4610 到 4620
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.63s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.43s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.38s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.38s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.35s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.33s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.32s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.30s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.28s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.36s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.37s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4620 到 4630
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.68s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.58s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.38s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.33s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.37s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.31s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.36s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.29s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.25s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.42s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4630 到 4640
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.23s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.21s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.20s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.21s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.22s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:15,  3.20s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.27s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.27s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.22s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.19s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.22s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4640 到 4650
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.23s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.35s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.27s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.27s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.25s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.31s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.26s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4650 到 4660
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.23s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.24s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.34s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.33s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.29s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.35s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.38s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.39s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.39s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.35s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4660 到 4670
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.42s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.35s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.31s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.27s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.19s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:15,  3.18s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.19s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.29s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4670 到 4680
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.34s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.43s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.32s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.25s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.36s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.38s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.35s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.28s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.25s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.32s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4680 到 4690
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.27s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.23s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.34s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.32s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.27s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.24s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.18s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.14s/it]processing embeddings:  82%|████████▏ | 9/11 [00:28<00:06,  3.16s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.19s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.22s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4690 到 4700
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.30s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.36s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.23s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.37s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.26s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.30s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.29s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.49s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.41s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.42s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.40s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4700 到 4710
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.28s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.37s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.41s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.45s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.33s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.35s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.31s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.38s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.36s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.36s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4710 到 4720
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.76s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.51s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.38s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.27s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.28s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.23s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.32s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.25s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.25s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.30s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4720 到 4730
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.29s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.33s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.35s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.37s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.39s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.32s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.28s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.32s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4730 到 4740
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.47s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.29s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.35s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.30s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.27s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.28s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.29s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.30s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4740 到 4750
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.33s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.31s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.31s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.25s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.24s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.21s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.24s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.20s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4750 到 4760
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.38s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.23s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.25s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.30s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.28s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.22s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4760 到 4770
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.34s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.44s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.35s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.31s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.24s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.28s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.24s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.31s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.25s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4770 到 4780
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.42s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.22s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.19s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.19s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:15,  3.18s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.26s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.20s/it]processing embeddings:  82%|████████▏ | 9/11 [00:28<00:06,  3.18s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.21s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.21s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4780 到 4790
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.33s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.23s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.21s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.19s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.22s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.35s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.29s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.23s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.20s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.25s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4790 到 4800
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.32s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.32s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.27s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.23s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.22s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.31s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.28s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.26s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4800 到 4810
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.14s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.38s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.33s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.43s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.33s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.35s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.34s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.30s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4810 到 4820
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.48s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.33s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.25s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.20s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.27s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.24s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.22s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4820 到 4830
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.34s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.26s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.33s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.25s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.24s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.23s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.31s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.32s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4830 到 4840
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.26s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.26s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.22s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.28s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.24s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.24s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.23s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.35s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.41s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.36s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4840 到 4850
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.16s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.37s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.40s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.34s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.27s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.23s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.28s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.37s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4850 到 4860
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.58s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.53s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.38s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.41s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.34s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.28s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.36s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.30s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.36s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.35s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4860 到 4870
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.25s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.24s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.25s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.28s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.28s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.26s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.22s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.25s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4870 到 4880
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.51s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.34s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.41s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.32s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.36s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.33s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.29s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.39s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.39s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.36s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4880 到 4890
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.44s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.59s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.86s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.69s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.59s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.45s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.54s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.43s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.41s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.35s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.48s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4890 到 4900
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.26s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.20s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.29s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.35s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.30s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.27s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.27s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.22s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4900 到 4910
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.54s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.34s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.35s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.38s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.30s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.27s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.25s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.22s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4910 到 4920
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.17s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.24s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.20s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.21s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.22s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:15,  3.19s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.20s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.22s/it]processing embeddings:  82%|████████▏ | 9/11 [00:28<00:06,  3.21s/it]processing embeddings:  91%|█████████ | 10/11 [00:31<00:03,  3.18s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.20s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4920 到 4930
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.31s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.26s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.28s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.28s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.29s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.29s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.34s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.25s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.21s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4930 到 4940
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.39s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.31s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.30s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.36s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.39s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.32s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.28s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.21s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.18s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.19s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4940 到 4950
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.27s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.25s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.31s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.32s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.31s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.31s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.29s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.37s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4950 到 4960
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.31s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.18s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.24s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.27s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.26s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.25s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.24s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.36s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4960 到 4970
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.28s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.19s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.27s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.22s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.22s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.26s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.35s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.31s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4970 到 4980
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.22s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.23s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.28s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.23s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.20s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.21s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.28s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.28s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.35s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4980 到 4990
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.31s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.31s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.37s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.32s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.27s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.36s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.41s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.32s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.39s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.35s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.35s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 4990 到 5000
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.35s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.31s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.29s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.39s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.38s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.36s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.39s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.48s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.44s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.39s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5000 到 5010
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.27s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.34s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.24s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.33s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.41s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.30s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.32s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.30s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.30s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5010 到 5020
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.18s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.22s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.34s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.40s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.35s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.32s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.33s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.33s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.35s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5020 到 5030
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.55s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.34s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.24s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.34s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.34s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.37s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.32s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.30s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5030 到 5040
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.32s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.34s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.26s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.31s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.25s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.21s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.22s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.19s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5040 到 5050
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.45s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.39s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.26s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.17s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.26s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.35s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.34s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.33s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.32s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5050 到 5060
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.46s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.20s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.28s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.32s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.31s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.26s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5060 到 5070
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.42s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.29s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.21s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.30s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.37s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.33s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.32s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.28s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5070 到 5080
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.14s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.20s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.17s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.19s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:19,  3.20s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:15,  3.18s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.21s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.20s/it]processing embeddings:  82%|████████▏ | 9/11 [00:28<00:06,  3.21s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.23s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5080 到 5090
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.18s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.20s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.31s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.23s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.30s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.33s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.29s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.28s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.24s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5090 到 5100
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.41s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.31s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.22s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.30s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.27s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.26s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.24s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.35s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.41s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5100 到 5110
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.38s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.40s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.33s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.25s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.26s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.26s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.25s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.24s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.22s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5110 到 5120
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.23s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.38s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.35s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.28s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.27s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.26s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.39s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.36s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5120 到 5130
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.38s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.35s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.38s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.41s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.33s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.32s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.31s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.34s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.37s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5130 到 5140
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.71s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.48s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.33s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.37s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.29s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.26s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.33s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.33s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.38s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.35s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.38s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5140 到 5150
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.35s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.28s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.25s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.25s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.18s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.26s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.20s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.31s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5150 到 5160
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.25s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.27s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.28s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.26s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.24s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.24s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.20s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.22s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.19s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5160 到 5170
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.15s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.15s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.16s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.25s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.24s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.29s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.25s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.26s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5170 到 5180
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.22s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.24s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.26s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.21s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.35s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.35s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.29s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.35s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.36s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5180 到 5190
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.25s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.19s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.26s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.28s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.38s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.32s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.35s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5190 到 5200
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.30s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.31s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.16s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.15s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.22s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.28s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:12,  3.24s/it]processing embeddings:  73%|███████▎  | 8/11 [00:25<00:09,  3.20s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.25s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.26s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.25s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5200 到 5210
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.49s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.40s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:26,  3.34s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.32s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.29s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.32s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.26s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.22s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.19s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5210 到 5220
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.16s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.16s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.20s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.33s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.33s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.29s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.38s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.36s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.41s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.35s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5220 到 5230
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.32s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.27s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.22s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.22s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:15,  3.18s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.29s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.36s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.36s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.31s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5230 到 5240
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.16s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:32,  3.56s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.52s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.42s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.41s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.44s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.38s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:09,  3.32s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.29s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.36s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.41s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5240 到 5250
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.33s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.26s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.25s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.31s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.31s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.29s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.43s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.37s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.37s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5250 到 5260
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.45s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.33s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.21s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.24s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.25s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.23s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.27s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.24s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.25s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.28s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5260 到 5270
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.15s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.25s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.35s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.31s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.27s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.37s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.40s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.38s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.38s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.37s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5270 到 5280
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.50s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.52s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.45s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.41s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.37s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.29s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.31s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.35s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.39s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5280 到 5290
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.24s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:29,  3.31s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.22s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:22,  3.26s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:20,  3.37s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:16,  3.39s/it]processing embeddings:  64%|██████▎   | 7/11 [00:23<00:13,  3.32s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:09,  3.30s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.32s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5290 到 5300
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:30,  3.09s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.19s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:26,  3.26s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.22s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.30s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.25s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.32s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.37s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.36s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.33s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.33s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5300 到 5310
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.24s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.34s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.22s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.24s/it]processing embeddings:  45%|████▌     | 5/11 [00:16<00:19,  3.21s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.22s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.32s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.33s/it]processing embeddings:  82%|████████▏ | 9/11 [00:29<00:06,  3.28s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]processing embeddings:  91%|█████████ | 10/11 [00:32<00:03,  3.27s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5310 到 5320
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.41s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.45s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.39s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.45s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.44s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.43s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.48s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.53s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.58s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.61s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.53s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5320 到 5330
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:38,  3.84s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.67s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.62s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.55s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.49s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.49s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.60s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.60s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.62s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.66s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.62s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5330 到 5340
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.60s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.72s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.70s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.62s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.58s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.51s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.55s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.60s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.55s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.54s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.61s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5340 到 5350
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.53s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:35,  3.96s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.78s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.73s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.67s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.69s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.67s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.62s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.64s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.59s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.67s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5350 到 5360
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.70s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.62s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.59s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.62s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.66s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.63s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.66s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.63s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.64s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.64s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5360 到 5370
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.50s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.56s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.54s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.61s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.66s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.60s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.53s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.60s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.61s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.61s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.61s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5370 到 5380
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.74s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.65s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.58s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.59s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.68s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.71s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.74s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.85s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.86s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.78s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.74s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5380 到 5390
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.61s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.57s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.62s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.54s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.63s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.58s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.53s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.52s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.46s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.40s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.52s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5390 到 5400
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.35s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.38s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:29,  3.73s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:26,  3.85s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:23,  3.90s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:19,  3.89s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:15,  3.84s/it]processing embeddings:  73%|███████▎  | 8/11 [00:30<00:11,  3.77s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.74s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.76s/it]processing embeddings:  91%|█████████ | 10/11 [00:38<00:03,  3.82s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5400 到 5410
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.77s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.69s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.75s/it]processing embeddings:  36%|███▋      | 4/11 [00:19<00:38,  5.57s/it]processing embeddings:  45%|████▌     | 5/11 [00:29<00:42,  7.00s/it]processing embeddings:  55%|█████▍    | 6/11 [00:38<00:39,  7.93s/it]processing embeddings:  64%|██████▎   | 7/11 [00:47<00:33,  8.31s/it]processing embeddings:  73%|███████▎  | 8/11 [00:57<00:25,  8.66s/it]processing embeddings:  82%|████████▏ | 9/11 [01:06<00:17,  8.85s/it]processing embeddings:  91%|█████████ | 10/11 [01:15<00:08,  8.91s/it]processing embeddings:  91%|█████████ | 10/11 [01:15<00:07,  7.57s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5410 到 5420
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:10<01:41, 10.13s/it]processing embeddings:  18%|█▊        | 2/11 [00:16<01:10,  7.86s/it]processing embeddings:  27%|██▋       | 3/11 [00:23<00:58,  7.35s/it]processing embeddings:  36%|███▋      | 4/11 [00:32<00:57,  8.17s/it]processing embeddings:  45%|████▌     | 5/11 [00:41<00:51,  8.56s/it]processing embeddings:  55%|█████▍    | 6/11 [00:52<00:46,  9.20s/it]processing embeddings:  64%|██████▎   | 7/11 [01:02<00:38,  9.63s/it]processing embeddings:  73%|███████▎  | 8/11 [01:12<00:29,  9.82s/it]processing embeddings:  82%|████████▏ | 9/11 [01:23<00:20, 10.13s/it]processing embeddings:  91%|█████████ | 10/11 [01:34<00:10, 10.28s/it]processing embeddings:  91%|█████████ | 10/11 [01:34<00:09,  9.44s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5420 到 5430
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:10<01:48, 10.89s/it]processing embeddings:  18%|█▊        | 2/11 [00:20<01:33, 10.40s/it]processing embeddings:  27%|██▋       | 3/11 [00:27<01:09,  8.74s/it]processing embeddings:  36%|███▋      | 4/11 [00:30<00:43,  6.24s/it]processing embeddings:  45%|████▌     | 5/11 [00:32<00:29,  4.95s/it]processing embeddings:  55%|█████▍    | 6/11 [00:35<00:21,  4.22s/it]processing embeddings:  64%|██████▎   | 7/11 [00:38<00:14,  3.67s/it]processing embeddings:  73%|███████▎  | 8/11 [00:41<00:10,  3.50s/it]processing embeddings:  82%|████████▏ | 9/11 [00:44<00:06,  3.31s/it]processing embeddings:  91%|█████████ | 10/11 [00:47<00:03,  3.23s/it]processing embeddings:  91%|█████████ | 10/11 [00:47<00:04,  4.75s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5430 到 5440
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:30,  3.05s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:27,  3.05s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:24,  3.05s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:21,  3.04s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:18,  3.06s/it]processing embeddings:  55%|█████▍    | 6/11 [00:18<00:15,  3.06s/it]processing embeddings:  64%|██████▎   | 7/11 [00:21<00:12,  3.03s/it]processing embeddings:  73%|███████▎  | 8/11 [00:24<00:08,  2.96s/it]processing embeddings:  82%|████████▏ | 9/11 [00:27<00:05,  2.98s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:02,  2.93s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:02,  3.00s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5440 到 5450
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:30,  3.06s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:26,  2.99s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:24,  3.01s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:21,  3.00s/it]processing embeddings:  45%|████▌     | 5/11 [00:14<00:17,  2.89s/it]processing embeddings:  55%|█████▍    | 6/11 [00:17<00:14,  2.90s/it]processing embeddings:  64%|██████▎   | 7/11 [00:20<00:11,  2.89s/it]processing embeddings:  73%|███████▎  | 8/11 [00:23<00:08,  2.94s/it]processing embeddings:  82%|████████▏ | 9/11 [00:26<00:05,  2.98s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:03,  3.02s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:02,  3.00s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5450 到 5460
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:29,  2.90s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:25,  2.85s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:23,  2.91s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:20,  2.95s/it]processing embeddings:  45%|████▌     | 5/11 [00:14<00:17,  2.98s/it]processing embeddings:  55%|█████▍    | 6/11 [00:17<00:14,  2.98s/it]processing embeddings:  64%|██████▎   | 7/11 [00:20<00:11,  2.97s/it]processing embeddings:  73%|███████▎  | 8/11 [00:23<00:08,  3.00s/it]processing embeddings:  82%|████████▏ | 9/11 [00:26<00:06,  3.03s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:03,  3.01s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:02,  2.98s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5460 到 5470
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:29,  2.96s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:25,  2.87s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:23,  2.91s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:20,  2.95s/it]processing embeddings:  45%|████▌     | 5/11 [00:14<00:17,  2.89s/it]processing embeddings:  55%|█████▍    | 6/11 [00:17<00:14,  2.81s/it]processing embeddings:  64%|██████▎   | 7/11 [00:20<00:11,  2.88s/it]processing embeddings:  73%|███████▎  | 8/11 [00:23<00:08,  2.95s/it]processing embeddings:  82%|████████▏ | 9/11 [00:26<00:06,  3.09s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:03,  3.10s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:02,  2.99s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5470 到 5480
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:30,  3.02s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:26,  2.94s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:23,  2.95s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:20,  3.00s/it]processing embeddings:  45%|████▌     | 5/11 [00:14<00:17,  2.97s/it]processing embeddings:  55%|█████▍    | 6/11 [00:17<00:14,  2.93s/it]processing embeddings:  64%|██████▎   | 7/11 [00:20<00:11,  2.98s/it]processing embeddings:  73%|███████▎  | 8/11 [00:24<00:09,  3.11s/it]processing embeddings:  82%|████████▏ | 9/11 [00:27<00:06,  3.09s/it]processing embeddings:  91%|█████████ | 10/11 [00:30<00:03,  3.07s/it]processing embeddings:  91%|█████████ | 10/11 [00:30<00:03,  3.05s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5480 到 5490
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.11s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:26,  2.98s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:23,  2.95s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:20,  2.93s/it]processing embeddings:  45%|████▌     | 5/11 [00:14<00:17,  2.96s/it]processing embeddings:  55%|█████▍    | 6/11 [00:17<00:14,  2.98s/it]processing embeddings:  64%|██████▎   | 7/11 [00:20<00:11,  2.96s/it]processing embeddings:  73%|███████▎  | 8/11 [00:23<00:09,  3.00s/it]processing embeddings:  82%|████████▏ | 9/11 [00:26<00:06,  3.01s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:02,  2.99s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:02,  2.99s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5490 到 5500
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:30,  3.07s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:27,  3.08s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:23,  2.95s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:20,  2.93s/it]processing embeddings:  45%|████▌     | 5/11 [00:14<00:17,  2.86s/it]processing embeddings:  55%|█████▍    | 6/11 [00:17<00:14,  2.94s/it]processing embeddings:  64%|██████▎   | 7/11 [00:20<00:11,  2.95s/it]processing embeddings:  73%|███████▎  | 8/11 [00:23<00:08,  2.97s/it]processing embeddings:  82%|████████▏ | 9/11 [00:26<00:05,  2.97s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:02,  2.98s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:02,  2.97s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5500 到 5510
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:29,  3.00s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:26,  2.97s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:23,  2.97s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:20,  2.95s/it]processing embeddings:  45%|████▌     | 5/11 [00:14<00:17,  2.99s/it]processing embeddings:  55%|█████▍    | 6/11 [00:18<00:15,  3.04s/it]processing embeddings:  64%|██████▎   | 7/11 [00:20<00:11,  2.97s/it]processing embeddings:  73%|███████▎  | 8/11 [00:23<00:08,  3.00s/it]processing embeddings:  82%|████████▏ | 9/11 [00:26<00:06,  3.00s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:03,  3.01s/it]processing embeddings:  91%|█████████ | 10/11 [00:30<00:03,  3.01s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5510 到 5520
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:30,  3.03s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:27,  3.06s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:24,  3.09s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:21,  3.09s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:18,  3.11s/it]processing embeddings:  55%|█████▍    | 6/11 [00:18<00:15,  3.07s/it]processing embeddings:  64%|██████▎   | 7/11 [00:21<00:12,  3.04s/it]processing embeddings:  73%|███████▎  | 8/11 [00:24<00:09,  3.04s/it]processing embeddings:  82%|████████▏ | 9/11 [00:27<00:06,  3.03s/it]processing embeddings:  91%|█████████ | 10/11 [00:30<00:03,  3.05s/it]processing embeddings:  91%|█████████ | 10/11 [00:30<00:03,  3.08s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5520 到 5530
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:27,  2.80s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:25,  2.81s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:22,  2.80s/it]processing embeddings:  36%|███▋      | 4/11 [00:11<00:19,  2.85s/it]processing embeddings:  45%|████▌     | 5/11 [00:14<00:17,  2.89s/it]processing embeddings:  55%|█████▍    | 6/11 [00:17<00:14,  2.93s/it]processing embeddings:  64%|██████▎   | 7/11 [00:20<00:11,  2.96s/it]processing embeddings:  73%|███████▎  | 8/11 [00:23<00:08,  2.90s/it]processing embeddings:  82%|████████▏ | 9/11 [00:26<00:05,  2.92s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:02,  2.93s/it]processing embeddings:  91%|█████████ | 10/11 [00:29<00:02,  2.92s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5530 到 5540
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:30,  3.02s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:28,  3.19s/it]processing embeddings:  27%|██▋       | 3/11 [00:09<00:25,  3.16s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:21,  3.11s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:18,  3.03s/it]processing embeddings:  55%|█████▍    | 6/11 [00:19<00:16,  3.25s/it]processing embeddings:  64%|██████▎   | 7/11 [00:22<00:13,  3.42s/it]processing embeddings:  73%|███████▎  | 8/11 [00:26<00:10,  3.52s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:07,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.49s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.36s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5540 到 5550
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.47s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.57s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:29,  3.67s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.51s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.46s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.41s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.44s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.38s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.37s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.44s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.48s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5550 到 5560
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.41s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.64s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.49s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.52s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.53s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.57s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.60s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.59s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.50s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.55s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5560 到 5570
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.70s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.61s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.52s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.47s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.45s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.45s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.52s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.50s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.48s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.53s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.51s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5570 到 5580
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.48s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.49s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.49s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.45s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.48s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.50s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.64s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:11,  3.67s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.62s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.67s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.59s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5580 到 5590
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.48s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.48s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.43s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.38s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.57s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.71s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.59s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.55s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:07,  3.53s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.54s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.54s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5590 到 5600
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.41s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.67s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:31,  3.89s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.81s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.70s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.80s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.66s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.61s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.55s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.70s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.69s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5600 到 5610
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.49s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.54s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.58s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.66s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.76s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.72s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.61s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.56s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.58s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.61s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5610 到 5620
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.69s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:35,  3.91s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.72s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.74s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.65s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.59s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.51s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.55s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.55s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.61s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5620 到 5630
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.44s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.37s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.45s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.45s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.52s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.49s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.48s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.46s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.49s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.45s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.49s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5630 到 5640
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.64s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.46s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.52s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.44s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:20,  3.42s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.43s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.40s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.47s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:06,  3.49s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.53s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.49s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5640 到 5650
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:33,  3.33s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:31,  3.51s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.47s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.56s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.52s/it]processing embeddings:  55%|█████▍    | 6/11 [00:20<00:17,  3.44s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.46s/it]processing embeddings:  73%|███████▎  | 8/11 [00:27<00:10,  3.41s/it]processing embeddings:  82%|████████▏ | 9/11 [00:30<00:06,  3.34s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.47s/it]processing embeddings:  91%|█████████ | 10/11 [00:34<00:03,  3.46s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5650 到 5660
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.67s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.64s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.56s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:24,  3.47s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.53s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.57s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.57s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.57s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.60s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.56s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.57s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5660 到 5670
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.47s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.40s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.40s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:23,  3.36s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.53s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.62s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:14,  3.62s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.60s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.67s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.66s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.58s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5670 到 5680
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.55s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.69s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.71s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:26,  3.72s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.68s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.65s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.56s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.66s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.65s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.67s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.69s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5680 到 5690
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.77s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.67s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.69s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.71s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.74s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.71s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:14,  3.73s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.69s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.69s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.69s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.73s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5690 到 5700
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.73s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.73s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.74s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:26,  3.72s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.72s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.71s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.69s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.65s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.59s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.67s/it]processing embeddings:  91%|█████████ | 10/11 [00:37<00:03,  3.70s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5700 到 5710
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:35,  3.60s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.69s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.58s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.65s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.70s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.62s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.68s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:10,  3.64s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.71s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.71s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.68s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5710 到 5720
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.73s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.65s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.62s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.62s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.64s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.69s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.72s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.68s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.64s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.66s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5720 到 5730
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:38,  3.89s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.77s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:29,  3.71s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.64s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.67s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.68s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.68s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.67s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.65s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.67s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.70s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5730 到 5740
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.64s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:32,  3.59s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.62s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.62s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:21,  3.59s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:17,  3.54s/it]processing embeddings:  64%|██████▎   | 7/11 [00:24<00:13,  3.47s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:10,  3.57s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.61s/it]processing embeddings:  91%|█████████ | 10/11 [00:35<00:03,  3.64s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.61s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5740 到 5750
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:34,  3.48s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:31,  3.54s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:28,  3.60s/it]processing embeddings:  36%|███▋      | 4/11 [00:14<00:25,  3.65s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:21,  3.66s/it]processing embeddings:  55%|█████▍    | 6/11 [00:21<00:18,  3.61s/it]processing embeddings:  64%|██████▎   | 7/11 [00:25<00:14,  3.62s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.69s/it]processing embeddings:  82%|████████▏ | 9/11 [00:32<00:07,  3.63s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.61s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.62s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5750 到 5760
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:37,  3.71s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:33,  3.73s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:30,  3.76s/it]processing embeddings:  36%|███▋      | 4/11 [00:15<00:26,  3.83s/it]processing embeddings:  45%|████▌     | 5/11 [00:18<00:22,  3.73s/it]processing embeddings:  55%|█████▍    | 6/11 [00:22<00:18,  3.70s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:14,  3.70s/it]processing embeddings:  73%|███████▎  | 8/11 [00:29<00:11,  3.73s/it]processing embeddings:  82%|████████▏ | 9/11 [00:33<00:07,  3.62s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.57s/it]processing embeddings:  91%|█████████ | 10/11 [00:36<00:03,  3.67s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5760 到 5770
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:32,  3.25s/it]processing embeddings:  18%|█▊        | 2/11 [00:06<00:30,  3.37s/it]processing embeddings:  27%|██▋       | 3/11 [00:10<00:27,  3.42s/it]processing embeddings:  36%|███▋      | 4/11 [00:13<00:24,  3.49s/it]processing embeddings:  45%|████▌     | 5/11 [00:17<00:22,  3.73s/it]processing embeddings:  55%|█████▍    | 6/11 [00:23<00:22,  4.46s/it]processing embeddings:  64%|██████▎   | 7/11 [00:29<00:19,  5.00s/it]processing embeddings:  73%|███████▎  | 8/11 [00:35<00:15,  5.33s/it]processing embeddings:  82%|████████▏ | 9/11 [00:41<00:11,  5.55s/it]processing embeddings:  91%|█████████ | 10/11 [00:48<00:05,  5.70s/it]processing embeddings:  91%|█████████ | 10/11 [00:48<00:04,  4.80s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5770 到 5780
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:00,  6.04s/it]processing embeddings:  18%|█▊        | 2/11 [00:12<00:59,  6.56s/it]processing embeddings:  27%|██▋       | 3/11 [00:19<00:51,  6.45s/it]processing embeddings:  36%|███▋      | 4/11 [00:26<00:45,  6.57s/it]processing embeddings:  45%|████▌     | 5/11 [00:32<00:39,  6.65s/it]processing embeddings:  55%|█████▍    | 6/11 [00:39<00:32,  6.57s/it]processing embeddings:  64%|██████▎   | 7/11 [00:45<00:25,  6.48s/it]processing embeddings:  73%|███████▎  | 8/11 [00:52<00:19,  6.66s/it]processing embeddings:  82%|████████▏ | 9/11 [00:59<00:13,  6.62s/it]processing embeddings:  91%|█████████ | 10/11 [01:05<00:06,  6.65s/it]processing embeddings:  91%|█████████ | 10/11 [01:05<00:06,  6.58s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5780 到 5790
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:05,  6.51s/it]processing embeddings:  18%|█▊        | 2/11 [00:13<01:03,  7.08s/it]processing embeddings:  27%|██▋       | 3/11 [00:21<00:59,  7.44s/it]processing embeddings:  36%|███▋      | 4/11 [00:30<00:54,  7.76s/it]processing embeddings:  45%|████▌     | 5/11 [00:37<00:46,  7.77s/it]processing embeddings:  55%|█████▍    | 6/11 [00:42<00:34,  6.85s/it]processing embeddings:  64%|██████▎   | 7/11 [00:47<00:24,  6.15s/it]processing embeddings:  73%|███████▎  | 8/11 [00:52<00:17,  5.72s/it]processing embeddings:  82%|████████▏ | 9/11 [00:57<00:10,  5.40s/it]processing embeddings:  91%|█████████ | 10/11 [01:03<00:05,  5.74s/it]processing embeddings:  91%|█████████ | 10/11 [01:03<00:06,  6.37s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5790 到 5800
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:08<01:26,  8.63s/it]processing embeddings:  18%|█▊        | 2/11 [00:16<01:16,  8.45s/it]processing embeddings:  27%|██▋       | 3/11 [00:25<01:07,  8.38s/it]processing embeddings:  36%|███▋      | 4/11 [00:33<00:58,  8.40s/it]processing embeddings:  45%|████▌     | 5/11 [00:44<00:55,  9.29s/it]processing embeddings:  55%|█████▍    | 6/11 [00:55<00:49,  9.94s/it]processing embeddings:  64%|██████▎   | 7/11 [01:07<00:41, 10.38s/it]processing embeddings:  73%|███████▎  | 8/11 [01:18<00:31, 10.57s/it]processing embeddings:  82%|████████▏ | 9/11 [01:29<00:21, 10.74s/it]processing embeddings:  91%|█████████ | 10/11 [01:40<00:10, 10.87s/it]processing embeddings:  91%|█████████ | 10/11 [01:40<00:10, 10.03s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5800 到 5810
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:10<01:46, 10.66s/it]processing embeddings:  18%|█▊        | 2/11 [00:21<01:36, 10.67s/it]processing embeddings:  27%|██▋       | 3/11 [00:32<01:26, 10.78s/it]processing embeddings:  36%|███▋      | 4/11 [00:44<01:18, 11.20s/it]processing embeddings:  45%|████▌     | 5/11 [00:54<01:06, 11.09s/it]processing embeddings:  55%|█████▍    | 6/11 [01:06<00:55, 11.11s/it]processing embeddings:  64%|██████▎   | 7/11 [01:16<00:43, 10.99s/it]processing embeddings:  73%|███████▎  | 8/11 [01:27<00:32, 10.86s/it]processing embeddings:  82%|████████▏ | 9/11 [01:38<00:21, 10.78s/it]processing embeddings:  91%|█████████ | 10/11 [01:47<00:10, 10.42s/it]processing embeddings:  91%|█████████ | 10/11 [01:47<00:10, 10.77s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5810 到 5820
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:09<01:35,  9.54s/it]processing embeddings:  18%|█▊        | 2/11 [00:18<01:24,  9.43s/it]processing embeddings:  27%|██▋       | 3/11 [00:28<01:15,  9.42s/it]processing embeddings:  36%|███▋      | 4/11 [00:38<01:07,  9.57s/it]processing embeddings:  45%|████▌     | 5/11 [00:47<00:56,  9.48s/it]processing embeddings:  55%|█████▍    | 6/11 [00:56<00:47,  9.43s/it]processing embeddings:  64%|██████▎   | 7/11 [01:06<00:37,  9.41s/it]processing embeddings:  73%|███████▎  | 8/11 [01:15<00:28,  9.44s/it]processing embeddings:  82%|████████▏ | 9/11 [01:25<00:18,  9.47s/it]processing embeddings:  91%|█████████ | 10/11 [01:34<00:09,  9.49s/it]processing embeddings:  91%|█████████ | 10/11 [01:34<00:09,  9.47s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5820 到 5830
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:13<02:11, 13.16s/it]processing embeddings:  18%|█▊        | 2/11 [00:27<02:02, 13.65s/it]processing embeddings:  27%|██▋       | 3/11 [00:41<01:50, 13.80s/it]processing embeddings:  36%|███▋      | 4/11 [00:54<01:36, 13.80s/it]processing embeddings:  45%|████▌     | 5/11 [01:08<01:23, 13.86s/it]processing embeddings:  55%|█████▍    | 6/11 [01:23<01:10, 14.11s/it]processing embeddings:  64%|██████▎   | 7/11 [01:36<00:54, 13.62s/it]processing embeddings:  73%|███████▎  | 8/11 [01:40<00:32, 10.79s/it]processing embeddings:  82%|████████▏ | 9/11 [01:46<00:18,  9.16s/it]processing embeddings:  91%|█████████ | 10/11 [01:52<00:08,  8.06s/it]processing embeddings:  91%|█████████ | 10/11 [01:52<00:11, 11.20s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5830 到 5840
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:05<00:56,  5.68s/it]processing embeddings:  18%|█▊        | 2/11 [00:11<00:54,  6.03s/it]processing embeddings:  27%|██▋       | 3/11 [00:18<00:48,  6.12s/it]processing embeddings:  36%|███▋      | 4/11 [00:23<00:41,  5.98s/it]processing embeddings:  45%|████▌     | 5/11 [00:26<00:28,  4.79s/it]processing embeddings:  55%|█████▍    | 6/11 [00:29<00:20,  4.08s/it]processing embeddings:  64%|██████▎   | 7/11 [00:31<00:14,  3.56s/it]processing embeddings:  73%|███████▎  | 8/11 [00:34<00:09,  3.25s/it]processing embeddings:  82%|████████▏ | 9/11 [00:37<00:06,  3.06s/it]processing embeddings:  91%|█████████ | 10/11 [00:39<00:02,  2.93s/it]processing embeddings:  91%|█████████ | 10/11 [00:39<00:03,  3.97s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5840 到 5850
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:31,  3.13s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:26,  2.96s/it]processing embeddings:  27%|██▋       | 3/11 [00:08<00:23,  2.98s/it]processing embeddings:  36%|███▋      | 4/11 [00:12<00:22,  3.24s/it]processing embeddings:  45%|████▌     | 5/11 [00:15<00:18,  3.01s/it]processing embeddings:  55%|█████▍    | 6/11 [00:18<00:14,  2.98s/it]processing embeddings:  64%|██████▎   | 7/11 [00:20<00:11,  2.84s/it]processing embeddings:  73%|███████▎  | 8/11 [00:23<00:08,  2.77s/it]processing embeddings:  82%|████████▏ | 9/11 [00:25<00:05,  2.73s/it]processing embeddings:  91%|█████████ | 10/11 [00:28<00:02,  2.78s/it]processing embeddings:  91%|█████████ | 10/11 [00:28<00:02,  2.89s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5850 到 5860
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:03<00:36,  3.62s/it]processing embeddings:  18%|█▊        | 2/11 [00:07<00:34,  3.87s/it]processing embeddings:  27%|██▋       | 3/11 [00:11<00:31,  3.96s/it]processing embeddings:  36%|███▋      | 4/11 [00:16<00:31,  4.45s/it]processing embeddings:  45%|████▌     | 5/11 [00:20<00:25,  4.20s/it]processing embeddings:  55%|█████▍    | 6/11 [00:23<00:19,  3.85s/it]processing embeddings:  64%|██████▎   | 7/11 [00:26<00:13,  3.38s/it]processing embeddings:  73%|███████▎  | 8/11 [00:28<00:09,  3.13s/it]processing embeddings:  82%|████████▏ | 9/11 [00:31<00:05,  2.94s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:02,  2.81s/it]processing embeddings:  91%|█████████ | 10/11 [00:33<00:03,  3.39s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5860 到 5870
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:02<00:26,  2.61s/it]processing embeddings:  18%|█▊        | 2/11 [00:05<00:23,  2.60s/it]processing embeddings:  27%|██▋       | 3/11 [00:07<00:20,  2.59s/it]processing embeddings:  36%|███▋      | 4/11 [00:10<00:18,  2.63s/it]processing embeddings:  45%|████▌     | 5/11 [00:13<00:15,  2.60s/it]processing embeddings:  55%|█████▍    | 6/11 [00:15<00:12,  2.60s/it]processing embeddings:  64%|██████▎   | 7/11 [00:18<00:10,  2.60s/it]processing embeddings:  73%|███████▎  | 8/11 [00:20<00:07,  2.60s/it]processing embeddings:  82%|████████▏ | 9/11 [00:23<00:05,  2.59s/it]processing embeddings:  91%|█████████ | 10/11 [00:26<00:02,  2.67s/it]processing embeddings:  91%|█████████ | 10/11 [00:26<00:02,  2.63s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5870 到 5880
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:05<00:59,  5.96s/it]processing embeddings:  18%|█▊        | 2/11 [00:11<00:53,  5.93s/it]processing embeddings:  27%|██▋       | 3/11 [00:17<00:47,  5.98s/it]processing embeddings:  36%|███▋      | 4/11 [00:23<00:41,  5.93s/it]processing embeddings:  45%|████▌     | 5/11 [00:29<00:35,  6.00s/it]processing embeddings:  55%|█████▍    | 6/11 [00:35<00:30,  6.01s/it]processing embeddings:  64%|██████▎   | 7/11 [00:42<00:24,  6.05s/it]processing embeddings:  73%|███████▎  | 8/11 [00:48<00:18,  6.10s/it]processing embeddings:  82%|████████▏ | 9/11 [00:54<00:12,  6.06s/it]processing embeddings:  91%|█████████ | 10/11 [01:00<00:06,  6.13s/it]processing embeddings:  91%|█████████ | 10/11 [01:00<00:06,  6.05s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5880 到 5890
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:03,  6.37s/it]processing embeddings:  18%|█▊        | 2/11 [00:12<00:57,  6.35s/it]processing embeddings:  27%|██▋       | 3/11 [00:19<00:51,  6.42s/it]processing embeddings:  36%|███▋      | 4/11 [00:25<00:44,  6.38s/it]processing embeddings:  45%|████▌     | 5/11 [00:31<00:38,  6.36s/it]processing embeddings:  55%|█████▍    | 6/11 [00:38<00:31,  6.34s/it]processing embeddings:  64%|██████▎   | 7/11 [00:44<00:25,  6.30s/it]processing embeddings:  73%|███████▎  | 8/11 [00:50<00:19,  6.35s/it]processing embeddings:  82%|████████▏ | 9/11 [00:57<00:12,  6.35s/it]processing embeddings:  91%|█████████ | 10/11 [01:03<00:06,  6.41s/it]processing embeddings:  91%|█████████ | 10/11 [01:03<00:06,  6.37s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5890 到 5900
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:03,  6.36s/it]processing embeddings:  18%|█▊        | 2/11 [00:12<00:57,  6.44s/it]processing embeddings:  27%|██▋       | 3/11 [00:19<00:50,  6.31s/it]processing embeddings:  36%|███▋      | 4/11 [00:25<00:43,  6.22s/it]processing embeddings:  45%|████▌     | 5/11 [00:31<00:37,  6.19s/it]processing embeddings:  55%|█████▍    | 6/11 [00:37<00:30,  6.17s/it]processing embeddings:  64%|██████▎   | 7/11 [00:43<00:24,  6.15s/it]processing embeddings:  73%|███████▎  | 8/11 [00:49<00:18,  6.10s/it]processing embeddings:  82%|████████▏ | 9/11 [00:55<00:12,  6.19s/it]processing embeddings:  91%|█████████ | 10/11 [01:02<00:06,  6.23s/it]processing embeddings:  91%|█████████ | 10/11 [01:02<00:06,  6.22s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5900 到 5910
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:02,  6.24s/it]processing embeddings:  18%|█▊        | 2/11 [00:12<00:55,  6.22s/it]processing embeddings:  27%|██▋       | 3/11 [00:18<00:49,  6.23s/it]processing embeddings:  36%|███▋      | 4/11 [00:25<00:43,  6.29s/it]processing embeddings:  45%|████▌     | 5/11 [00:31<00:37,  6.27s/it]processing embeddings:  55%|█████▍    | 6/11 [00:37<00:31,  6.33s/it]processing embeddings:  64%|██████▎   | 7/11 [00:44<00:25,  6.45s/it]processing embeddings:  73%|███████▎  | 8/11 [00:50<00:19,  6.34s/it]processing embeddings:  82%|████████▏ | 9/11 [00:56<00:12,  6.23s/it]processing embeddings:  91%|█████████ | 10/11 [01:03<00:06,  6.40s/it]processing embeddings:  91%|█████████ | 10/11 [01:03<00:06,  6.33s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5910 到 5920
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:02,  6.29s/it]processing embeddings:  18%|█▊        | 2/11 [00:12<00:56,  6.22s/it]processing embeddings:  27%|██▋       | 3/11 [00:18<00:49,  6.17s/it]processing embeddings:  36%|███▋      | 4/11 [00:24<00:43,  6.16s/it]processing embeddings:  45%|████▌     | 5/11 [00:30<00:36,  6.16s/it]processing embeddings:  55%|█████▍    | 6/11 [00:36<00:30,  6.14s/it]processing embeddings:  64%|██████▎   | 7/11 [00:43<00:25,  6.26s/it]processing embeddings:  73%|███████▎  | 8/11 [00:49<00:18,  6.27s/it]processing embeddings:  82%|████████▏ | 9/11 [00:56<00:12,  6.40s/it]processing embeddings:  91%|█████████ | 10/11 [01:02<00:06,  6.40s/it]processing embeddings:  91%|█████████ | 10/11 [01:02<00:06,  6.29s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5920 到 5930
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:04,  6.48s/it]processing embeddings:  18%|█▊        | 2/11 [00:13<00:59,  6.58s/it]processing embeddings:  27%|██▋       | 3/11 [00:19<00:52,  6.60s/it]processing embeddings:  36%|███▋      | 4/11 [00:26<00:46,  6.59s/it]processing embeddings:  45%|████▌     | 5/11 [00:32<00:39,  6.55s/it]processing embeddings:  55%|█████▍    | 6/11 [00:39<00:32,  6.52s/it]processing embeddings:  64%|██████▎   | 7/11 [00:45<00:26,  6.51s/it]processing embeddings:  73%|███████▎  | 8/11 [00:52<00:19,  6.60s/it]processing embeddings:  82%|████████▏ | 9/11 [00:59<00:13,  6.56s/it]processing embeddings:  91%|█████████ | 10/11 [01:05<00:06,  6.50s/it]processing embeddings:  91%|█████████ | 10/11 [01:05<00:06,  6.54s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5930 到 5940
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:06,  6.69s/it]processing embeddings:  18%|█▊        | 2/11 [00:13<00:59,  6.62s/it]processing embeddings:  27%|██▋       | 3/11 [00:19<00:53,  6.67s/it]processing embeddings:  36%|███▋      | 4/11 [00:26<00:45,  6.55s/it]processing embeddings:  45%|████▌     | 5/11 [00:32<00:39,  6.54s/it]processing embeddings:  55%|█████▍    | 6/11 [00:39<00:32,  6.53s/it]processing embeddings:  64%|██████▎   | 7/11 [00:45<00:25,  6.46s/it]processing embeddings:  73%|███████▎  | 8/11 [00:51<00:19,  6.38s/it]processing embeddings:  82%|████████▏ | 9/11 [00:58<00:12,  6.46s/it]processing embeddings:  91%|█████████ | 10/11 [01:04<00:06,  6.41s/it]processing embeddings:  91%|█████████ | 10/11 [01:04<00:06,  6.49s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5940 到 5950
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:06<01:07,  6.77s/it]processing embeddings:  18%|█▊        | 2/11 [00:13<00:59,  6.65s/it]processing embeddings:  27%|██▋       | 3/11 [00:20<00:53,  6.66s/it]processing embeddings:  36%|███▋      | 4/11 [00:26<00:45,  6.55s/it]processing embeddings:  45%|████▌     | 5/11 [00:33<00:39,  6.59s/it]processing embeddings:  55%|█████▍    | 6/11 [00:39<00:32,  6.57s/it]processing embeddings:  64%|██████▎   | 7/11 [00:46<00:26,  6.58s/it]processing embeddings:  73%|███████▎  | 8/11 [00:53<00:20,  6.71s/it]processing embeddings:  82%|████████▏ | 9/11 [01:00<00:13,  6.94s/it]processing embeddings:  91%|█████████ | 10/11 [01:08<00:07,  7.38s/it]processing embeddings:  91%|█████████ | 10/11 [01:08<00:06,  6.90s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5950 到 5960
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:08<01:23,  8.34s/it]processing embeddings:  18%|█▊        | 2/11 [00:16<01:13,  8.17s/it]processing embeddings:  27%|██▋       | 3/11 [00:24<01:05,  8.25s/it]processing embeddings:  36%|███▋      | 4/11 [00:32<00:57,  8.23s/it]processing embeddings:  45%|████▌     | 5/11 [00:41<00:50,  8.34s/it]processing embeddings:  55%|█████▍    | 6/11 [00:48<00:40,  8.04s/it]processing embeddings:  64%|██████▎   | 7/11 [00:56<00:31,  7.80s/it]processing embeddings:  73%|███████▎  | 8/11 [01:03<00:23,  7.73s/it]processing embeddings:  82%|████████▏ | 9/11 [01:11<00:15,  7.83s/it]processing embeddings:  91%|█████████ | 10/11 [01:19<00:07,  7.82s/it]processing embeddings:  91%|█████████ | 10/11 [01:19<00:07,  7.97s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5960 到 5970
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:15,  7.53s/it]processing embeddings:  18%|█▊        | 2/11 [00:15<01:08,  7.56s/it]processing embeddings:  27%|██▋       | 3/11 [00:22<01:01,  7.67s/it]processing embeddings:  36%|███▋      | 4/11 [00:30<00:53,  7.63s/it]processing embeddings:  45%|████▌     | 5/11 [00:37<00:44,  7.45s/it]processing embeddings:  55%|█████▍    | 6/11 [00:44<00:36,  7.39s/it]processing embeddings:  64%|██████▎   | 7/11 [00:53<00:30,  7.71s/it]processing embeddings:  73%|███████▎  | 8/11 [01:05<00:26,  9.00s/it]processing embeddings:  82%|████████▏ | 9/11 [01:16<00:19,  9.66s/it]processing embeddings:  91%|█████████ | 10/11 [01:27<00:10, 10.06s/it]processing embeddings:  91%|█████████ | 10/11 [01:27<00:08,  8.71s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5970 到 5980
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:10<01:47, 10.72s/it]processing embeddings:  18%|█▊        | 2/11 [00:21<01:37, 10.81s/it]processing embeddings:  27%|██▋       | 3/11 [00:33<01:29, 11.21s/it]processing embeddings:  36%|███▋      | 4/11 [00:44<01:17, 11.04s/it]processing embeddings:  45%|████▌     | 5/11 [00:53<01:03, 10.56s/it]processing embeddings:  55%|█████▍    | 6/11 [01:01<00:48,  9.66s/it]processing embeddings:  64%|██████▎   | 7/11 [01:06<00:32,  8.21s/it]processing embeddings:  73%|███████▎  | 8/11 [01:12<00:22,  7.42s/it]processing embeddings:  82%|████████▏ | 9/11 [01:18<00:13,  6.96s/it]processing embeddings:  91%|█████████ | 10/11 [01:24<00:06,  6.74s/it]processing embeddings:  91%|█████████ | 10/11 [01:24<00:08,  8.49s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5980 到 5990
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:05<00:51,  5.18s/it]processing embeddings:  18%|█▊        | 2/11 [00:10<00:44,  5.00s/it]processing embeddings:  27%|██▋       | 3/11 [00:15<00:39,  4.98s/it]processing embeddings:  36%|███▋      | 4/11 [00:19<00:34,  4.92s/it]processing embeddings:  45%|████▌     | 5/11 [00:24<00:29,  4.88s/it]processing embeddings:  55%|█████▍    | 6/11 [00:29<00:24,  4.91s/it]processing embeddings:  64%|██████▎   | 7/11 [00:34<00:19,  4.95s/it]processing embeddings:  73%|███████▎  | 8/11 [00:39<00:14,  4.93s/it]processing embeddings:  82%|████████▏ | 9/11 [00:44<00:09,  4.96s/it]processing embeddings:  91%|█████████ | 10/11 [00:49<00:05,  5.03s/it]processing embeddings:  91%|█████████ | 10/11 [00:49<00:04,  4.98s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 5990 到 6000
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:05<00:52,  5.23s/it]processing embeddings:  18%|█▊        | 2/11 [00:10<00:46,  5.13s/it]processing embeddings:  27%|██▋       | 3/11 [00:15<00:40,  5.09s/it]processing embeddings:  36%|███▋      | 4/11 [00:20<00:36,  5.20s/it]processing embeddings:  45%|████▌     | 5/11 [00:27<00:33,  5.62s/it]processing embeddings:  55%|█████▍    | 6/11 [00:33<00:29,  5.84s/it]processing embeddings:  64%|██████▎   | 7/11 [00:40<00:25,  6.27s/it]processing embeddings:  73%|███████▎  | 8/11 [00:47<00:19,  6.65s/it]processing embeddings:  82%|████████▏ | 9/11 [00:55<00:13,  6.91s/it]processing embeddings:  91%|█████████ | 10/11 [01:02<00:07,  7.06s/it]processing embeddings:  91%|█████████ | 10/11 [01:02<00:06,  6.28s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 6000 到 6010
processing embeddings:   0%|          | 0/11 [00:00<?, ?it/s]processing embeddings:   9%|▉         | 1/11 [00:07<01:19,  8.00s/it]processing embeddings:  18%|█▊        | 2/11 [00:16<01:13,  8.12s/it]processing embeddings:  27%|██▋       | 3/11 [00:24<01:05,  8.21s/it]processing embeddings:  36%|███▋      | 4/11 [00:30<00:50,  7.14s/it]processing embeddings:  45%|████▌     | 5/11 [00:34<00:36,  6.10s/it]processing embeddings:  55%|█████▍    | 6/11 [00:38<00:27,  5.45s/it]processing embeddings:  64%|██████▎   | 7/11 [00:42<00:20,  5.04s/it]processing embeddings:  73%|███████▎  | 8/11 [00:47<00:14,  4.88s/it]processing embeddings:  82%|████████▏ | 9/11 [00:54<00:11,  5.55s/it]processing embeddings:  91%|█████████ | 10/11 [01:01<00:06,  6.08s/it]processing embeddings:  91%|█████████ | 10/11 [01:01<00:06,  6.15s/it]
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
flash_attn is not installed. Using PyTorch native attention implementation.
处理嵌入批次 6010 到 6015
processing embeddings:   0%|          | 0/6 [00:00<?, ?it/s]processing embeddings:  17%|█▋        | 1/6 [00:07<00:36,  7.36s/it]processing embeddings:  33%|███▎      | 2/6 [00:15<00:30,  7.54s/it]processing embeddings:  50%|█████     | 3/6 [00:22<00:22,  7.45s/it]processing embeddings:  67%|██████▋   | 4/6 [00:29<00:14,  7.42s/it]processing embeddings:  83%|████████▎ | 5/6 [00:37<00:07,  7.37s/it]processing embeddings: 100%|██████████| 6/6 [00:42<00:00,  6.70s/it]processing embeddings: 100%|██████████| 6/6 [00:42<00:00,  7.07s/it]
合并所有批次的嵌入...
合并嵌入:   0%|          | 0/602 [00:00<?, ?it/s]合并嵌入:   1%|          | 4/602 [00:00<00:15, 39.54it/s]合并嵌入:   1%|▏         | 8/602 [00:00<00:57, 10.29it/s]合并嵌入:   2%|▏         | 11/602 [00:01<01:23,  7.07it/s]合并嵌入:   2%|▏         | 13/602 [00:01<01:18,  7.54it/s]合并嵌入:   2%|▏         | 15/602 [00:02<01:34,  6.20it/s]合并嵌入:   3%|▎         | 17/602 [00:08<10:30,  1.08s/it]合并嵌入:   3%|▎         | 18/602 [00:10<10:51,  1.11s/it]合并嵌入:   3%|▎         | 19/602 [00:10<09:07,  1.07it/s]合并嵌入:   3%|▎         | 21/602 [00:10<06:37,  1.46it/s]合并嵌入:   4%|▍         | 24/602 [00:10<03:55,  2.45it/s]合并嵌入:   4%|▍         | 27/602 [00:11<02:33,  3.73it/s]合并嵌入:   5%|▍         | 30/602 [00:11<01:48,  5.25it/s]合并嵌入:   5%|▌         | 33/602 [00:11<01:21,  6.97it/s]合并嵌入:   6%|▌         | 35/602 [00:11<01:09,  8.15it/s]合并嵌入:   6%|▌         | 37/602 [00:11<01:00,  9.33it/s]合并嵌入:   6%|▋         | 39/602 [00:11<00:52, 10.67it/s]合并嵌入:   7%|▋         | 42/602 [00:11<00:42, 13.26it/s]合并嵌入:   7%|▋         | 44/602 [00:11<00:38, 14.52it/s]合并嵌入:   8%|▊         | 46/602 [00:12<00:36, 15.39it/s]合并嵌入:   8%|▊         | 49/602 [00:12<00:55, 10.04it/s]合并嵌入:   9%|▊         | 52/602 [00:12<00:44, 12.35it/s]合并嵌入:   9%|▉         | 55/602 [00:12<00:37, 14.71it/s]合并嵌入:  10%|▉         | 58/602 [00:12<00:33, 16.17it/s]合并嵌入:  10%|▉         | 60/602 [00:13<00:37, 14.65it/s]合并嵌入:  10%|█         | 62/602 [00:13<00:35, 15.38it/s]合并嵌入:  11%|█         | 64/602 [00:14<01:24,  6.33it/s]合并嵌入:  11%|█         | 66/602 [00:20<08:33,  1.04it/s]合并嵌入:  11%|█         | 67/602 [00:20<07:32,  1.18it/s]合并嵌入:  11%|█▏        | 69/602 [00:20<05:18,  1.67it/s]合并嵌入:  12%|█▏        | 72/602 [00:28<12:36,  1.43s/it]合并嵌入:  12%|█▏        | 73/602 [00:30<13:23,  1.52s/it]合并嵌入:  12%|█▏        | 74/602 [00:36<20:12,  2.30s/it]合并嵌入:  13%|█▎        | 76/602 [00:42<22:02,  2.51s/it]合并嵌入:  13%|█▎        | 77/602 [00:47<26:46,  3.06s/it]合并嵌入:  13%|█▎        | 78/602 [00:47<21:18,  2.44s/it]合并嵌入:  13%|█▎        | 79/602 [00:48<17:39,  2.03s/it]合并嵌入:  13%|█▎        | 80/602 [00:50<17:43,  2.04s/it]合并嵌入:  13%|█▎        | 81/602 [00:50<14:17,  1.65s/it]合并嵌入:  14%|█▎        | 82/602 [00:51<12:04,  1.39s/it]合并嵌入:  14%|█▍        | 83/602 [00:57<24:03,  2.78s/it]合并嵌入:  14%|█▍        | 85/602 [00:59<15:55,  1.85s/it]合并嵌入:  14%|█▍        | 86/602 [00:59<13:22,  1.55s/it]合并嵌入:  14%|█▍        | 87/602 [01:02<14:59,  1.75s/it]合并嵌入:  15%|█▍        | 88/602 [01:03<14:05,  1.64s/it]合并嵌入:  15%|█▍        | 89/602 [01:04<11:46,  1.38s/it]合并嵌入:  15%|█▍        | 90/602 [01:06<12:34,  1.47s/it]合并嵌入:  15%|█▌        | 92/602 [01:11<17:19,  2.04s/it]合并嵌入:  15%|█▌        | 93/602 [01:16<24:00,  2.83s/it]合并嵌入:  16%|█▌        | 94/602 [01:17<18:47,  2.22s/it]合并嵌入:  16%|█▌        | 95/602 [01:23<27:19,  3.23s/it]合并嵌入:  16%|█▌        | 96/602 [01:24<23:08,  2.74s/it]合并嵌入:  16%|█▌        | 97/602 [01:29<28:42,  3.41s/it]合并嵌入:  16%|█▋        | 98/602 [01:30<20:53,  2.49s/it]合并嵌入:  17%|█▋        | 101/602 [01:30<09:26,  1.13s/it]合并嵌入:  17%|█▋        | 102/602 [01:31<10:21,  1.24s/it]合并嵌入:  17%|█▋        | 103/602 [01:38<20:48,  2.50s/it]合并嵌入:  17%|█▋        | 104/602 [01:38<16:26,  1.98s/it]合并嵌入:  17%|█▋        | 105/602 [01:39<12:32,  1.51s/it]合并嵌入:  18%|█▊        | 108/602 [01:39<06:02,  1.36it/s]合并嵌入:  18%|█▊        | 110/602 [01:39<04:21,  1.88it/s]合并嵌入:  19%|█▊        | 112/602 [01:48<14:40,  1.80s/it]合并嵌入:  19%|█▉        | 113/602 [01:53<19:54,  2.44s/it]合并嵌入:  19%|█▉        | 116/602 [01:53<11:06,  1.37s/it]合并嵌入:  20%|█▉        | 118/602 [01:56<11:34,  1.43s/it]合并嵌入:  20%|█▉        | 119/602 [02:02<17:44,  2.20s/it]合并嵌入:  20%|█▉        | 120/602 [02:02<14:31,  1.81s/it]合并嵌入:  20%|██        | 122/602 [02:03<09:43,  1.22s/it]合并嵌入:  21%|██        | 124/602 [02:03<06:32,  1.22it/s]合并嵌入:  21%|██        | 127/602 [02:03<03:52,  2.05it/s]合并嵌入:  21%|██▏       | 129/602 [02:12<12:31,  1.59s/it]合并嵌入:  22%|██▏       | 131/602 [02:17<14:35,  1.86s/it]合并嵌入:  22%|██▏       | 134/602 [02:17<09:03,  1.16s/it]合并嵌入:  23%|██▎       | 136/602 [02:26<15:52,  2.04s/it]合并嵌入:  23%|██▎       | 137/602 [02:26<13:34,  1.75s/it]合并嵌入:  23%|██▎       | 139/602 [02:26<09:24,  1.22s/it]合并嵌入:  23%|██▎       | 141/602 [02:34<16:06,  2.10s/it]合并嵌入:  24%|██▎       | 142/602 [02:34<13:23,  1.75s/it]合并嵌入:  24%|██▍       | 143/602 [02:43<23:39,  3.09s/it]合并嵌入:  24%|██▍       | 144/602 [02:43<19:30,  2.55s/it]合并嵌入:  24%|██▍       | 145/602 [02:48<23:55,  3.14s/it]合并嵌入:  25%|██▍       | 148/602 [02:48<11:45,  1.55s/it]合并嵌入:  25%|██▌       | 151/602 [02:52<10:08,  1.35s/it]合并嵌入:  25%|██▌       | 152/602 [02:57<15:18,  2.04s/it]合并嵌入:  25%|██▌       | 153/602 [02:57<12:35,  1.68s/it]合并嵌入:  26%|██▌       | 155/602 [03:06<19:17,  2.59s/it]合并嵌入:  26%|██▌       | 156/602 [03:07<16:48,  2.26s/it]合并嵌入:  26%|██▌       | 157/602 [03:12<22:07,  2.98s/it]合并嵌入:  26%|██▌       | 158/602 [03:13<18:17,  2.47s/it]合并嵌入:  26%|██▋       | 159/602 [03:17<20:12,  2.74s/it]合并嵌入:  27%|██▋       | 160/602 [03:23<26:42,  3.62s/it]合并嵌入:  27%|██▋       | 161/602 [03:23<19:33,  2.66s/it]合并嵌入:  27%|██▋       | 164/602 [03:23<09:03,  1.24s/it]合并嵌入:  28%|██▊       | 166/602 [03:23<06:05,  1.19it/s]合并嵌入:  28%|██▊       | 168/602 [03:32<14:06,  1.95s/it]合并嵌入:  28%|██▊       | 169/602 [03:32<12:08,  1.68s/it]合并嵌入:  28%|██▊       | 170/602 [03:36<15:48,  2.20s/it]合并嵌入:  28%|██▊       | 171/602 [03:38<15:51,  2.21s/it]合并嵌入:  29%|██▊       | 172/602 [03:42<17:43,  2.47s/it]合并嵌入:  29%|██▉       | 175/602 [03:42<08:40,  1.22s/it]合并嵌入:  29%|██▉       | 176/602 [03:42<07:05,  1.00it/s]合并嵌入:  30%|██▉       | 178/602 [03:42<04:43,  1.50it/s]合并嵌入:  30%|██▉       | 180/602 [03:42<03:14,  2.17it/s]合并嵌入:  30%|███       | 183/602 [03:42<02:00,  3.49it/s]合并嵌入:  31%|███       | 186/602 [03:42<01:22,  5.07it/s]合并嵌入:  31%|███       | 188/602 [03:43<01:06,  6.22it/s]合并嵌入:  32%|███▏      | 190/602 [03:43<00:55,  7.48it/s]合并嵌入:  32%|███▏      | 192/602 [03:43<00:46,  8.78it/s]合并嵌入:  32%|███▏      | 194/602 [03:43<00:40, 10.05it/s]合并嵌入:  33%|███▎      | 197/602 [03:43<00:31, 12.67it/s]合并嵌入:  33%|███▎      | 199/602 [03:43<00:29, 13.87it/s]合并嵌入:  33%|███▎      | 201/602 [03:43<00:26, 15.01it/s]合并嵌入:  34%|███▎      | 203/602 [03:43<00:25, 15.41it/s]合并嵌入:  34%|███▍      | 205/602 [03:44<00:52,  7.53it/s]合并嵌入:  34%|███▍      | 207/602 [03:44<00:44,  8.82it/s]合并嵌入:  35%|███▍      | 209/602 [03:44<00:38, 10.16it/s]合并嵌入:  35%|███▌      | 211/602 [03:45<01:20,  4.84it/s]合并嵌入:  35%|███▌      | 213/602 [03:50<05:28,  1.18it/s]合并嵌入:  36%|███▌      | 215/602 [03:50<03:59,  1.61it/s]合并嵌入:  36%|███▌      | 217/602 [03:50<02:59,  2.15it/s]合并嵌入:  36%|███▌      | 218/602 [03:50<02:36,  2.46it/s]合并嵌入:  36%|███▋      | 219/602 [03:51<03:01,  2.11it/s]合并嵌入:  37%|███▋      | 222/602 [03:51<01:44,  3.63it/s]合并嵌入:  37%|███▋      | 224/602 [03:51<01:18,  4.84it/s]合并嵌入:  38%|███▊      | 227/602 [03:52<00:54,  6.94it/s]合并嵌入:  38%|███▊      | 229/602 [03:54<02:39,  2.34it/s]合并嵌入:  38%|███▊      | 231/602 [03:56<04:01,  1.54it/s]合并嵌入:  39%|███▉      | 234/602 [03:57<02:35,  2.37it/s]合并嵌入:  39%|███▉      | 236/602 [04:00<05:03,  1.20it/s]合并嵌入:  39%|███▉      | 237/602 [04:01<04:48,  1.26it/s]合并嵌入:  40%|███▉      | 238/602 [04:03<05:51,  1.03it/s]合并嵌入:  40%|███▉      | 239/602 [04:03<05:31,  1.09it/s]合并嵌入:  40%|███▉      | 240/602 [04:08<10:54,  1.81s/it]合并嵌入:  41%|████      | 247/602 [04:11<04:57,  1.19it/s]合并嵌入:  41%|████      | 248/602 [04:12<05:09,  1.15it/s]合并嵌入:  41%|████▏     | 249/602 [04:13<04:37,  1.27it/s]合并嵌入:  42%|████▏     | 252/602 [04:13<02:53,  2.02it/s]合并嵌入:  42%|████▏     | 254/602 [04:13<02:10,  2.66it/s]合并嵌入:  43%|████▎     | 256/602 [04:18<05:22,  1.07it/s]合并嵌入:  43%|████▎     | 257/602 [04:20<06:40,  1.16s/it]合并嵌入:  43%|████▎     | 259/602 [04:20<04:36,  1.24it/s]合并嵌入:  44%|████▎     | 262/602 [04:20<02:48,  2.02it/s]合并嵌入:  44%|████▍     | 265/602 [04:20<01:51,  3.02it/s]合并嵌入:  44%|████▍     | 267/602 [04:25<05:04,  1.10it/s]合并嵌入:  45%|████▍     | 269/602 [04:31<07:37,  1.37s/it]合并嵌入:  45%|████▌     | 272/602 [04:31<04:52,  1.13it/s]合并嵌入:  46%|████▌     | 275/602 [04:31<03:15,  1.67it/s]合并嵌入:  46%|████▌     | 277/602 [04:35<04:50,  1.12it/s]合并嵌入:  46%|████▋     | 279/602 [04:36<04:30,  1.19it/s]合并嵌入:  47%|████▋     | 281/602 [04:36<03:20,  1.60it/s]合并嵌入:  47%|████▋     | 283/602 [04:36<02:29,  2.13it/s]合并嵌入:  48%|████▊     | 286/602 [04:36<01:37,  3.24it/s]合并嵌入:  48%|████▊     | 288/602 [04:43<05:50,  1.12s/it]合并嵌入:  48%|████▊     | 290/602 [04:48<07:30,  1.44s/it]合并嵌入:  48%|████▊     | 291/602 [04:50<08:37,  1.66s/it]合并嵌入:  49%|████▉     | 294/602 [04:51<05:08,  1.00s/it]合并嵌入:  49%|████▉     | 296/602 [04:53<05:09,  1.01s/it]合并嵌入:  50%|████▉     | 298/602 [04:58<07:15,  1.43s/it]合并嵌入:  50%|████▉     | 299/602 [05:01<08:49,  1.75s/it]合并嵌入:  50%|████▉     | 300/602 [05:06<12:22,  2.46s/it]合并嵌入:  50%|█████     | 301/602 [05:06<09:46,  1.95s/it]合并嵌入:  50%|█████     | 304/602 [05:07<05:05,  1.03s/it]合并嵌入:  51%|█████     | 306/602 [05:07<04:01,  1.23it/s]合并嵌入:  51%|█████     | 307/602 [05:10<05:44,  1.17s/it]合并嵌入:  51%|█████▏    | 310/602 [05:11<03:35,  1.35it/s]合并嵌入:  52%|█████▏    | 311/602 [05:12<03:49,  1.27it/s]合并嵌入:  52%|█████▏    | 314/602 [05:12<02:15,  2.13it/s]合并嵌入:  52%|█████▏    | 316/602 [05:15<03:37,  1.32it/s]合并嵌入:  53%|█████▎    | 317/602 [05:15<03:11,  1.49it/s]合并嵌入:  53%|█████▎    | 318/602 [05:15<02:47,  1.69it/s]合并嵌入:  53%|█████▎    | 319/602 [05:17<03:36,  1.31it/s]合并嵌入:  53%|█████▎    | 320/602 [05:19<05:29,  1.17s/it]合并嵌入:  53%|█████▎    | 321/602 [05:20<05:47,  1.24s/it]合并嵌入:  53%|█████▎    | 322/602 [05:23<07:38,  1.64s/it]合并嵌入:  54%|█████▎    | 323/602 [05:24<06:57,  1.50s/it]合并嵌入:  54%|█████▍    | 324/602 [05:27<08:28,  1.83s/it]合并嵌入:  54%|█████▍    | 326/602 [05:27<04:48,  1.04s/it]合并嵌入:  54%|█████▍    | 327/602 [05:31<07:20,  1.60s/it]合并嵌入:  54%|█████▍    | 328/602 [05:34<09:30,  2.08s/it]合并嵌入:  55%|█████▍    | 329/602 [05:36<09:43,  2.14s/it]合并嵌入:  55%|█████▍    | 330/602 [05:38<08:32,  1.89s/it]合并嵌入:  55%|█████▍    | 331/602 [05:38<06:15,  1.39s/it]合并嵌入:  55%|█████▌    | 333/602 [05:38<03:32,  1.27it/s]合并嵌入:  56%|█████▌    | 335/602 [05:40<03:54,  1.14it/s]合并嵌入:  56%|█████▌    | 338/602 [05:40<02:27,  1.79it/s]合并嵌入:  56%|█████▋    | 340/602 [05:40<01:46,  2.47it/s]合并嵌入:  57%|█████▋    | 341/602 [05:41<01:44,  2.50it/s]合并嵌入:  57%|█████▋    | 342/602 [05:41<01:44,  2.48it/s]合并嵌入:  57%|█████▋    | 345/602 [05:43<02:13,  1.93it/s]合并嵌入:  57%|█████▋    | 346/602 [05:44<02:17,  1.87it/s]合并嵌入:  58%|█████▊    | 347/602 [05:46<03:23,  1.26it/s]合并嵌入:  58%|█████▊    | 349/602 [05:47<03:01,  1.40it/s]合并嵌入:  58%|█████▊    | 350/602 [05:51<05:57,  1.42s/it]合并嵌入:  58%|█████▊    | 351/602 [05:53<06:42,  1.61s/it]合并嵌入:  58%|█████▊    | 352/602 [05:54<05:57,  1.43s/it]合并嵌入:  59%|█████▊    | 353/602 [05:57<07:42,  1.86s/it]合并嵌入:  59%|█████▉    | 354/602 [06:00<08:26,  2.04s/it]合并嵌入:  59%|█████▉    | 355/602 [06:01<07:17,  1.77s/it]合并嵌入:  59%|█████▉    | 356/602 [06:05<10:00,  2.44s/it]合并嵌入:  59%|█████▉    | 357/602 [06:06<09:07,  2.23s/it]合并嵌入:  59%|█████▉    | 358/602 [06:08<07:45,  1.91s/it]合并嵌入:  60%|█████▉    | 359/602 [06:09<06:43,  1.66s/it]合并嵌入:  60%|█████▉    | 360/602 [06:16<13:22,  3.31s/it]合并嵌入:  60%|██████    | 362/602 [06:18<09:31,  2.38s/it]合并嵌入:  60%|██████    | 364/602 [06:21<07:40,  1.94s/it]合并嵌入:  61%|██████    | 365/602 [06:31<14:20,  3.63s/it]合并嵌入:  61%|██████    | 366/602 [06:31<11:05,  2.82s/it]合并嵌入:  61%|██████    | 367/602 [06:32<09:16,  2.37s/it]合并嵌入:  61%|██████    | 368/602 [06:32<07:08,  1.83s/it]合并嵌入:  61%|██████▏   | 370/602 [06:32<04:10,  1.08s/it]合并嵌入:  62%|██████▏   | 371/602 [06:33<03:19,  1.16it/s]合并嵌入:  62%|██████▏   | 372/602 [06:33<02:41,  1.43it/s]合并嵌入:  62%|██████▏   | 373/602 [06:33<02:26,  1.56it/s]合并嵌入:  62%|██████▏   | 375/602 [06:39<06:04,  1.61s/it]合并嵌入:  63%|██████▎   | 377/602 [06:42<05:35,  1.49s/it]合并嵌入:  63%|██████▎   | 378/602 [06:47<08:56,  2.39s/it]合并嵌入:  63%|██████▎   | 379/602 [06:50<09:09,  2.47s/it]合并嵌入:  63%|██████▎   | 380/602 [06:51<07:22,  1.99s/it]合并嵌入:  63%|██████▎   | 381/602 [06:58<13:01,  3.54s/it]合并嵌入:  63%|██████▎   | 382/602 [06:59<10:16,  2.80s/it]合并嵌入:  64%|██████▎   | 383/602 [06:59<07:28,  2.05s/it]合并嵌入:  64%|██████▍   | 385/602 [07:06<09:40,  2.67s/it]合并嵌入:  64%|██████▍   | 387/602 [07:08<06:52,  1.92s/it]合并嵌入:  64%|██████▍   | 388/602 [07:09<06:20,  1.78s/it]合并嵌入:  65%|██████▍   | 390/602 [07:09<03:57,  1.12s/it]合并嵌入:  65%|██████▍   | 391/602 [07:09<03:09,  1.11it/s]合并嵌入:  65%|██████▌   | 392/602 [07:09<02:29,  1.40it/s]合并嵌入:  65%|██████▌   | 394/602 [07:11<02:38,  1.32it/s]合并嵌入:  66%|██████▌   | 395/602 [07:12<02:54,  1.19it/s]合并嵌入:  66%|██████▌   | 396/602 [07:19<07:39,  2.23s/it]合并嵌入:  66%|██████▌   | 397/602 [07:20<06:36,  1.93s/it]合并嵌入:  66%|██████▌   | 398/602 [07:28<11:51,  3.49s/it]合并嵌入:  66%|██████▋   | 399/602 [07:28<09:04,  2.68s/it]合并嵌入:  67%|██████▋   | 402/602 [07:29<04:47,  1.44s/it]合并嵌入:  67%|██████▋   | 403/602 [07:31<04:35,  1.38s/it]合并嵌入:  67%|██████▋   | 404/602 [07:32<04:36,  1.39s/it]合并嵌入:  67%|██████▋   | 405/602 [07:39<09:04,  2.76s/it]合并嵌入:  67%|██████▋   | 406/602 [07:42<09:07,  2.80s/it]合并嵌入:  68%|██████▊   | 407/602 [07:43<07:31,  2.32s/it]合并嵌入:  68%|██████▊   | 408/602 [07:43<05:58,  1.85s/it]合并嵌入:  68%|██████▊   | 409/602 [07:46<06:42,  2.08s/it]合并嵌入:  68%|██████▊   | 410/602 [07:46<04:50,  1.52s/it]合并嵌入:  68%|██████▊   | 411/602 [07:46<03:31,  1.11s/it]合并嵌入:  68%|██████▊   | 412/602 [07:47<02:41,  1.18it/s]合并嵌入:  69%|██████▊   | 413/602 [07:54<08:41,  2.76s/it]合并嵌入:  69%|██████▉   | 414/602 [07:59<10:57,  3.50s/it]合并嵌入:  69%|██████▉   | 415/602 [08:02<09:56,  3.19s/it]合并嵌入:  69%|██████▉   | 416/602 [08:03<08:37,  2.78s/it]合并嵌入:  70%|██████▉   | 419/602 [08:05<04:44,  1.56s/it]合并嵌入:  70%|██████▉   | 421/602 [08:05<03:07,  1.04s/it]合并嵌入:  70%|███████   | 423/602 [08:14<06:21,  2.13s/it]合并嵌入:  70%|███████   | 424/602 [08:15<05:40,  1.91s/it]合并嵌入:  71%|███████   | 425/602 [08:17<05:23,  1.83s/it]合并嵌入:  71%|███████   | 428/602 [08:17<02:49,  1.03it/s]合并嵌入:  71%|███████▏  | 429/602 [08:18<02:56,  1.02s/it]合并嵌入:  71%|███████▏  | 430/602 [08:24<05:58,  2.09s/it]合并嵌入:  72%|███████▏  | 432/602 [08:26<04:39,  1.64s/it]合并嵌入:  72%|███████▏  | 433/602 [08:28<05:11,  1.85s/it]合并嵌入:  72%|███████▏  | 434/602 [08:33<07:08,  2.55s/it]合并嵌入:  72%|███████▏  | 435/602 [08:37<07:47,  2.80s/it]合并嵌入:  72%|███████▏  | 436/602 [08:39<07:01,  2.54s/it]合并嵌入:  73%|███████▎  | 437/602 [08:39<05:11,  1.89s/it]合并嵌入:  73%|███████▎  | 439/602 [08:48<08:36,  3.17s/it]合并嵌入:  73%|███████▎  | 440/602 [08:49<06:50,  2.53s/it]合并嵌入:  73%|███████▎  | 441/602 [08:54<08:19,  3.10s/it]合并嵌入:  73%|███████▎  | 442/602 [08:54<06:10,  2.31s/it]合并嵌入:  74%|███████▍  | 445/602 [08:54<02:53,  1.10s/it]合并嵌入:  74%|███████▍  | 448/602 [08:56<02:17,  1.12it/s]合并嵌入:  75%|███████▍  | 450/602 [08:56<01:47,  1.41it/s]合并嵌入:  75%|███████▍  | 451/602 [08:59<02:49,  1.12s/it]合并嵌入:  75%|███████▌  | 452/602 [09:06<05:24,  2.16s/it]合并嵌入:  75%|███████▌  | 453/602 [09:06<04:15,  1.72s/it]合并嵌入:  76%|███████▌  | 455/602 [09:15<06:41,  2.73s/it]合并嵌入:  76%|███████▌  | 456/602 [09:15<05:36,  2.30s/it]合并嵌入:  76%|███████▌  | 457/602 [09:21<07:21,  3.04s/it]合并嵌入:  76%|███████▌  | 459/602 [09:24<05:43,  2.40s/it]合并嵌入:  76%|███████▋  | 460/602 [09:29<07:09,  3.02s/it]合并嵌入:  77%|███████▋  | 461/602 [09:30<05:54,  2.51s/it]合并嵌入:  77%|███████▋  | 462/602 [09:35<07:22,  3.16s/it]合并嵌入:  77%|███████▋  | 463/602 [09:35<05:28,  2.36s/it]合并嵌入:  77%|███████▋  | 464/602 [09:40<07:11,  3.13s/it]合并嵌入:  77%|███████▋  | 465/602 [09:40<05:16,  2.31s/it]合并嵌入:  77%|███████▋  | 466/602 [09:46<07:09,  3.15s/it]合并嵌入:  78%|███████▊  | 467/602 [09:51<08:36,  3.83s/it]合并嵌入:  78%|███████▊  | 469/602 [09:56<07:14,  3.27s/it]合并嵌入:  78%|███████▊  | 470/602 [09:56<05:30,  2.50s/it]合并嵌入:  78%|███████▊  | 471/602 [10:02<07:08,  3.27s/it]合并嵌入:  78%|███████▊  | 472/602 [10:07<08:20,  3.85s/it]合并嵌入:  79%|███████▊  | 473/602 [10:08<06:11,  2.88s/it]合并嵌入:  79%|███████▊  | 474/602 [10:13<07:21,  3.45s/it]合并嵌入:  79%|███████▉  | 475/602 [10:16<07:19,  3.46s/it]合并嵌入:  79%|███████▉  | 476/602 [10:22<08:30,  4.05s/it]合并嵌入:  79%|███████▉  | 477/602 [10:22<06:01,  2.89s/it]合并嵌入:  80%|███████▉  | 480/602 [10:22<02:38,  1.30s/it]合并嵌入:  80%|████████  | 483/602 [10:22<01:28,  1.35it/s]合并嵌入:  81%|████████  | 486/602 [10:22<00:54,  2.13it/s]合并嵌入:  81%|████████  | 488/602 [10:29<02:32,  1.33s/it]合并嵌入:  81%|████████▏ | 490/602 [10:35<03:11,  1.71s/it]合并嵌入:  82%|████████▏ | 493/602 [10:35<01:58,  1.09s/it]合并嵌入:  82%|████████▏ | 496/602 [10:38<01:56,  1.10s/it]合并嵌入:  83%|████████▎ | 497/602 [10:44<03:08,  1.80s/it]合并嵌入:  83%|████████▎ | 498/602 [10:45<02:39,  1.53s/it]合并嵌入:  83%|████████▎ | 499/602 [10:49<03:45,  2.19s/it]合并嵌入:  83%|████████▎ | 500/602 [10:53<04:16,  2.52s/it]合并嵌入:  83%|████████▎ | 501/602 [10:55<03:47,  2.26s/it]合并嵌入:  83%|████████▎ | 502/602 [10:57<04:00,  2.40s/it]合并嵌入:  84%|████████▎ | 503/602 [11:00<03:58,  2.41s/it]合并嵌入:  84%|████████▎ | 504/602 [11:00<02:54,  1.78s/it]合并嵌入:  84%|████████▍ | 506/602 [11:06<03:52,  2.42s/it]合并嵌入:  84%|████████▍ | 508/602 [11:07<02:22,  1.51s/it]合并嵌入:  85%|████████▍ | 511/602 [11:09<01:47,  1.18s/it]合并嵌入:  85%|████████▌ | 513/602 [11:09<01:14,  1.19it/s]合并嵌入:  85%|████████▌ | 514/602 [11:10<01:11,  1.23it/s]合并嵌入:  86%|████████▌ | 515/602 [11:11<01:14,  1.16it/s]合并嵌入:  86%|████████▌ | 516/602 [11:14<01:55,  1.34s/it]合并嵌入:  86%|████████▌ | 517/602 [11:19<03:09,  2.22s/it]合并嵌入:  86%|████████▌ | 518/602 [11:22<03:22,  2.41s/it]合并嵌入:  86%|████████▌ | 519/602 [11:23<02:54,  2.10s/it]合并嵌入:  86%|████████▋ | 520/602 [11:28<03:55,  2.87s/it]合并嵌入:  87%|████████▋ | 523/602 [11:28<01:45,  1.34s/it]合并嵌入:  87%|████████▋ | 525/602 [11:31<01:43,  1.35s/it]合并嵌入:  87%|████████▋ | 526/602 [11:34<02:08,  1.69s/it]合并嵌入:  88%|████████▊ | 527/602 [11:41<03:37,  2.90s/it]合并嵌入:  88%|████████▊ | 528/602 [11:44<03:41,  2.99s/it]合并嵌入:  88%|████████▊ | 529/602 [11:50<04:21,  3.58s/it]合并嵌入:  88%|████████▊ | 531/602 [11:50<02:29,  2.10s/it]合并嵌入:  88%|████████▊ | 532/602 [11:57<03:54,  3.35s/it]合并嵌入:  89%|████████▊ | 533/602 [12:00<03:49,  3.33s/it]合并嵌入:  89%|████████▊ | 534/602 [12:05<04:13,  3.73s/it]合并嵌入:  89%|████████▉ | 536/602 [12:05<02:22,  2.16s/it]合并嵌入:  89%|████████▉ | 538/602 [12:09<02:10,  2.04s/it]合并嵌入:  90%|████████▉ | 539/602 [12:11<02:02,  1.94s/it]合并嵌入:  90%|████████▉ | 540/602 [12:13<02:01,  1.96s/it]合并嵌入:  90%|████████▉ | 541/602 [12:19<03:00,  2.97s/it]合并嵌入:  90%|█████████ | 542/602 [12:24<03:38,  3.65s/it]合并嵌入:  90%|█████████ | 544/602 [12:24<02:02,  2.11s/it]合并嵌入:  91%|█████████ | 546/602 [12:25<01:14,  1.33s/it]合并嵌入:  91%|█████████ | 548/602 [12:25<00:49,  1.09it/s]合并嵌入:  91%|█████████ | 549/602 [12:25<00:40,  1.32it/s]合并嵌入:  91%|█████████▏| 550/602 [12:34<02:15,  2.61s/it]合并嵌入:  92%|█████████▏| 551/602 [12:35<01:57,  2.30s/it]合并嵌入:  92%|█████████▏| 552/602 [12:42<02:46,  3.33s/it]合并嵌入:  92%|█████████▏| 554/602 [12:43<01:44,  2.17s/it]合并嵌入:  92%|█████████▏| 555/602 [12:43<01:22,  1.76s/it]合并嵌入:  92%|█████████▏| 556/602 [12:45<01:24,  1.83s/it]合并嵌入:  93%|█████████▎| 557/602 [12:47<01:23,  1.86s/it]合并嵌入:  93%|█████████▎| 558/602 [12:49<01:16,  1.74s/it]合并嵌入:  93%|█████████▎| 559/602 [12:51<01:18,  1.84s/it]合并嵌入:  93%|█████████▎| 560/602 [12:57<02:14,  3.20s/it]合并嵌入:  93%|█████████▎| 561/602 [13:02<02:33,  3.74s/it]合并嵌入:  94%|█████████▎| 564/602 [13:05<01:24,  2.23s/it]合并嵌入:  94%|█████████▍| 565/602 [13:11<01:47,  2.90s/it]合并嵌入:  94%|█████████▍| 567/602 [13:11<01:04,  1.85s/it]合并嵌入:  95%|█████████▍| 569/602 [13:11<00:41,  1.25s/it]合并嵌入:  95%|█████████▍| 570/602 [13:15<00:58,  1.82s/it]合并嵌入:  95%|█████████▍| 571/602 [13:21<01:24,  2.74s/it]合并嵌入:  95%|█████████▌| 573/602 [13:23<00:55,  1.90s/it]合并嵌入:  95%|█████████▌| 574/602 [13:29<01:19,  2.84s/it]合并嵌入:  96%|█████████▌| 575/602 [13:32<01:20,  2.97s/it]合并嵌入:  96%|█████████▌| 576/602 [13:38<01:32,  3.57s/it]合并嵌入:  96%|█████████▌| 577/602 [13:38<01:06,  2.66s/it]合并嵌入:  96%|█████████▌| 578/602 [13:44<01:26,  3.60s/it]合并嵌入:  96%|█████████▋| 580/602 [13:44<00:45,  2.05s/it]合并嵌入:  97%|█████████▋| 581/602 [13:52<01:12,  3.45s/it]合并嵌入:  97%|█████████▋| 582/602 [13:55<01:08,  3.41s/it]合并嵌入:  97%|█████████▋| 583/602 [13:59<01:06,  3.50s/it]合并嵌入:  97%|█████████▋| 584/602 [14:05<01:15,  4.21s/it]合并嵌入:  97%|█████████▋| 585/602 [14:05<00:52,  3.10s/it]合并嵌入:  97%|█████████▋| 586/602 [14:07<00:42,  2.63s/it]合并嵌入:  98%|█████████▊| 587/602 [14:09<00:37,  2.53s/it]合并嵌入:  98%|█████████▊| 588/602 [14:16<00:54,  3.92s/it]合并嵌入:  98%|█████████▊| 589/602 [14:17<00:40,  3.14s/it]合并嵌入:  98%|█████████▊| 590/602 [14:20<00:33,  2.83s/it]合并嵌入:  98%|█████████▊| 591/602 [14:21<00:25,  2.33s/it]合并嵌入:  98%|█████████▊| 592/602 [14:23<00:21,  2.19s/it]合并嵌入:  99%|█████████▊| 593/602 [14:25<00:21,  2.38s/it]合并嵌入:  99%|█████████▊| 594/602 [14:26<00:14,  1.83s/it]合并嵌入:  99%|█████████▉| 595/602 [14:29<00:16,  2.31s/it]合并嵌入:  99%|█████████▉| 596/602 [14:31<00:12,  2.16s/it]合并嵌入:  99%|█████████▉| 597/602 [14:35<00:13,  2.71s/it]合并嵌入: 100%|█████████▉| 599/602 [14:35<00:04,  1.49s/it]合并嵌入: 100%|██████████| 602/602 [14:35<00:00,  1.46s/it]
开始聚类处理，使用GPU 3
聚类完成，用时： 47711.923458099365
聚类完成，标签已保存至 outputs/COT_all/dedup_eps0.2/all_files_labels_eps0.2.npy
生成去重结果:   0%|          | 0/3048334 [00:00<?, ?it/s]生成去重结果:   2%|▏         | 59912/3048334 [00:00<00:04, 599102.00it/s]生成去重结果:   5%|▌         | 153211/3048334 [00:00<00:03, 795493.57it/s]生成去重结果:   8%|▊         | 250146/3048334 [00:00<00:03, 874867.90it/s]生成去重结果:  12%|█▏        | 351791/3048334 [00:00<00:02, 930755.37it/s]生成去重结果:  15%|█▍        | 453701/3048334 [00:00<00:02, 962607.97it/s]生成去重结果:  18%|█▊        | 556531/3048334 [00:00<00:02, 984937.75it/s]生成去重结果:  21%|██▏       | 655025/3048334 [00:00<00:02, 983877.45it/s]生成去重结果:  25%|██▍       | 753414/3048334 [00:00<00:02, 978293.11it/s]生成去重结果:  28%|██▊       | 856288/3048334 [00:00<00:02, 993987.51it/s]生成去重结果:  31%|███▏      | 955699/3048334 [00:01<00:02, 991699.77it/s]生成去重结果:  35%|███▍      | 1054878/3048334 [00:01<00:02, 918686.33it/s]生成去重结果:  38%|███▊      | 1147779/3048334 [00:01<00:02, 881798.03it/s]生成去重结果:  41%|████      | 1236841/3048334 [00:01<00:02, 875063.29it/s]生成去重结果:  43%|████▎     | 1324931/3048334 [00:01<00:02, 830767.20it/s]生成去重结果:  46%|████▋     | 1411244/3048334 [00:01<00:01, 839773.70it/s]生成去重结果:  49%|████▉     | 1505978/3048334 [00:01<00:01, 870381.63it/s]生成去重结果:  53%|█████▎    | 1603754/3048334 [00:01<00:01, 901414.60it/s]生成去重结果:  56%|█████▌    | 1694416/3048334 [00:01<00:01, 883515.05it/s]生成去重结果:  59%|█████▊    | 1788338/3048334 [00:01<00:01, 899665.26it/s]生成去重结果:  62%|██████▏   | 1884759/3048334 [00:02<00:01, 918568.79it/s]生成去重结果:  65%|██████▍   | 1981409/3048334 [00:02<00:01, 932703.59it/s]生成去重结果:  68%|██████▊   | 2078529/3048334 [00:02<00:01, 944112.10it/s]生成去重结果:  71%|███████▏  | 2174006/3048334 [00:02<00:00, 947276.14it/s]生成去重结果:  74%|███████▍  | 2268856/3048334 [00:02<00:00, 924666.75it/s]生成去重结果:  77%|███████▋  | 2362159/3048334 [00:02<00:00, 927116.58it/s]生成去重结果:  81%|████████  | 2455666/3048334 [00:02<00:00, 929462.82it/s]生成去重结果:  84%|████████▎ | 2551191/3048334 [00:02<00:00, 937112.40it/s]生成去重结果:  87%|████████▋ | 2647535/3048334 [00:02<00:00, 944947.57it/s]生成去重结果:  90%|████████▉ | 2742092/3048334 [00:03<00:00, 883210.42it/s]生成去重结果:  93%|█████████▎| 2831253/3048334 [00:03<00:00, 830040.00it/s]生成去重结果:  96%|█████████▌| 2915325/3048334 [00:03<00:00, 826480.55it/s]生成去重结果:  99%|█████████▊| 3006191/3048334 [00:03<00:00, 849593.28it/s]生成去重结果: 100%|██████████| 3048334/3048334 [00:03<00:00, 901484.64it/s]
